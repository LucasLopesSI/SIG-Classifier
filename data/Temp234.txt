The Cartographic Journal
The World of Mapping

ISSN: 0008-7041 (Print) 1743-2774 (Online) Journal homepage: http://www.tandfonline.com/loi/ycaj20

Experiments to Distribute and Parallelize Map
Generalization Processes

Guillaume Touya, Justin Berli, Imran Lokhat & Nicolas Regnauld

To cite this article: Guillaume Touya, Justin Berli, Imran Lokhat & Nicolas Regnauld (2017)
Experiments to Distribute and Parallelize Map Generalization Processes, The Cartographic Journal,
54:4, 322-332, DOI: 10.1080/00087041.2017.1413787

To link to this article:  https://doi.org/10.1080/00087041.2017.1413787

Published online: 19 Feb 2018.

Submit your article to this journal 

Article views: 28

View related articles 

View Crossmark data

Full Terms & Conditions of access and use can be found at
http://www.tandfonline.com/action/journalInformation?journalCode=ycaj20

The Cartographic Journal
Vol. 54 No. 4
© The British Cartographic Society 2018

pp. 322–332

2017

R E F E R E E D P A P E R

Experiments to Distribute and Parallelize Map Generalization
Processes

Guillaume Touya1

, Justin Berli1, Imran Lokhat1 and Nicolas Regnauld2

1LASTIG, COGIT, IGN, ENSG, University of Paris-Est, Saint-Mande, France. 21Spatial, Cambridge, UK
Email: guillaume.touya@ign.fr

Automatic map generalization requires the use of computationally intensive processes often unable to deal with large datasets. Distributing
the generalization process is the only way to make them scalable and usable in practice. But map generalization is a highly contextual process,
and the surroundings of a generalized map feature needs to be known to generalize the feature, which is a problem as distribution
might partition the dataset and parallelize the processing of each part. This paper proposes experiments to evaluate the past propositions
to distribute map generalization, and to identify the main remaining issues. The past propositions to distribute map generalization are
first discussed, and then the experiment hypotheses and apparatus are described. The experiments confirmed that regular partitioning
was the quickest strategy, but less effective when taking context into account. The geographical partitioning, though less effective for
now, is quite promising regarding the quality of the results as it better integrates the geographical context.

Keywords: generalization, partitioning, parallelization

1.

INTRODUCTION

Similar to a summary of text, map generalization seeks
to abstract and simplify the geographic content of a map to
display it at a smaller scale. Where symbols are enlarged to
ensure their legibility, as a consequence, there is less space
on the map to render map content without overlaps. When
manually carried out, map generalization can be a very long
task for a cartographer, so its automation has been studied
by scholars and practitioners for years (Foerster et al.,
2010). Automatic map generalization processes are computa-
tionally intensive, and usually they are unable to deal with the
size of real region-wide or countrywide geographical data-
sets. In computer science, distributed computing is used to
scale such complex processes by sharing the computation
with multiple computers. Distributed computing often
comes with parallel computing, which means that
the
process is cut into several sub-processes that are computed
simultaneously using different computer cores. Distributing
map generalization processes can help to both reduce the
amount of data processed at once, and to reduce the compu-
tation time by parallelizing the processes. But map generaliz-
ation is a well-known holistic problem (Bundy et al., 1995), as
an automatic system needs to analyse the geographical context
of any feature to decide upon the best operation to apply
(Stoter et al., 2009). For instance, the generalization of build-
ings requires the recognition of implicit structures such as
alignments (Basaraner and Selcuk, 2008). If generalization
is distributed, there is a major risk that quality might be

DOI: 10.1080/00087041.2017.1413787

reduced by hiding some parts of the geographical context.
This problem is illustrated in Figure 1, using the example of
road generalization, which needs some large context to ident-
ify the important roads in an area.

Some first proposals have been made to distribute
generalization processes in the recent years (Chaudhry and
Mackaness, 2010; Briat et al., 2011; Thiemann et al., 2013;
Stanislawski et al., 2015). But there are still no general guide-
lines on how to distribute a generalization process given the
characteristics of the process and the dataset. So, we propose
some experiments to compare existing approaches, in order
to analyse how much they can process large datasets without
affecting the geographical context too much.

The second part of the paper describes the key problems
of distributing generalization processes (partitioning, distri-
buting context, parallelizing and reconciliation) and analyses
the approaches of each problem in the literature. Then, the
third part describes how we conducted our experiments.
The fourth part shows and discusses the results obtained
and the fifth part draws some conclusions and discusses
further work.

2. KEY PROBLEMS TO DISTRIBUTE

GENERALIZATION PROCESSES

2.1. Partitioning
The first step to distribute a generalization process is to par-
tition a large dataset into parts that are small enough to be

Experiments to Distribute and Parallelize Map Generalization Processes

323

Figure 1. To generalize the roads of the centre blue partition without the surrounding context, it is not possible to identify the indicated road as the most
important one without its context. Source: @OpenStreetMap contributors

manageable by the process. Two main approaches exist and
have been tried in the literature: regular partitioning and geo-
graphical partitioning.

Regular partitioning includes two methods, the use of a
regular (often rectangular) grid, or the use of a quad tree.
Regular grids have been used for land-use generalization by
Thiemann et al. (2011), and for most generic processes in
Briat et al. (2011) and Thiemann et al. (2013). The size of
the grid is adjusted based on the amount of data that can
be found in one cell of the grid. The quad tree is a smarter
version of the regular grid with smaller cells used in more
dense areas (Figure 2), and Briat et al. (2011) showed that
it can go faster than a simple regular grid.

An alternative strategy, described in Chaudhry and Macka-
ness (2008), uses a geographical partitioning that would
better capture the necessary geographical context while
cutting data into small parts. A geographical partitioning
can simply use features like administrative boundaries, as
per the US counties in Briat et al. (2011). Chaudhry and
Mackaness (2010) proposed a combination of a regular
grid and a geographical partitioning based on geomorpholo-
gical regions, for DTM generalization. Touya (2010) pro-
posed a geographical partitioning based on main landscapes
(urban, rurban, rural, mountain areas) with consideration
for size (e.g. rural areas are cut by network elements and
spaces without buildings to keep them small enough). Thie-
mann et al. (2013) propose to cluster data based on proxi-
mity (Anders, 2003) to create meaningful partitions.

boundary of a partition cell. The main proposition in the litera-
ture is to provide a buffer area around the partition where data
are added for context, but not generalized by the process that
handles the partition cell (Briat et al., 2011; Thiemann et al.,
2011). One difficulty here is to find the buffer size that gives
enough context without making the partition cell too large
to be processed. Thiemann et al. (2013) propose a classification
of the generalization operations that requires a large context,
and the ones that can be triggered without any regard for the
context. For instance, there is no need to look at the neighbours
to simplify the shape of a building polygon, but network selec-
tion requires a large context (Figure 1).

2.3. Parallelization
Different methods exist to parallelize the processes, even if
the differences are more technical than conceptual. Paralleliz-
ing a process means that several nodes, that is, cells of the par-
tition, are processed in parallel by different computer cores,
that can be in a same machine (Briat et al., 2011), or not,
and even in a machine cluster (Stanislawski et al., 2015).
There are some interesting details to tackle: for instance if
the system allows multiple or single reads or writes on the
dataset, or if some asynchronous mechanisms are used for
adjacent partition cells (Briat et al., 2011).

If the Map/Reduce framework is used for parallelization
(Thiemann et al., 2013), there are also implications for the
way processes are implemented, and reimplementations
might be required.

2.2. Distribution of geographical context
Once a partitioning technique has been chosen, it is necessary
to add a mechanism to restore some kind of geographical
context, at least for the features that are located near the

2.4. Reconciliation
The final issue is the reconciliation of the data processed in
parallel, that is, to decide what to do if a feature has been

324

The Cartographic Journal

Figure 2.
@OpenStreetMap contributors

Illustration of the quad-tree-based partitioning: a cell of the map is divided in four equal cells if there are too many features in the cell. Source:

included in several partition cells. Thiemann et al. (2013) call
this step composition. Briat et al. (2011) use an attribute field
on features that says if it has been processed, and only the first
processed partition is able to write the result on the feature at
the reconciliation step. Thiemann et al. (2011) cut the fea-
tures at the limits of the partition and reconcile by merging
the cut parcels once generalized. However, cutting features
is dangerous (as shown in Chaudhry and Mackaness, 2008)
with the example of the Douglas & Peucker algorithm
(Douglas and Peucker, 1973) that fixes the initial/final ver-
tices of the simplified lines, so more line cuts means more
fixed points and less quality in generalization.

Thiemann et al. (2013) discuss three methods for reconci-
liation: selection (objects on the boundary of partition can be
selected in only one partition cell), cut and merge, and match
and adjust (objects are generalized in parallel and their new
representation is matched and adjusted).

3. DESCRIPTION OF THE EXPERIMENTS

3.1. Hypotheses
Large datasets can cause two problems when generalized: pro-
cesses can be too long and crash because of the large amount of
data to process. The distribution techniques have to find the
balance between computation time, the maximum amount
of data processed at once, and the cartographic quality of the
generalized map. We made four hypotheses about
this
balance between the three objectives of distribution:
. Optimizing computation time or the amount of processed

data does not optimize cartographic quality (H1).

. Regular partitioning is a better choice for non-contextual

. Geographical partitioning is better for contextual pro-

processes (H2).

cesses (H3).

. There is no generic best distribution method; it may
depend on data types and generalization processes (H4).

. Distribution is not really platform dependent (H5).

3.2. Case study
We used a large dataset to experiment with different distri-
bution strategies, extracted from the IGN (the French
national mapping agency) topographic database that con-
tains geographical data with a one-metre geometric resol-
ution. Data from Reunion Island was used as input data in
our experiments. Reunion Island located in the Indian
Ocean has been chosen mainly because of the variety of geo-
graphical features that it presents (dense cities, rural areas,
dense hydrographic network, and so on), on an area large
enough (2512 km2) to cause issues for many non-distributed
processes. We processed buildings, roads, rivers and coast-
lines from this dataset.

The major part of the experiments was conducted using
CartAGen (Renard et al., 2010), which is the module dedi-
cated to generalization in the open-source GeOxygene Java
platform (Bucher et al., 2012). For the sake of simplicity,
we distributed the processes of CartAGen using the Java Par-
allel Processing Framework (JPPF), which only requires
minimum refactoring of the code to distribute Java software.
The cluster used to process the data is composed of five stan-
their computing power being
dard desktop computers,
uneven. Each computer has four cores, so is able to run

Experiments to Distribute and Parallelize Map Generalization Processes

325

four processes in parallel. In order to test (H5), we also
carried out experiments with the commercial platform 1Gen-
eralise from 1Spatial, which uses its own distributed system
based on Oracle Weblogic Server.

For the remainder of the paper, we call a node a unitary
element of the architecture able to run one process. In our
architecture a node is one core of one of the available compu-
ters. We call a job the processing of a partition cell by one node.
For the purpose of the tests, two algorithms were chosen:
the polyline simplification algorithm (Visvalingam and
Whyatt, 1993; Visvalingam and Whelan, 2016) and the
building squaring algorithm currently developed at
the
IGN (Lokhat and Touya, 2016). The simplification algor-
ithm is contextual because it was enhanced to avoid topologi-
cal errors with the other lines of the dataset. A high parameter
value (2000 m2) was chosen for the effective areas of the
polyline simplification algorithm to highlight possible topo-
logical inconsistencies. The squaring algorithm is not contex-
any
tual,
consideration for its neighbours. It will be used to test (H2).

processed without

building

being

each

3.3. Description of the experiments
Each distribution experiment was carried out with three
different configurations of available nodes to distribute the
process:
. A single computer with four nodes (a total of 4 nodes).

. Five computers, with a single node each (a total of 5

nodes).

. Five computers with four nodes each (a total of 20 nodes).

The limitation to three configurations guarantees a small
amount of instances of the experiments, but these particular
configurations offer a different number of nodes, to verify
that more nodes lead to faster processing times. These con-
figurations also allow the comparison between nodes on
the same computer and nodes on different computers for a
similar number of nodes.

3.3.1. Experiments with regular partitions. We first
carried out experiments with the simplest partitioning
method, the rectangular grid. Two types of entities are
treated using this partitioning solution, polylines (streams,
roads and coastlines) and polygons (buildings). Regarding
lines, the regular rectangular grid is implemented following
two processing methods to handle context (Figure 3a and
b): one creating a buffer around each cell to provide a
context for the simplification of polylines; the other cutting
each lines according to the processed cell boundaries.

In the first method, it was decided to use a buffer that
includes each of the eight surrounding cells (Figure 3a).
The lines that intersect the buffer are loaded into memory,
then their centres (located on the line) are calculated. If

Figure 3. Two strategies to handle context in a regular grid partition: (a) a buffer area around each cell; (b) cutting features at the edge of partition cells

326

The Cartographic Journal

that point is inside the cell, the line will be processed, if not, it
will be used as a context for the simplification algorithm in
order to check any potential topology error caused by line
intersections. If the centre point of a line is located on the
boundary of the cell, its identifier is stored and it will be
treated
stage.
However, the error checking is done with the initial version
of the lines, not the simplified ones, so intersections still
might occur with the simplified lines. To avoid this
problem, some asynchronous distribution should be used.

reconciliation

afterwards,

during

the

In the second method (Figure 3b), all the new lines created
during the splitting phase must keep an attribute indicating
the initial line identifier. This allows the reconciliation stage

to recreate initial lines by aggregating all the sections that
have the same attribute.

Processing buildings using the regular grid is the sim-
plest method to set up as the centroid of each entity
it will be processed (Figure 4).
defines in which cell
When a centroid is located on top of a cell’s boundary,
which does happen when processing very large datasets
(a dozen instances in our building dataset), its identifier
is stored and the building is processed at the end, during
the reconciliation stage.

We also carried out experiments with a quad tree regular
partition, as it allows to keep a similar number of features
in each cell, by dividing cells where the feature density is

Figure 4. Regular grid applied to building squaring: the building centroid is used to assign a building to a cell; buildings with the centroid on a partition
edge are assigned to a final reconciliation job

Experiments to Distribute and Parallelize Map Generalization Processes

327

high. But the results highlighted a performance issue in our
implementation of the quad tree, making the quad tree less
effective than the regular grid, which is not consistent with
past research (Briat et al., 2011). Hence, we do not present
results from the quad tree in this paper.

3.3.2. Experiments with geographical partitions. The
geographical partitioning methods use different types of geo-
graphical features to make small regions. In order to test
(H4) that makes the assumption that geographical partition-
ing are adapted to some features types but not to all, it has
been decided to work on three feature types to offer a
variety of results for them to be compared: roads, rivers,
coastlines. As all three types of features are linear, the same
simplification algorithm is applied (Visvalingam–Whyatt).
Three types of geographical partitioning are also tested:
administrative boundaries of cities that is supposed to be
quite neutral for all three feature types, watershed extents
that are supposed to be adapted to river lines, and divisions
based on the road network that are supposed to be adapted
to road lines.

The partitioning according to the administrative bound-
aries and to the watershed extents is achieved following the
same workflow as for the segmentation method. Lines are
loaded, split, processed and reconciled the same way, only
the mask changes,
from a regular grid it becomes a
complex polygon geometry (which will cause some issues
discussed in the last section).

The partitioning according to the road network was per-
formed on the 1Generalise platform (Regnauld 2014). It
uses areas enclosed by road sections to create polygons
which will be used as partitions. All small partitions formed
inside the network are aggregated according to two main par-
ameters: the maximum number of partitions to be merged
and the maximum area allowed for a single partition. This
method produces partitions which have various sizes but a

similar amount of data, producing smaller partitions in
dense urban areas and larger ones in rural areas. This
ensures that the processing time is fairly homogeneous
across the partitions, for a more efficient load balancing
across the grid of processing nodes. Using roads to partition
space is a classical method in generalization, as roads often
delimit the spatial context necessary to generalize features
(Ruas and Plazanet, 1996; Burghardt and Neun, 2006;
Touya 2010; Briat et al., 2011). The processing then
follows the same workflow as the previous method, cutting
every line according to the boundaries of the partitions.
Choosing the roads to be partitioning features also helps to
keep the number of split features down, and therefore
limits the need for adding fixed points which are not ideal
for the quality of the result.

3.4. Operational limitations
To properly understand the results presented in the follow-
ing, it is first mandatory to consider the material limitations
as well as the other issues inherent to the method deployed.
One has to take into consideration the memory limits of
every node which happen when the partitions sent to the
cluster hold too many entities. This phenomenon is observa-
ble when the regular grid used contains a small number of
cells (Figure 5) or when the extent of the geographical
object – such as the administrative areas or the watersheds
– is too large (Figure 8); these can induce the presence of a
large number of lines or buildings to be treated at once by
a node. With more memory on each node, the balance
between speed and cell size could be different.

Another limitation lies in the use of too many partitions,
which can lead to a significant growth in processing time.
Indeed, in that case, the implemented distribution frame-
work faces network congestions leading to failures with
some jobs. This is not a major problem because it would be
avoided by using a real grid architecture, and a more

Figure 5. Results of the experiments with a regular grid for the generalization of rivers using the Visvalingam–Whyatt algorithm

328

The Cartographic Journal

sophisticated distribution framework than JPPF. The JPPF is
a black box that gives minimal control on the parallelization
step. For instance, using the Spark framework, already used
for the analysis of large Lidar point clouds (Brédif et al.,
2015), enables parallel processes that share input or output
datasets, which can be useful
to deal with the spatial
context of a given generalization algorithm. Finally, the hard-
ware differences inside the cluster must be considered, one of
the processor being weaker than the other four, the random-
ness of the node assignation can lead to different results with
the use of the same architecture and the same number of par-
titions. We believe that this is not a standard configuration,
and it may cause biases preventing the comparisons
between two strategies. So to overcome this limitation, we
carried out each experiment several times and picked only
the quickest results, that is, the ones where the weak node
of the grid did not hinder the process too much.

4. RESULTS AND DISCUSSION

This section presents and discusses the results obtained with
regular grids and geographical partitioning in the exper-
iments described above.

4.1. Regular grid
Concerning the results obtained with the regular rectangular
grid, the first thing to notice is the overall lower speed of the
method that cuts every line according to the cells boundaries.
The duration is around two to three times higher when using
the contextual method (Figures 5 and 6). This is due to the
reconciliation step that is not necessary with the contextual
method.

The difference increases along with the number of nodes
used in the cluster. That being mentioned, one must consider
the quality of the data obtained as well. The results (showed

in Figures 5 and 6) show that there is a minimum processing
time around 20 × 20 grids, which corresponds to 2.5 ×
2.5 km2 cells on Reunion Island. We can also see that the
architecture with five computers and four nodes by computer
is the best one as predicted. The fall in the number of gener-
alized features in the case with 200 × 200 cells and a 5 × 4
architecture illustrates the limitations of our framework, the
high number of nodes to manage leading to network conges-
tion and job failures.

The method that splits the lines generates fixed points at
every partition boundary, as extremities are kept in place
during the simplification process. The contextual method
produces data showing no trace of the partitioning stage as
the algorithm considers the whole line while simplifying.
Figure 7 shows that the optimal configuration of nodes and
partitions is similar, but large partitions are preferred as
they minimize the number of cut features. Figure 8 shows
an example where cutting lines leads to a result very different
from the buffer method output: the line is less simplified.
The number of lines to reunite during the reconciliation
stage then constitutes an indicator of the quality of the
obtained data; the more lines needing to be aggregated, the
worse the quality become. This proves that (H1) is true:
the method that optimizes processing time and memory
load does not provide the best cartographic results.

In the case of the building squaring, a non-contextual
algorithm, the use of a regular rectangular grid provides gen-
eralized buildings very quickly, and way more quickly than
the geographic partitioning. This result shows that (H2) is
true, there is no need for geographical partitioning when
the generalization operation is not contextual. However,
that method is quite unstable and sensitive to density differ-
ences: using too many cells gives worse results, but with
fewer cells, the ones with more building density crash
because of the memory load. As shown by Briat et al.
(2011) a quad-tree-based method that makes more cells in
dense areas would be the optimal solution.

Figure 6. Results of the experiments with a regular grid for the generalization of rivers using the Visvalingam–Whyatt algorithm

Experiments to Distribute and Parallelize Map Generalization Processes

329

Figure 7. Results of the experiments with a regular grid for the generalization of roads using the Visvalingam–Whyatt algorithm. The right vertical axis
corresponds to the black line, and gives the number of features after cutting: the more features are cut, the worse the generalization

4.2. Geographical partitioning
First, both the use of administrative boundaries and water-
sheds extent imply a significant limitation. The complexity
of the geometries used to split lines is too important for
the spatial query to be time-efficient. The difference observa-
ble with the use of a similar number of rectangular cells –
which are simple-shaped polygons – is really noticeable and
makes geographical partitioning ineffective
for now.
Another limitation is that the cells of the geographical par-
titions we used were too big compared to the optimal cell
size found with the previous experiments. Further exper-
iments are clearly necessary to overcome these limitations
that prevent us from asserting that (H3) is true, that is, geo-

graphical partitioning is better for contextual generalization
processes.

Nevertheless, our results give us hints on (H3). For
instance, the use of watersheds as masks to split water
streams, could be, if optimized, a way to enhance time-effi-
ciency while preserving the quality of the data. Indeed,
streams only cross watersheds boundaries at one point, the
outlet, and the results have a much better quality (Figure
9). Partitioning the dataset according to zones derived from
the road network allows the same kind of principle as no
road crosses another. The limitation for now lies in the fact
that the whole network needs to be simplified before the cre-
ation of the actual partitions. This can induce some issues,

Figure 8. Differences in the cartographic output for Visvalingam–Whyatt simplification of rivers when using a buffer for context, or when cutting lines

330

The Cartographic Journal

Figure 9. Synthesis of the results for the simplification of lines using geographical partitioning based on watershed extents and administrative limits

particularly if the nodes composing the cluster have limited
cache memory. The results obtained using this method
show that the partitioning does not reflect on the quality of
the simplified roads.

More generally, it might be difficult to assert that (H3) is
true or false for all contextual processes. For instance,
Figure 8 shows that river streams simplification mostly
requires the minimization of intersections between the par-
tition cells and the streams, while building typification does
require a view of the buildings neighbourhoods to identify
and preserve patterns, which cannot be guaranteed by a
regular grid.

These first results also suggest that (H4) might be true: the
best distribution strategy depends on the feature types pro-
cessed, and on the fact that the generalization process itself
is more or less contextual. Apart from the current limitations
we believe that the watershed based partitioning is the best
when processing only rivers with a contextual algorithm
such as simplification but also selection that is often carried
out by watershed analysis (Stanislawski et al., 2015).

The results obtained on the 1Generalise platform (Figure
10) with the road network based partitioning show similar
patterns between the number/size of cells and the processing
time, with slight differences that might be due to differences
in algorithm implementation and in the distribution architec-
ture. One obvious difference lies in the fact that the proces-
sing nodes load the data in a local cache. This slows down
the process, but removes the risk of failure due to lack of
memory if
the node is given a large area to process.
However, we think that the patterns are similar enough to
consider that (H5) is probably true: the platform differences
are not significant compared to the differences due to parti-
tioning and context handle methods.

In addition to the platform comparison, this experiment
with 1Generalise confirms both (H4) and (H5) as the road
partitioning is suitable for buildings and coastlines, but
clearly not for rivers, even when the partition cells are large.

5. CONCLUSIONS AND FUTURE WORK

The use of regular rectangular grid as a partitioning method
seems to be the most time-efficient, whatever the type of
entity treated (polylines or polygons). The contextual
method produces a better simplification, as the partitioning
grid does not interfere with the result. However, it comes
at a cost, as the processing time is higher. Splitting the lines
according to a rectangular grid, even though it represents
the quickest method, creates too many fixed points and
affects the quality of the simplified polylines. The aesthetic
aspect makes this method less interesting than the contextual
one. This is the main reason why this solution will not be
tested further and why the future studies should focus on
contextual strategies.

Concerning the partitioning using administrative or
watershed areas, the idea for a division taking the type
of entity into consideration is interesting and needs to be
investigated further. For now, the main problem impacting
the time-efficiency is the geometry of each zone that can
be very complex, which slows down spatial queries;
perhaps a simplification of watersheds as well as adminis-
trative areas could be a way to solve it. Thereafter, more
tests need to be run to see if this method proves to be
quicker than the contextual one with a minor loss of
quality. More generally, we plan to conduct much more
experiments, with other partitioning and reconciliation

Experiments to Distribute and Parallelize Map Generalization Processes

331

Figure 10. Synthesis of the results with 1Generalise

methods, with generalization processes that require more
than the simplification algorithms, and with
context
more robust distribution architectures.

is

true,

For now, we only carried out experiments with the pro-
cessing of a single algorithm on a single layer of the map,
to
but a more realistic generalization processes needs
handle all the map layers and orchestrate the application
(Regnauld et al.,
of a large number of algorithms
2014). If the assumption that
the optimal distribution
strategy depends on the feature type and the amount of
complete generalization
required context
process would require multiple distribution strategies,
which might not be a feasible solution. In order to step
up, and really make map generalization scalable, we have
to develop global distribution models, as 1Generalise
does, or maybe include the distribution issue into the gen-
eralization orchestration models. Finally, generalization will
have to process big data more and more, which are pro-
vided by tiles (Sester et al., 2014), so the techniques to
distribute generalization processes will surely be used to
deal with this amount of data. The development of

a

vector tiles to render maps on the web (Gaffuri, 2012)
is another example of the future application of distributed
generalization processes, and in both applications,
the
future work described in this
conclusion will be
fundamental.

BIOGRAPHICAL NOTES

a

at
(the

is
the LASTIG,

senior
Guillaume Touya
IGN
researcher
France
French mapping
agency), and head of the COGIT
research team. He holds a PhD and
habilitation in GI science from Paris-
Est University. His research interests
focus on automated cartography,
map generalization and volunteered
geographic information. He currently leads the MapMuxing
(https://mapmuxing.ign.fr) research project on mixing carto-
graphy and human-computer interaction issues.

332

ORCID

Guillaume Touya

http://orcid.org/0000-0001-6113-6903

REFERENCES
Anders, K.-H. (2003). ‘A hierarchical graph clustering approach to find
groups of objects’, in Proceedings of 5th ICA Workshop on Progress
in Automated Map Generalization. Paris, France.

Basaraner, M. and Selcuk, M. (2008). ‘A structure recognition technique
in contextual generalisation of buildings and built-up areas’, The
Cartographic Journal, 45 (4), pp. 274–285.

Brédif, M., Vallet, B. and Ferrand, B. (2015). ‘Distributed dimensional-
ity-based rendering of lidar point clouds’, in International Archives of
Photogrammetry Remote Sensing and Spatial Information Sciences
(GeoBigData). XL-3/W5, Montpellier, France.

Briat, M.-O., Monnot, J.-L., Punt, E. M. (2011). ‘Scalability of contex-
tual generalization processing using partitioning and parallelisation’,
in Proceedings of 14th ICA Workshop on Generalisation and
Multiple Representation. Paris, France.

Bucher, B., Brasebin, M., Buard, E., Grosso, E., Mustière, S. and Perret,
‘GeOxygene: built on top of the expertness of the
J. (2012).
french NMA to host and share advanced GI science research
results’,
in Geospatial Free and Open Source Software in the 21st
Century, ed. by Bocher, E. and Neteler, M., pp. 21–33, Springer,
Berlin Heidelberg.

large-scale cartographic data’,

Bundy, G. L., Jones, C. B. and Furse, E. (1995). ‘Holistic generalization
in GIS and Generalisation:
of
Methodology and Practice, ed. by Müller, J.-C., Lagrange, J.-P. and
Weibel, R., pp. 106–119, Taylor & Francis, London.

Burghardt, D. and Neun, M. (2006). ‘Automated sequencing of general-
isation services based on collaborative filtering’,
in Geographic
Information Science – 4th International Conference GIScience, ed. by
Raubal, M., Miller, H. J., Frank, A. U., Goodchild, M. F. IFGI
prints, pp. 41–46, Münster, Germany.

Chaudhry, O. Z. and Mackaness, W. A. (2008). ‘Partitioning techniques
to make manageable the generalisation of national spatial datasets’, in
ICA Workshop on Generalisation and Multiple Representation.
Montpellier, France.

Chaudhry, O. Z. and Mackaness, W. A. (2010). ‘DTM generalisation:
Handling large volumes of data for Multi-Scale mapping’, The
Cartographic Journal, 47 (4), pp. 360–370.

Douglas, D. H. and Peucker, T. K. (1973). ‘Algorithms for the reduction
of the number of points required to represent a digitized line or its
caricature’, Cartographica: The
for
Geographic Information and Geovisualization, 10 (2), pp. 112–122.
Foerster, T., Stoter, J. and Kraak, M.-J. (2010). ‘Challenges for auto-
mated generalisation at European mapping agencies: A qualitative
and quantitative analysis’, The Cartographic Journal, 47 (1), pp.
41–54.

International

Journal

The Cartographic Journal

Gaffuri, J. (2012). ‘Toward web mapping with vector data’, in Geographic
Information Science, ed. by Xiao, N., Kwan, M.-P., Goodchild, M. and
Shekhar, S., pp. 87–101, Springer, Berlin Heidelberg.

Lokhat, I. and Touya, G. (2016). ‘Enhancing building footprints with
squaring operations’, Journal of Spatial Information Science, 13,
pp. 33–60.

Regnauld, N. (2014). ‘1Generalise: 1Spatial’s new automatic generalis-
in Proceedings of 17th ICA Workshop on

ation platform’,
Generalisation and Multiple Representation. Vienna, Austria.

Regnauld, N., Touya, G., Gould, N. and Foerster, T. (2014). ‘Process
in Abstracting
modelling, web services
Geographic Information in a Data Rich World, ed. by Burghardt, D.,
Duchêne, C. and Mackaness, W., pp. 198–225, Springer, Berlin
Heidelberg.

and geoprocessing’,

Renard, J., Gaffuri, J. and Duchêne, C. (2010). ‘Capitalisation problem
in research – example of a new platform for generalisation:
CartAGen’,
on
of
Generalisation and Multiple Representation. Zurich, Switzerland.
Ruas, A. and Plazanet, C. (1996). ‘Strategies for automated generaliz-
ation’, in 7th International Symposium on Spatial Data Handling.
Delft, Netherlands, pp. 319–336.

ICA Workshop

in Proceedings

11th

Sester, M., Jokar Arsanjani, J., Klammer, R., Burghardt, D. and Haunert,
J.-H. (2014). ‘Integrating and generalising volunteered geographic
information’, in Abstracting Geographic Information in a Data Rich
World, ed. by Burghardt, D., Duchêne, C. and Mackaness, W., pp.
119–155, Springer International Publishing, Cham, Switzerland.
Stanislawski, L. V., Falgout, J. and Buttenfield, B. P. (2015). ‘Automated
extraction of natural drainage density patterns for the conterminous
computing’, The
United States
Cartographic Journal, 52 (2), pp. 185–192.

through High-Performance

Stoter, J., van Smaalen, J., Bakker, N. and Hardy, P. (2009). ‘Specifying
map requirements for automated generalization of topographic data’,
The Cartographic Journal, 46 (3), pp. 214–227.

land cover data’,

Thiemann, F., Warneke, H., Sester, M. and Lipeck, U. (2011). ‘A scalable
in Advancing
approach for generalization of
Geoinformation Science for a Changing World, ed. by Geertman, S.,
Reinhardt, W. and Toppen, F., pp. 399–420, Springer, Berlin, Heidelberg.
(2013).
‘Investigations into partitioning of generalization processes in a dis-
tributed processing framework’,
the 26th
International Cartographic Conference, ed. by Buchroithner, M. F.,
Dresden, Germany.

Thiemann, F., Werder, S., Globig, T. and Sester, M.

in Proceedings of

Touya, G. (2010). ‘Relevant space partitioning for collaborative general-
isation’, in Proceedings of 12th ICA Workshop on Generalisation and
Multiple Representation. Zurich, Switzerland.

Visvalingam, M. and Whelan, J. C. (2016). ‘Implications of weighting
metrics for line generalization with Visvalingam’s algorithm’, The
Cartographic Journal, 53 (3), pp. 253–267.

Visvalingam, M. and Whyatt, J. D. (1993). ‘Line generalisation by
repeated elimination of points’, The Cartographic Journal, 30 (1),
pp. 46–51.

