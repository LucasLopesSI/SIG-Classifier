bs_bs_banner

Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129)): (cid:129)(cid:129)–(cid:129)(cid:129)

Research Article

Towards Usability Engineering for Online
Editors of Volunteered Geographic
Information: A Perspective on
Learnability

Catherine E. Jones
Department of Geography
University of Portsmouth

Patrick Weber
Department of Civil, Environmental
and Geomatic Engineering
University College London

Abstract
This article presents one of the ﬁrst systematic usability investigations for a Vol-
unteered Geographic Information (VGI) editor. This research is motivated by the
fact that although VGI is now widely consumed, contribution rates are lagging
considerably. Compared to traditional GIS interfaces, with complex interfaces
resulting in high cognitive loads and barriers to participation, VGI tools and inter-
faces need to be easy to use and learn to encourage and facilitate contributions.
This article develops a case study of OpenStreetMap, one of the most successful
VGI projects, and its default editor, Potlatch2. Ten participants with no prior
experience of VGI contribution, were instructed to contribute data to OSM in a
structured exercise, while being monitored using an eye tracker and audio/video
screen capture software. Each participant was asked to Think Aloud, i.e. describe
what they were thinking and doing as they completed the tasks. The results high-
light signiﬁcant usability issues impacting learnability, especially from the perspec-
tive of a new contributor: hidden functionality, lack of user feedback between
interactions and the inefﬁcient and inconsistent placement of functionality and
map controls. The facilitation of VGI contributions clearly depends on designing
targeted interfaces, optimized to the needs of speciﬁc levels of contributors with
deﬁned goals and expectations.

Address for correspondence: Dr Catherine E. Jones, Department of Geography, University of
Portsmouth, Portsmouth PO1 3HE, UK. E-mail: kate.jones@port.ac.uk

© 2012 Blackwell Publishing Ltd
doi: 10.1111/j.1467-9671.2012.01319.x

2

C E Jones and P Weber

1 Introduction

1.1 Why Volunteered Geographic Information?

Traditionally Geographic Information (GI) has been expensive and time-consuming to
collect, constrained to the hands of specialists. However, in the last decade, methods and
technologies for acquiring, compiling, printing and sharing GI have changed, resulting in
improved accessibility of GI to a wider range of users. These advances also impacted the
traditional practices for data collection, analysis and presentation of GI (Goodchild
2008, Sui 2008), resulting in the emergence of Volunteered Geographic Information
(VGI), contributed by private individuals. These changes represent new research chal-
lenges in terms of data integrity and validity, social inequalities, privacy, citizens as
sensors, participant democracy and activism (Goodchild 2007, Goodchild and Glennon
2010, Ghose 2003, Zook and Graham 2007). Whilst beyond the scope of this article, an
excellent review of VGI debates can be read in Sarah Elwood’s paper, discussing the
future research directions of VGI from the perspective of critical, participatory and
feminist GIS (Elwood 2008).

VGI growth is part of the Web 2.0’s trend for user-contributed information, and
represents a major new force in geographic data research and practice. Building upon the
popularity of user generated content in Wikipedia or Flickr, VGI harnesses the power of
Internet technology to disseminate and generate new geospatial information. Interactive
online and mobile services enable any member of the public to use and create digital
geographic information as part of a non-specialist ‘voluntary’ collective. Barriers
between expert and non-expert users then become fuzzy and indistinct, with a new class
of engaged contributors to GI, challenging the previously dominant asymmetric power
balance of a few major data contributors, versus many passive consumers. These col-
laborative approaches deﬁne the public as citizen scientists, participating and contribut-
ing to scientiﬁc activities (Cohn 2008, Jonathan 2009, Haklay 2010a).

VGI projects cover diverse application domains including crisis mapping, bird
watching or galaxy classiﬁcation, always driven by dedicated and motivated citizens.
Another example is Ushahidi, an open source platform enabling the crowd-sourcing of
crisis information via text messaging (SMS), e-mail, twitter or the Internet, gathering and
monitoring geo-referenced reports associated with humanitarian crises. Other examples
include OpenStreetMap (OSM) and Google Map Maker, both crowd-source and model
abstractions of the real world by representing features such as buildings and streets in a
spatial database, historically the domain of national mapping agencies.

Anyone with suitable interest, information and motivation is free to contribute to
these citizen-driven projects. The OSM community has a core of dedicated, committed
and enthusiastic participants, who contribute a signiﬁcant proportion of the edits (see
section on OSM). However, they represent a small minority when compared to the larger
proportion of passive consumers of OSM driven websites and mobile applications. It
seems that whilst the outputs of VGI projects are increasingly adopted by a large public,
a ‘chasm’ is observed between VGI contributors and consumers, in part driven by user
issues with the technology. If the lay person is expected to invest their time to contribute
to VGI projects then the tools available need to be easy to use and by corollary easy to
learn.

So far, research into OSM focused on the validity, accuracy and completeness of VGI
user contributions (Zielstra and Zipf 2010, Haklay 2010, Mooney et al. 2010). What has
not been considered so far are barriers for non-expert users to contribute to VGI projects.

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

Towards Usability Engineering for Online Editors of VGI

3

Figure 1 A selection of different interfaces from (clockwise) ArcGIS, GoogleMaps, Geo-
commons and Open Street Map

This research aims to investigate the usability of VGI projects through the case study of
OSM, and one of its most popular editing interfaces, Potlatch2. Such a detailed evalu-
ation of an exemplar VGI contribution interface will also signiﬁcantly contribute to the
understanding of usability issues likely to be encountered in present and future VGI
projects.

1.2 Human Computer Interaction (HCI) Traditions in Geo-technology

Traynor and Williams (1995) identiﬁed the inherent complexities present within con-
ventional desktop Geographical Information Systems (GIS), resulting in a restricted
user base consisting mainly of domain experts with extensive training on how to use
desktop GIS packages. They observed traditional desktop GIS users, who are con-
fronted with a myriad of map interaction possibilities, distracting users from their
primary objective of developing spatial knowledge. Instead, the GIS user is more con-
cerned with focusing on map manipulation (Jones et al. 2009). See Figure 1 for an
example of a traditional desktop GIS and more contemporary designs of online
mapping applications.

Further evidence of signiﬁcant usability issues in GIS come from a growing body of
work in Human Computer Interaction (MacEachren and Kraak 2001, Haklay and
Tobón 2003, Worboys et al. 2004, Cöltekin et al. 2009, Fuhrmann et al. 2005, Sidlar and
Rinner 2009). They justify the notion that the complex user interaction designs of most
desktop GIS result in signiﬁcantly increased cognitive loads for the user. Users are less

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

4

C E Jones and P Weber

able to process information and develop knowledge because intricate interfaces require
much more mental activity than simple ones. In 2001, MacEachren and Kraak stated that
desktop GIS remain arduous to learn and remember, inefﬁcient and idiosyncratic, making
them prone to errors, with unhelpful feedback and error types. To interact successfully
with a desktop GIS, users are required to retain many items in their short-term memory.
This renders the desktop GIS difﬁcult to use and time consuming to learn.

Currently, mainstream desktop GIS software is not user friendly; can the same be
said of today’s Geoweb applications? There are a number of interactive web tools within
the domain of geovisualization, concerned with representation, integration, and spatial
cognition to facilitate user interaction with spatial data (MacEachren 2004, Slocum
1999, Dykes et al. 2005). These web-based geovisualization applications represent sys-
tematic improvements in technical functionality and opened up GI consumption on the
Internet via exploratory analysis, but crucially do not improve user interaction signiﬁ-
cantly. These Geoweb applications still have signiﬁcant interface complexity issues,
affecting the usability of these tools, leading to a rather limited uptake by potential users
(Slocum 1999, Robinson et al. 1995, Robinson et al. 2005, Andrienko & Andrienko
2006). These types of geovisualisation tools are, much like desktop GIS, still targeted at
the skilled and proﬁcient user and again require high cognitive loads for different tasks.
At the same time, there have been recent technical advances resulting in the rise of
web-mapping applications based on the slippy map paradigm (Bing Maps, Google Maps,
etc.), representing a distinct development stream of Geoweb applications. Ever-increasing
numbers of lay users use these mapping portals for access to spatial data and function-
ality, to answer questions such as where the nearest good Italian restaurant is. These
types of mapping applications have entered, with relative ease, the wide consumer space
occupied by non-geographic experts. The provision to third parties of such web-mapping
Application Programming Interfaces (APIs) enabled developers to integrate web-
mapping functionality into numerous web sites and services, resulting in the mass-market
adoption of geospatial data and services. Their success means that web-mapping services
are moving closer to the attainment of almost universal usability – which is even more
astonishing given the exceptionally complex spatial concepts they encapsulate (Shneider-
man and Plaisant 2005, Marsh 2007).

The simplicity of the interactions of mapping applications, such as Bing Maps or
Google Maps, minimizes the number of complex interactions required, reducing a user’s
cognitive load. Users almost instinctively know how to interact with the map, and can
concentrate on the speciﬁc task they set out to achieve. There is a direct relationship
between cognitive load and user performance; the ease in which a user can interact with
a website expedites efﬁcient task performance. The usability of such applications stems
from the design emphasis centred on user needs where a user intuitively starts using it
without prior training.

1.3 OpenStreetMap and Technology Adoption

The rise of Volunteered Geographic Information as a signiﬁcant new paradigm is driven
by: (1) the advent of the aforementioned web-mapping technologies and services,
together with (2) ubiquitous GPS capability in smartphones and personal navigation
devices (PND) and (3) the increasing availability of Internet access leading to improved
possibilities of mass collaboration. One of the most signiﬁcant examples of a VGI project
is OpenStreetMap (OSM), an initiative driven by volunteers, who not only contribute the

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

Towards Usability Engineering for Online Editors of VGI

5

Figure 2 Technology
en.wikipedia.org/wiki/File:Technology-Adoption-Lifecycle.png)

adoption lifecycle

(from WikiMedia Commons; http://

data but also drive the technical design, development and maintenance of the infrastruc-
ture. OSM follows the peer production model of Wikipedia, with the aim of creating a
map database that is free to use, editable and licensed under a liberal copyright scheme
encouraging dissemination and reuse (Haklay and Weber 2008).

OSM has reached a small core user group of highly motivated enthusiasts who act
as technology innovators. In June 2011, there were about 14,000 active contributors
versus a total registered user-base of about 420,000, i.e. only 4% of registered users were
active contributors (see http://wiki.openstreetmap.org/wiki/Stats). User contribution pat-
terns also highlight a further disparity, with just 31 user accounts contributing 50% of
the VGI data (a caveat being that this number includes user accounts that import bulk
datasets). However impressive the growth of OSM has been, in terms of active partici-
pation, it is fair to say that participation rates remain low, a challenge faced by many VGI
projects looking to increase contribution rates.

This trajectory of technology adoption for VGI projects can be aligned with the
model of technology market diffusion and adoption phases (Rogers 1962). Signiﬁcantly,
in 1991 Geoffrey Moore suggested that a step change in adoption, or “Chasm” exists in
Roger’s framework between the Innovators, Early Adopters and the Early Majority (see
Figure 2). This gap signiﬁes a difﬁcult transition from niche technology towards mass
market adoption, and in the context of OSM, represents the difference between the small
number of enthusiastic contributors and those interested enough to register but who do
not go on to make any map edits.

OSM is crossing this ‘chasm’ as a provider of VGI sourced data, most notably
through adoption by mass market value added ‘resellers’ and reuse in web-mapping
applications such as Mapquest, Microsoft, or third party distributors of OSM based
web-map services, such as Cloudmade and Nestoria or Skobbler, a mobile navigation
application. For active participation rates though, the question is whether it is possible to
move from a small number of dedicated, enthusiastic contributors to a larger mass of
active participants.

The challenge for OSM and other VGI projects like it, then, is why mass-market
contributions have not increased at the same pace as the consumption of the VGI data.
One more recent statistic highlighting this participation gap is that of all users registering
an OSM account, only 35% go on to make at least one edit to the database. Given that

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

6

C E Jones and P Weber

no account is required to consume OSM data or services, the only motivation for
registration should be the desire to contribute data, yet users somehow lose interest or
give up before making or saving an edit.

Nielsen (2003), a leader in the usability analysis of websites, states that if a website
is difﬁcult to use people leave it. Is this the case of the editing process and interface in
OSM? The results in this article represent the ﬁrst step, a qualitative analysis based on the
observations of 10 participants, with data collected through eye tracking and screen
video/audio recording, as well as pre- and post-test questionnaires to explore their
individual experiences and interactions of editing OSM for the ﬁrst time using the
Potlatch2 editing tool. Potlatch2 is the default OpenStreetMap editor which most users
encounter when they ﬁrst click on the ‘Edit’ tab on the website. Written in Adobe Flash,
it enables users to edit OpenStreetMap inside their browser. Potlatch2 is only one of
several OSM editing interfaces, but was chosen for this study given that it is the default
editing interface for OSM, and is aimed at both novice contributors and experienced
contributors, creating interesting usability conﬂicts which will be discussed in this article.

2 Experiment Methodology for Exploring User Interactions with

VGI Interface

A number of usability evaluation methods have been applied to geo-technology including
usability testing, heuristic evaluation, cognitive or pluralistic walkthroughs and predic-
tive models (Nielsen 2004, Haklay and Zaﬁri 2008, Skarlatidou 2010, Rogers et al.
2007). Various usability engineering techniques have been used to evaluate mapping
applications including: (1) observation studies of users (Davies and Medyckyj-Scott
1996, Traynor and Williams 1995); (2) screen shot studies (Haklay and Zaﬁri 2008); (3)
Video recording of end-user input (Robinson et al. 2005, Jones et al. 2009); (4) Eye
movement analysis of user interactions (Çöltekin et al. 2009). These approaches repre-
sent best practice for geospatial usability research, and act as a development guide for the
methodology used, combining participant observation, eye tracking, participant’s Think
Aloud comments, screen video and audio capture to explore contributors’ interactions.
We are concerned with understanding the user experience from the perspective of a
new/novice user, and chose the Think Aloud method (Voudouris and Marsh 2008, Marsh
et al. 2006, Neilsen et al. 2002), where participants express and describe their actions,
thinking, doing, and feeling, as they progress through the experiment. This method
allows the capture of actual user experiences, in opposition to Cognitive Walkthroughs,
where the usability expert may not behave as the average user.

The experiment comprised 11 tasks, expected to take around an hour to complete
and was designed following an initial discussion with one of the Potlatch2 developers
(Figure 3). This dialogue revealed key tasks new users undertake and enabled us to
identify common activities. The task complexity built up sequentially, starting with the
sign-up process, and encompassed the three different vector objects a new user would
add/edit: points, lines and polygons (areas). A task sheet guided the users, including maps
of the areas of interest, without explaining the use of Potlatch2. (see Figure 3). Before
starting the experiment, participants were made aware that they could drop out of the
experiment at any time and could move on from any task at their choosing, without a
time limit. Each participant signed a consent form and completed a general IT question-
naire to gauge computer literacy and GIS experience.

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

Towards Usability Engineering for Online Editors of VGI

7

Figure 3 Flow diagram of tasks, and example step to show how tasks were designed.
Users were given a description of what edit to complete and a map of the local area with
the object to be edited highlighted

The OSM team provided access to their development server, providing a consistent
and controlled test-bed. This ensured all experiment participants made their edits on the
exact same data and application environment. The only differences would arise from
their interactions with the editing interface. A non-intrusive eye tracker captured users’
interest interface elements as their eyes ﬁxated upon them (Bruneau et al. 2002), see
Figure 4. This method of eye tracking records the path of where the user is looking (gaze
plots), the location of where they look (eye ﬁxations), and how much time they spend
viewing different elements (ﬁxation, and durations).

The gaze tracks were recorded on top of a screen recording of the user’s interaction
with the website (showing mouse movements and clicks). Each participant ﬁlled out a
post-experiment questionnaire, on topics such as their sense of satisfaction with the
editing process, and how easy they found it to use.

2.1 Participant Characteristics

The 10 participants (N = 10) were recruited via a call circulated on Facebook, Twitter
and e-mail lists, the only pre-requisite being that they had absolutely no prior experience
of editing OSM. A total of four females and six males aged between from 25 to 50 agreed
to take part. This selection of participants does not match the typical OSM contributor,

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

8

C E Jones and P Weber

Figure 4 Examples of different
(http://www.tobii.com)

types of eye trackers

(from Tobii Studio;

who is male aged between 19 and 35 (observation at: SOTM EU 2011). We asked
participants to classify their experience with desktop GIS: Novice beginner (less than 1
year’s experience), – three participants; Intermediate (1 to 3 years’ experience) – three
participants; Expert (more than 3 years’ experience) – four participants. All participants
had heard of OSM and GoogleMaps but only four participants had heard of Google
MapMaker (none of whom had any editing experience with it).

3 Analysis of Results

This article presents a qualitative analysis of the usability evaluation and focuses upon
issues related to learnability. Usability is “(t)he extent to which a product can be used by
speciﬁed users to achieve speciﬁed goals with effectiveness, efﬁciency, and satisfaction in
a speciﬁed context of use” (Nielsen 2003). Especially in VGI, the systems and interface
design and functionality need to be accessible to experts and non-experts. It is then
essential that interfaces conform to usability principles to maximize contributions. The

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

Towards Usability Engineering for Online Editors of VGI

9

usability of systems is commonly evaluated through ﬁve concepts deﬁned by Nielsen
(2003):

1. Learnability – ability of users to understand the purpose of interactive tools and learn

how to use them, how easy is it for users to accomplish basic tasks;

2. Memorability – ability of users to retain the acquired skills and utilize the tools after

a time lapse – how easy is it to re-establish proﬁciency;

3. Satisfaction – whether people like to use the tools and are not afraid of them;
4. Efﬁciency – once users have learned a design, how quickly can they perform tasks;
5. Accuracy – how many errors do users make, how severe are the errors and how can

they recover from the errors.

3.1 Evaluating Learnability

Learnability is one of the main tenants of usability, yet there tends to be discussion
around how it should be appraised (Grossman et al. 2009). The most common deﬁnition
of learnability goes back to 1980 and suggests that “the system should be easy to learn
by the class of users for whom it is intended” (Michelsen et al. 1980). Learnability, then,
equates to the ability of users to understand the purpose of a tool and how quickly and
efﬁciently they can learn how to accomplish basic tasks. This in line with Shneiderman’s
deﬁnition that “it is the time it takes a member of the community to learn how to use the
basic commands relevant to a set of tasks” (Shneiderman 2003).

3.1.1 Task durations and completion rates

The average durations for each task across the 10 participants, regardless of whether they
completed the task successfully or not, represents the average time spent on each task;
one would expect the later tasks to take longer as they increase in complexity. On
average, it took participants 03:12 minutes to sign up and register for OSM (Task 1) but
observation of the users revealed that many users tried to log in without realising they
needed to wait for the required activation e-mail.

A common metric in usability evaluation is the success rate of a task, “the percentage
of users that completed a task correctly” (Nielsen 2003, Skarlatidou 2010). Each par-
ticipant was given a score of 1 for a completed task, 0.5 for a partially completed task,
and 0 for an incomplete task. The overall success rate was 75% with the 95% conﬁdence
interval of the success rate falling between 0.65 and 0.81. Three tasks appeared particu-
larly problematic with completion rates of 50% or less:

• Task 3 – Adding a road, naming it and setting it as one way (a partial completion was

awarded if the road failed to connect to other roads)

• Task 8 – Editing the outline of a complex building footprint
• Task 11 – Connecting a road at both ends where there is an overshoot and an

undershoot.

Users struggled the ﬁrst time they encountered the task of creating a road. Only one
user successfully completed the task, all others failed to connect the road they drew.
This is a fundamental task for most, if not all OMS edits. Users appeared surprised
and confused. They were unaware roads were created by simply clicking on the map
in the edit view:

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

10

C E Jones and P Weber

“. . . [I] was not aware it was going to start drawing when I clicked on the
map . . . A bit of trial and error there to get the road to draw” [P06: 10:00], and

“... I can’t quite work out how to make a road.” [P07 09:05].

The interface did not work as they expected: users searched the interface for
something to click on before they drew the road. They were expecting to activate
functionality and were surprised when this was not the case. It was not obvious to the
user that the moment they select the edit map tab from the interface, that objects were
editable or could be created immediately. The interface worked in a way that was
unexpected. This issue of unexpected behaviour also impacted the editing of existing
objects, and led to considerable user frustration. Only half of all participants managed to
edit an existing building to match the footprint from the underlying aerial photograph
(task 8, completing the “Cruciform” university building). At their own choosing, three
users returned to the task at the end of the experiment, their frustration was evident:

“... let’s go back to the Cruciform, my nemesis!. . . . OK so I give up!” [P06
50:07].

Confounding the issue was an absence of a visible user interface element to edit and
add nodes to an existing building footprint. The user was required to add new nodes to
the outline and then drag them to form the correct shape. Users either: (1) dragged
existing nodes of the geometry over resulting in an erroneous footprint; or (2) created a
separate footprint for the missing building wing. Relevant keyboard shortcuts for adding
nodes to an existing feature exist, but none of the participants discovered them. The
functionality was hidden and unexpected.

These complications point towards discoverability issues regarding key functional-
ities in the system (also discussed in the following section). Simple, usable interfaces
require that certain functionality is hidden. This is part of the design process known as
progressive disclosure – interfaces are optimised to hide infrequently used features whilst
ensuring visibility for functions that are. In this instance, hiding the functionality as
keyboard shortcuts, only discoverable in the help, hindered the success of this particular
task. This increases the cognitive load for the user, increasing the effort required to
complete the task because they struggled with the interface. A balance is required
between the drive for less is more, and consideration for how this impacts learnability,
particularly since Potlatch2 is the default editor for OSM beginners.

3.2 Locating Functionality

Observing how users struggled to edit a building revealed an important aspect of
learnability, how users locate key functionality within the interface. Lazar et al. (2006)
found that users lose up to 40% of their time due to frustrating experiences with missing,
hard to ﬁnd, and unusable software features. For online VGI editing interfaces, effective
placement of map controls is essential for users to be able to interact with the map, locate
areas of interest and identify the appropriate scale required for accurate editing.

3.2.1 Looking for the zoom

The most common user interaction (UI) elements on a map, for both desktop GIS or
web-based APIs, are pan and zoom. Although usability best practice suggests consistency
in their placement and size, there are no web standards for the placement, design and

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

Towards Usability Engineering for Online Editors of VGI

11

functionality of common map interaction elements (Harrower and Sheesley 2005). To
explore this in Potlacth2, each time a user looked for the map controls, a code was
created in the video analysis software (Interact), marking length of time spent looking for
the control.

We observed two types of behaviours amongst participants looking to zoom: (1)
participants with desktop GIS experience instinctively used the mouse-scrolling wheel;
while (2) participants without a GIS background looked for speciﬁc UI elements to
activate zoom, relying on previous experience of the OSM View mode. The heat plots
(see Figure 5) for two participants searching for the zoom functionality highlights areas
where the participants’ eyes ﬁxated most often during their search. The hotspot in the
centre of the map window represents users reading the help for guidance.

Users had trouble locating the zoom bar because: (1) in the edit mode, the zoom
elements are in the top-right corner of the map window, in opposition to the view
window zoom elements, i.e. the top left of the map window (as evidenced by the top-left
hot spot in the gaze heat map); (2) not only is the position not consistent, but the discreet
+ - symbols (which again are not consistent with expected interface elements from the
view window) are drowned out by the noise of a cartographically busy map, especially
in densely mapped urban areas such as Central London. A comment by one participant
summarises this inconsistency quite clearly:

“... not sure if I am missing the obvious Zoom and Pan functions . . . Aaaghhh
there they are, small and hidden” [P10, 31:40].

The participant is blaming himself for his inability to locate the zoom functionality
in the edit window. Self-blame is a common response of users in usability experiments,
especially if they consider the task to be relatively straightforward. They are unaware
that this is a ﬂaw of the interface design (Norman 1998). It would be relatively simple to
be consistent in both look and placement of the zoom and pan controls in both view and
edit mode.

3.2.2 Using pan and selecting objects

Most web-mapping interfaces and desktop GIS traditionally implement map panning
functionality by clicking on a location on the map and dragging the map. This is the same
in Potlatch2, where panning is initiated by clicking and dragging the mouse on the map.
Unfortunately, if the ﬁrst mouse dragging action happens to start above an existing
object, instead the object will be selected and moved by the user. This happened regularly,
with many users unintentionally selecting objects and dragging them across the map.
Some users noticed, others did not. Given the density of mapped features in Central
London, this selection versus pan issue became very apparent, as expressed by partici-
pants when trying to pan to a new area:

“. . . there is a lot of clutter there. . . .” [P03 11:44].

“Even though I know this area, this visualization is making it difﬁcult for me to
ﬁnd things” [P06 30:28]

“Oh my gosh, it’s hard to know where to click so you don’t impact what is there
already!” [P08 37:50].

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

12

C E Jones and P Weber

w
o
d
n
W

i

t
i
d
E
M
S
O

i

)
b
(
d
n
a
w
o
d
n
W
w
e
i
V
M
S
O

)
a
(

e
h
t
n

i

y
t
i
l
a
n
o
i
t
c
n
u
f

m
o
o
z

e
h
t

r
o
f

g
n
i
k
o
o

l

s
t
n
a
p
i
c
i
t
r
a
p
o
w

t

f
o
p
a
m

t
a
e
h
e
z
a
G

5
e
r
u
g
i
F

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

Towards Usability Engineering for Online Editors of VGI

13

Figure 6 Example screenshot of participant inadvertently moving an existing map
object (a pathway) (in yellow) while trying to pan

In Figure 6, the user clicks on the map – does not realize this action selected a map
object and exclaims: “Wooow, wooow, wooow!” expressing surprise at the unexpected
interactions, the user then selects undo [P03: 12:06]. This user, a desktop GIS expert did
not understand why the object moved, as in a matter of seconds they repeated the exact
same error. The user failed to learn how they mistakenly moved objects. The issue of
panning and moving objects is succinctly summarized by participant 6,

“Ooops I just moved the anatomy building, did not mean to do that!” [P06:
31:42].

This type of unintended human error emerged because of the similarity between
functions of: (1) selecting objects; and (2) panning. To pan in a dense area you need to
click on a map where there are no exiting map objects but as expressed by one
participant:

“. . . soon there will be so many objects in the map I won’t be able to ﬁnd an
area that I can use to pan” [P06: conversation post experiment].

This error could be resolved by adding a visible pan map control so users can pan
without the danger of selection and a select/deselect button so users can only select an
object when consciously aware. Although this would increase the number of mouse clicks
needed to complete an edit, it would reduce the likelihood of unnoticed errors and
corruptions to the existing data.

Given the aforementioned statistic that only about 35% of all registered users go on to
make at least one upload to OSM, we were also interested in the usability of the save

3.2.3 Save functionality

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

14

C E Jones and P Weber

Figure 7 Looking for save button gaze heat map of 4 participants

functionality. Did users instinctively know how to save their edits? Potlatch2 does not
automatically save edits, and part of our experiment design was to determine if users
saved their edits automatically or required prompting (which occurred half-way through
the experiment). Saving equates to uploading data edits to the main OSM database. We
observed three issues our participants encountered with this process.

Location of the save button: Participants had difﬁculty ﬁnding the save button: This
could be due to conventions set-up for example by Microsoft Ofﬁce where the save
functionality is normally placed at the top-left corner of the UI. In Potlatch2 the save
button is located in the top-right corner. This presumption was also apparent in the eye
tracking heat map in Figure 7 and user comments:

“Am I supposed to click somewhere to save this. Ummm it should have a save
right. . . . ! Aghh top right . . .” [P03: began searching at 10:51 found it at 11:03
seconds]

“. . . [I was] not expecting it to be in top right-hand corner . . . I suppose” [P06
27:14]

Repeatedly, participants ﬁxated on the top left corner or the bottom right to locate
the save button and generally scanned in an anti-clockwise direction ﬁxating on the most
obvious and visible elements on the map/page.

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

Towards Usability Engineering for Online Editors of VGI

15

Figure 8 Timeline of when users clicked save function

Exiting edit mode without saving: There was a knock-on effect for users who had
difﬁculty zooming and panning. As an alternative for moving/zooming the map, they
resorted to switching back to the View mode to navigate to the next task location, and
then switch back to the Edit window. If they had unsaved changes, a modal message box
would appear before exiting the Edit map mode, giving the participant two options: OK
to continue to the View mode, or Cancel to remain in the editor and save their changes.
The participants generally clicked OK without reading the message text or stated that,
“they had not made that many edits” [P03 21:50] so they selected OK regardless and
thus lost all of their edits.

In usability engineering the OK/Cancel order represents natural reading order, while
Cancel/OK improves the information ﬂow as the action ends with its conclusion. From
this perspective the order of the buttons is inconsequential but an improvement would be
to set the default button to the outcome where no edits are lost, i.e. Cancel and highlight
the button. Users rely upon defaults as guidance and a default would guide a novice user
to the expected response.

Users did not save frequently: One user did not save any edits at all and only three
users saved edits 11 times (at the end of every task, see Figure 8). On average, partici-
pants saved edits six times. It is thus not a given that users will always remember to save
edits, and provisions for this should be made in the software.

4 Discussion: towards Usability Engineering for VGI to Improve Learnability

The results presented in this article are indicative of initial user behaviours, expectations
and interaction patters which impact learnability and other tenants of usability. In
usability engineering best practice principles, ‘heuristics’, have been developed by experts
to diagnose and evaluate user issues, most notably: (1) Nielsen’s usability heuristics
(1994); and (2) Shneiderman’s eight golden rules of interface design (Shneiderman 1986).
The following section extends these heuristics to VGI interfaces, such as Potlatch2,
creating a classiﬁcation of learnability issues for VGI. This classiﬁcation marks a useful
synthesis of learnability issues and some tentative remarks towards their improvement.

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

16

C E Jones and P Weber

Figure 9 Different conceptualizations and terminologies used in VGI editors and
desktop GIS

1. Provide visibility and feedback of VGI edits status

In a useable system, users are informed about actions, via appropriate feedback within a
reasonable time frame. In general, Potlatch2 did not provide feedback for all actions to
users. For example, there was no clear system status indication for when users could start
editing, causing confusion and users looking for an explicit ‘start edit’ button. Further
confusion arose due to lack of feedback on how to transit from one edit to another. There
was no explicit action for ﬁnishing the addition or edit of a feature, leaving users unsure
if their edits were complete. The lack of explicit feedback improves efﬁciency for
experienced users by reducing visual and interaction noise (i.e. messages and clicks), but
at the expense of new learners who require feedback and reassurance that a given task is
completed. A conscious trade-off thus needs to be reached in VGI editors on the level of
explicit user feedback, depending on the target audience and their experience level, from
novice to expert.

2. Match languages of VGL objects attributes to the real world, and embed meaning for

the users

It is important to match the language used by the interface to the language of the users,
not the technical developers! For example, Figure 9 shows the different desktop GIS and
VGI system terminologies for representing objects such as locations, roads and buildings.
Whilst there is no absolute consistency across the different systems, the terminology
points, lines and polygons are most commonly used. In Potlatch2, users were particularly
frustrated by the OSM terminology of a “closed way” or a “tag” which had little sense,
clarity or meaning relevant to user.

3. Ensure clarity and consistency of editing process for different map objects

System learnability depends on the consistency of editing processes (Figure 10). Cre-
ating a point, line (way) or polygon (closed way) in Potlatch2 lacks consistency. For
example, to draw a point, the user ﬁrst selects an attribute (tag) icon, which is dragged
onto the map, before adding extra attributes. When to draw a line (way), users
expected a method similar to learned process for adding points, and attempted to pick

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

Towards Usability Engineering for Online Editors of VGI

17

Figure 10 Conceptual editing process of objects using Google MapMaker and OSM

and drag an attribute icon, which failed (for lines,
the user ﬁrst draws the
geometry, then selects attributes), and ﬁnally, to draw a polygon (closed way), users
need to draw a line that closes on itself, before selecting attributes. It took participants
longer to add a road than to add a Point of Interest to OSM, not only because a road
is a more complex object to draw than a point, but also because of the aforementioned
confusing conceptual differences. In contrast, adding features in Google Mapmaker is
more consistent: select feature to edit or create, deﬁne attribute, draw object, add
extended attributes, click save. This mechanism is similar to the editing process imple-
mented in a desktop GIS system and is a consistent process for any created map
objects.

4. Present editing options for speciﬁc objects only

The inconsistencies between adding points versus lines were exacerbated by the fact that
the icons/symbols (tags), which only apply to point creation, are also present when users
are trying to create a line, adding to the confusion. Ease of learning can be improved by
only presenting options for one object at a time, making the user aware of the type of
object to be created.

5. Have consistent and standardized map controls and clear interaction element for

both editing and viewing different windows

Section 3.2 discussed the inconsistent placement of map interaction elements (pan
and zoom) between view and edit modes, as well as the suboptimal placement of the
search and save UI elements. Clearly, common UI elements design and placement
should take into account established practice, real world user expectations and internal
consistency.

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

18

C E Jones and P Weber

6. Minimize editing errors by preventing similar interaction actions for different VGI

edits

We observed a number of errors that occurred as users were learning to use the system.
These resulted because of the close similarity in interaction actions. For example, moving
objects when panning arose because of the similarity between select and pan actions
(Section 3.2).

7. Understand editing task from a user’s perspective and their behaviour and ensure

interface visibility of common editing interactions

Users need to be able to recognize commonly used editing options on the interface and
not have to rely on their memory recall. A balance between progressive disclosure,
interface buttons and keyboard accelerators needs to be implemented for frequently used
editing actions. Keyboard shortcuts are effective accelerators for experienced users, but
their functionality needs to be accessible through UI elements for novice users, which was
not always the case in Potlatch2.

8. Enable users to escape easily from editing errors

Linked quite closely to the point above are accidental errors when the system does not
behave as users expect. Often users unintentionally selected an object, and wondered
how to deselect the object with no clear exit path provided by the interface. This issue led
to users moving on and forgetting about selected objects, attempting to create different
objects and in the process corrupting the selected object instead. The provision of a
select/deselect button would be an improvement to minimize editing errors. Google
Mapmaker has explicit UI elements for selection of elements, as well as a cancel button
to exit an edit without affecting changes.

9. Provide obvious and visible links to editing tutorials, videos and help from the

editing interface

The experiments focused on ﬁrst-time contributors to OSM, including the user registra-
tion process. Although the activation e-mail contains introductory videos with editing
tutorials, none of the participants watched them, and instead proceeded straight to the
editing window. Although Potlatch2 has an integrated text-based help ﬁle, most users did
not make extensive use of this resource. Other help resources such as the OSM Wiki and
Documentation are not made obvious to new users, and there is confusion between the
Help Centre (user driven question and answers forum), and Documentation (the OSM
Wiki Site). For example, to ﬁnd out how to add certain features and attributes, the
relevant Wiki Documentation page is hidden under a myriad of links on different wiki
pages (Documentation → Map Making → Map Features). More attention could be
drawn to the excellent introductory tutorial videos for ﬁrst time users of Potlatch by
embedding them into the interface for ﬁrst time users.

This list of commonly observed editing heuristics represents best practice guidance
towards improving the learnability of VGI interfaces based on the qualitative observa-
tions of 10 novice participants. The selection of 10 was driven by research in the user
interaction literature. There are many debates around the question of how many users
are required for testing and no clear consensus has emerged (Hwang and Salvendy 2010).
In general terms the number of recommended users range from ﬁve (Nielsen and Land-
auer 2003), 10–20 (Faulkner 2003), 11 (Law and Hvannberg 2004), 10 +/-2 (Hwang

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

Towards Usability Engineering for Online Editors of VGI

19

and Salvendy 2010), justifying 10 participants as an ample sample, with diminishing
returns for discovering supplemental issues.

5 Conclusions and Future Work

This article’s methodology combined different data sources, including audio and video
streams and user gaze recording, to facilitate the capture of a rich data stream giving
insights into user interactions and learning processes involved in VGI data contributions.
The ﬁndings are not only valid in the context of OSM, but allow conclusions to be drawn
on generic barriers to good usability in VGI editing interfaces, speciﬁcally focusing on
learnability. These include the limitations of hidden functionality, lack of user feedback
between interactions and tasks and the inefﬁcient/inconsistent location of existing func-
tionality and map controls. Some of the interface issues are relatively straightforward to
improve, for example the location and style of user interface elements.

Other issues touched upon here require more effort, and whilst this research high-
lights problems, quick and easy solutions to these issues are not always possible. Some
issues are intrinsically linked to the OSM data-model: the lack of a polygon object class
in the OSM data model presents not only conceptual data modelling ambiguities, but
also interface and cartography challenges. Such architectural, conceptual and structural
considerations, then, clearly are also important in other VGI projects.

Perhaps one of the most signiﬁcant factors inﬂuencing learnability is the impact the
system has on the users’ mental model. The mental model we build in our head of a
system, based on our perceptions and experience of the system, can positively or nega-
tively inﬂuence usability. For this particular editor the inconsistency of actions required
for editing a point, line or area was confusing. The start-middle-end process of adding a
point was different from a line or area. Therefore the mental model of the interface the
user built up for adding a point was not applicable to other tasks. This mismatch between
mental model and interface model increased the cognitive load for the user, decreased
their effectiveness and increased the number of errors ensuring it was more complex to
learn.

From the perspective of a practical contribution to the OSM project, this article
presents the beginning of a dialogue with the Potlatch developers, in the spirit of
continued usability evaluation and scientiﬁc rigor to explore the impact and effectiveness
changes may have on a new user’s experiences with OSM. With respect to crossing the
technology “Chasm”, Potlatch2 provides the user with complex functionality to edit data
at speed, with the trade-off that it is more difﬁcult to use, i.e. a higher cognitive load for
new users. It could be argued that Potlatch2 tries to address too broad a spectrum of
contributors, from the complete novice through to intermediate to expert users, which
have potentially conﬂicting expectations from the editing process and interface. There is
then a very valid question of whether a general-purpose VGI editor can efﬁciently satisfy
the needs of all contributors or, instead, separate specialized tools and interfaces designed
for different levels of contributors would be a more adequate approach.

In terms of scientiﬁc development, this work represents one of the ﬁrst contributions
to a growing body of research investigating the usability of VGI and its editing tools. The
knowledge gained from this work will be inﬂuential in the embedment of good usability
engineering practice in the design, development and evaluation of future web-based GI
and VGI systems, positively affecting VGI contribution rates. The results presented in this

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

20

C E Jones and P Weber

article are just the ﬁrst observations related to learnability of VGI contribution interfaces,
and the data collected still contains the potential for further development of research
results, including further usability components apart from learnability. Finally, we aim to
compare the results obtained for Potlatch with other OSM editors, as well as other more
traditional GIS type interfaces and expand this research to other VGI projects, and
interaction mediums.

Acknowledgements

We would like to thank Professor Angela Sasse and Charlene Jennet from University
College London who gave us permission and support to use the Eye Tracking Equipment.
Thanks also goes to the JISC-funded G3 project (http://jiscg3.blogspot.com/) at Univer-
sity College London and the University of Portsmouth. The results of this analysis are
informing the development of the e-learning environment http://www.IIGLU.com/.

References

Andrienko N and Andrienko G 2006 Exploratory Analysis of Spatial and Temporal Data: A

Systematic Approach. Basel, Switzerland, Birkhäuser

Bruneau D, Sasse A, and McCarthy J 2002 The eyes never lie: The use of eye tracking data in HCI
research. In Proceedings of the International Conference on Human Factors in Computing
Systems (CHI ’02), Minneapolis, Minnesota

Cohn J P 2008 Citizen science: Can volunteers do real research? BioScience 58: 192–97
Çöltekin A, Heil B, Garlandini S, and Fabrikant S I 2009 Evaluating the effectiveness of interactive
map interface designs: A case study integrating usability metrics with eye-movement analysis.
Cartography and Geographic Information Science 36: 5–17

Davies C and Medyckyj-Scott D 1996 GIS users observed. International Journal of Geographical

Information Systems 10: 363–84

Dykes J, MacEachren A M, and Kraak M J 2005 Exploring Geovisualization. Oxford, Elsevier
Elwood S 2008 Volunteered geographic information: Future research directions motivated by

critical, participatory, and feminist GIS. GeoJournal 72: 173–83

Faulkner L 2003 Beyond the ﬁve-user assumption: Beneﬁts of increased sample sizes in usability

testing. Behavior Research Methods, Instruments, and Computers 35: 379–83

Fuhrmann S, Ahonen-Rainio P, Edsall R, Fabrikant S, Koua E, Tobon C, Ware C, and Wilson S
2005 Making useful and useable geovisualization: Design and evaluation issues. In Dykes J,
MacEachren A M, and Kraak M J (eds) Exploring Geovisualization. Oxford, Elsevier: 553–66
Ghose R 2003 Investigating community participation, spatial knowledge production and GIS use in

inner city revitalization. Journal of Urban Technology 10: 39–60

Goodchild M F 2007 Citizens as sensors: The world of volunteered geography. GeoJournal 69:

211–21

Goodchild M F 2008 Commentary: Whither VGI? GeoJournal 72: 239–44
Goodchild M F and Glennon J A 2010 Crowdsourcing geographic information for disaster

response: A research frontier. International Journal of Digital Earth 3: 231–41

Grossman T, Fitzmaurice G, and Attar R 2009 A survey of software learnability: Metrics, meth-
odologies, and guidelines. In Proceedings of the Twenty-seventh International Conference on
Human Factors in Computing Systems (CHI ’09), Boston, Massachusetts: 649–58

Haklay M 2010a Geographical Citizen Science: Clash of Cultures and New Opportunities. WWW

document, http://discovery.ucl.ac.uk/150398/

Haklay M 2010b How good is volunteered geographical information? A comparative study of
OpenStreetMap and Ordnance Survey datasets. Environment and Planning B 37: 682–
703

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

Towards Usability Engineering for Online Editors of VGI

21

Haklay M and Tobón C 2003 Usability evaluation and PPGIS: Towards a user-centred design

approach. International Journal of Geographical Information Science 17: 577–92

Haklay M and Weber P 2008 OpenStreetMap: User-generated street maps. IEEE Pervasive Com-

Haklay M and Zaﬁri A 2008 Usability engineering for GIS: Learning from a screenshot. Carto-

puting 7(4): 12–18

graphic Journal 45: 87–97

Harrower M and Sheesley B 2005 Designing better map interfaces: A framework for panning and

zooming. Transactions in GIS 9: 77–89

Hwang W and Salvendy G 2010 Number of people required for usability evaluation: The 10+/-2

rule. Communications for the ACM 53(5): 130–33

Jonathan S 2009 A new dawn for citizen science. Trends in Ecology and Evolution 24: 467–71
Jones C E, Haklay M, Grifﬁths S, and Vaughan L 2009 A less-is-more approach to geovisualization:
Enhancing knowledge construction across multidisciplinary teams. International Journal of
Geographical Information Science 23: 1077–93

Law E L-C and Hvannberg E T 2004 Analysis of combinatorial user effect in international usability
tests. In Proceedings of the International Conference on Human Factors in Computing systems
(CHI ’04), New York, New York: 9–16

Lazar J, Jones A, Hackley M, and Shneiderman B 2006 Severity and impact of computer user
frustration: A comparison of student and workplace users. Interacting with Computers 18:
187–207

MacEachren A M 2004 How Maps Work: Representation, Visualization, and Design. New York,

Guilford Press

MacEachren A M and Kraak M J 2001 Research challenges in geovisualization. Cartography and

Geographic Information Science 28: 3–12

Marsh S L 2007 Using and Evaluating HCI Techniques in Geovisualization: Applying Standard and
Adapted Methods in Research and Education. WWW document, http://citeseerx.ist.psu.edu/
viewdoc/summary

Marsh S L, Dykes J, and Attilakou F 2006 Evaluating a geovisualization prototype with
two approaches: Remote instructional vs. face-to-face exploratory. In Proceedings of the
Tenth International Conference on Information Visualisation (IV ’06), London, England:
310–15

Michelsen C D, Dominick W D, and Urban J E 1980 A methodology for the objective evaluation
of the user/system interfaces of the MADAM system using software engineering principles. In
Proceedings of the Eighteenth ACM Southeast Regional Conference (ACM-SE 18), Tallahas-
see, Florida: 103–09

Mooney P, Corcoran P, and Winstanley A C 2010 Towards quality metrics for OpenStreetMap. In
Proceedings of the Eighteenth SIGSPATIAL International Conference on Advances in Geo-
graphic Information Systems (ACM GIS ’10), San Jose, California: 514–17

Moore G A 1991 Crossing the Chasm. New York, Harper Collins
Nielsen J 1994 Heuristic evaluation. In Nielsen J and Mack R L (eds) Usability Inspection Methods.

Nielsen J 2003 Usability 101: Introduction to Usability. WWW document, http://www.useit.com/

New York, John Wiley and Sons: 25–62

alertbox/20030825.html

Nielsen J 2004 Designing Web Usability. Munich, Pearson Deutschland GmbH
Nielsen J and Landauer T 2003 Why you only need to test with ﬁve users. Alertbox: Current Issues
in Web Usability (bi-weekly newsletter; available at http://www.useit.com/alertbox/
2000319.html)

Nielsen J, Clemmensen T, and Yssing C 2002 Getting access to what goes on in people’s heads?:
Reﬂections on the think-aloud technique. In Proceedings of the Second Nordic Conference on
Human-Computer Interaction (NordiCHI ’02), Aarhus, Denmark: 101–10

Norman D 1998 The Design of Everyday Things. New York, Basic Books
Robinson A C, Chen J, Lengerich E J, Meyer H G, and MacEachren A M 2005 Combining usability
techniques to design geovisualization tools for epidemiology. Cartography and Geographic
Information Science 32: 243–55

Robinson A H, Morrison J L, and Muehrcke P C 1995 Elements of Cartography. New York, John

Wiley and Sons

Rogers E M 1962 Diffusion of Innovations. Glencoe, IL, Free Press

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

22

C E Jones and P Weber

Rogers Y, Preece J, and Sharp 2007 Interaction Design: Beyond Human-Computer Interaction.

Chichester, John Wiley and Sons

Shneiderman B 1986 Eight Golden Rules of

Interface Design. WWW document, http://

faculty.washington.edu/jtenenbg/courses/360/f04/sessions/schneidermanGoldenRules.html
Shneiderman B 2003 Promoting universal usability with multi-layer interface design. ACM

SIGCAPH Computers and the Physically Handicapped 76: 1–8

Shneiderman B and Plaisant C 2005 Designing the User Interface (Fourth Edition). Upper Saddle

River, NJ, Pearson Addison Wesley

Sidlar C L and Rinner C 2009 Utility assessment of a map-based online geo-collaboration tool.

Journal of Environmental Management 90: 2020–26

Skarlatidou A 2010 Web-mapping applications and HCI considerations for their design. In Haklay
M (ed) Interacting with Geospatial Technologies Interacting with Geospatial Technologies.
Chichester, John Wiley and Sons: 245–64

Slocum T A 1999 Thematic Cartography and Visualization. Upper Saddle Creek, NJ, Prentice Hall
Sui D 2008 The wikiﬁcation of GIS and its consequences: Or Angelina Jolie’s new tattoo and the

future of GIS. Computers, Environment and Urban Systems 32: 1–5

Traynor C and Williams M G 1995 Why are geographic information systems hard to use? In
Proceedings of the International Conference on Human Factors in Computing Systems (CHI
’95), Denver, Colorado: 288–89

Voudouris V and Marsh S 2008 Geovisualisation and GIS: A human centered approach. In Ferri F
(ed) Visual Languages for Interactive Computing: Deﬁnitions and Formalizations. London,
Idea Group

Worboys M, Duckham M, and Kulik L 2004 Commonsense notions of proximity and direction in

environmental space. Spatial Cognition and Computation 4: 285–312

Zielstra D and Zipf A 2010 Quantitative studies on the data quality of OpenStreetMap in
Germany. In Proceedings of the Sixth International Conference on Geographic Information
Science (GIScience 2010), Zurich, Switzerland

Zook M and Graham M 2007 Mapping DigiPlace: Geocoded Internet data and the representation

of place. Environment and Planning B 34: 466–82

© 2012 Blackwell Publishing Ltd
Transactions in GIS, 2012, (cid:129)(cid:129)((cid:129)(cid:129))

