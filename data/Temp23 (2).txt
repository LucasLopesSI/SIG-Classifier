Geoinformatica
DOI 10.1007/s10707-017-0300-7

Humaine: a ubiquitous smartphone-based user heading
estimation for mobile computing systems

Nesma Mohssen1 · Rana Momtaz1 · Heba Aly2 ·
Moustafa Youssef1,3

Received: 1 March 2016 / Revised: 24 January 2017 / Accepted: 27 March 2017
© Springer Science+Business Media New York 2017

Abstract Recently, there have been a wide range of mobile computing and crowd-sourcing
applications that leverage the proliferating sensing capabilities of smartphones. Many of
these place a paramount importance on accurate user heading estimation. Such applications
include dead-reckoning-based localization and many crowd-sensing applications where the
user typically carry her phone in arbitrary positions and orientations relative to her body
and her transportation mode. However, there is no general solution available to estimate the
user’s heading as current state-of-the-art focus on improving the phone orientation estima-
tion, require the phone to be placed in a particular position, require a fixed transportation
mode, require user intervention, and/or do not work accurately indoors. In this paper we
present Humaine, a novel ubiquitous system that reliably and accurately estimates the user
orientation relative to the Earth coordinate system. Humaine works accurately whether the
user is riding a vehicle or walking indoors/outdoors for arbitrary cell phone positions and
orientations relative to the user body. Moreover, it requires no prior-configuration nor user
intervention. The system intelligently fuses the different inertial sensors widely available

(cid:2) Moustafa Youssef

moustafa.youssef@ejust.edu.eg

Nesma Mohssen
nesma.mohssen.k@alexu.edu.eg

Rana Momtaz
rana.momtaz@alexu.edu.eg

Heba Aly
heba@cs.umd.edu

1

Computer and Systems Engineering Department, Faculty of Engineering, Alexandria University,
Alexandria, Egypt

2 Department of Computer Science, University of Maryland, College Park, MD, USA

3 Wireless Research Center, E-JUST, New Borg El Arab, Egypt

Geoinformatica

in off-the-shelf smartphones and employs statistical analysis techniques to their measure-
ments to estimate the user orientation. Implementation of the system on different Android
devices with 300 experiments performed at different indoor and outdoor testbeds shows
that Humaine significantly outperforms the state-of-the-art in diverse scenarios, achieving
a median accuracy of 14◦ and 16◦ for indoor and outdoor pedestrian users and 20◦ for in-
vehicle users over a wide variety of phone positions. This is better than the-state-of-the-art
by 523% and 594% for indoor and outdoor pedestrian users and 750% for in-vehicle users.
This accuracy highlights the ubiquity of Humaine and its robustness against the various
noise sources.

Keywords User heading direction · Bearing · Inertial sensors integration ·
Dead-reckoning · Orientation

1 Introduction

1Recent advances in ubiquitous computing highlighted the importance of user direction
estimation for various ubiquitous and mobile computing applications such as localization
[7–10, 14, 15, 41], activity recognition [45], virtual reality, among others [3, 6, 12, 37].
Today’s smart-phones are equipped with a number of sensors; e.g. accelerometer, magne-
tometer, and gyroscope; that can be used to estimate the phone’s orientation relative to
the earth’s magnetic North. However, users carry cell phones in arbitrary positions and
orientations that are typically disoriented with respect to the user (Fig. 1). Thus, depend-
ing on the phone’s orientation, rather than the user orientation, can lead to huge errors in
many applications. For example, in the popular pedestrian and in-vehicle dead-reckoning
localization techniques, e.g. [14, 43], the user displacement obtained from the inertial
sensors is combined with the movement direction to estimate the next user location. Erro-
neous direction estimation, based on the returned phone orientation from the OS API,
will result in a large error in localization that accumulates quickly with time. This is
especially true for the growing field of mobile applications that cannot assume a certain
placement or orientation of the phone, e.g. in hand or in pocket, such as crowd-sensing
applications.

To overcome these problems and obtain the actual user direction, a number of systems
have been proposed [11, 22–25, 29, 30, 36, 38, 42]. For example, [11, 25, 29, 38, 42] depend
on special external sensors attached to a fixed position (e.g. the user’s leg or placed in her
pants pocket) to detect her orientation. Other systems, e.g. [22–24, 30, 36], use the inertial
sensors in standard cell phones to estimate the user direction. However, these solutions
assume a fixed transportation mode for the user and either work only in specific phone
positions (e.g. pants pocket), are limited to outdoor environments where the phone sensors
are not affected by the indoor magnetic noise [22, 23], or require special user actions (e.g.
[30]), thus limiting their ubiquitous usability.

In this paper, we present Humaine: a system capable of accurately estimating the user
orientation in different environments at arbitrary phone positions and orientations without
user intervention or assumption about her transportation mode. Humaine starts by fusing the

1An earlier version of this paper appeared in the proceedings of the 11th International Conference on Mobile
and Ubiquitous Systems: Computing, Networking and Services 2014 (MobiQuitous’14).

Geoinformatica

Fig. 1 The Different coordinate
systems: The phone coordinate
system (X, Y, Z) is misaligned
from the human coordinate
system (F, S, −G), which in
turn is misaligned with the world
coordinate system (N, E, −G).
The user plane of motion is the
(F, S) plane, which is the plane
perpendicular to gravity

Y

X

Z

E

S

F

N

different phone inertial sensors to obtain the phone orientation in the user horizontal plane
of motion. To estimate the actual user heading, Humaine takes advantage of the observation
that the direction of motion is the direction that has the maximum acceleration variance.
Therefore, it applies the principal component analysis (PCA) on the linear acceleration read-
ings in the user horizontal plane of motion to obtain the final user heading. In addition, it
further applies different preprocessing and post-processing steps to reduce the noise effect
and remove the inherent ambiguity in the direction estimation. For the various phone posi-
tions spanning from in-pants pocket to in-shirt pocket and even when in-bag, Humaine’s
preprocessed acceleration signal is sensitive to the body movement and could capture its
moving direction.

Evaluation of Humaine on different Android devices with 300 experiments (covering
typical homes, a college library, office rooms, garden, college campus, different wide and
narrow streets, among others) shows that it can estimate the user direction with a median
error of 14◦ and 16◦ for indoor and outdoor pedestrian users and 20◦ for in-vehicle users
over a wide variety of phone positions. This is better than the-state-of-the-art by 523% and
594% for indoor and outdoor pedestrian users and 750% for in-vehicle users. This accuracy
highlights the true ubiquity of Humaine.

In summary, our main contributions are four-fold:

– We present the architecture of Humaine: a system to detect accurate user orientation
using standard smartphones at arbitrary positions and orientations for in-vehicle and
pedestrian users in both indoor and outdoor environments.

– We provide the details of our novel smartphone-based heading estimation algorithm
that includes employing PCA with a number of optimizations based on sensors fusion
as well as a technique for resolving the 180◦ ambiguity problem, to achieve a high
accuracy ubiquitously using the commodity off-the-shelf smartphones’ noisy sensors.
– We implement our system on Android-based mobile devices and evaluate its perfor-

mance as compared to state-of-the-art systems.

Geoinformatica

– We provide a thorough study on the effect of different phone positions (in hand, in
pants pocket, in bag and in shirt pocket), phone orientations relative to the user body,
transportation modes (in-vehicle and walking), and the indoor/outdoor effect on the
different user direction estimation techniques.

The rest of the paper is organized as follows: In Section 2, we cover related heading esti-
mation techniques. Section 3 gives the details of the Humaine system. We provide the
implementation and evaluation of the system in Section 4 and discuss different aspects of
the system in Section 5. Finally, Section 6 concludes the paper and gives directions for
future work.

2 Related work

Smartphone-based applications such as vehicular/pedestrian dead-reckoning based localiza-
tion [1, 14, 43] require knowledge of the user’s actual heading direction. Yet, for simplicity,
they assume a fixed-position for the phone and that it is oriented with the user. This lim-
its their practicality and suitability for ubiquitous deployment. Typically, these applications
either depend on the standard cell phone API that uses the magnetometer; depend on other
phone sensors, e.g. the camera [39, 40], to obtain more accurate results; or add more simpli-
fying assumptions to limit the problem and improve the accuracy for these specific usages,
e.g. [1] where they assume multiple users holding the phone in the same (slowly varying
over time) orientation to fuse their heading estimates and reduce the phone heading errors
significantly. However, even with zero error in phone direction estimation, using phone-
heading estimates can lead to huge errors in case the phone is not aligned with the user
direction. Through this section, we discuss the different techniques for heading direction
estimation that have been proposed in literature for pedestrian and in-vehicle users.

2.1 Techniques based on location estimation

Frequent logging of user location, e.g. using GPS [21], can provide accurate user direc-
tion. In this case, the direction is estimated as the direction of the line joining the last two
estimated locations. However, this depends on the availability and the accuracy of the local-
ization system. For example, since the GPS accuracy is low in urban areas [16], the direction
estimation is not accurate. In addition, it completely fails in indoor environments and has
significant latency and energy-consumption as we quantify in Section 4.

2.2 Techniques that use special sensors

Researchers installed/attached various special sensors with high-sensitivity (e.g. wear-
able cameras and/or fixed-position MEMS sensors) to provide accurate user heading
estimation [11, 26–29, 38, 39, 42].

In [27, 29, 38], a special acceleration sensor, the MTx motion sensor [29] is used to
obtain the motion axis that is parallel to the walking movement direction, but it fails to deter-
mine the forward direction itself, leading to a “180◦ ambiguity problem”. [29] addressed
the 180◦ ambiguity problem using integration of the acceleration signal in the global frame,
which does not yield a robust estimate [38].

To detect the forward direction, [38] leverages the rotational motion of the sensor before
foot impact. However, using the foot impact to solve the 180◦ ambiguity leads to a problem

Geoinformatica

when applying the technique indoors as we show in Section 4 and limits the algorithm
to pedestrian users. Note that while [29, 38] show the possibility of using PCA to iden-
tify the user direction, their approach is limited to highly-accurate special sensors, a fixed
phone position, works outdoors only, suffers from the 180◦ problem, and/or supports fixed
transportation mode (walking only).

In [27], authors used inertial sensors, a wearable camera, and an inertial head tracker
to determine the user’s walking forward direction by testing whether the slope of vertical
acceleration at the peak of forward acceleration is increasing. This algorithm requires sen-
sors to be attached to the torso for correct detection of the acceleration patterns, limiting
its applicability for different positions. In addition, using a wearable camera imposes fur-
ther limitations in terms of privacy concerns and the applicability of the technique and the
environment (e.g. lighting).

In [25], authors employ a fixed-position inertial navigation system (INS) inside a car to
estimate the car attitude for dead-reckoning its location. Integrating INS-based localization
with GPS is common in vehicular systems for better localization. However, installing a
special sensor in a vehicle limits the ubiquity of the approach and has a higher cost when
compared to the ubiquitous smart-phone solutions.

Different from all these techniques, Humaine provides a robust and accurate heading
estimation indoors and outdoors using inertial sensors available on commodity smartphones
(which usually have lower quality compared to the special sensors used in these techniques)
with no restrictions on the phone’s position or the user’s transportation mode.

2.3 Techniques based on cell phone sensors

Recently, researchers have focused on using standard cell phones’ sensors to detect the user
heading direction [13]. In [30], the system assumes that the user is walking, initially the
cell phone is in the pants pocket, and the heading offset is known. It leverages the peri-
odicity of the leg movement during walking to identify a point during each step where the
relative orientation of the phone to the user’s body is the same as in the initial standing
state. The system uses a particle filter to mitigate the magnetic field noise effect. However,
this particle filter requires a map of the building, which may not be ubiquitously available
especially for crowd-sensing applications. Similarly, in [34] to provide indoor localization,
authors leverage the periodicity of the leg movement during the walking cycle to iden-
tify her direction. However, instead of the known heading offset assumption, the system
assumes that the phone gets aligned with the walking direction at certain moments, e.g.
to check the map; and applies PCA to determine the offset if the phone is in pocket. To
solve the 180◦ problem, the system relies on the user’s step pattern features to determine
her direction. Nevertheless, assuming that the phone is aligned with the user walking direc-
tion while in hand, calling, or navigating; leads to high errors as shown in our evaluation
(Section 4). To improve the heading estimates, the system employs a particle filter that
requires the building’s floorplan as an input. In [17], authors employ a similar approach to
identify the user’s heading direction assuming the phone is in pants pocket. The system is
also limited to pedestrian users since it addresses the 180◦ problem using user’s step pattern
features.

The uDirect

[22, 23] and the WalkCompass [36] systems employ a similar technique
to estimate the walking heading direction; they identify a point during the user’s walking
cycle where the device orientation is close to the device orientation in the standing mode.
These systems, however, require a model for the acceleration pattern within a step for each
phone position which is not straightforward to derive for the different phone placements.

Geoinformatica

Moreover, the acceleration pattern for some positions may not be clear enough to identify a
suitable point, e.g. inside a bag [36]. Furthermore, the magnetic field noise, which affects the
oriented/rotated acceleration pattern used in heading estimation, degrades uDirect accuracy
indoors as we quantify in Section 4.

2.4 Summary

Table 1 summarizes the differences between Humaine and the most relevant state-of-the-art.
The current state-of-the-art either require special external sensors, work in a specific phone
position (e.g. in pants pocket) or orientation (e.g. oriented phone with the user), require user
intervention, limited to a certain transportation mode and/or work only outdoors.

Humaine, on the other hand, depends only on available inertial sensors in standard smart-
phones. It is applicable indoors and outdoors for arbitrary phone positions and orientations
without any intervention from the user or restrictions on her transportation mode.

3 The humaine system

In this section, we provide the details of the different components of the system; covering the
sensor readings preprocessing, the acceleration transformation to the user’s plane, detection
of the user’s motion axis, and finally detection of the user’s orientation relative to North.
We start by defining the coordinate systems used in the paper, followed by an overview of
the system architecture, and finally the details of each module.

3.1 Coordinate systems

Figure 1 shows the different coordinate systems used in the paper. The world coordinate
system (N, E, −G) is defined by North (N ), East (E), and the Earth gravity (−G). We refer
to the phone local coordinate system as (X, Y, Z). The user plane of motion is perpendicular
to gravity (−G) and we are interested in the user forward direction (F ). Therefore, the user
coordinate system is defined as (F, S, −G) where S points toward the right side of the
user’s forward direction (F ). Table 2 summarizes all symbols used in this section.

3.2 System overview

Figure 2 shows the system architecture. The system detects the orientation, relative to North,
of a user that carries a cell phone with her in an arbitrary position using the available cell
phone’s inertial sensors.

The Sensor Fusion Module fuses the different inertial sensors to obtain the linear
acceleration, the phone azimuth direction, and the phone rotation angles relative to the
world.

The Preprocessing Module filters the linear acceleration readings to reduce the noise

based on the user’s context (her transportation mode).

The User Direction Estimation Module transforms the linear acceleration readings to the
user plane of motion and estimates the user motion axis as the direction with the maximum
variance. Finally, the Ambiguity Resolution Module disambiguates the final user’s heading
direction along the motion axis.

Geoinformatica

e
n
i
a
m
u
H

.
l
a

t
e
n
a
i
Q

v
a
N
e

s
s
a
p
m
o
C
k
l
a

W

.
l
a

t
e

i

L
n
a
F

t
c
e
r
i

D
u

.
l
a

t
e

f
f
o
h
n
i
e
t
S

.
l
a

t
e

e
z
n
u
K

,
]
0
3
[

.
l
a

t
e

i

L

n
a
F

,
]
3
2

,
2
2
[

t
c
e
r
i

D
u

,
]
8
3
[

.
l
a

t
e

f
f
o
h
n
i
e
t
S

,
]
9
2
[

.
l
a

t
e

e
z
n
u
K

:
s
e
u
q
i
n
h
c
e
t

n
o
i
t
c
e
t
e
d

n
o
i
t
a
t
n
e
i
r
o

r
e
s
u

t
n
a
v
e
l
e
r

t
s
o
m
e
h
t

h
t
i

w
e
n
i
a
m
u
H

f
o

n
o
s
i
r
a
p
m
o
C

1

e
l
b
a
T

]
4
3
[

.
l
a

t
e
n
a
i
Q
d
n
a

]
4
2
[
v
a
N
e

,
]
6
3
[

s
s
a
p
m
o
C
k
l
a

W

e
n
o
N

n
a
l
p
r
o
o
l
f

.
l
i
a
v
A

n
o
i
t
i
s
o
p
c
i
f
i
c
e
p
S

n
o
i
t
i
s
o
p
c
i
f
i
c
e
p
S

-
r
o
o
l
f

.
l
i
a
v
A

d
n
a
H
n
i

d
r
a
o
b
h
s
a
d

d
n
a
H
n
i

d
n
a
H
n
i

d
n
a

e
r
e
h
w
y
n
A

d
n
a

t
e
k
c
o
P

s
t
n
a
P

d
n
a

t
a
e
s
-
n
o

d
n
a

t
e
k
c
o
P

s
t
n
a
P

t
e
k
c
o
P

s
t
n
a
P

t
e
k
c
o
P
s
t
n
a
P

t
e
k
c
o
P
s
t
n
a
P

t
e
k
c
o
P
s
t
n
a
P

t
n
e
m
e
c
a
l
p

e
n
o
h
p
/
r
o
s
n
e
S

s
e
Y

s
e
Y

s
e
Y

s
e
Y

s
e
Y

s
e
Y

o
N

o
N

s
e
n
o
h
p
-
l
l
e
C
d
r
a
d
n
a
t
S

c
i
f
i
c
e
p
S

n
o
i
t
i
s
o
p

c
i
f
i
c
e
p
S

n
o
i
t
i
s
o
p

g
n
i
v
o
m

r
e
s
U

d
n
a

d
r
a
w
r
o
f

g
n
i
g
n
a
h
c

t
o
n

n
o
i
t
c
e
r
i
d

s
n
o
i
t
p
m
u
s
s
A

s
r
o
o
d
n
I
d
n
a

s
r
o
o
d
t
u
O

y
l
n
o

s
r
o
o
d
n
I

y
l
n
o

s
r
o
o
d
t
u
o

s
r
o
o
d
t
u
O

y
l
n
o

s
r
o
o
d
n
I

y
l
n
o

s
r
o
o
d
t
u
O

y
l
n
o

s
r
o
o
d
t
u
O

y
l
n
o

s
r
o
o
d
t
u
O

d
e
b
t
s
e
t

n
o
i
t
a
u
l
a
v
E

e
l
c
i
h
e
v
-
n
I
d
n
a

g
n
i
k
l
a
W

y
l
n
o

g
n
i
k
l
a

W

y
l
n
o
e
l
c
i
h
e
v
-
n
I

y
l
n
o

g
n
i
k
l
a

W

y
l
n
o

g
n
i
k
l
a

W

y
l
n
o

g
n
i
k
l
a

W

y
l
n
o

g
n
i
k
l
a

W

y
l
n
o

g
n
i
k
l
a

W

e
d
o
M
n
o
i
t
a
t
r
o
p
s
n
a
r
T

s
r
o
o
d
n
I

d
n
a

g
e
l

o
t

n
w
o
n
k

,
n
a
l
p

,
.
d
a
e
h

e
l
b
a
t
s

e
n
o
h
p

.
t
i
n
i

.
v
o
m

.
l
e
r

Geoinformatica

Table 2 Summary of the symbols used

Symbol

Description

N, E, −G
F, S, −G

X, Y, Z

The world axes (Fig. 1): N points to North, E points to East, and −G is opposite to gravity.
The axes of the user coordinate system (Fig. 1): F points in the forward user motion direction,
S points toward the side, and −G is opposite to gravity.
The axes of the phone coordinate system (Fig. 6): X points towards the phone side, Y points
toward the phone head, and Z is perpendicular to phone screen.

α

β

γ
θu
RA(b)
g
at
(cid:6)
(cid:6)u
ψ

Gm
M

δ

ω

The phone pitch angle (Fig. 6).

The phone roll angle (Fig. 6).

The phone yaw angle relative to North (phone azimuth, Fig. 6).

The user orientation angle relative to North.

Rotation matrix of angle b around axis A.
The Earth’s gravity acceleration (9.80665m/s2).
Total acceleration affecting the phone in the phone coord. system (Fig. 4).

Linear acceleration in the phone coordinate system (Fig. 4).
((cid:6)F , (cid:6)S ), the linear acceleration in the user coordinate system.
The dip angle of the magnetic field measured downwards from the horizontal plane [31] for a
perfectly oriented phone, i.e. pointing to North.
[gx , gy , gz]t , gravity acceleration components in the phone coordinate system (Fig. 4).
[mx , my , mz]t , the measured magnetic field in the phone coordinate system.
Noise filter smoothing factor.

PCA window size.

3.3 Sensor fusion

The system collects raw sensor information from inertial sensors available in the cell phone.
In particular, we collect the 3D acceleration, the 3D magnetic field from the magnetometer,
and the relative rotation angle from the gyroscope. Sensor fusion is an important step to
reduce noise and estimate the quantities of interest. Figure 3 shows an overview of our
sensor fusion module.

3.3.1 Gravity acceleration estimation

The accelerometer measurements consist of two components: the gravity and the lin-
ear acceleration applied to the phone due to the gravity force and the phone’s motion

Humaine

User Direction Estimation

-G

Y

S

F

X

Z

Transformed linear acc. (

)

Motion axis

Transformation
to user plane

Principal comp.
detection

180o
Ambiguity
Resolution

F

n
o
i
s
u
F
r
o
s
n
e
S

Transp.
Mode Det.

Mobile
Azimuth

(

)

Linear acc. ( )

i

g
n
s
s
e
o
r
p
e
r
P

Mobile Pitch
and Roll Angles

(

)

Z

= -G

N

Y

X

E

)
u

(
n
o
i
t
c
e
r
i

D

r
e
s
U

Fig. 2 Humaine system architecture — The system takes the raw sensor readings from the user’s cell phone
and gives the user’s direction relative to North

Geoinformatica

Gyro.

No

Track with gyro
(Section 3.3.1)

|at|~=g

,

Save

Tracked(

)

Ref.(

)

s
e
y

Yes

Calc. Pitch & Roll
(Section 3.3.2)

Acc.(at)

Mag. (M)

Corr. Compass
& gyro
(Section 3.3.1)

compass

Calc. Yaw
(Section 3.3.2)

M

at

.

c
c
A
r
a
e
n
L

i

.

l

c
a
C

)
2
.
3
.
3

n
o
i
t
c
e
S

(

Fig. 3 Sensor fusion: The inertial sensors are combined to obtain an accurate phone orientation in the
presence of sensors noise and drift

respectively (Fig. 4). Since, we are only interested in the device’s acceleration due to motion,
we need to remove the gravity component. To do so, Humaine opportunistically uses the
instances when the linear acceleration is approximately zero; i.e. the phone’s acceleration
is solely resultant from its gravity acceleration and its magnitude would be almost equals
the gravity reference (g = 9.80665m/s2). The intuition is that, at these instances, there are
no other forces applied to the phone. Otherwise, Humaine uses the gyroscope to track the
gravity vector angles as it moves due to the user movement (Fig. 3). Note that there may be
cases where the acceleration magnitude equals g while there are other forces that affect the
phone in addition to gravity. We believe this happens with a low probability and does not
affect our system significantly. This is quantified in Section 4.

The gravity vector is then factored out to obtain the linear acceleration in the phone
coordinate system as described below in Section 3.3.2. Note that using static periods to help
in estimating the orientation/attitude from acceleration measurements was used earlier for
accurate device orientation estimation with special sensors [33, 35]. Humaine on the other
hand, leverages the human walking cycle periodic static periods to estimate the user heading
direction using the noisy smartphone sensors.

To accurately track the gravity vector and obtain accurate orientation, we eliminate the
gyroscope sensor drift, i.e. accumulation of error with time, by fusing it with the compass
readings—which has long term stability but suffers from short term magnetic noise. We
depend on the the correlation between the compass and the gyroscope readings to determine
the points in time when the compass reading is reliable (Fig. 5). When both sensors exhibit

Y

(cid:2)

X

g

at

gz

gy

g

gx

Z

(cid:2)

g

Fig. 4 The total force (at ) applied to the phone at any time instance is the sum of the gravity acc. (g) and
the linear acc. ((cid:6)). The gravity acc. components in the phone coordinate system are (gX, gY , gZ)

Geoinformatica

 

Compass
Gyroscope

)
.

d
a
r
(
 

l

e
g
n
A

8

6

4

2

0

−2

−4

 
0

200

400

600

800

1000

1200

1400 1500

Correlated Trends

Time (msec.)

Fig. 5 Example showing leveraging the correlation between the compass and gyroscope sensors to determine
when the compass readings are reliable

a similar pattern, we declare that the compass reading is accurate and can be used to correct
the gyroscope drift [2, 41].

3.3.2 Phone orientation estimation

Users carry cell phones in different positions (e.g. pants’ pocket, shirt’s pocket, in bag, or in
hand). Therefore, the phone can have an arbitrary orientation relative to the user’s plane of
motion. To estimate the phone orientation, we depend on the estimated gravity acceleration
(Section 3.3.1). For ease of illustration, we first use Euler angles and rotation matrices to
explain how Humaine estimates the phone orientation angles around the three main axes;
i.e. yaw, pitch, and roll (Fig. 6). Then, we explain our actual implementation.

Let Gm = [gx, gy, gz]t be the gravity components, of the estimated gravity acceleration

affecting the phone in its arbitrary location. Gm can be written as:
⎤

⎤

⎡

⎡

⎣

⎦ = RX(α)RY (β)RZ(γ )

⎣

⎦

(1)

gx
gy
gz

0
0
g

Fig. 6 Different phone
orientation angles: pitch (α), roll
(β), and yaw (γ ). γ is the phone
orientation angle relative to
North (azimuth angle)

-G

E

N

Z

X

Y

Geoinformatica

where RA(b) is the rotation matrix representing a rotation with angle b around axis A. In
particular:

RX(α) =

RY (β) =

RZ(γ ) =

⎡

⎣

⎡

⎣

⎡

⎣

⎤

⎦

⎤

⎦

⎤

⎦

0

0
1
0 cos(α)
sin(α)
0 − sin(α) cos(α)

cos(β) 0 − sin(β)
1
sin(β) 0 cos(β)

0

0

cos(γ )
sin(γ ) 0
− sin(γ ) cos(γ ) 0
1
0
0

−1
A (b) = RA(−b), we obtain:
⎤
0
0
g

⎡

⎣

⎦

RY (−β)RX(−α)Gm = RZ(γ )

To obtain the pitch (α) and roll (β) angles, we multiply both sides of Eq. 1 by
R

−1
X (α) and noting that R

−1
Y (β)R

Substituting from Eqs. 2, 3 and 4 we obtain:

⎡

⎣

cos(β)
0

sin(β) sin(α) sin(β) cos(α)

cos(α)

− sin(α)

− sin(β) cos(β) sin(α) cos(β) cos(α)

⎤

⎡

⎦

⎣

⎤

⎡

⎦ =

⎣

gx
gy
gz

⎤

⎦

0
0
g

From the second and first rows of Eq. 6 we get:

tan(α) =

gy
gz
−gx
gy sin(α) + gz cos(α)

tan(β) =

To obtain the yaw angle (γ ), which is the phone orientation angle relative to North (Fig. 7),
we leverage the magnetometer signal. In particular, let M = [mx, my, mz]t be the magnetic
field at the arbitrary phone orientation. Using a similar approach to Eq. 5, we get

⎡

⎣

⎡

⎣

=

mx cos(β) + my sin(β) sin(α) + mz sin(β) cos(α)
my cos(α) − mz sin(α)
−mx sin(β) + my cos(β) sin(α) + mz cos(β) cos(α)
E cos(ψ) sin(γ )
−E cos(ψ) cos(γ )
E sin(ψ)

⎤

⎦

⎤

⎦

where E and ψ are the unknown Earth magnetic field strength and the dip angle of the field
measured downwards from horizontal [31] for a perfectly oriented phone, i.e. pointing to
North. From the first and second rows of Eq. 9 we get:

tan(γ ) =

mx cos(β) + my sin(β) sin(α) + mz sin(β) cos(α)
mz sin(α) − my cos(α)

Equations 7, 8 and 10 are solved taken into account the sign of the gravity acceleration and
magnetometer components to obtain the correct quadrant for the respective angles.

(2)

(3)

(4)

(5)

(6)

(7)

(8)

(9)

(10)

Geoinformatica

Fig. 7 The phone orientation
after applying the rotation
matrices R(−β)R(−α). The
phone Z-axis becomes aligned
with −G and the phone rests in
the horizontal plane of motion
making an angle γ with North
(phone orientation angle)

Actual implementation We use unit quaternions to represent the rotation operation in
Humaine rather than rotation matrices. This representation evolves from Euler’s rotation
theorem [18], which implies that any rotation or sequence of rotations of a rigid body in
a three-dimensional space is equivalent to a pure rotation about a single fixed axis r =
[rx, ry, rz]t , r 2
= 1 by an angle θ (Fig. 8). Quaternions give a simple way to
x
encode the rotation operation in 4 parameters, compared to 9 parameters in case of rotation
matrices. In addition, quaternions suffer from fewer mathematical rounding defects and are
not subject to the gimbal lock problem [18, 19].

+ r 2
z

+ r 2
y

The relation between the pitch, roll, and yaw angles obtained in the previous section and

the 4D quaternion vector is as follows:

⎤

⎥
⎥
⎦ =

⎡

⎢
⎢
⎢
⎣

⎡

⎢
⎢
⎣

cos( θ
2 )
sin( θ
2 )rx
sin( θ
2 )ry
sin( θ
2 )rz

q =

cos( α
cos( α
sin( α
cos( α

2 ) cos( β
2 ) sin( β
2 ) cos( β
2 ) cos( β

2 ) cos( γ
2 ) cos( γ
2 ) cos( γ
2 ) sin( γ

2 ) + sin( α
2 ) − sin( α
2 ) + cos( α
2 ) − sin( α

2 ) sin( β
2 ) cos( β
2 ) sin( β
2 ) sin( β

2 ) sin( γ
2 )
2 ) sin( γ
2 )
2 ) sin( γ
2 )
2 ) cos( γ
2 )

⎤

⎥
⎥
⎥
⎦

(11)

Fig. 8 Transforming between
two coordinate systems can be
performed using three rotations
around the three orthogonal axes
by the corresponding Euler
angles. This is equivalent to a
single rotation around axis (cid:3)r with
an angle θ .

Z2

Z1

X1

X2

Y2

Y1

Geoinformatica

3.4 Transportation mode detection

To tune Humaine’s performance depending on the user’s context, we identify her transporta-
tion mode and feed it to the system’s modules. Transportation mode detection for outdoor
users has been thoroughly studied in the literature. We follow the approach proposed by [20]
that provides high accuracy of differentiation between the different transportation modes
based on the smartphone’s acceleration measurements. In particular, we used their presented
kinematic motion classifier module which identifies whether the user is walking or riding
a vehicle. To do so, the module extracts different time and frequency domain features from
the acceleration signals and uses adaptive-boosting to classify them.

3.5 Preprocessing

Humaine estimates the user direction based on processing the linear acceleration vector
from raw sensor measurements; These measurements are sensitive to abrupt changes in the
cell phone, e.g. due to shaking. We apply a low-pass filter on the linear acceleration to
reduce the effect of the noisy measurements with the following equation:

s(i) = s(i − 1) + δ.(r(i) − s(i − 1)), i > 0

Where s(i) is the ith smoothed linear acceleration signals, r(i) is the ith raw linear acceler-
ation sample, and δ is the smoothing factor. We analyze the effect of the smoothing factor
in Section 4.

3.6 Obtaining the user motion direction

To obtain the user motion direction, we transform the linear acceleration ((cid:6)), which is the
acceleration due to all forces applied to the phone except gravity, from the cell phone coor-
dinate system to the user coordinate system to obtain (cid:6)u. This is achieved by applying the
quaternions to the linear acceleration vector ((cid:6)):

(cid:6)u = q.(cid:6).q

∗

where: q∗ is the conjugate of the quaternion q.

Once the phone linear acceleration is transformed to the user coordinate system, what
remains is to obtain the user direction relative to North. Figure 9 shows that even though

2

1

Y

0

−1

−2
−2

N

Actual User
Direction

E

First Principle
 Component

−1.5

−1

−0.5

0.5

1

1.5

2

0
X

Fig. 9 PCA applied to the linear acceleration samples (red points) in the user plane after orienting the phone.
The figure shows the estimated as well as the actual user direction

Geoinformatica

the phone has been oriented to North by applying the rotation angles, the linear acceleration
samples are not aligned with North, but rather with the user direction. Humaine exploits this
observation to detect the user direction as the direction that has the maximum variance. To
obtain this direction, we consider only the two horizontal components of the transformed
linear acceleration ((cid:6)u = ((cid:6)F , (cid:6)S)) that lie in the (F,S) plane, which is the user plane of
motion. We then apply PCA on a window that contains values of ((cid:6)F , (cid:6)S) components of
the transformed linear acceleration ((cid:6)u). The first principal component is the direction of
maximum variance. Figure 10 shows the acceleration signal at different stages of processing
by Humaine. We analyze the effect of the window size in Section 4.

3.7 Resolving ambiguity

The obtained direction through PCA cannot differentiate between the actual user direction
and its opposite, i.e. θu and θu +180. To resolve this ambiguity, we use the phone orientation
angle (γ ) as a hint and choose the PCA output direction that is closest to γ . This will
work as long as the difference between the y-axis of the phone and the forward direction of
the user is within ±90◦, which is the typical case for various phone positions at different
transportation modes as we quantify in Section 4.

4 Evaluation

We implemented Humaine on different Android devices including Samsung Galaxy Nexus
S, LG Nexus 5, Samsung Galaxy Tab 10.1, Samsung Galaxy Note 2 and an Asus Nexus
7 tablet. Raw sensor measurements were obtained through the Android API with sampling
rate 50 Hz. To evaluate the system applicability under different magnetic field characteris-
tics, we used 30 test environments in Alexandria, Egypt and London, UK including different
rooms at a typical home environment, a college library, offices, a garden, a college campus,
various vehicles (e.g. cars and buses), different wide and narrow streets, among others. A
total of 300 experiments with more than 12000 user direction estimates were performed by
10 users using different Android smart-phone devices while having them carry the phones

Raw Linear Acc.
Smoothed Linear Acc.
Linear Acc. in User Plane
First Principle Component
Actual User Direction
Phone Direction

-G

5

0

-5

-10
20

5

2.5

10

0

E

0

N

-2.5

-10

-5

Fig. 10 The figure shows the linear acceleration at different processing steps by Humaine to get the motion
axis: raw acceleration, de-noised, and transformed linear acceleration

Geoinformatica

at different positions, for both pedestrian and in-vehicle cases, including pants pocket, shirt
pocket, in bag, and in hand; as well as covering different phone orientations relative to the
user direction of motion. 75 experiments were conducted for each of the positions stated
above. To obtain ground truth for pedestrian cases, we marked the user path on the ground
and used the path orientation from Google Maps as the ground-truth. On the other hand,
for in-vehicle cases, we map-matched the user trajectory [4, 32] and, similarly, used the
map-matched path orientation from Google Maps as the ground-truth.

For the rest of the section, we start by evaluating the effect of the system parameters
on accuracy, mainly the noise filter smoothing factor (δ) and the PCA window size (ω).
Then, we compare the performance of the end-to-end system, in typical indoor/outdoor and
in-vehicle testbeds under different phone positions, with the Android API (as the current
widely deployable system) and uDirect system [22, 23] (closest related work) and GPS. The
metrics used in the comparison are absolute angle estimation error, latency in adapting to
direction change, and power consumption.

4.1 Performance of the different system parameters

4.1.1 Smoothing factor effect (δ)

Figure 11 shows the effect of the low pass filter smoothing factor (δ), applied on the linear
acceleration to reduce the noise effect, on the orientation estimation accuracy for the differ-
ent contexts (Section 3.5). The figure shows that using a high value for δ leads to ignoring
the samples history while using a low value ignores recent values; both are not good for
the system performance. We choose δ = 0.25 for indoor and outdoor walking cases and
δ = 0.1 for in-vehicle cases (detected by the transportation mode detection module) as they
give the best accuracy eliminating noise without affecting the acceleration signal.

4.1.2 PCA sliding window size (ω)

Figure 12 shows the effect of the PCA sliding window size (ω) described in Section 3.6
on both indoor and outdoor experiments for walking and in-vehicle cases. As expected, the
user’s orientation estimation improves as we increase the window size. However, a larger
window size will cause latency in adaptation when the user changes her direction. Note that
for walking users they can change their heading direction suddenly. However, this is not the
case for vehicles which updates its heading gradually, e.g. moving over a curvature to take

)
e
e
r
g
e
d
(
 
r
o
r
r

l

 

E
 
e
g
n
A
e
g
a
r
e
v
A

 30

 25

 20

 15

 10

 5

 0

)
e
e
r
g
e
d
(
 
r
o
r
r

l

E
 
e
g
n
A
 
e
g
a
r
e
v
A

 80
 70
 60
 50
 40
 30
 20
 10
 0

Indoors
Outdoors

 0

 0.4

 0.2
 0.8
Smoothing Factor (δ)

 0.6

 1

 0

(a)

 0.6

 0.4

 0.2
 0.8
Smoothing Factor (δ)
(b)

 1

Fig. 11 Effect of the low pass filter smoothing factor (δ) applied to the linear acceleration

)

%

(
 
r
o
r
r

l

E
 
e
g
n
A
 
n
i
 
e
g
n
a
h
C

 0

-20

-40

-60

-80

Indoors
Outdoors
Latency

In-vehicles
Latency

 7
 6
 5
 4
 3
 2
 1
 0

)
c
e
s
(
 
y
c
n
e
t
a
L

)

%

(
 
r
o
r
r

l

E
 
e
g
n
A

 0

-10

-20

-30

-40

 1

 2

 0
 5
PCA Window size - ω (sec)

 3

 4

 2

 1

 0
 5
PCA Window size - ω (sec)

 4

 3

(a)

(b)

Fig. 12 Effect of the PCA sliding window on the orientation estimation accuracy and latency

Geoinformatica

 5

 4

 3

 2

 1

 0

)
c
e
s
(
 
y
c
n
e
t
a
L

a turn. Hence, we choose a window size of 3 seconds for walking cases and 2 seconds for
in-vehicle cases to balance between responsiveness and accuracy.

4.2 Comparison with other systems

In this section, we compare the performance of Humaine, in terms of heading estimation
error, latency in direction change estimation, and power consumption; to uDirect [22, 23]
and the Android API, and GPS. uDirect uses inertial sensors available on the cell phone
to estimate the user direction. However, it employs a step detection technique to detect
the user heading. uDirect requires a new analytical model of the generated acceleration

F
D
C

F
D
C

 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0

 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0

F
D
C

 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0

F
D
C

 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0

Humaine
uDirect
Android API

Humaine
uDirect
Android API

 0  20  40  60  80  100  120  140  160  180
Estimated Angle Error (degree)

 0  20  40  60  80  100  120  140  160  180
Estimated Angle Error (degree)

(a)

(b)

Humaine
uDirect
Android API

Humaine
uDirect
Android API

 0  20  40  60  80  100  120  140  160  180
Estimated Angle Error (degree)

 0  20  40  60  80  100 120 140 160 180
Estimated Angle Error (degree)

(c)

(d)

Fig. 13 CDF plots comparing Humaine, uDirect [22, 23], and Android API for pedestrians indoors.
Humaine outperforms other techniques in all positions. uDirect fails indoors, specially when the phone is not
in the pants pocket it was designed for

Geoinformatica

pattern for each new position [22, 23]. However, the only model presented and evaluated
in details is for handling the acceleration pattern of the femur bone (i.e. in pants pocket
position), and deriving models for other positions is not straight forward as we show later
in this section. On the other hand, the Android API is the default heading estimation
technique available on Android phones and has been used by a number of systems,
e.g. [14, 43], to determine the phone orientation, rather than the human orientation
(assuming both are the same). However, it is considered the widely deployed state-of-the-
art. We also compare with the user bearing provided by the cell phone’s GPS as widely used
outdoor technique that can estimate the user heading and does not depend on the phone
position. However, GPS availability depends on the environment, e.g. it is not available
indoors and at roads with urban canyons, and the phone’s GPS chip quality.

We start by evaluating the accuracy of the different techniques on a single segment to
quantify the effect of different phone positions. We then perform a continuous trace exper-
iment to study the latency of the different techniques and their suitability for real-time
applications.

4.3 One segment user’s heading estimation error

Figures 13, 14 and 15 compares the CDFs of the user orientation estimation error for the
three systems—Humaine, uDirect [22, 23], and the Android API—indoors, outdoors and
in-vehicles respectively for the different smartphone positions under 20 different testbeds.
The experiments were performed by 10 users who used different Android devices while
placing the phones at different positions covering different phone orientations relative to the

F
D
C

F
D
C

 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0

 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0

F
D
C

 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0

F
D
C

 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0

Humaine
GPS
uDirect
Android API

Humaine
Android API
GPS
uDirect

 0  20  40  60  80  100  120  140  160  180
Estimated Angle Error (degree)
(a)

 0  20  40  60  80  100  120  140  160  180
Estimated Angle Error (degree)

(b)

Humaine
GPS
Android API
uDirect

Humaine
GPS
Android API
uDirect

 0  20  40  60  80  100  120  140  160  180
Estimated Angle Error (degree)

 0  20  40  60  80  100  120  140  160  180
Estimated Angle Error (degree)

(c)

(d)

Fig. 14 CDF plots comparing Humaine, GPS, uDirect [22, 23], and Android API for pedestrians outdoors.
Humaine outperforms all systems in all positions. uDirect fails when the phone is not in the pants pocket (the
position it was designed for). GPS gives good accuracy outdoors. However, it has significant latency as we
quantify in Section 4.4

Geoinformatica

Humaine
uDirect
Android API

Humaine
uDirect
Android API

 0  20  40  60  80  100 120 140 160 180
Estimated Angle Error (degree)

 0  20  40  60  80  100 120 140 160 180
Estimated Angle Error (degree)

(b)

F
D
C

F
D
C

 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0

 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0

(a)

(c)

F
D
C

 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0

F
D
C

 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0

Humaine
uDirect
Android API

 0  20  40  60  80  100 120 140 160 180
Estimated Angle Error (degree)

 0  20  40  60  80  100 120 140 160 180
Estimated Angle Error (degree)

Humaine
uDirect
Android API

(d)

Fig. 15 CDF plots comparing Humaine, uDirect [22, 23], and Android API in-vehicles. Humaine outper-
forms all systems in all positions. uDirect fails in all positions even when the phone is in the pants pocket
(the position it was designed for), as the step pattern can’t be detected in the sitting position

user direction of motion. We also show the GPS for outdoor experiments. Tables 3, 4 and 5
summarize the results. Through this evaluation, we used straight segments, i.e. without
including any changes in direction. We evaluate the effect of the change in direction on
the techniques estimation error and latency in Section 4.4.

For walking cases: The results show that Humaine gives the best accuracy in all cases.
Although both Humaine and uDirect use the magnetometer sensor, which is sensitive to
magnetic noise in the environment especially indoors; we believe that Humaine is less sen-
sitive due to two reasons: First Humaine depends on estimating the heading direction based
on the variance of the user linear acceleration, which is less sensitive to noise compared
to the rotated acceleration pattern within a step used by uDirect. Second, Humaine sen-
sor fusion module described in Section 3.3 lessens the effect of the magnetometer noise or
drift. For example, Fig. 16 shows the user step pattern used by uDirect in indoor and out-
door environments. The figure shows that the step pattern is noisy in indoor environment,
significantly affecting uDirect accuracy.

The same figure also show that uDirect is sensitive to the movement model used. It has
been designed to work with the in-pocket position, which gives the best accuracy for it.
However using this model with other phone positions leads to excessive errors.

For in-vehicle case: Humaine still gives the best accuracy across all positions and uDirect
gives the worst performance. The main reason behind this bad performance is that uDirect
depends on the user’s step pattern to estimate her direction. However, for in-vehicle case,
there is no steps to detect as the user is typically sitting or standing (e.g. in buses).

The Android standard API, as it does not estimate the user heading, has large errors
for both transportation modes and positions, especially in the shirt pocket position. At this

Geoinformatica

e
r
a

n
o
i
t
a
d
a
r
g
e
d

s
e
g
a
t
n
e
c
r
e
P

.
s
r
o
o
d
n
i

k
r
o
w

t
o
n

s
e
o
d

S
P
G

t
a
h
t

e
t
o
N

.
s
t
n
e
m
n
o
r
i
v
n
e

r
o
o
d
n
i

n
i

I
P
A

d
i
o
r
d
n
A

d
n
a

,
]
3
2

,
2
2
[

t
c
e
r
i

D
u

,
e
n
i
a
m
u
H

n
e
e
w
t
e
b

n
o
s
i
r
a
p
m
o
C

3

e
l
b
a
T

)
s
e
e
r
g
e
d
(

s
r
o
o
d
n
I

r
o
r
r
E
n
o
i
t
a
m

i
t
s
E
g
n
i
d
a
e
H

r
e
s
U

e
u
q
i
n
h
c
e
T

e
n
i
a
m
u
H
o
t

e
v
i
t
a
l
e
r
d
e
t
a
l
u
c
l
a
c

g
a
B

%
0
5

7
1

0
9

2
4

.
x
a
M

%
5
7

.
x
a
M

%
5
7

%
0
5

.
x
a
M

%
0
5

.
x
a
M

%
5
7

%
0
5

t
e
k
c
o
p

t
r
i
h
S

d
l
e
h
d
n
a
H

t
e
k
c
o
p

s
t
n
a
P

)

%
0
.
0
5
3
(

)

%
7
.
1
4
4
(

)

%
1
.
7
4
1
(

)

%
0
.
0
0
3
(

)

%
3
.
1
3
9
(

)

%
9
.
8
8
2
1
(

)

%
3
.
3
3
2
(

)

%
3
.
6
2
2
(

)

%
3
.
3
3
3
(

)

%
3
.
7
2
2
(

)

%
2
.
3
0
1
(

)

%
2
.
6
7
1
(

)

%
5
.
7
3
3
(

)

%
8
.
0
7
4
(

)

%
4
.
9
2
4
(

)

%
0
.
0
0
3
(

)

%
5
.
7
8
7
(

)

%
4
.
4
4
0
1
(

)

%
0
.
0
0
5
(

)

%
1
.
2
4
6
(

)

%
0
.
0
5
7
(

)

%
6
.
3
6
1
(

)

%
3
.
1
6
(

)

%
9
.
2
4
(

0
4

5
7
1

0
8
1

4
2

7
3
1

0
3
1

5
4

0
8
1

0
8
1

6
1

2
4
1

5
6
1

3
0
1

9

5
2
1

0
3

0
8
1

0
0
1

2
1

2
0
1

2
5

5
5

5
4
1

0
8
1

1
3

0
5

3
6

1
2

0
3

e
n
i
a
m
u
H

t
c
e
r
i

D
u

8
5

I
P
A
d
i
o
r
d
n
A

%
5
7

9
1

1
4
1

2
6

Geoinformatica

o
t

e
v
i
t
a
l
e
r

d
e
t
a
l
u
c
l
a
c

e
r
a

n
o
i
t
a
d
a
r
g
e
d

s
e
g
a
t
n
e
c
r
e
P

.
s
n
a
i
r
t
s
e
d
e
p

r
o
f

s
t
n
e
m
n
o
r
i
v
n
e

r
o
o
d
t
u
o

n
i

S
P
G
d
n
a

,
I
P
A
d
i
o
r
d
n
A

,
]
3
2

,
2
2
[

t
c
e
r
i

D
u

,
e
n
i
a
m
u
H
n
e
e
w
t
e
b

n
o
s
i
r
a
p
m
o
C

4

e
l
b
a
T

0
5

0
8
1

0
8
1

7
7
1

4
2

1
2
1

7
4

7
5

g
a
B

%
0
5

3
1

2
8

6
3

7
3

.
x
a
M

%
5
7

.
x
a
M

%
5
7

%
0
5

.
x
a
M

%
5
7

%
0
5

.
x
a
M

%
5
7

%
0
5

)

%
0
.
4
5
2
(

)

%
5
.
7
3
1
(

)

%
2
6
.
4
8
1
(

)

%
2
8
.
1
2
2
(

)

%
0
.
8
2
1
(

)

%
7
6
.
6
4
1
(

)

%
0
.
0
9
4
(

)

%
7
6
.
6
1
2
(

)

%
3
.
8
0
2
(

)

%
2
8
.
1
2
2
(

)

%
0
.
0
9
(

)

%
7
1
.
4
5
(

)

%
0
.
0
6
2
(

)

%
8
.
5
9
(

)

%
9
.
6
7
1
(

)

%
3
.
7
2
2
(

)

%
0
.
8
2
5
(

)

%
0
.
0
8
4
(

)

%
0
.
0
0
5
(

)

%
2
.
2
7
1
(

)

%
3
.
3
3
2
(

)

%
3
.
7
2
2
(

)

%
0
.
0
3
1
(

)

%
5
.
7
3
1
(

)

%
0
.
0
6
2
(

)

%
2
.
4
0
4
(

)

%
8
.
0
3
5
(

)

%
3
.
7
2
2
(

)

%
0
.
0
2
5
(

)

%
3
.
3
1
7
(

)

%
0
.
0
0
5
(

)

%
8
.
7
7
6
(

)

%
7
.
1
9
6
(

)

%
2
.
8
1
1
(

)

%
3
.
3
3
(

)

%
2
.
4
(

5
5

0
8
1

0
8
1

7
7
1

5
2

5
5
1

7
5
1

7
5

5
1

2
2
1

7
8

7
3

0
3

0
8
1

0
8
1

7
7
1

8
1

0
4
1

9
4

7
5

2
1

5
9

0
4

7
3

5
5

0
2
1

0
8
1

7
7
1

0
3

0
4

9
6

7
5

4
2

5
2

e
n
i
a
m
u
H

t
c
e
r
i

D
u

7
5

I
P
A
d
i
o
r
d
n
A

7
3

S
P
G

t
e
k
c
o
p

t
r
i
h
S

d
l
e
h
d
n
a
H

t
e
k
c
o
p
s
t
n
a
P

y
d
o
b
r
e
s
u

o
t

e
v
i
t
a
l
e
r

n
o
i
t
i
s
o
p

e
n
o
h
p

e
h
t

n
o

d
n
e
p
e
d

t
o
n

o
d

s
t
l
u
s
e
r
S
P
G

.
e
n
i
a
m
u
H

)
s
e
e
r
g
e
d
(

s
r
o
o
d
t
u
O

r
o
r
r
E
n
o
i
t
a
m

i
t
s
E
g
n
i
d
a
e
H

r
e
s
U

e
u
q
i
n
h
c
e
T

Geoinformatica

g
a
B

%
0
5

5
1

0
8
1

5
4

.
x
a
M

%
5
7

.
x
a
M

%
5
7

%
0
5

.
x
a
M

%
0
5

.
x
a
M

%
5
7

0
7

0
8
1

5
4
1

0
4

0
8
1

5
2
1

0
6

0
8
1

0
8
1

5
3

1
8

0
2

3
7

5
5
1

5
3
1

0
8

0
8
1

5
9

0
2

0
8
1

5
1

0
7

8
7
1

5
2
1

6
3

0
6
1

2
1
1

)

%
1
.
7
5
1
(

)

%
0
.
0
5
3
(

)

%
0
.
0
0
1
1
(

)

%
0
.
0
0
2
(

)

%
4
.
1
3
1
(

)

%
0
.
5
6
2
(

)

%
0
.
5
2
1
(

)

%
3
.
4
1
4
(

)

%
0
.
0
0
8
(

)

%
3
.
4
5
1
(

)

%
4
.
4
4
3
(

)

%
0
.
0
6
3
(

)

%
1
.
7
0
1
(

)

%
5
.
2
1
2
(

)

%
0
.
0
0
2
(

)

%
0
.
0
0
2
(

)

%
9
.
2
4
3
(

)

%
0
.
5
7
5
(

)

%
8
.
8
1
(

)

%
3
.
4
7
(

)

%
5
2
(

)

%
6
.
8
7
(

)

%
1
.
1
1
2
(

)

%
0
.
2
9
1
(

%
5
7

5
3

0
8
1

1
6

%
0
5

5
2

5
1
1

e
n
i
a
m
u
H

t
c
e
r
i

D
u

3
7

I
P
A
d
i
o
r
d
n
A

t
e
k
c
o
p

t
r
i
h
S

d
l
e
h
d
n
a
H

t
e
k
c
o
p
s
t
n
a
P

)
s
e
e
r
g
e
d
(

e
l
c
i
h
e
v
-
n
I

r
o
r
r
E
n
o
i
t
a
m

i
t
s
E
g
n
i
d
a
e
H

r
e
s
U

e
u
q
i
n
h
c
e
T

e
n
i
a
m
u
H
o
t

e
v
i
t
a
l
e
r
d
e
t
a
l
u
c
l
a
c

e
r
a

n
o
i
t
a
d
a
r
g
e
d

s
e
g
a
t
n
e
c
r
e
P

.
s
t
n
e
m
n
o
r
i
v
n
e

e
l
c
i
h
e
v
-
n
i
n
i

I
P
A
d
i
o
r
d
n
A
d
n
a

]
3
2

,
2
2
[

t
c
e
r
i

D
u

,
e
n
i
a
m
u
H
n
e
e
w
t
e
b

n
o
s
i
r
a
p
m
o
C

5

e
l
b
a
T

Geoinformatica

Fig. 16 The vertical acceleration used by uDirect [22, 23] for estimating the user heading (solid red lines
represent the ground truth, circles represent the global and local minimums at each step used to estimate the
point of foot impact, dotted blue lines represent the estimated point by uDirect): (a) in pants pocket outdoors
(best), (b) in pants pocket indoors and (c) hand held outdoors. Due to magnetic noise indoors, the step pattern
is deformed; explaining uDirect performance degradation indoors. Also, the in-pocket step model cannot be
used directly with other positions (e.g. shown in-hand)

position, the cell phone is vertically orientated relative to the user’s direction, leading to the
maximum error.

GPS has good accuracy outdoors when the user is not changing her direction. However,
it has a large fix time (average two minutes in open areas), excessive latency when the user
makes a turn, and its accuracy in urban area decreases significantly. This is quantified in the
next section.

4.4 Performance in a continuous trace

Figures 17 and 18 show the trajectory of the experiments to examine the effect of chang-
ing the direction during a continuous trace on Humaine and uDirect [22, 23] indoors and on
Humaine, uDirect [22, 23] and GPS outdoors for walking user. We chose the walking case
as it suffers from more latency as compared to in-vehicle case (Section 4.1.2). Table 6 sum-
marizes the results. For both cases, the phone was placed in the pants pocket as uDirect does
not perform well in other cases, i.e. this is the best case scenario for uDirect as shown in the
previous section. The results confirm that Humaine can smoothly track the user heading in
both indoors and outdoors environments with most of the errors at the instances of direction
change. As discussed in Section 4.1.2, the appropriate PCA window size is chosen to bal-
ance the trade-off between accuracy and responsiveness to user direction change. Humaine

Geoinformatica

Segment 5: 4.0m

 
:
4
 
t
n
e
m
g
e
S

m
3
.
3

N

E

Baseline
Humaine
uDirect

Segment 1: 2.7m

 
:
2
 
t
n
e
m
g
e
S

m
7
.
2

(a)

2

1

Latency

)
e
e
r
g
e
d
(
 
h
t
r
o
N
m
o
r
f
 
e
l
g
n
A

 

 160
 120
 80
 40
 0
-40
-80

5

3

4

Angle error

 0

 10

 20

 30

 40

 50

Time (sec)

(b)

Fig. 17 Tracking performance for Humaine and uDirect [22, 23] for a continuous motion trace in an indoor
environment. Phone placed in pants pocket only as uDirect completely fails in other positions as in Fig. 13

also has the minimum latency, highlighting its suitability for applications that can not toler-
ate delay. In addition, uDirect accuracy is significantly affected in indoor environments due
to the noise affecting the acceleration pattern used in heading estimation (Fig. 16).

GPS suffers from degradation in accuracy at areas without clear view of the sky, e.g.
indoors, and urban canyons [5]. In addition, GPS has an initial fix latency with an average
over different devices of 2 minutes. Moreover, it suffers from latency when changing direc-
tion with an average of 70 seconds. This latency affects the performance of GPS as shown
in the experiment in Fig. 18.

4.5 Power consumption

Figure 19 and Table 6 summarize the power consumption of the different algorithms. To
calculate the power consumption, we used the PowerTutor profiler [44] while the system
was used by the user for about 5 minutes. The results are conducted using two different
Android devices (Galaxy Nexus S and Samsung Galaxy Note 2). During each experiment,
we made sure that no other applications were running with the system on the platform.

The figure shows that as expected, GPS has the worst energy consumption. uDirect
involves searching for a specific pattern inside a step. Therefore, its complexity is linear

Geoinformatica

Seg 2: 
25m

Seg 1:
20m

N

)
e
e
r
g
e
d
(
 
h
t
r
o
N
m
o
r
f
 
e
l
g
n
A

 

 150
 100
 50
 0
-50
-100
-150
-200
-250
-300

E

1

(a)

Baseline
Humaine
uDirect
GPS

(b)

2

3

Angle error

Latency

4

5

 0  15  30  45  60  75  90  105
Time (sec)

Fig. 18 Tracking performance for Humaine, uDirect [22, 23], and GPS for a continuous motion trace in
an outdoor environment. Note that GPS can track the angle accurately within a single segment but gives
significant latency (70 seconds on average). Phone placed in pants pocket only as uDirect completely fails
in other positions as in Fig. 14

in the step length. The results shows that Humaine energy consumption is comparable to
uDirect. This can be further enhanced by other techniques, e.g. duty-cycling.

5 Discussion

Through this section, we discuss different aspects of the Humaine system.

5.1 User bearing and phone attitude

User bearing is of huge importance for a wide range of location-based services such as
navigation systems and energy-efficient dead reckoning-based localization techniques. Cur-
rently, GPS and the Android API are the main deployed methods for user bearing and
phone attitude estimation in all smartphones. However, GPS has a large power consump-
tion, latency and inefficient for usage in real-time to show the user’s bearing. Thus, typically
systems use the Android API and assume that the estimated orientation is the user’s heading

Geoinformatica

n
o
i
t
a
d
a
r
g
e
d
s
e
g
a
t
n
e
c
r
e
P

.
3
1
.
g
i
F
n
i

s
a
s
n
o
i
t
i
s
o
p
r
e
h
t
o
n
i

s
l
i
a
f
y
l
e
t
e
l
p
m
o
c
t
c
e
r
i

D
u
s
a
t
e
k
c
o
p
s
t
n
a
p
n
i
y
l
n
o
d
e
c
a
l
p
e
n
o
h
P

.
s
t
n
e
m

i
r
e
p
x
e
e
c
a
r
t
-
s
u
o
u
n
i
t
n
o
c
e
h
t

r
o
f
y
r
a
m
m
u
S

6
e
l
b
a
T

n
o
i
t
p
m
u
s
n
o
c
-
y
g
r
e
n
e

e
l
b
a
r
a
p
m
o
c

h
t
i

w
y
c
n
e
t
a
l

d
n
a
y
c
a
r
u
c
c
a

h
t
o
b

n
i

m
h
t
i
r
o
g
l
a

t
c
e
r
i

D
u

s
m
r
o
f
r
e
p
t
u
o

e
n
i
a
m
u
H

t
a
h
t

s
w
o
h
s

e
l
b
a
t

e
h
T

.
e
n
i
a
m
u
H
o
t

e
v
i
t
a
l
e
r
d
e
t
a
l
u
c
l
a
c

e
r
a

)

W
m

(
r
e
w
o
P

s
r
o
o
d
t
u
O

s
r
o
o
d
n
I

t
n
e
m
n
o
r
i
v
n
E

e
g
a
r
e
v
A

x
a
M

e
g
a
r
e
v
A

e
g
a
r
e
v
A

x
a
M

e
g
a
r
e
v
A

)
c
e
s
(
y
c
n
e
t
a
L

)
e
e
r
g
e
d
(

r
o
r
r
E

.
s
b
A

)
c
e
s
(
y
c
n
e
t
a
L

)
e
e
r
g
e
d
(

r
o
r
r
E

.
s
b
A

)

%
5
.
9
-
(

5
1
3

)

%
9
.
0
5
1
(

5
.
5
2
1

5
.
3
1
1

)

%
3
.
3
3
(

3

4

0
7

3
1
.
5
9

7
1
.
1
1
1

)

%
9
.
6
1
(

5
6
1

6
8
.
1
1

1
4
.
7
1

)

%
8
.
6
4
(

4
9
.
6
6

n
i
M

7
0
0
.
0

1
1
1
.
0

2

)

%
7
.
5
8
4
1
(

)

%
3
.
4
6
(

)

%
5
.
8
3
(

)

%
6
.
3
1
9
7
(

5
.
3

5
7
.
5

1
7
.
3
8

9
6
.
1
9

)

%
5
.
9
(

4
2
.
6
1

9
4
.
2
2

n
i
M

2
2
0
.
0

3
6
7
.
1

e
n
i
a
m
u
H

t
c
e
r
i

D
u

S
P
G

)

%
3
.
3
3
2
2
(

)

%
5
4
.
3
7
(

)

%
4
.
4
6
4
(

)

%
4
.
1
7
4
8
2
(

–

–

–

–

Fig. 19 Power consumption for
the different algorithms

Geoinformatica

)

W
m

(
 
r
e
w
o
P

 400

 350

 300

 250

 200

 150

 100

 50

GPS

uDirect

Humaine
(ω=3)

direction. This unrealistic assumption hinders the progress of mobile-computing systems
that depend on knowledge of the user’s heading direction. Humaine provides a ubiquitous
solution is needed to solve this problem.

5.2 Smart-phones heterogeneity

Humaine depends on the user’s motion direction to identify her heading orientation by fus-
ing the different inertial sensors. This leads to a more accurate and reliable user heading
estimation as compared to step-detection based systems. Step detection-based systems are
based on the assumption that the user’s steps have a similar pattern across the different
devices as they rely on detection of a certain moment within the user’s step. However, due to
the users different walking styles, phones’ heterogeneity, environment effects and the exter-
nal magnetic interference the step pattern can get totally deformed (e.g. Fig. 16) affecting
their robustness against heterogeneity.

5.3 Ubiquitous heading direction estimation

As Humaine depends only on the user’s motion acceleration to estimate her heading direc-
tion; this makes it a truly ubiquitous system that can work anywhere regardless from the
user’s mobility mode (e.g. walking, riding a bus, driving, etc) and the phone’s holding
position (in a bag, hand-held, in pants pocket, etc...).

5.4 Other sensors

Humaine fuses the energy efficient inertial sensors commonly available in the off-the-shelf
smartphones through the sensor fusion module (Section 3.3) to reduce the effect of the sur-
rounding magnetic noise and transform the sensor measurements to the human coordinate
system. However, it can be extended to get benefit form other sensors, such as the camera,
to further improve this fusion and provide even better accuracy.

6 Conclusion

We introduced Humaine, a system for robustly estimating the orientation of users carrying
cell phones ubiquitously, suitable for new emerging crowd-sensing applications where the

Geoinformatica

user has the freedom to have her phone in any arbitrary position or orientation. It fuses the
phone’s energy-efficient inertial sensors and applies the PCA technique effectively to detect
the user direction.

Evaluation of Humaine on Android devices with 300 experiments on different testbeds
and phone positions shows that the system works accurately indoors, outdoors and in-
vehicles, without user involvement or prior configurations. Humaine achieved a median
accuracy of 14◦ and 16◦ for indoor and outdoor pedestrian users and 20◦ for in-vehicle users
over a wide variety of phone positions and platforms. This is better than the-state-of-the-art
by 523% and 594% for indoor and outdoor pedestrian users and 750% for in-vehicle users.
Furthermore, Humaine has a minimal effect on the phone battery and latency, highlighting
its suitability for real-time applications.

References

1. Abadi MJ, Luceri L, Hassan M, Chou CT, Nicoli M (2014) A collaborative approach to heading

estimation for smartphone-based pdr indoor localisation. In: IPIN. IEEE

2. Abdelnasser H, Mohamed R, Elgohary A, Farid M, Wang H, Sen S, Choudhury R, Youssef M (2015)
Semanticslam: Using environment landmarks for unsupervised indoor localization. IEEE Trans Mob
Comput

3. Aly H et al (2015) semMatch: Road semantics-based accurate map matching for challenging positioning

4. Mohamed R et al (2014) Accurate and efficient map matching for challenging environments. In: ACM

5. Aly H, Youssef M (2013) Dejavu: an accurate energy-efficient outdoor localization system. In:

data. In: ACM SIGSPATIAL

SIGSPATIAL

SIGSPATIAL. ACM

identification. In: SECON. IEEE

6. Aly H, Basalamah A, Youssef M (2014) Map++: A crowd-sensing system for automatic map semantics

7. Aly H, Basalamah A, Youssef M (2015) Lanequest: an accurate and energy-efficient lane detection
system. In: 2015 IEEE International conference on pervasive computing and communications (PerCom).
IEEE, pp 163–171

8. Aly H, Basalamah A, Youssef M (2015) Robust and ubiquitous smartphone-based lane detection.

9. Alzantot M, Youssef M (2012) Crowdinside: automatic construction of indoor floorplans. In: ACM

10. Alzantot M, Youssef M (2012) Uptime: Ubiquitous pedestrian tracking using mobile phones. In: WCNC.

11. Beauregard S (2007) Omnidirectional pedestrian navigation for first responders. In: Proceedings of

workshop on positioning navigation and communication. IEEE

12. Blum JR, Greencorn D, Cooperstock JR (2012) Smartphone sensor reliability for augmented reality

applications. In: MobiQuitous

13. Combettes C, Renaudin V (2015) Comparison of misalignment estimation techniques between handheld
device and walking directions. In: International conference on indoor positioning and indoor navigation
(IPIN). IEEE, pp 1–8

14. Constandache I, Choudhury RR, Rhee I (2010) Compacc: Using mobile phone compasses and

accelerometers for localization. INFOCOM

15. Constandache I, Choudhury RR, Rhee I (2010) Towards mobile phone localization without war-driving.

In: INFOCOM. IEEE

Trans Robot Autom

16. Cui Y, Ge SS (2003) Autonomous vehicle positioning with gps in urban canyon environments. IEEE

17. Deng ZA, Wang G, Hu Y, Wu D (2015) Heading estimation for indoor pedestrian navigation using a

smartphone in the pocket. Sensors 15(9):21,518–21,536
18. Goldstein H (1980) Classical mechanics, Addison-Wesley
19. Hamilton W, Hamilton W (1866) Elements of quaternions. Green, & Company, Longmans

Pervasive Mob Comput

SIGSPATIAL GIS

IEEE

Geoinformatica

20. Hemminki S, Nurmi P, Tarkoma S (2013) Accelerometer-based transportation mode detection on smart-
phones. In: Proceedings of the 11th ACM conference on embedded networked sensor systems. ACM,
p 13

21. Hofmann-Wellenhof B, Lichtenegger H, Collins J (1993) Global Positioning System: Theory and

Practice. Springer

22. Hoseinitabatabaei SA, Gluhak A, Tafazolli R (2011) Udirect: A novel approach for pervasive observation

of user direction with mobile phones. In: PerCom. IEEE

23. Hoseinitabatabaei SA, Gluhak A, Tafazolli R, Headley W (2014) Design, realization, and evaluation of
udirect–an approach for pervasive observation of user facing direction on mobile phones. IEEElTMC
24. Hu S, Su L, Li S, Wang S, Pan C, Gu S, Al Amin MT, Liu H, Nath S, Choudhury RR et al (2015)
Experiences with enav: a low-power vehicular navigation system. In: Proceedings of the 2015 ACM
international joint conference on pervasive and ubiquitous computing. ACM, pp 433–444

25. Jiang Z, Liu C, Zhang G, Wang Y, Huang C, Liang J (2013) Gps/ins integrated navigation based on
ukf and simulated annealing optimized svm. In: 2013 IEEE 78th vehicular technology conference (VTC
Fall). IEEE, pp 1–5

26. Kourogi M, Kurata T (2003) A method of personal position-ing based on sensor data fusion of wear-
able camera and self-contained sensors. In: IEEE international conference on multisensor fusion and
integration for intelligent system

27. Kourogi M, Kurata T (2003) Personal positioning based on walking locomotion analysis with self-
contained sensors and a wearable camera. In: International symposium on mixed and augmented reality.
IEEE

28. Kourogi M, Kuratta T (2003) A wearable augmented reality system with personal positioning based on

walking locomotion analysis. In: ISMAR. IEEE

29. Kunze K, Lukowicz P, Partridge K, Begole B (2009) Which way am i facing: Inferring horizontal device

orientation from an accelerometer signal. In: International symposium on wearable comps. IEEE

30. Li F, Zhao C, Ding G, Gong J, Liu C, Zhao F (2012) A reliable and accurate indoor localization method

using phone inertial sensors. In: Ubicomp. ACM

31. Merrill RT, McElhinny W, McFadden P (1998) The magnetic field of the earth: paleomagnetism, the

core and the deep mantle. International geophysics series, Academic Press

32. Mohamed R, Aly H, Youssef M (2016) Accurate real-time map matching for challenging environments.

33. Oshman Y et al (1985) Attitude determination from vector observations: Quaternion estimation. IEEE

In: IEEE T-ITS

Trans Aerosp Electron Syst 1:128–136

34. Qian J, Ma J, Ying R, Liu P, Pei L (2013) An improved indoor localization method using smartphone
inertial sensors. In: International conference on indoor positioning and indoor navigation (IPIN). IEEE,
pp 1–7

35. Renaudin V, Combettes C (2014) Magnetic, acceleration fields and gyroscope quaternion (magyq)-based
attitude estimation with smartphone sensors for indoor pedestrian navigation. Sensors 14(12):22,864–
22,890

36. Roy N, Wang H, Choudhury RR (2014) I am a smartphone and i can tell my user’s walking direction.
In: Proceedings of the 12th Annual International Conference on Mobile Systems, Applications, and
Services. ACM, pp 329–342

37. Schall G (2013) Mobile Computing: Mobile Augmented Reality for Human Scale Interaction with

Geospatial Models: the Benefit for Industrial Applications. Springer

38. Steinhoff U, Schiele B (2010) Dead reckoning from the pocket-an experimental study. In: PerCom. IEEE
39. Sun Z (2012) Polaris: getting accurate indoor orientations for mobile devices using ubiquitous visual

patterns on ceilings. ACM HotMobile

40. Sun Z, Pan S, Su YC, Zhang P (2013) Headio: zero-configured heading acquisition for indoor mobile

devices through multimodal context sensing. ACM, UbiComp

41. Wang H, Sen S, Elgohary A, Farid M, Youssef M, Choudhury RR (2012) No need to war-drive:

Unsupervised indoor localization. In: MobiSys. ACM

42. Wang Q, Zhang X, Chen X, Chen R, Chen W, Chen Y (2010) A novel pedestrian dead reckoning

algorithm using wearable emg sensors to measure walking strides. In: UPINLBS. IEEE

43. Youssef M, Yosef MA, El-Derini M (2010) Gac: Energy-efficient hybrid gps-accelerometer-compass

gsm localization. In: GLOBECOM. IEEE

44. Zhang L, Tiwana B, Qian Z, Wang Z, Dick RP, Mao ZM, Yang L (2010) Accurate online power estima-
tion and automatic battery behavior based power model generation for smartphones. In: IEEE/ACM/IFIP
International Conference CODES+ISSS

45. Zhang M, Sawchuk AA (2012) Motion primitive-based human activity recognition using a bag-of-

features approach. In: ACM SIGHIT international health informatics symposium

Geoinformatica

Nesma Mohssen holds a B.Sc. in Computer Engineering from Alexandria university, Egypt 2014. Her
research interests include mobile computing, computer vision and location determination systems.

Rana Momtaz received her B.Sc. from Alexandria University, Egypt in 2014. She is currently taking up
her Master’s degree in Computer Science at Alexandria University. Her research interests include mobile
computing, data mining and bioinformatics.

Heba Aly is a PhD student at the University of Maryland College Park, USA. She received her B.Sc. and
M.Sc. in computer science from Alexandria University, Egypt in 2011 and 2015 respectively. Her research
interests include mobile computing, location determination technologies, pervasive computing, and data min-
ing. Heba is the recipient of the 2014 COMESA Innovation Award, the 2013 ACM SIGSPATIAL Conference
Best Paper Award, among others.

Geoinformatica

Moustafa Youssef is an Associate Professor at Egypt-Japan University of Science and Technology (E-JUST)
and Founder & Director of the Wireless Research Center of Excellence, Egypt. His research interests include
mobile wireless networks, mobile computing, location determination technologies, pervasive computing,
and network security. He is an associate editor for the ACM TSAS, a previous area editor of the ACM
MC2R and served on the organizing and technical committees of numerous prestigious conferences. Prof.
Youssef is the recipient of the 2003 University of Maryland Invention of the Year award, the 2010 TWAS-
AAS-Microsoft Award for Young Scientists, the 2012 Egyptian State Award, the 2013 and 2014 COMESA
Innovation Awards, the 2013 ACM SIGSpatial GIS Conference Best Paper Award, among many others. He
is also an ACM Distinguished Scientist and an ACM Distinguished Speaker.

