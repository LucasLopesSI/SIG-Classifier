Transactions in GIS, 2000, 4(2): 145–159

Research Article

A Geostatistical Approach to Modelling
Positional Errors in Vector Data

Jingxiong Zhang
University of California
Santa Barbara, California
USA

Roger P Kirby
The University of Edinburgh
UK

Abstract
As part of the theoretical development and practical applications of GISs, error
issues are receiving increasing attention. This paper contributes to the debate in
GIS error issues by exploring the applications of geostatistics in vector data, where
positional errors are of major concern. A review is provided of the methods for
handling positional errors in GIS vector data comprising points and lines. This is
followed by a description of a stochastic simulation approach to modelling
positional errors, which is remarkable for its ability to accommodate the spatial
correlation characteristics of spatial data and their errors. Results from an
experiment using photogrammetric data confirm the effectiveness of the proposed
approach for modelling positional errors. The simulation approach is also
examined with respect to other methods where due consideration is not given to
the spatial correlation that is intrinsic to positional errors. Stochastic simulation-
based modelling of uncertain vector data via raster structures represents a valuable
extension and contribution of geostatistical approaches to integrated handling of
errors in heterogeneous spatial data.

1 Introduction

Vector data, which depict the real world as discrete points and lines, constitute an
important type of spatial data incorporated into Geographic Information Systems
(GISs). Vector data can be obtained from primary sources such as photogrammetry and
from secondary sources such as map digitising. For example, from a stereopair of aerial
photographs reconstituted on an analytical plotter, photogrammetrists can identify and
land parcels, property
delineate landscape features, such as contours, buildings,

Address for correspondence: R P Kirby, Department of Geography, The University of Edinburgh,
Drummond Street, Edinburgh EH8 9XP, UK. E-mail: rpk@geovax.ed.ac.uk

(cid:223) 2000 Blackwell Publishers, 108 Cowley Road, Oxford OX4 1JF, UK and
350 Main Street, Malden, MA 02148, USA.

146

Jingxiong Zhang and Roger P Kirby

boundaries and road networks. These features are then recorded as points and lines to
facilitate data management and manipulation.

As is commonly understood in the surveying and mapping communities, vector
data are subject to gross, systematic and random measurement errors. Gross errors
may be identified by inspection or by repeated measurement (Kirby 1992a). Surveying
adjustment, of which least squares is widely known, is conventionally used to deal with
systematic and random errors in positional data (Cooper and Cross 1988). However,
errors therein are examined to a very limited extent. For instance,
in line plots
produced by photogrammetric digitising, only simple error estimates such as RMSEs in
position (X, Y) are reported, which provide global descriptions, but not information,
on the spatial variability of positional errors. Discussion of absolute and relative errors,
though useful, tends to be confined to a conceptual level: absolute errors refer to
individual points in isolation, while relative errors are associated with pairs of points.
But developments of GISs have greatly enhanced management and manipulation of
massive spatial data, and thus have also facilitated the handling of errors in spatial
data, including vector data (Berry 1987).

The first issue in researching errors is to identify them. In vector data, for spatial
entities populating spatial databases, which are modelled as objects (Goodchild 1992),
errors in position and errors of attributes are frequently discussed. The position of an
object is described by a set of coordinates, while its attributes are described by
qualitative and quantitative facts (Goodchild 1995). Assuming there is no error of fact
with respect to the identification and measurement of attributes, the main concern for
vector data is thus about their position (Drummond 1995).

The next concern is the description of these errors. Error descriptors such as error
ellipses and epsilon error bands are used in the handling of positional errors in points
and lines respectively, and have proved useful (Goodchild and Hunter 1997). Error
ellipses and epsilon error bands can be assigned to individual point and line features,
with the latter more commonly ascribed to the whole data set as global estimates.

How to model the errors is a more important issue. One method is to use analytic
tools such as variance propagation to ascribe mathematical formulae for specific data
sets or geo-processing tasks (Drummond 1995). Modelling errors is more effectively
and flexibly carried out by simulating alternative, equal-probable realisations of a
vector data set so that it is possible to analyse the propagation of errors from source
data sets such as polygon coverages to an overlaid coverage (Goodchild 1992). Based
on error modelling, both data producers and data users are able to assess the fitness of
a particular data product for a certain purpose.

The process of modelling enables exploration of spatial variability and thus the
spatial correlation of errors, which is crucial for geographical studies, where conven-
tional methods for handling positional errors are rather lacking. This paper seeks to fill
a gap in research on positional errors in vector data by exploring the possibilities by
which the spatial variability of positional errors may be usefully accommodated.

2 Modelling Positional Errors: Problems and Prospects

Error is understood as the discrepancy between a measured value and the true value.
Positional errors are the differences between the measured and the assumed true
coordinates. Positional error is often termed displacement or distortion in coordinates.

(cid:223) Blackwell Publishers Ltd. 2000

Modelling Positional Errors

147

Figure 1

Error descriptors: (a) error ellipse, and (b) epsilon error band.

Error ellipses are suitable models as well as descriptors of positional errors in
points. Thus, given parameters for an error ellipse, one is able to simulate distorted
point samples, which conform to the distribution prescribed by the parameters given.
Isolines correspond to different confidence levels in assessing the closeness between the
measured and the true points (as shown in Figure 1a).

For lines, the situation becomes more complicated. Epsilon error bands, though
useful as good error descriptors, fall short of error models that can be used to generate
realisations of equal-probable lines, unless points comprising lines are assumed to be
homogeneous and uncorrelated. This is because, unlike an error ellipse model with
parameters defining variance and covariance in and between x and y coordinates, an
error band width alone does not provide any information on the spatial correlation
that may be significant between errors in points comprising a line. Besides, the error
band width of a line does not have simple relationships with error ellipses in its
component points. However, if it is possible to devise methods for simulating lines with
spatially correlated errors in points properly incorporated, epsilon error bands can be
derived from overlaid simulated lines and graphically represented with isolines of
increasing confidence growing outwards, as is shown in Figure 1b.
Autoregressive methods have found useful applications

in description of
cartographic boundaries based on curvatures (Garcia et al 1995). Computer scientists
have also contributed to the discussion of GIS errors, by introducing the methods of
deformable templates and deformable contours (Jain and Zhong 1996). A deformable
template is constructed as a 2-dimensional displacement field of a continuous function
with certain boundary conditions. Kiiveri (1997) was able to extend the use of a
deformable template with a trigonometric diagonal basis to simulate distorted
polygonal data. However, the spatial correlation of the positional errors has rarely
been accommodated in an explicit way in the past. Even when spatial correlation is
admitted in a general form, there are no easy methods to follow for incorporating the
spatial variability into practical use.

In this paper, lines are defined as topologically structured line segments connecting
vertices. Thus, stochastic realisations of lines can be generated by simulating vertices
which follow certain stochastic characteristics, as can be seen in Figure 2.

One of the main stochastic characteristics considered here is spatial correlation.
Simulation is better performed via raster fields depicting errors as the variables
(attributes). The application of raster structures in the study of vector data error may
surprise some GIS analysts because vector and raster are usually treated in GISs as two

(cid:223) Blackwell Publishers Ltd. 2000

148

Jingxiong Zhang and Roger P Kirby

Figure 2

Lines simulated from stochastic points.

Figure 3 A polygonal data model.

distinctive data structures. However, the use of raster structures for vector data is
justified for reasons illustrated by the following example.

Figure 3 shows a polygonal data structure where three areas (c1, c2 and c3) are
created from 9 points (a1–a9) and 6 lines (a1a2a9a3; a3a8a7; a7a6a5a1; a1a4; a4a3; a4a7).
Consider a point u(x,y) lying on the line segment a4a3, which is also on the line drawn
from a9 and perpendicular to the line segment a4a3 (Figure 3). Suppose the probability
density function for point u is defined as pdf(u), as shown in Figure 4a. Kiiveri (1997)
provides a Fourier series model for such a pdf. Though not explicitly indicated in the
discussion above, the description of area c1 will not be complete without correct
identification. This is associated with the assumption underlying object-based data
models, which is effectively represented, again, by probability.

By virtue of discrete objects and assuming no error in object identification, the
probability of identifying area c1 (denoted by pr(A)) along the profile ua9 is a crisp set:
pr(A) is 1.0 if located along the profile, 0.0 otherwise, as shown in Figure 4b. The
combined effect of the pdf and object identification of area c1 is exhibited by Figure 4c,
resulting in non-sharp boundaries of area. A similar observation is made in Kiiveri
(1997).

When dealing with pure points and lines, as opposed to areas, the results may
appear unusual. It is not difficult to show that the probability of precisely locating a
point, say point u in Figure 3, will become vanishingly small (Goodchild 1996, pers
comm). The same result applies to lines of zero width (i.e. geometric lines), as the
convolution operation leading to Figure 4c is, in fact, a two-dimensional calculation.
However, one might have anticipated that the probability of a point lying exactly at a

(cid:223) Blackwell Publishers Ltd. 2000

Modelling Positional Errors

149

Figure 4
(c) their combination.

Positional error: (a) a probability density function, (b) object identification, and

location or along a specified line should be a positive value, based on a crisp set-based
interpretation of objects.

To resolve the problems in evaluating probability of locating pure points and lines,
it is worth reminding ourselves that real world points and lines have finite sizes. In
other words, pure points and lines do not exist in reality and polygonal boundaries
have to be simplified to permit digital processing of spatial data. For example, map
lines may represent roads and rivers of finite width, and lake shorelines on maps are
commonly approximated by generalised line segments. Even well-defined point and
line objects measured with acceptable accuracy will have effective sizes due to
positional errors, leading to the existence of objects of finite sizes in spatial databases.
It will be more objective and sensible to conceive a vector data set as a raster of variable
resolution associated with positional errors than as discrete geometric primitives of
spurious accuracy. Such a raster-based strategy will ensure that zero probability ceases
to occur at raster cells on or containing individual objects. Therefore, the introduction
of a raster structure, whose equivalent resolution is adapted to the inherent positional
error of
justified as a move to
accommodate positional errors and to permit flexibility in geo-processing.

the underlying vector-structured data,

is well

Further, simulation is often more concerned with reproducing certain global
spatial variability than with getting the best local estimates for the variables under
study. Thus, the approximation involved in the transformation between raster and
vector is a trade-off for mapping spatial variability in positional errors. Dunn et al
(1990) provided empirical evidence that there is a certain parallel between raster data
and vector data of limited accuracy.

(cid:223) Blackwell Publishers Ltd. 2000

150

Jingxiong Zhang and Roger P Kirby

Surfaces of positional errors may be simulated with prescribed degrees of spatial
autocorrelation denoted by the parameter (cid:26) (Haining et al 1983). This is an
unconditional simulation, which is usually performed in an iterative way so that the
resulting surface recovers the degree of spatial autocorrelation aimed for. Usually,
pseudo random numbers are generated from a computer.

Conditional simulation is more useful than an unconditional simulation as the
former uses both available observation data and previously simulated data to condition
a simulated data set. Another advantage of conditional simulation lies in its ability to
quantify and incorporate the degree of spatial correlation intrinsic to a particular data
set,
leading to a data-driven solution. Geostatistics provides the facilities for
conditional simulation, as will be described in the next section.

3 Modelling with Spatial Correlation: Geostatistical Simulation

To conduct a conditional simulation, the spatial correlation in the underlying process
or properties (attributes, errors, etc.) must be quantified and modelled properly. In
geostatistics, the properties of interest are modelled as spatially correlated random
variables. A random variable is a variable that can take a variety of outcome values
according to some probability (frequency) distribution, which is usually denoted by Z
(Journel 1996). Examples include pollution concentration and population densities.
Under the intrinsic hypothesis assumption, there is a stationary variance of the
differences in a random variable between places separated by a given distance and
direction. The semi-variance of difference (usually denoted by (cid:13)) is half of the expected
(E) squared difference between two values:

(cid:13)(cid:133)h(cid:134) (cid:136) E(cid:137)fz(cid:133)x(cid:134) (cid:255) z(cid:133)x (cid:135) h(cid:134)g2(cid:138)=2

where z(x) and z(x+h) are the values of variable Z at positions x and x+h
respectively; h is the lag which describes a separation in both distance and direction
between two positions. The function that relates (cid:13) to h is called the semivariogram,
which is the function used to quantify the spatial correlation and to guide interpolation
known as Kriging (Cressie 1991).

An experimental semivariogram can be estimated from sample data. The formula is:

^(cid:13)(cid:133)h(cid:134) (cid:136)

1
2M(cid:133)h(cid:134)

XM(cid:133)h(cid:134)

i(cid:136)1

fz(cid:133)xi(cid:134) (cid:255) z(cid:133)xi(cid:135)h(cid:134)g2;

where M(h) is the number of pairs of observations separated by lag h. By changing h, a
set of values is obtained, from which the experimental semivariogram is constructed.
Consider the distribution of a random variable Z over a field A, {z(u), u(cid:15)A}.
Stochastic simulation is the process of building alternative, equally probable, high
resolution models of z(u), with each realisation denoted with the superscript l: {z(l)(u),
u(cid:15)A}. Conditional simulation results in realisations that honour the data values of
observations z(u(cid:11)):

z(cid:133)1(cid:134)(cid:133)u(cid:11)(cid:134) (cid:136) z(cid:133)u(cid:11)(cid:134)

Consider the joint distribution of N random variables Zi with N very large, where the
N variables Zi represent the variable Z at the N nodes of a dense grid discretising the

(cid:133)1(cid:134)

(cid:133)2(cid:134)

(cid:133)3(cid:134)

(cid:223) Blackwell Publishers Ltd. 2000

Modelling Positional Errors

151

field A. A common approach in stochastic simulation is the Gaussian sequential
simulation approach. In this approach, all univariate values of the conditional
cumulative distribution function (ccdf) of Zi are assumed Gaussian, and conditioning
includes original data and all previously simulated values (denoted by |(n)). Thus, an
N-variate ccdf is written as:

F

(cid:133)N(cid:134)

(cid:133)z1; . . . ; zNj(cid:133)n(cid:134)(cid:134) (cid:136) probabilityfZi (cid:20) zi; i (cid:136) 1; . . . ; Nj(cid:133)n(cid:134)g

(cid:133)4(cid:134)

Successive application of the conditional probability relation shows that drawing an N-
variate sample from equation (4) can be accomplished in N successive steps, each using
a univariate ccdf. The procedure for a Gaussian sequential simulation is as follows:

(1) determine the univariate cdf F(Z) (z) for the entire field A;
(2) perform the normal score transform of z-data into y-data with a standard normal

cdf;

(3) define a random path by which each node of the grid is visited;
(4) use simple Kriging with the normal score variogram model to determine means

and variance of the ccdf of the random variable Yi;

(5) draw a value y1

(l) from the univariate ccdf of Y1 given original data (n), and update

the conditioning data set to (n+1) (cid:136) (n) [ {Y1 (cid:136) y1

(l)};

(6) proceed to the next node, and loop until all N random variables Yi are simulated

with increasing levels of conditioning; and
(7) back-transform the simulated normal values {yi

(l), i (cid:136) 1; . . ., N} into a simulated

joint realisation {zi

(l), i (cid:136) 1; . . ., N} of the original variables.
Usually, position and attributes are separable for well-defined spatial entities,
implying that attributes can be handled independently of position. However, for
positional errors, as
simulation involves direct
displacement of positions in points and lines, and there is no guarantee that
topological structures are maintained in simulated data, which are distorted versions of
original vector data. Thus, there is a need in stochastic simulation for positional errors
to check for any topological inconsistency that might be incurred in simulated vector
data.

special attributes of entities,

Assume that topology is built appropriately for a vector data set before simulation.
Topological consistency may be violated due to unchecked simulation (distortion) of
lines and polygons, in which distorted lines and polygons are intersected unduly (often
to themselves), leading to folding. Figure 5 illustrates the situation where a fold results
from simulated displacement values z1 and z2 corresponding to the two grid nodes 1
and 2, as shaded in the diagram. In Figure 5, dx is the size of grid cell in the x direction,
while dz is the increment of values from grid node 1 to 2 (i.e. dz (cid:136) z2(cid:255)z1), with positive
values of z1 and z2 being shown. The condition under which a fold is formed is written
as:

z2 (cid:255) z1 (cid:20) (cid:255)dx or dz=dx (cid:20) (cid:255)1

(cid:133)5(cid:134)

The condition indicated in equation (5) is interpreted to show a fold is formed if the
difference of simulated values of two neighbouring grid cells is no greater than the
negative of the grid cell size along the direction of the profile passing them. Figure 6
shows an example in which a line and a polygon intersect after simulation, a typical
result of folding.

(cid:223) Blackwell Publishers Ltd. 2000

152

Jingxiong Zhang and Roger P Kirby

Figure 5

The condition when a fold forms.

Figure 6 A hypothetical example of a fold:
simulated data set.

(a) the original vector data set, and (b) a

4 An Experiment

4.1 Test Site and Data Sources

Mapping of suburban areas involves a range of medium and large-scale data products,
usually incorporating precise positional data for buildings, street networks,
land
records and contours on the one hand, and environmental data such as soil type and
noise level on the other hand (Jensen 1983). Therefore, there is a need in suburban
applications to combine data sets with quite different positional and attribute
accuracies. This is the main reason why this experiment was undertaken in a suburban
area where data sets of varying accuracies provide a more realistic test of error issues.
The varied and concentrated nature of any urban fabric requires that spatial data
for urban applications should be recorded at large scale, to permit more accuracy.
Accurate positions may be obtained by land surveying, principally by use of total
stations and GPS. An accuracy of centimetres is usually achievable, allowing for
detailed mapping at 1:2,500 or larger scales. Using photogrammetric techniques in
urban areas for increased efficiency, aerial photographs at large and medium scales are
normally used for topographic and thematic mapping. An Edinburgh suburb was
chosen as the test site, with the 1:24,000 scale aerial photographs being used to generate

(cid:223) Blackwell Publishers Ltd. 2000

Modelling Positional Errors

153

test data and 1:5,000 scale aerial photographs to provide reference data. The 1:24,000
scale aerial photographs (in natural colour) were flown in mid June 1988, as a part of
the Scottish national aerial photographic initiative (Kirby 1992). The 1:5,000 scale
aerial photographs are in natural colour and are part of a July 1990 experimental sortie
of high resolution material flown for the Ordnance Survey.

Ground control for the aerial photographs was established by land surveying,
which, in turn, enabled the implementation of a photogrammetric block adjustment
using the 1:5,000 scale aerial photographs. This block consists of two strips of
photographs, each of five stereo-models, generating photocontrol for photogrammetric
digitising based on the 1:5,000 scale aerial photographs. One stereo model using the
1:24,000 scale aerial photographs was orientated using ground control points obtained
jointly by the land surveying and the block adjustment (Zhang 1996).

4.2 Photogrammetric Digitising

entities

extracted include property boundaries

Photogrammetric digitising was then performed using an AP190 analytical plotter. The
spatial
and walls),
houses(buildings), footpaths and the margin of a large pond. Both the test data and
reference data were transformed into ARC/INFO coverages for ease of management
and data analysis. The vector data are shown mapped in Figure 7, where dashed lines
and solid lines are based on the 1:24,000 scale and 1:5,000 scale aerial photographs
respectively.

(hedges

To provide initial estimation of the positional accuracy of points digitised from the
1:24,000 scale aerial photographs, a test was carried out in which the measured
coordinates of a few well-defined points such as outstanding landmarks, bounding

Figure 7
photographs (dashed lines) and the 1:5,000 scale aerial photographs (solid lines).

Photogrammetrically digitised vector data using the 1:24,000 scale aerial

(cid:223) Blackwell Publishers Ltd. 2000

154

Jingxiong Zhang and Roger P Kirby

Table 1 Accuracy estimate for photogrammetrically digitised points (unit: metres)

Test

model scale
1:24,000

number of points
15

RMSE

sdx
0.595

sdy
0.569

corners, centres of manholes and road junctions are checked against the points
densified from the block adjustment based on the 1:5,000 scale aerial photographs. The
checking points were not those used in controlling the 1:24,000 scale stereo model, so
that independence in checking is not violated. Results are listed in Table 1, with
RMSEs of the planimetric (X, Y) data (ASPRS 1989).

The task of evaluating accuracy becomes less straightforward when dealing with
lines and polygons. A usual way of doing this is by overlaying the test data set with an
assumed reference data set so that estimates of digitising accuracy descriptors such as
epsilon error band width may be obtained. However, as discussed in Section 2, it is not
adequate for those error descriptors to be used as vector error models to predict the
accuracy of derivative data products such as line lengths and polygon areas by means of
variance propagation, unless homogeneity and spatial
independence of positional
errors among points are assumed. The method used in this experiment was to apply
conditional simulation to simulate alternative versions of the test data in order to
model errors in the source data and assess the consequences of using them in a certain
map operation.

4.3 Stochastic Simulation of Vector Data

Stochastic simulation is supported in the geostatistical software package GSLIB
it is
(Deutsch and Journel 1992). Before implementing a stochastic simulation,
necessary to compute experimental
semivariograms and then create suitable
semivariogram models. For this, the test vector data digitised from the 1:24,000 scale
aerial photographs were overlaid with the reference data acquired from the 1:5,000
scale aerial photographs. Thus, it was possible to match points (including nodes and
line vertices) across the two data layers, and to compute the displacements for
individual points. This process resulted in an extended ARC/INFO point attribute data
(PAT) file comprising IDs, reference coordinates and the displacements among others
for 785 points correctly matched.

Data were re-organised from the PAT file to build a new data file suitable for
GSLIB to calculate semivariograms. Experimental semivariograms for the positional
errors in X and Y coordinates are shown in (a) and (b) of Figure 8, respectively. As a
requirement in Gaussian based simulation, the original error data were transformed
into normal scores. Experimental semivariograms were then calculated for normal
scores of positional errors in X and Y coordinates, which are shown as diamonds in (a)
and (b) of Figure 9 respectively. Model fitting is very important and may require
comparing alternative models. Inspection of Figure 9 suggests using spherical and
Gaussian models. Analysis of variance for residuals in regression indicated slightly
better fitting of Gaussian as opposed to spherical models: F statistics values are 2.39
and 3.57 for Gaussian and spehrical models respectively in terms of the X coordinate,
and 2.79 and 3.00 in terms of the Y coordinate, with a critical value F1, 54 equal to 4.02

(cid:223) Blackwell Publishers Ltd. 2000

Modelling Positional Errors

155

Figure 8
coordinate.

Experimental semivariograms for positional errors in: (a) X coordinate, and (b) Y

Figure 9
coordinate, and (b) Y coordinate.

Semivariograms and models for normal scores of positional errors:

(a) X

at the 5% significance level, though residuals were all insignificant. Fitted models are
shown in Figure 9, where the solid and dashed lines correspond to Gaussian and
spherical models respectively, with Gaussian models chosen (nugget effect, sill and
range being 0.15, 0.85 and 4.5 m for the X coordinate, and 0.2, 0.8 and 5.5 m for the Y
coordinate).

Stochastic simulation was then performed using a Gaussian sequential simulation
program SGSIM provided in GSLIB. The parameter file was supplied with suitable
data including grid cell size (8 by 8 metres), ranges, sills and nugget effects describing
semivariogram models. Ten realisations were created from SGSIM for X, Y
independently, and were added as new data items in the PAT file mentioned above.
Ten versions of vector data were generated from the expanded PAT file, and these were
then overlaid, in dashed lines, with the original vector data digitised from the 1:24,000
scale aerial photographs (in solid lines) in Figure 10.

Topological inconsistency was checked using the criterion expressed in equation
(5). It was found that no folding occurred when grid cell size (dx) was set at 8.0 m and
4.0 m, but six folds were registered when grid cell size (dx) was set at 2.0 m. It can be
seen that there exists a case of topological inconsistency at the middle west side of
Figure 10, where houses and property boundaries are too crowded to register an exact
simulation with topology.

(cid:223) Blackwell Publishers Ltd. 2000

156

Jingxiong Zhang and Roger P Kirby

Figure 10 Conditionally simulated vector data (dashed lines) overlaid with the original
data (solid lines).

4.4 Errors of Polygonal Areas

Area calculation represents a classical yet important function of GISs. Areas calculated
from vector data will reflect any positional errors in the points and lines defining the
area polygons. How to predict errors in area estimates is a topic of continuing research
(Chrisman and Yandell 1988, Prisley et al 1989, Kiiveri 1997).

In this experiment, attention was given to the area estimates for two polygons, the
pond and a house, as labelled in Figure 10. Using the formulae in Chrisman and
Yandell (1988), area estimates were obtained for the two polygons based on the
original vector data (digitised from the 1:24,000 scale aerial photographs). Assuming
zero correlation among adjacent points and independence between X and Y
coordinates, theoretical values of standard errors in area estimates were also computed
for the two polygons based on the point error estimates shown in Table 1.

Ten versions of simulated vector data sets were examined with respect to the
means and standard errors in the area estimates for the two polygons. It can be seen
from Table 2 that the simulated data tend to underestimate the mean area of the house

Table 2 Means and standard errors for polygonal areas based on the formulae (I) and the
simulated data (II) (units: m2)

Polygons

house
pond

Number
of points

10
136

Means

I

II

Standard errors
II
I

118.34
7954.33

111.61
8107.30

6.84
18.29

10.77
35.91

(cid:223) Blackwell Publishers Ltd. 2000

Modelling Positional Errors

157

and overestimate the mean area for the pond. Both polygons register significantly
larger values of standard errors from the simulated data than from the theoretical
estimates. Using (cid:31)2 statistic with 9 degrees of freedom, the null hypothesis of equal
variances in area estimates was rejected at the 5% significance level for both polygons.
Thus, it is confirmed that significant spatial correlation does exist in positional errors,
and an objective assessment of the errors in area quantities computed from vector data
limited accuracy must be based on appropriate accommodation of spatial
of
correlation intrinsic to positional errors.

4.5 Discussion

The test described a geostatistical approach to modelling positional errors, which is
built upon the capability and flexibility of raster structures to accommodate spatial
heterogeneity and correlation. While the necessity for discrete digital representation of
objects in spatial databases is widely admitted, the idea of using a raster of finite
resolution for modelling of uncertain vector data seems hardly convincing at first
instance. In this experiment, spatial correlation in positional errors was confirmed to
exist and quantified by semivariograms, by which accuracy of polygonal areas was
shown to be significantly affected. To facilitate computer simulation of spatially
correlated errors, rasters were hence adopted, which were conceived to be composed of
spatially varying and dense fields of positional errors, upon which vector data were
overlaid and interpolated at data points. Moreover, the existence of positional errors in
vector data requires that one has to live with a digital world of finite resolution and
accuracy. Thus, the raster-based methods for handling positional errors of vector
origin should not be seen as an imposed limitation but a sensible adaptation to reality.
Figure 10 shows that topological inconsistency (e.g. folding) occurred when the
raster resolution was set at 2 m, the finest resolution tested. This resolution may be too
fine to accommodate the spatial variation of positional errors in the original vector
data, leading to an increased possibility of folding. The issue of matching resolution
(precision) to accuracy remains because of the need to avoid the occurrence of artifacts
such as folds when performing computer simulation of error-stricken vector data.
Goodchild (1999) recently reviewed some of the key issues affecting objects and
positional errors. It should be emphasised that occurrence of topological inconsistency
should not be seen to be confined to or taken as a proof of invalidity of raster-based
simulation methods for data of vector origin. Other simulation methods are not
necessarily immune to this type of problems, as documented in Hunter and Goodchild
(1996) and Kiiveri (1997).

This experiment has considered a special type of vector data which comprises
well-defined point and line objects, reinforcing the versatility of simulation in
modelling positional errors (Hunter and Goodchild 1996). There are, however,
other types of vector data created from continuous curves (Garcia et al 1995) and
even greater complications occur in the case of poorly defined objects such as
boundaries in resource inventory data, where boundary lines may not be interpreted
on a pure geometric basis: boundary lines are actually zones of uncertainty, as
highlighted in Burrough and Frank (1996). Therein, Boolean logic underlying
conventional probabilistic methods is less suitable than fuzzy set theory which has
been greeted with growing popularity in research on geo-spatial data modelling and
analysis.

(cid:223) Blackwell Publishers Ltd. 2000

158

Jingxiong Zhang and Roger P Kirby

5 Conclusions

This paper has examined the possibilities by which spatial correlation may be usefully
explored in the handling of positional errors in vector data. An empirical study using
photogrammetric data for an Edinburgh suburb has shown that geostatistics can be
applied to analyse vector data and photogrammetric data in particular without major
difficulties. The results also confirm that spatial correlation can and should be
incorporated in the analysis of positional errors.

The emphasis on positional errors in vector data is in contrast with the case of
raster data, whose main concerns are spatial resolution and attribute errors. For this
reason, there is a growing literature on applying novel methods such as geostatistics
and fuzzy sets for enhanced geo-processing of spatially varying errors in qualitative and
quantitative attributes. These methods can be used to explore spatial correlation in
attribute errors and have met with remarkable success in analysis of remotely sensed
images (increasingly in raster data format) and other geo-spatial data.

It is thus clear that the experiment reported in this paper extends the application of
geostatistics into the handling of positional errors: spatial correlation is also central to
positional errors and as such, should be sensibly explored. For photogrammetric and
remote sensing specialists, geostatistics is not a luxury curiosity but an enabling vision,
which will greatly enhance the productivity and reliability of
the image-based
information industry.

Comments from two anonymous reviewers helped to improve the exposition of the
paper. Dr Zhang’s contribution to this article was made while working at Wuhon
Technical University of Surveying and Mapping, P R China.

Acknowledgements

References

American Society for Photogrammetry and Remote Sensing (ASPRS) 1989 ASPRS interim
accuracy standards for large-scale line maps. Photogrammetric Engineering and Remote
Sensing 55: 1038–40

Berry J K 1987 Computer-assisted map analysis: Potential and pitfalls. Photogrammetric

Engineering and Remote Sensing 53: 1405–10

Burrough P A and Frank A U (eds) 1996 Geographic Objects with Indeterminate Boundaries.

Chrisman N R and Yandell B S 1988 Effects of point error on area calculations: A statistical

Basingstoke, Taylor and Francis

model. Surveying and Mapping 48: 241–6

Cooper M A R and Cross P A 1988 Statistical concepts and their application in photogrammetry

and surveying. Photogrammetric Record 12: 637–63

Cressie N A C 1991 Statistics for Spatial Data. New York, John Wiley and Sons
Deutsch C V and Journel A G 1992 GSLIB: Geostatistical Software Library and User’s Guide.

New York, Oxford University Press

Drummond J E 1995 Positional accuracy. In Guptill S C and Morrison J L (eds) Elements of

Spatial Data Quality. Oxford, Elsevier: 31–58

Dunn R, Harrison A R, and White J C 1990 Positional accuracy and measurement error in digital
International Journal of Geographical

land use: An empirical study.

databases of
Information Systems 4: 385–98

(cid:223) Blackwell Publishers Ltd. 2000

Modelling Positional Errors

159

Garcia J A, Fdez-Valdivia J, and Perez de la Blanca N 1995 An autoregressive curvature model

for describing cartographic boundaries. Computers and Geosciences 21: 397–408

Goodchild M F 1992 Geographical Information Science. International Journal of Geographical

Information Systems 6: 31–46

Goodchild M F 1995 Attribute accuracy. In Guptill S C and Morrison J L (eds) Elements of

Spatial Data Quality. Oxford, Elsevier: 59–79

Goodchild M F 1999 Keynote Speech: Measurement-based GIS. In Shi W, Goodchild M F and
Fisher P F (eds) Proceedings of the International Symposium on Spatial Data Quality, Hong
Kong: 1–9

Goodchild M F and Hunter G J 1997 A simple positional accuracy measure for linear features.

International Journal of Geographical Information Systems 11: 299–306

Haining R, Griffith D A and Bennett R 1983 Simulating two-dimensional autocorrelated

surfaces. Geographical Analysis 15: 247–55

Hunter G J and Goodchild M F 1996 A new model for handling vector data uncertainty in
Geographic Information Systems. Journal of the Urban and Regional Information Systems
Association 8: 51–7

Jain A K and Zhong Yu 1996 Object matching using deformable templates. IEEE Transactions

on Pattern Analysis and Machine Intelligence 18: 267–77

Jensen J R 1983 Urban/suburban land use analysis. In Colwell R N (ed) Manual of Remote

Sensing. Falls Church, VA, The Sheridan Press: 1571–666

Journel A G 1996 Modelling uncertainty and spatial dependence: Stochastic imaging.

International Journal of Geographical Information Systems 10: 517–22

Kiiveri H T 1997 Assessing, representing, and transmitting positional uncertainty in maps.

International Journal of Geographical Information Systems 11: 33–52

Kirby R P 1992 The 1987-1989 Scottish national aerial photographic initiative. Photogrammetric

Kirby R P 1999 Revision measurement of large scale topographic data. OEEPE Official

Record 14: 187–200

Publication 36: 13–69

Prisley S P, Gregoire T G and Smith J L 1989 The mean and variance of area estimates computed
Information System. Photogrammetric Engineering and

in an arc-node Geographical
Remote Sensing 55: 1601–12

Zhang J 1996 A surface-based approach to the handling of uncertainties in an urban-orientated

spatial database. Unpublished PhD Thesis, University of Edinburgh

(cid:223) Blackwell Publishers Ltd. 2000

