The Cartographic Journal
The World of Mapping

ISSN: 0008-7041 (Print) 1743-2774 (Online) Journal homepage: http://www.tandfonline.com/loi/ycaj20

Teragons for Testing Implementations of Point
Reduction Algorithms

Mahes Visvalingam

To cite this article: Mahes Visvalingam (2018) Teragons for Testing Implementations
of Point Reduction Algorithms, The Cartographic Journal, 55:3, 256-272, DOI:
10.1080/00087041.2017.1414017

To link to this article:  https://doi.org/10.1080/00087041.2017.1414017

Published online: 18 Oct 2018.

Submit your article to this journal 

Article views: 12

View Crossmark data

Full Terms & Conditions of access and use can be found at
http://www.tandfonline.com/action/journalInformation?journalCode=ycaj20

THE CARTOGRAPHIC JOURNAL
2018, VOL. 55, NO. 3, pp. 256–272
https://doi.org/10.1080/00087041.2017.1414017

REFEREED PAPER

Mahes Visvalingam

Department of Computer Science, University of Hull, Hull, UK

Teragons for Testing Implementations of Point Reduction Algorithms

scope for

line generalization.

The algorithm provides

ABSTRACT
There are several open source and commercial implementations of the Visvalingam algorithm
implementation-speciﬁc
for
interpretations, with diﬀerent outcomes. This is inevitable and sometimes necessary and, it
does not imply that an implementation is ﬂawed. The only restriction is that the output must
not be so inconsistent with the intent of the algorithm that it becomes inappropriate. The
aim of this paper is to place the algorithm within the literature, and demonstrate the value
of the teragon-test for evaluating the appropriateness of implementations; Mapshaper v
0.2.28 and earlier versions are used for illustrative purposes. Data pertaining to natural
features, such as coastlines, are insuﬃcient for establishing whether deviations in output are
signiﬁcant. The teragon-test revealed an unexpected loss of symmetry from both the
Visvalingam and Douglas-Peucker options, making the tested versions unsuitable for some
applications, especially outside of cartography. This paper describes the causes, and
discusses their implications. Mapshaper 0.3.17 passes the teragon test. Other developers and
users should check their implementations using contrived geometric data, such as the
teragon data used in this paper, especially when the source code is not available for
inspection. The teragon-test is also useful for evaluating other point reduction algorithms.

KEYWORDS
Teragon-test;
implementations of point
reduction algorithms by
Visvalingam and Douglas-
Peucker; Mapshaper

Introduction

Visvalingam (2015a) explained why the speciﬁcation of Visvalingam’s algorithm (Visvalingam and Whyatt, 1992;
1993; Whyatt, 1991) was not overly prescriptive and open to variations in implementation. The primary aim of this
paper is to alert implementers and package users of the scope for variations and potential errors in the
implementation and use of Visvalingam’s algorithm. David Luebke (May 2015, personal communication)
pointed out that Schroeder et al. (1992) had proposed a similar approach in 3D graphics, which they called
decimation, for reducing the vertices in 3D meshes. Their and subsequent research are covered in the surveys
by Cignoni et al. (1998), Luebke et al. (2003) and Garland and Zhou (2005).

Visvalingam’s algorithm was popularized by Bloch’s (2015) open source Mapshaper program, by Bostock’s
(2012) demonstrator and Javascript code; and, by republication of the original paper by Visvalingam and
Whyatt (1993) in Field and Kent (2014). Visvalingam and Whelan (2014) found that Mapshaper’s weighted
Visvalingam area metric provided more pleasing simpliﬁcations of coastlines but noted some diﬀerences in
output between Mapshaper’s Visvalingam eﬀective area (EA) option and Visvalingam’s implementation of the
algorithm.

Visvalingam (2015b) explored whether the Mapshaper implementation had any unexpected errors over and
above expected variations in implementation. It focused on whether implementations conformed to the
speciﬁcation of the algorithm, so as to assess their suitability for intended uses. It was not overly concerned
with the properties of the algorithm or with metrics and measures. This paper provides an update based on
dialogues with others, especially Matthew Bloch (the author of Mapshaper), and includes an extended
background, a description of possible sources of error, and a revised discussion and conclusion. It suggests that
similar implementation issues may arise with other geometric algorithms, using a ﬁgure in Garland and Zhou
(2005) as an example. More recent versions of Mapshaper pass the teragon-test. Other developers and users
could check their own implementations of geometric algorithms using the teragon-test, especially when the
source code is not available.

Background

This section starts by explaining how Visvalingam’s algorithm for point reduction diﬀers from its predecessors with
respect to its aims and approach (Section ‘Line generalization versus line approximation’). It then describes the

CONTACT Mahes Visvalingam

m.visvalingam@hull.ac.uk

© 2018 British Cartographic Society

algorithm and its usage (Section ‘Visvalingam’s algorithm’) and reviews some similar algorithms in Computer
Graphics and Pattern Recognition (Section ‘Other global search and merge algorithms’).

THE CARTOGRAPHIC JOURNAL

257

Line generalization versus line approximation

As Garland and Zhou (2005: 3) stated ‘The study of curve simpliﬁcation has a much longer history than surface
simpliﬁcation’. In cartography, curve simpliﬁcation is commonly referred to as line (polyline) simpliﬁcation.
Heckbert and Garland (1997: 2) deﬁned decimation as a ‘ﬁne-to-coarse approach starting with an exact ﬁt, and
discarding details to create less and less accurate approximations’. Schroeder et al. (1992) had used the term
decimation to refer to the reduction of triangle meshes by iterative elimination of the vertices until some
threshold condition was reached. Visvalingam’s algorithm (Visvalingam and Whyatt, 1992; 1993) involved the
iterative elimination of points (vertices) from polylines.

Since Visvalingam’s algorithm was not included in the surveys provided by Heckbert and Garland (1997) and
others, this paper explains where it ﬁts. Jenks’ (1981) levels of generalization are useful for understanding the
cartographic reasons for vertex reduction. His primary distinction was between output lines which were no
longer recognisable after generalization, and those which were. The latter he classed into (a) those which were
perceived as essentially the same as the original (referred to here as approximations) and (b) those which were
seen as distinctly diﬀerent versions of the original (generalizations). The former were the product of line
approximation algorithms, which removed superﬂuous points, errors and some insigniﬁcant features. The
same algorithms were, and still are, taught and used with much larger tolerances for line simpliﬁcation and
generalization. However, manual line generalization involves the removal of scale-related features in their
entirety; this was diﬃcult to achieve with available approximation algorithms. Visvalingam found by trial-and-
error that the method of iterative point removal, driven with the concept of EA, could even achieve caricatural
generalizations in which the original line can be portrayed with very few points. Whyatt (1991) included
Visvalingam’s algorithm in his evaluation of
line generalization algorithms. The algorithm was formally
presented in Visvalingam and Whyatt (1992; 1993). These two aims of polyline reduction are discussed below
to explain the position of the algorithm within digital cartography, before reviewing the Visvalingam and
similar algorithms.

Line approximation
In the early days, the main concern in digital cartography, pattern recognition and in 3D computer graphics was the
approximation of polylines/polygons and surfaces – not generalization. Manual digitization of the lines on maps
and algorithmic extraction of boundaries of polygons on scanned images gave rise to superﬂuous points and errors.
Diﬀerent approaches were explored to remove errors and to represent polylines by a reduced number of vertex
points. Koning’s (2012) psimpl is a lightweight header-only C++ library which includes some of these early
algorithms, which were reviewed by McMaster (1987). Ignoring Nth point sampling, the other point reduction
algorithms tend to fall into two classes, namely those based on:

. Sequential search. These were partly inﬂuenced by the restrictions of the technology of the day and include
some of the early algorithms which incrementally worked through the line, from start to ﬁnish, rejecting any
points which fell outside a tolerance band (sometimes called a sleeve or envelope) deﬁned on diﬀerent
criteria within a search region. Some sequential point elimination algorithms used other criteria, such as the
curvature of the line at a given point (See Weibel, 1997). Similar sequential algorithms were reported in
Pattern Recognition. Leu and Chen (1988) and Boxer et al. (1993) are widely cited by others seeking to
improve on the quality and/or speed of the sequential approach. Such sequential algorithms which retain
points by a process of elimination are referred to as merge algorithms since the algorithm connects the two
segments of the original line after a vertex or a segment of the line is eliminated. This class of algorithms
includes piecewise linear approximations of curves, which is outside the scope of this paper.

. Global search. The algorithm proposed by Ramer (1972) and by Douglas and Peucker (1973), now known as the
RDP algorithm, belongs to this category. Unlike the sequential algorithms, which were focused on rejecting
points, the RDP algorithm and its variants simplify by recursive or iterative selection of points. The
algorithm selects the point with the maximum oﬀset from the line joining the start and end points, and
divides the original line into two parts at this point. These two parts are recursively subjected to the same
procedure. In Pattern Recognition, the RDP algorithm is classed with split algorithms, i.e. those which split
the original line into smaller and smaller segments, which may be independently processed.

258

M. VISVALINGAM

Maps consist of complex detail and mapping agencies provide access to maps at multiple levels of detail (LoD).
For example, maps of Britain can be viewed at diﬀerent scales (see OS, 2015a). Luebke et al.’s (2003) classiﬁcation of
LoD diﬀerentiates between discrete and continuous LoD. Decimations which reduce data until a terminating
condition deliver snapshots at discrete LoD. A convenient feature of the RDP algorithm is that the vertices can
be tagged with the oﬀset values, which led to their selection, as implemented by Wade (Fortran source in
Whyatt and Wade [1988]; see discussion in Visvalingam [2015a]). The weighted vertices could be interactively
ﬁltered or animated in continuous LoD and snapshots taken as and when needed. This ﬁlter value was usually
user-speciﬁed, but it can be computed to match the display resolution.

The RDP algorithm is now widely available in open source and commercial GIS packages. Hershberger and
Snoeyink (1992) provide complete C code for their convex hull-based speeded up version, which has been
converted to C++ by Sunday (2012); a non-parametric version was provided by Prasad et al. (2012). McMaster
(1987: 108) promoted the RDP algorithm as ‘mathematically and perceptually superior’ to the others he
compared. He believed that perceptually it tended to select points which closely matched those selected by
humans, citing White (1983); and, that it produced the least areal and vector displacement from the original
line, and best preserved its angularity. In their extensive review, Heckbert and Garland (1997) noted that the
Douglas-Peucker algorithm is probably the most commonly used curve simpliﬁcation algorithm and described
some variants of the method. Their survey also included reference to terrain simpliﬁcation in cartography.

Visvalingam and Whyatt (1990) pointed out that the RDP algorithm was designed for polyline/polygon
approximation and that it is insuﬃcient for the type of caricatural generalization undertaken by cartographers.
With large tolerances, RDP tends to produce an output line that is very angular/spiky and unrepresentative of
real world geographic features. Line generalization involves the omission of less important features, deliberately
causing the generalized line to deviate from the original. So, McMaster’s measures of goodness of ﬁt were only
relevant for line approximation and inappropriate for line generalization.

Line generalization by repeated elimination of points
Within cartography, Visvalingam’s algorithm (see pseudocode) oﬀers a global search and merge algorithm to
complement the global search and split RDP algorithm. Visvalingam and Whyatt (1992; 1993) demonstrated
that it was able to achieve generalization, and especially caricatural generalization, as never done before. It is a
merge algorithm, in that it focuses on elimination but it involves global, not sequential, searches. It diﬀers
fundamentally from the algorithms reviewed in the section ‘Line approximation’ in that it was conceived for
diﬀerent reasons – for caricature and not approximation; the latter was widely regarded as solved by the RDP
algorithm. The algorithm was designed to displace the line from the original so as to progressively eliminate
important point and its speciﬁcation
scale-related features. It undertakes a global search for the least
deliberately avoids reference to ‘error terms’ and similar nomenclature to emphasise that the algorithm was not
designed for approximation but for generalization, i.e. when a line is perceived as a representation of the
original even though it departs from the original.

Also, Visvalingam (2015a) explained that the algorithm can be driven by any metric, and that the EA is a
heuristic measure. Heuristic measures are indicators and are not guaranteed to provide optimal solutions in all
the oﬀset metric is more suitable when
situations. Visvalingam and Brown (1999) pointed out
Visvalingam’s algorithm is used for line approximation. The algorithm is restated below (Section ‘Visvalingam’s
algorithm’) and similar algorithms in related ﬁelds are brieﬂy reviewed in the section ‘Other global search and
merge algorithms’.

that

Visvalingam’s algorithm

The Visvalingam algorithm for polyline generalization is very simple. ‘It consists of repeated elimination of the
point which is least signiﬁcant in a given line and treating the remainder as forming the new input line.’
Visvalingam (2015a) described how it can be expressed in diﬀerent but consistent ways to suit diﬀerent
circumstances and purposes. She noted why some expressions have limitations and explained why she favoured
the speciﬁcation published in Visvalingam and Whyatt (1993); Whyatt (1991) only needed to implement a part
of it for comparing the performance of generalization algorithms using individual lines. The full speciﬁcation
enables the ﬁltering of a set of lines on maps with a single ﬁlter threshold. The algorithm was designed
primarily to facilitate heuristic research on line segmentation, structuring and modelling of complex lines, such
as coastlines, which with their sometimes convoluted shapes, remain a research challenge in digital cartography
(see Visvalingam, 2015a).

THE CARTOGRAPHIC JOURNAL

259

Let previous = 0.0
Calculate EA for all internal points of the input line
While there are internal points {

Find the point with the least EA
if (EA of this point <= previous) EA = previous

else previous = EA

Record the EA of this point and note its rank (adjusted if and when needed)
Recalculate EA for the two neighbouring points

}

Pseudocode: The Visvalingam algorithm

[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]

Point reduction algorithms tend to be computationally demanding and it is more eﬃcient to use them in a one-
oﬀ process to attach metrics and ranks to the vertices of polylines and to cells of digital terrain models (DTMs). The
tags enable speedy, often interactive, ﬁltering and mapping of the data by subsequent processes. The pseudocode in
this paper only describes the Visvalingam algorithm for tagging polyline vertices.

Visvalingam’s algorithm does not specify how the importance of a point should be measured – this depends on
application requirements. Any metric can be used, but Visvalingam (2015a) explained why the EA was chosen
initially and why EA functions as a heuristic indicator. The EA in line 2 of the pseudocode starts oﬀ as the
triangular areal displacement which would occur if the point was to be dropped; this is the calculated metric. In
the original paper, it was noted that the metric could be weighted and this was explored by Zhou and Jones
(2004) and Harrower and Bloch (2006). There may be several points with the same minimal value (Line 4) and
the next point to be eliminated should be chosen in array access order (Visvalingam, 2015a).

The value of the metric is changed if the condition in line 5 is true, which usually indicates the presence of a line
conﬁguration suggestive of a feature. Visvalingam (2015a: Appendix) demonstrated how without lines 5 and 6,
lines ﬁltered on unaltered values will not correspond to the rank order of point elimination. This modiﬁcation
of EA is quite important since it can lead to a cascade of points being eliminated with the same EA (or rank if
needed) on thin elongated features. Visvalingam (2015a) favoured the conditional operator (<=) in line 5 over
the original (<) operator published in Visvalingam and Whyatt (1993).

Lines 5–7 in the pseudocode are implementation speciﬁc and are not an integral part of the basic generalization
algorithm (see Visvalingam, 2015a). They facilitate the tagging of vertices (in Line 7) with the value of the metric
which would have led to their removal. Later, user-speciﬁed ﬁlter tolerances select desired levels of generalization as
in Figure 7 of Visvalingam and Whelan (2014). Lines 5–7 also provide scope for ﬁltering a whole map, consisting of
several lines with a single tolerance value (Visvalingam and Williamson, 1995). It is also possible to use multiple
tags and ﬁlter values as demonstrated by Visvalingam and Dowson (1998) when needed. A full analysis of the
algorithm identifying opportunities for further research will be provided in a separate paper.

Other global search and merge algorithms

Similar algorithms to Visvalingam’s were reported in other ﬁelds at about the same time. The following references
are indicative and suﬃcient to suggest that the implementation issues discussed in this paper may be of wider
concern.

Computer graphics
The application of global search and merge in higher dimensions than 2D involves a more complex decision space,
including (a) the choice of entity for removal (for example, vertex or edge); (b) the metric to be used to select the
next entity for deletion from a candidate list; (c) the procedure for merging; and, (d) whether there should be
constraints, such as topological constraints. Given the immense scope for choice and the prodigious literature
in computer graphics, only some directly comparable global search and merge algorithms are included here.

Turk (1992) referred to two contemporary projects which used global search and merge. He stated that in 1992
Novins had developed a method for removing vertices in relatively ﬂat portions of a polygonal object. The user
speciﬁed the number of vertices to be retained. Novins’ program queued vertices for removal based on the
surface normal of triangles linked to each. Whenever a vertex was removed, the hole was re-triangulated. Turk
also referred to the approach adopted by Schroeder et al. (1992) for vertex reduction or decimation, which used
diﬀerent criteria (distance from the plane approximating the surface near the vertex) and topological
constraints on vertex removal and re-triangulation.

In their catalogue of useful algorithms, Luebke et al. (2003) included Garland and Heckbert (1997) who
proposed quadric error metrics, ‘which strikes perhaps the best balance between speed, robustness, simplicity,
and ﬁdelity’. Garland and Heckbert (1997) proposed simpliﬁcation by repeatedly contracting a pair of vertices

260

M. VISVALINGAM

into a single vertex, reconnecting the incident edges and removing degenerate edges and faces. The metric used for
selecting the pair for contraction was their plane-based error quadric. As in Schroeder et al. (1992) their approach
could enforce constraints; contraction could be disallowed or penalised to preserve boundaries and to prevent face
inversion. Garland (1998) provides an example of contraction and ‘planes’ in 2D, to illustrate how pair contraction
uses new approximating points to replace the vertex pairs. Garland and Zhou (2005) generalized the quadric error
metric to propose a new simpliﬁcation method that produces approximations in any dimension. Figure 7 in
Garland and Zhou (2005) includes approximating points that do not lie on the spiral arms. This signiﬁcant
departure from vertex elimination as undertaken by Schroeder et al. (1992) and Visvalingam is outside the
scope of this paper. However, an implementation-speciﬁc issue, which falls within the theme of this paper, will
be discussed later.

Pattern recognition
Pikaz and Dinstein (1995) proposed a global search and merge algorithm, which is very similar to the partial
implementation of Visvalingam’s algorithm by Whyatt (1991); see Visvalingam (2015a) for more details. The
test data they used (the outline of a key) were not as demanding as convoluted coastlines. They advanced
several propositions and formal proofs to draw inferences about this algorithm but as Visvalingam and Brown
(1999) demonstrated their conclusions relate to their aim of approximation and did not extend to
generalization. Pikaz and Dinstein considered two metrics, namely the oﬀset distance for shape preservation
and areal displacement
for smoothing and their illustrations are based on the latter. Visvalingam and
Williamson (1995) had demonstrated that even though Visvalingam’s algorithm could be used for
approximation with the oﬀset distance, oﬀset based global search and split methods, such as RDP, are better for
weeding (removing superﬂuous and digitising errors) and for approximation. They also pointed out that
Visvalingam’s algorithm with EA is not suitable for generalizing height contours since it has a tendency to cut
curves and this would also apply to Pikaz and Dinstein’s test data. The expression of Visvalingam’s algorithm
was designed to adapt it to application and data requirements.

Pikaz and Dinstein also recalculated the areal displacement of the neighbours when a vertex is eliminated. They
noted that the error metric (e.g. area) will not necessarily increase monotonically and that it could give rise to
suboptimal results. However, their data prompted them to disregard this as causing minor aberrations, which
occurred at the early stages of decimation, mainly along unsmoothed data. Like Whyatt (1991) they undertook
the decimation until a terminating condition. With this approach there was no need for Visvalingam’s special
case (lines 5–7) which is essential for compute-once and ﬁlter later during interactive exploration of the pre-
tagged data. Visvalingam (2015a) illustrated the unacceptable results which would be obtained if the data were
ﬁltered on EA without implementing the special case in lines 5–7 of the pseudocode.

Visvalingam and Whyatt (1991) discussed variations in the implementation of cartographic algorithms; these
included rounding and digitising errors and the presence of equal metric values. Even using limited and less
exacting data, Pikaz and Dinstein noted that there may be problems when a number of points have the same
minimal error; and, that an arbitrary selection of the elimination order may result in a slightly diﬀerent
polygonal approximation. They considered and then rejected as unnecessary the following modiﬁcation to
obtain a unique solution: ‘while the minimal error is less than the threshold, at each iteration eliminate all the
points with minimal errors’. They felt that in practice, the error terms for their data were not signiﬁcantly
diﬀerent and that it was more important that the approximation had the same geometrical meaning as the
input. Visvalingam and Brown (1999) demonstrated that the order of selection can generate shapes which
appear distinctly diﬀerent. However, this may not be an issue with all data, such as those used by Pikaz and
Dinstein, nor in all applications, e.g. it may be unimportant in ﬂeeting 3D computer graphics animations.

Some implementations of the Visvalingam algorithm

Release of free topographic data by various government agencies and by corporations, such as Google and
OpenStreetMap, has promoted the use of point reduction algorithms in GIS research and applications. Given
the huge amounts of high resolution vector data that can be browsed, the subject of cartographic generalization
has become topical. There are a growing number of implementations of both the RDP and Visvalingam’s
algorithms for line approximation and generalization – some available as open source software and others have
been incorporated within commercial GIS and mapping software. Although the observations made in this
paper are also applicable to implementations of the RDP and other algorithms, the following list is limited to
representative examples of the use of Visvalingam’s algorithm.

THE CARTOGRAPHIC JOURNAL

261

. Ariza-López et al. (2005) used Visvalingam’s algorithm to tag vertices of roads with EA. They then traced the
proﬁle of EA against the distance between vertices and used the RDP algorithm to segment the trace and the
corresponding roads. Garcia-Balboa and Ariza-López (2009) suggested parameter values for automating this
process. This is an example of a merge and split approach.

. Aisch (2012–14) generated compact SVGs using Visvalingam simpliﬁcation in the free to use version of

Kartograph.

applications.

. Bostock (2012) posted a demonstrator using his Javascript implementation.
. Davies (2012) modiﬁed Bostock’s implementation to preserve topological relationships between polygons.
. Duﬁlie and Grinstein (2014) used the Visvalingam algorithm for progressive transmission of vector data in web

. Frye (2013) illustrated the use of the algorithm to simplify and compress auto traced coastlines by NASA.
. Gaborit (2014) provided a Python implementation of Bostock’s code.
. Hamid et al. (2010) used it for progressive vector transmission in mobile GIS.
. Harrower and Bloch (2006) announced Mapshaper; for the latest version, see Bloch (2015).
.

IGN (2014) included the algorithm in their generalization suite.

. Kaefer (2012) implemented the C++ version within Mapnik.
. Mapbox Studio (2014) is an open source desktop software for designing maps. It uses Mapnik, which includes
the Visvalingam algorithm, for rendering maps. Mapbox is not entirely free and has raised substantial funding to
compete with Google Maps (see Kolodny, 2013).

. McMaster et al. (2005) and Schroeder and McMaster (2007) reported on the 5-year NSF-funded project, based
on the US Bureau of Census TIGER data, to create a comprehensive National Multiscale Database for the free to
use National Historical Geographic Information System (NHGIS, 2011). After pre-ﬁltering with the RDP
algorithm to weed and simplify the raw vector data, multiple databases for target scales were automatically
generalized using the Visvalingam algorithm with weighted EA. Other extensions were included for speciﬁc
purposes (Jonathan Schroeder, June 2015, personal communication; see Schroeder, 2010).

. OSGeo-org (2015) has a thread on implementation of Visvalingam’s algorithm within this Open Source

Foundation.

. Oracle Spatial and Graph (12.1) implements the basic algorithm which works on single polylines at a time and

also a topology-based constrained simpliﬁcation (Siva Ravada, personal communication, July 2015).

. Others are using the algorithm in applications beyond cartography; for example, for simplifying data
visualizations for display on mobile devices. (Daniel Cascais, personal communication, 2014) and as already
noted in the ﬁeld of Pattern Recognition (see citations of the work by Pikaz and Dinstein (1995).

. PostGIS (2015) closed the thread following their implementation.
. Reimer and Kempf (2014) used a self-intersection-free implementation of Visvalingam’s algorithm for
caricaturing the outlines of urban settlements, derived from large-scale maps, for display at substantially
reduced scales.

. Steinarsson (2013) adapted the algorithm for down sampling ﬁnancial time series data.
. The focus of ACM (2014) SIGSPATIAL Cup 2014 was on generalizing maps with the emphasis on the
preservation of topological relationships. The constrained vertex removal used by Chen et al. (2014, 3rd
prize winners) drew on Visvalingam’s algorithm and is similar to the approach of Yang et al. (2004).

. The Zhou and Jones (2004) implementation is used by Ordnance Survey for generalizing coastlines (see Revell
et al., 2011). Ordnance Survey is now using the 1Spatial 1Generalise implementation. Zhou (2014) attempted to
segment coastlines using RDP and then use Visvalingam’s algorithm to generalize the segments. This is one
example of the split-and-merge approach. He provided a link to the download site for his demonstrator
program, which includes the Java source.

. Vivid Solutions (2001) posted a Java implementation on sourceforge.net. for users of its Java Topology Suite

(JTS).

across the internet.

. Weifang and Li (2012) adapted Visvalingam’s algorithm for progressive transmission of a dendritic river system

. Yang et al. (2004; 2007) adapted Visvalingam’s algorithm with a constraint to remove a vertex, only when its
triangle does not contain other vertices. Their subsequent publications on progressive transmission of vector
data for web-based applications refer back to these papers for their simpliﬁcation method.

This project tested just the implementation in Mapshaper for the following reasons. Bloch’s open source
Mapshaper has been instrumental
inspired the
demonstrator by Bostock (2012), which has in turn inspired Davies (2012) and several others. Mapshaper’s
weighted area option produced aesthetically pleasing simpliﬁcations (Visvalingam and Whelan, 2014). Matthew

in promoting the use of Visvalingam’s algorithm.

It

262

M. VISVALINGAM

Bloch (personal communication, 2014) noted our observations on version 0.2.0 and has changed the function for
the weighted EA option in subsequent versions. Also, Mapshaper is sometimes used for exporting generalized
shape ﬁles for use within some commercial GIS packages, which do not include the Visvalingam algorithm. His
source code has been used by others.

The issues identiﬁed by Visvalingam (2015b) have now been resolved in Mapshaper – see the section
‘Explanations’ below. This paper provides suﬃcient background, data and sample output to enable others to
test their implementations, using at least the black-box approach adopted here. Any implementation which
meets a speciﬁed purpose is valid so long as it eliminates the least important point on each iteration in a
systematic order (see Visvalingam, 2015a). The following section shows that it is not easy to reach deﬁnitive
conclusions with coastline data. Geometric patterns, such as fractals, can be more revealing.

Observations

At the start of the Visvalingam and Whelan (2014) project, Whelan downloaded the source of Mapshaper v 0.2.0
and checked it using data for the section of a road used by Visvalingam and Williamson (1995). He noticed some
diﬀerences in the values for EA. Visvalingam found that the discrepancies tended to occur on curved sections of
lines, such as at a roundabout and at a ﬁlleted road junction. At these places, Mapshaper was picking a diﬀerent
point to that selected by Visvalingam’s implementation, especially where these two points had the same EA.

Visvalingam and Whelan (2014) used two stretches of coastlines, namely the SWURCC data and the OS VMD
data, as described in their paper. These data sets can be downloaded from https://hydra.hull.ac.uk/resources/
hull:9040, which provides information on the sources of these free copyrighted data, maps and the co-ordinates
of the coastlines.

1:50,000 SWURCC data

This was the main data set used by Visvalingam and Whelan (2014). Mapshaper produced comparable results to
Visvalingam’s implementation for this data set. More recent investigations by the author suggest that the
diﬀerences were partly related to the special case (statements 5 and 6 in pseudocode). When an EA was less
than that of the previously eliminated point, Mapshaper did not always pick the point with minimum EA. It
picks the ﬁrst point which fulﬁlled this condition on some but not all occasions (see explanation in the section
‘Explanations – Treatment of neighbouring points’). This can have a knock-on eﬀect on the choice of some
subsequent points. Diﬀerent implementations of the RDP algorithm can produce diﬀerent, but equally valid,
for reasons of consistency,
results as observed and explained by Visvalingam and Whyatt (1991). So,
Visvalingam and Whelan (2014) used Mapshaper v 0.2.0 to compare maps produced with the standard weight
of 1 and Bloch’s weighted EAs. The subsets of points drawn for a given percentage of points were very similar
and often identical. In Figure 1a, there is a diﬀerence of just one point in the 0.9% of points retained.
Mapshaper picks a point which gives a better shape, while Visvalingam’s implementation picks a point which
produces the chopped eﬀect discussed in Visvalingam and Whelan (2014). Both implementations produce the
same 0.5% subset of 13 points in Figure 1b. Stepwise visualization of the elimination of the points in Figure 1b
showed that the two implementations were eliminating points in a diﬀerent order, especially after encountering
the special case. Figure 1c,d shows the last six points to be eliminated in their order of removal.

1:25,000 OS VectorMap® district data (OS VMD data)

This data related to an area known as The Scalp in Lincolnshire, which consists of wetlands drained by a complex of
meandering creeks (see Ordnance Survey, 2015a). Visvalingam and Whelan (2014) only compared output without
and with weighting of EA using maps with 1.4% of points or more. Figure 2 shows the lack of correspondence
between Mapshaper and Visvalingam’s output when only 0.5% of points were retained. Visvalingam introduces
A in Figure 2a before B & C in Figure 2b. At some levels of ﬁltering, Mapshaper produces better results. In
Figure 3, most of the retained features are remarkably similar when 5% of the points were retained – but there
are some notable exceptions. The depiction of tributaries A and B by Mapshaper look more appropriate, even if
C looks chopped. Gulch Creek and the trident shape created by the retention of A, make the streams instantly
recognizable. This seemed to suggest that Bloch’s implementation of the pseudocode could be preferable.

Again, the output for coastlines showed that diﬀerences tended to occur (a) when there were two or more
candidate points with equal EA, and (b) when the special case (statement 5 in pseudocode) was triggered. The
impact of equal-valued EAs on Mapshaper was investigated next using fractals.

THE CARTOGRAPHIC JOURNAL

263

Figure 1. Comparison of points selected by Bloch (mauve) and Visvalingam (blue); (a) 22 points (0.9%); (b) 13 points (0.5%); order of removal of the last 6
points by (c) Mapshaper v0.2.19; (d) Visvalingam.

Teragon test

It is possible to abstract a range of unexpected patterns from even the level 1 teragon of the rectangular (quadratic)
Koch Island as demonstrated by Visvalingam and Brown (their Figure 2), not just by using diﬀerent algorithms, but
also by driving Visvalingam’s algorithm with diﬀerent metrics and in diﬀerent directions. However, of those
metrics tested with Visvalingam’s algorithm, only EA was able to recover the original square initiator for
teragons of orders 1–3 of the rectangular Koch curve. Irrespective of the algorithm and metric in use, and the
shape chosen, all implementations of point reduction algorithms must output identical shapes for similar parts
of a ﬁgure.

264

M. VISVALINGAM

Figure 2. Filtering by (a) Visvalingam’s implementation and (b) Mapshaper.

Figure 4 shows the teragon and the generalizations produced by Visvalingam’s program using EA. The data for
the teragon is online at: https://hydra.hull.ac.uk/resources/hull:9040. As pointed out by Visvalingam and Brown
(pp. 164–165), Visvalingam’s algorithm retains the four-fold symmetry in the teragon and emulates the give-
and-take rule used in manual cartography (Maling, 1989). They illustrated how rounding errors in
implementation and the use of inappropriate start/end points can lead to a loss of symmetry. Visvalingam and
Herbert (1999) used coastlines and the quadratic Koch data to demonstrate that there were problems with the
Arc/Info Bendsimplify algorithm, which uses Visvalingam’s idea of iterative elimination to remove bends
instead of individual points.

Bloch’s implementation of Visvalingam’s algorithm produced rather unexpected results (see Figure 5). It was
unable to retain the symmetry of the Koch Island. Visvalingam’s implementation only outputs one ﬁgure
between the teragon and the initiator. Mapshaper outputs several but does not recover the initiator (Figure 5
only shows some of the intervening simpliﬁcations).

Mapshaper mimics the give-and-take rule in the bottom half of Figure 5a, but produces a diﬀerent simpliﬁcation
in the top half of the ﬁgure; Figure 6a shows the diﬀerence. This inconsistency results in unbalanced and
unacceptable results on further simpliﬁcation (5b–c). Visvalingam and Brown (1999,
in their Figure 3a)
produced symmetric generalizations of the level 2 Koch Island as well. Mapshaper produced very unbalanced
output from the same data, and the reasons for this were not immediately obvious. A screen image of
Mapshaper’s output with 50% of points ﬁltered from the Level 2 Koch Island is shown in Figure 6b. Davies

THE CARTOGRAPHIC JOURNAL

265

Figure 3. Five percent of points retained by (a) Visvalingam and (b) by Mapshaper.

(2012) used a pair of quadratic Koch Islands to
demonstrate his approach to preserving the topology
during Visvalingam simpliﬁcation. His output was
also unbalanced. Visvalingam and Brown (1999)
noted that like the RDP algorithm, the Visvalingam
algorithm is also sensitive to start and end points.
The unbalanced output may partly be the result of
the
the insertion of
polygons into three polylines. However, this does
not fully explain the lack of symmetry at even low
levels of simpliﬁcation.

topological nodes

to split

The Koch data were run through Mapshaper’s
Douglas-Peucker option. Philip Wade’s original
Fortran program (listed in Whyatt and Wade, 1988)
produced two sets of ﬁve symmetrical ﬁgures (see

Figure 4. Visvalingam’s implementation retains the 4-fold symmetry of the
Koch Island.

266

M. VISVALINGAM

Figure 5. Sample output from Mapshaper v 0.2.19.

Figure 2 in Visvalingam and Brown, 1999). Mapshaper
produces many more unbalanced ﬁgures,
including
that in Figure 7, which shows varying LoD on diﬀerent
wings of the ﬁgure.

Explanations

The following extracts are from Mathew Bloch’s
personal communication (7th March 2016) in response
to a revised version of Visvalingam (2015b) and to
comments on the latter by others:

a. Treatment of neighbouring points.

included

than the

pseudocode

removed and the EA of

‘Until very
recently, mapshaper followed a slightly diﬀerent
procedure
in
(Visvalingam and Whyatt, 1992). According to
mapshaper’s original implementation, after a vertex
adjacent points
is
recalculated, if an adjacent point’s updated EA value
is less than that of the removed point, mapshaper
would set the EA value associated with a lesser-value
adjacent point to be the same as that of the removed
point. Not uncommonly, both adjacent points would
be set to the same value (the value of the removed
point). These points would subsequently be removed
in an arbitrary order’. His implementation had been
changed in version 0.3.10 (in October 2015) to
match the
original pseudocode; his updated
implementation still did not generate symmetrical
output for teragons for the following two reasons.

Figure 6. Comparison of ﬁgures abstracted by Visvalingam’s implementation
and Mapshaper.

b. Selection of the least important point: Visvalingam (2015a: Section 2.4) used observations in Visvalingam
and Brown (1999) to explain why she did not specify precisely how the least important point should be
‘The only
implementations should output similar, even if not identical, generalizations.
selected. All
restriction is that the output must not be so inconsistent with the intent of the algorithm that it looks
inappropriate for its intended purpose. This can happen if the point is picked from a candidate set with
equal-values without due regard to its position along the line. This may not matter when coastlines are
only simpliﬁed to a modest extent.’ This conforms to Jenk’s (1981; see the section ‘Line generalization
versus line approximation’) view that generalizations, being representations, can depart (and vary) from the
original as long as they are recognisable.

(Matthew Bloch, March 2016) noted that ‘Mapshaper’s Visvalingam implementation uses a min-heap to
sort vertices, and the order in which equal-value vertices are removed from the heap is not deﬁned’. He
included ‘an additional constraint to the heap, such that when the heap contains several vertices of equal
weight, the vertex having the lowest array index is removed before the others. With this new constraint, the
teragon ﬁgure becomes symmetrical when simpliﬁed, just like in your implementation.’ However, even
with this correction, the output remained unbalanced due to the following.

c. Assumptions about the co-ordinate reference system. Mapshaper auto-detects whether a dataset has
‘Mapshaper’s current behavior is to assume unprojected
latitude-longitude or projected coordinates.
geographical coordinates when the bounding box of the data falls within the typical range of decimal
degree coordinates (−180, −90 to 180, 90). Mapshaper uses 3D simpliﬁcation by default when it thinks the
dataset is unprojected. … two triangles that have equal-area planar coordinates will most likely no longer
have equal areas when their coordinates are
interpreted as decimal-degree data. … Mapshaper’s
behavior works ﬁne for almost any geographical
dataset. It only breaks down when simplifying toy
datasets designed for testing, which look like lat-
long datasets according to Mapshaper’s heuristic.
With toy datasets, testers need to specify planar

Figure 7. Mapshaper’s output for the RDP algorithm.

THE CARTOGRAPHIC JOURNAL

267

simpliﬁcation explicitly … . A planar default will cause many users unwittingly to apply planar simpliﬁcation
to their unprojected data, and I believe that most of the time it is preferable to use 3D simpliﬁcation on
unprojected data. … The simpliﬁcation command for Mapshaper’s command line interface has a ‘cartesian’
option, which disables auto-detection of geographical coordinates. I just added a checkbox to the
simpliﬁcation settings menu of the web interface. Currently, in version 0.3.17, this check box only appears
when Mapshaper assumes lat-long unprojected co-ordinates.

Whether the simpliﬁcation should be applied to unprojected or projected co-ordinates by default is open to
discussion (see the section ‘Interpretation of the input data co-ordinates’). Ticking the checkbox for planar co-
ordinates in the simpliﬁcation user interface box does correct the north-south bias but it did not redress the
loss of symmetry in mid-March 2016 for the reason noted in 5b above but it does so as of 27th March 2016 in v
0.3.17. The newly installed settings button, to the left of the slider, enables users to set and change the
simpliﬁcation options at will.

Discussion

Of the issues raised in the section ‘Explanations’ above, only ‘Treatment of neighbouring points’ is speciﬁc to the
Visvalingam algorithm. The issues described in ‘Selection of the least important point’ and ‘Assumptions about the
co-ordinate reference system’ are discussed below since they can aﬀect the behaviour of other geometric algorithms,
such as of the RDP algorithm as demonstrated in this paper and the Garland and Zhou (2005) algorithm as noted
below.

The problem of equal areas

Visvalingam and Whelan were not unduly concerned that the output of Mapshaper v 0.2.0 was not identical to
theirs. Mapshaper is targeted at simplifying topographic data. Generalized depictions are inevitably subjective in
manual cartography and some variation in digital generalizations is equally acceptable. The processes involved
in the production of cartographic data introduce a margin of error. Visvalingam and Whyatt (1991) pointed
out that cartographic data are inexact and representative. Given that digitizing errors are much greater than
rounding errors and that data are rounded to the nearest precision for dissemination, they can make pedantic
stipulation of how to choose a point from a set of equal-valued candidates somewhat academic. Equal values
may be fortuitous and the choice of the point for elimination can vary, not just with test data but also with the
order in which data are presented as explained by Visvalingam (2015a). What is interesting is that despite the
loose speciﬁcation of the least important point (line 4 of pseudocode), Mapshaper outputs good results for
coastlines, suggesting that the method of iterative elimination is fairly robust when applied to topographic data
pertaining to natural irregular features.

if

However, the teragon-test has highlighted that a systematic choice is needed for applications outside of
cartography, such as Pattern Recognition and CAD. Unlike coastlines, fractals are by deﬁnition self-similar
and any generalization has to retain the symmetry, which deﬁnes their self-similarity. Mapshaper was never
intended to generalize fractals. However, until it was updated, it would have produced unsuitable results for
artiﬁcial geographies, such as the man-made coastline and census boundaries of Florida and the USA,
illustrated by McMaster et al. (2005). Nor would it have been suitable for applications outside of
cartography,
the
symmetry and balance in their original design. Shape distortion will also impede the segmentation of in-line
features and parts for model-based generalization, which has applications in pattern recognition and not
just cartography.

they require that simpliﬁed depictions of engineered components should reﬂect

Other geometric ﬁgures, such as the spiral used by Garland and Zhou (2005, Figure 7) can also enable users to
assess whether the implementation is appropriate for them. They noted that the spiral arms could be drastically
simpliﬁed using Garland’s pair contraction algorithm without substantial loss of shape but pointed out the loss
of symmetry. The loss of symmetry causes unnecessary congestion in the centre of the spiral. Diﬀerent
cartographers may use diﬀerent algorithms (even Nth point sampling) to ﬁlter the arms and may opt to retain
a diﬀerent number of vertices. But, having decided on the algorithm and the number of vertices to retain, each
cartographer would generalize all arms in a consistent way. This makes the author wonder whether the varying
number of vertices retained on diﬀerent arms was due to the implementation and not necessarily a product of
Garland’s algorithm.

Pikaz and Dinstein (1995, see the section ‘Pattern recognition’ above) considered eliminating all equal-valued
candidates on an iteration but dismissed this idea. This can make Visvalingam’s algorithm implementation

268

M. VISVALINGAM

independent, which may suit some data and applications. However, it can exacerbate the algorithm’s inherent
tendency to shortcut curves, as noted by Visvalingam and Williamson (1995); this can also make the problem
of self-intersection worse.

Interpretation of the input data co-ordinates

Geometric algorithms, such as point reduction algorithms, are usually conceived and expressed using planar
Cartesian x, y co-ordinates. They are often demonstrated using projected data, such as Ordnance Survey digital
topographic map data used in Figures 1–3 above. The x, y data co-ordinates refer to the Eastings and
Northings of the National Grid of Great Britain (Ordnance Survey, 2015b: section 7).

As noted by Ordnance Survey (2015b: 14), computations in geodesy are performed on the 3D co-ordinates of
spheroids and are only converted to projected map co-ordinates if and when a visual display is needed. GIS tend to
perform calculations on map co-ordinates, often by reprojecting data to a common co-ordinate reference system.
So, the distinction made by Bloch (see section 5c) between unprojected and projected data is pertinent. Users should
be mindful that the Mapshaper web service may assume unprojected degree data by default and use a simple
spherical model of the earth for calculations (Bloch, personal communication, 8th April 2016); this may or may
not be appropriate. Also, Mapshaper only uses a rectilinear Cartesian planar projection for display purposes at
present (Bloch, personal communication, 8th April 2016). When spherical co-ordinates are assumed for
calculation and then displayed using a Cartesian projection, the output can be inappropriate and confusing, as
demonstrated by the simpliﬁed teragons. The display of input and unprocessed data on the surface of a virtual
3D sphere would alert the user that Mapshaper was assuming lat-long co-ordinates – but this will introduce
other issues which are outside the scope of this paper.

Given the complexity of this subject and the variety of spatial referencing systems in use (ESRI, 2016; Ordnance
Survey, 2015b), the onus is on users to check any assumptions being made by GIS developers and to request the
inclusion of a planar option if required and if none exists. Mapshaper users should explicitly specify the planar
option when necessary and if in doubt.

Conclusion

There are several independent implementations of the Visvalingam algorithm (section ‘Some implementations of
the Visvalingam algorithm’). Most users would ﬁnd black-box testing with teragons easier than code inspection. It
quickly highlighted that there were some problems in the implementation of Mapshaper 0.2.28 and previous
versions. Although the source code for Mapshaper is available, this is not the case with all implementations.
Visvalingam’s algorithm will often form only a small part of a complex GIS system and its output can be
aﬀected by other ancillary functions.

Only one source of variability in output was directly related to the implementation of Visvalingam’s
algorithm. This has been addressed (see the section ‘Treatment of neighbouring points’). A further problem
arises from the use of unconstrained sorts to select the least/most important point. Despite the ambiguity in
line 4 of the pseudocode, hand working would select a point from a set of candidates in array access order.
The use of unconstrained sorts to choose minima and maxima can result in points being chosen in an
arbitrary unintended order. This has been corrected in Mapshaper (see the section ‘Selection of the least
important point’).

Also, the unbalanced generalization of fractals was due to the assumption that the input co-ordinates were
spherical, when they were planar. This was confusing since National Grid co-ordinates had been treated as
planar by Mapshaper. Now that this problem has been highlighted and a planar option included in the
Mapshaper 0.3.17 web interface, users have to specify the appropriate referencing system if and when necessary.
Other open source software, such as QGIS (2016), provide many more projection options. As the Ordnance
Survey (2015b: 3) guide pointed out, ‘Users of coordinates are often unaware that this subject exists, or that
they need to know some fundamental geodetic concepts in order to use coordinates properly.’ As explained in
the section ‘Background’, Visvalingam’s algorithm was designed for cartographic generalization and not for line
approximation. Generalization is performed normally on projected map data for human processing
(Visvalingam, 1990). Generalized data, especially caricatures, are unsuitable for calculations. Equally, data pre-
ﬁltered by approximation algorithms may not be optimal for deriving caricatures. This is especially so when the
data has also been subjected to weighting, smoothing or other modiﬁcations during the derivation of multiscale
cartographic products. It must be stressed that Mapshaper 0.3.17 passes the teragon-test when used with the
planar option. Others may wish to check their implementations.

THE CARTOGRAPHIC JOURNAL

269

Notes on the contributor

Mahes Visvalingam, BA (1968, Malaya), PhD (1973, Hull), has served on the Council of the
British Cartographic Society and Chaired its Research Committee. While a Research Fellow
in the Census Research Unit (Geography, Durham), Mahes originated the signed chi-square
measure for mapping, and co-authored the innovative People in Britain – a census atlas
(HMSO, 1980). As Hon. Research Associate (Geography, Hull, 1979–1985) she founded the
multidisciplinary Cartographic Information Systems Research Group (CISRG) and its
Discussion Paper Series in 1985 (CISRG, 2015) and established research collaboration with
Ordnance Survey (GB) and with others on Digital Mapping. She was appointed to a
Lectureship in Computer Science (Hull) in 1986 and retired as Reader Emeritus in 2003. In
2014, she restarted her independent unfunded research and established the Explorations in Digital Cartography
Discussion Paper Series, published by the University of Hull.

Acknowledgements

The data used in this project are covered by Crown Copyright. The SWURCC data were provided for research purposes and
contains public sector information licensed under the Open Government Licence v2.0. The data for The Scalp is Ordnance
Survey data © Crown copyright and database right [2015].

This unfunded project by Mahes Visvalingam (a retired, independent research worker – IRW) relied on input from many
others. Thanks to Matthew Bloch for freezing Mapshaper v 0.2.0 and for continuing to evolve and maintain his unfunded web
service; Chris Brown who generated the co-ordinates for the various levels of teragons using the lsys program written by John
Leech (published in Prusinkiewicz and Lindenmayer, 1990); John Griﬃths (a retired former colleague and fellow IRW) for
writing an interactive graphics program, PolylineViewer, for visualising the output of the author’s program in camaraderie
and friendship; and John Whelan whose contributions to Visvalingam and Whelan (2014) provided the impetus for this
research. Thanks also to the implementers who kindly checked and adjusted the text about their work in the section ‘Some
implementations of the Visvalingam algorithm’.

The author would also like to thank Morgan McGuire and David Luebke for their helpful suggestions and for picking out
the landmark papers in Computer Graphics, which are most relevant to the theme of this paper; and, the reviewers for their
corrections and helpful comments.

ORCID

Mahes Visvalingam http://orcid.org/0000-0001-9094-4635

References
ACM (2014) “ACM SIGSPATIAL Cup 2014 News & FAQ” Available at: http://mypages.iit.edu/~xzhang22/GISCUP2014/faq.

php (Accessed: July 2015).

Aisch, G. (2012–14) “What is Kartograph?” Available at: http://kartograph.org/ (Accessed: January 2015).
Ariza-López, F.J., Garcia-Balboa, J.L. and Reinoso-Gordo, J.F. (2005) “Segmentation of lines by means of douglas peucker
applied to eﬀective areas of the visvalingam and whyatt algorithm”, in Proceedings XXII International Cartographic
Conference (ICC2005), La Coruña (Spain). Available at: http://www.cartesia.org/geodoc/icc2005/pdf/poster/TEMA9/
FRANCISCO%20J.%20ARIZA%20LOPEZ1.pdf (Accessed: June 2015).

Bloch, M. (2014) An updated version of

the original Mapshaper tool v 0.2.0. Available at: http://mapshaper.org/

Visvalingam2014 (Accessed: 2014).

Bloch, M. (2015) “Mapshaper v. 0.2.28” Available at: http://mapshaper.org/ (Accessed: June 2015).
Bostock (2012) “Line simpliﬁcation – demonstrator” Available at: http://bost.ocks.org/mike/simplify/ Javascript source: http://
bost.ocks.org/mike/simplify/simplify.js (Accessed: January 2015). Discussion: https://groups.google.com/forum/#!topic/
d3-js/uPOao98T9mg and https://news.ycombinator.com/item?id=4055445

Boxer, L., Chang, C.-S., Miller, R. and Rau-Chaplin, A. (1993) “Polygonal Approximation by Boundary Reduction” Pattern

Recognition Letters 14 pp.111–119.

Chen, Y., Wang, Y., Chen, R., Chen, H., Zang, B. and Wang, Z. (2014) “Greedy map generalization by iterative point removal”
ACM SIGSPATIAL 2014. Available at: https://ipads.se.sjtu.edu.cn/zh/publications/Chensigspatialcup14.pdf (Accessed:
October 2015).

Cignoni, P., Montani, C. and Scopigno, R. (1998) “A Comparison of Mesh Simpliﬁcation Algorithms” Computers & Graphics

22 (1) pp.37–54.

January 2015).

CISRG (2015) Cartographic information systems research group (CISRG) discussion papers series, University of Hull
Available at: https://hydra.hull.ac.uk/resources?f%5Bcreator_name_ssim%5D%5B%5D=Visvalingam%2C+Maheswari.
Davies, J. (2012) “Quadratic Koch Island simpliﬁcation” Available at: http://www.jasondavies.com/simplify/koch/ (Accessed:

Douglas, D.H. and Peucker, T.K. (1973) “Algorithms for the Reduction of the Number of Points Required to Represent a
Information and

its Caricature” Cartographica: The

for Geographic

International

Journal

Digitised Line or
Geovisualization 10 (2) pp.112–122.

270

M. VISVALINGAM

Duﬁlie, A. and Grinstein, G. (2014) “Feathered Tiles with Uniform Payload Size for Progressive Transmission of Vector Data”
In Pfozer, D. and Li, K.-J. (Eds), Web and Wireless Geographical Information Systems Berlin: Springer, pp.19–35. Available
at: http://www.cs.uml.edu/~aduﬁlie/feathered-tiles.pdf (Accessed: January 2015).

ESRI (2016) “ArcGIS runtime SDK for. NET: Spatial references” Available at: https://developers.arcgis.com/net/desktop/guide/

spatial-references.htm (Accessed: April 2016).

Field, K. and Kent, A.J. (2014) “Landmarks in Mapping: 50 Years of the Cartographic Journal” Leeds: Maney Publishing for the

British Cartographic Society.

Frye, S. (2013) “NASA’s Earth Observing One (EO1) Satellite Advanced Land Imager Observations and Products for Disaster
Management” in Presented at the 15th Congres de l’AQT 26th September 2013. Available at: http://www.un-spider.org/
sites/default/ﬁles/201310_Washington_NASA%20DRM%20brieﬁng%20for%20IWG-SEM%20workshop.pdf
(Accessed:
January 2015).

Gaborit, M. (2014) “Visvalingam 0.3.0” https://pypi.org/project/visvalingam/0.3.0/. Available at: https://github.com/Matael/

Visvalingam-Wyatt (Accessed: January 2015).

Garcia-Balboa, J.L. and Ariza-López, F.J. (2009) “Sinuosity Pattern Recognition of Road Features for Segmentation Purposes in

Cartographic Generalization” Pattern Recognition 42 (9) pp.2150–2159.

Garland, M. (1988) “Fast and Eﬀective Polygonal Surface Simpliﬁcation” Available at: http://mgarland.org/ﬁles/talks/QSlim-

Talk.ppt (Accessed: June 2015).

Garland, M. and Heckbert, P.S. (1997) “Surface Simpliﬁcation Using Quadric Error Metrics” in Proceedings of SIGGRAPH 97,

ACM SIGGRAPH, 209–216 Available at: http://mgarland.org/papers/quadrics.pdf (Accessed: June 2015).

Garland, M. and Zhou, Y. (2005) “Quadric-Based Simpliﬁcation in any Dimension” ACM Transactions on Graphics 24 (2)

pp.209–239.

Oracle Spatial and Graph (12.1) “SDO_UTIL.SIMPLIFYVW in SDO_UTIL Package (Utility)” Available at: https://docs.oracle.

com/database/121/SPATL/sdo_util-simplifyvw.htm#SPATL1466 (Accessed: July 2015).

Hamid, A.A., Ahmed, M. and Helmy, Y. (2010) “Enhanced Progressive Vector Data Transmission for Mobile Geographic
Information Systems (MGIS)” In Innovations and Advances in Computer Sciences and Engineering Springer Netherlands,
pp.61–66.

Harrower, M. and Bloch, M. (2006) “Mapshaper.org: A Map Generalization Web Service” IEEE Computer Graphics and

Applications 26 (4) pp.22–27.

Heckbert, P. and Garland, M. (1997) “Survey of Polygonal Surface Simpliﬁcation Algorithms” SIGGRAPH 97 Course Notes:
Multiresolution Surface Modeling Available: at: http://www.cs.cmu.edu/~./garland/Papers/simp.pdf (Accessed June 2015).
Hershberger, J. and Snoeyink, J. (1992) “Speeding Up the Douglas–peucker Line-simpliﬁcation Algorithm” In Proceedings of
5th Symposium on Data Handling, pp.134–143. (UBC Tech Report TR-92-07). Available at: http://www.cs.ubc.ca/cgi-bin/tr/
1992/TR-92-07 (Accessed: June 2015)

IGN (2014) “Class VisvalingamWhyatt” Laboratoire COGIT, IGN, France. Available at: https://ignf.github.io/geoxygene/

apidocs/fr/ign/cogit/cartagen/genealgorithms/polygon/VisvalingamWhyatt.html (Accessed: July 2015).

Jenks, G.F. (1981) “Lines, Computers, and Human Frailties” Annals of the Association of American Geographers 71 (1) pp.1–10.
Kaefer, K. (2012) “Simpliﬁcation of geometries using the Visvalingam–Whyatt algorithm” Available at: https://github.com/

mapnik/mapnik/pull/1385 (Accessed: May 2015). See also http://mapnik.org/ and http://dbsgeo.com/sotm-pdx/.

Koning, E. (2012) “Psimpl: generic n-dimensional polyline simpliﬁcation” version 7. Available at: http://psimpl.sourceforge.

net/index.html (Accessed: June 2015).

Kolodny, L. (2013) “Google maps open-source challenger mapbox raises $10M from foundry group” Available at: http://blogs.

wsj.com/venturecapital/2013/10/16/google-maps-open-source-challenger-mapbox-raises-10m-from-foundry-group/
(Accessed: January 2015).

Leu, J.G. and Chen, L. (1988) “Polygonal Approximation of 2-D Shapes through Boundary Merging” Pattern Recognition

Letters 7 pp.231–238.

Francisco, CA: Morgan Kaufmann.

Luebke, D., Reddy, M., Cohen, J., Varshney, A., Watson, B. and Huebner, R. (2003) Level of Detail for 3D Graphics San

Maling, D.H. (1989) Measurements from Maps: Principles and Methods of Cartometry Oxford: Pergamon Press.
Mapbox Studio (2014) “Mapbox/carto documentation” Available at: https://github.com/mapbox/carto/blob/master/docs/

latest.md#polygon-simplify-algorithm-keyword (Accessed: January 2015).

McMaster, R.B. (1987) “Automated Line Generalization” Cartographica: The International Journal for Geographic Information

and Geovisualization 24 (2) pp.74–111.

McMaster, R.B., Galanda, M., Schroeder, J. and Koehnen, R. (2005) ‘The Creation of a National Multiscale Database for the
United States Census’, in Proceedings of the International Cartographic Conference, A Coruna, Spain. Available at: http://
www.cartesia.org/geodoc/icc2005/pdf/oral/TEMA9/Session%207/ROBERT%20MCMASTER.pdf (Accessed: June 2015).
NHGIS (2011) “The National Historical Geographic Information System” Available at: https://www.nhgis.org/ (Accessed: June

Ordnance Survey (2015a) “OS GB maps ©2015: Viewer” Available at: http://www.ordnancesurvey.co.uk/opendata/viewer/

2015).

index.html (Accessed: June 2015).

Ordnance Survey (2015b) “A Guide to Coordinate Systems in Great Britain” Available at: http://www.bnhs.co.uk/focuson/

grabagridref/html/OSGB.pdf (Accessed: March 2016).

OSGeo-org (2015) “Thread on implementation of Visvalingam’s algorithm Geo” Available at: http://osgeo-org.1560.x6.nabble.
com/Sprinting-td5180250.html#a5180696 (Accessed: January 2015) within the Open Source Geospatial Foundation. https://
www.osgeo.org/about/.

Pikaz, A. and Dinstein, I. (1995) “An Algorithm for Polygonal Approximation Based on Iterative Point Elimination” Pattern

Recognition Letters 16 (6) pp.557–563.

THE CARTOGRAPHIC JOURNAL

271

PostGIS (closed 2015) “Visvalingam Line Generalization Function” Available at: https://trac.osgeo.org/postgis/ticket/2227

(Accessed: March 2016).

Prasad, D.K., Leung, M.K.H., Quek, C. and Cho, S.-Y. (2012) “A Novel Framework for Making Dominant Point Detection

Methods Non-Parametric” Image and Vision Computing 30 (11) pp.843–859. 10.1016/j.imavis.2012.06.010.

Prusinkiewicz, P. and Lindenmayer, A. (1990) The Algorithmic Beauty of Plants New York: Springer.
QGIS (2016) Working with Projections Available at: https://docs.qgis.org/2.14/en/docs/user_manual/working_with_

projections/working_with_projections.html (Accessed: April 2016).

Ramer, U. (1972) “An Iterative Procedure for the Polygonal Approximation of Plane Curves” Computer Graphics and Image

Processing 1 pp.244–256.

at:

Reimer, A. and Kempf, C. (2014) ‘Eﬃcient Derivation and Caricature of Urban Settlement Boundaries for 1:250k’, in 17th ICA
Workshop on Generalization and Multiple Representation, Vienna, Austria, 23rd September Available at: http://
generalisation.icaci.org/prevevents/82-workshop2014program.html.

Revell, P., Regnauld, N. and Bulbrooke, G. (2011) “OS VectorMap® district: Automated Generalization, Text Placement and
Conﬂation in Making Public Data Public” in Proceedings of 25th International Cartographic Conference. Paris, France,
3–8
http://icaci.org/documents/ICC_proceedings/ICC2011/Oral%20Presentations%20PDF/D3-
Generalization/CO-358.pdf (Accessed: May 2014).

July Available

Schroeder, J.P. (2010) “Extensions to the Visvalingam–Whyatt line simpliﬁcation algorithm for improved boundary
characterizations” Available at: http://users.pop.umn.edu/~jps/SchroederJP_ICC_2011_Abstract.doc (Accessed: June 2015).
Schroeder, J.P. and McMaster, R.B. (2007) “The Creation of a Multiscale National Historical Geographic Information System
for the United States Census” in Proceedings of the 23rd International Cartographic Conference. Moscow, Russia, 4th–10th
August Available at: http://icaci.org/ﬁles/documents/ICC_proceedings/ICC2007/documents/doc/THEME%2010/Oral%
203/The%20Creation%20of%20a%20Multiscale%20National%20Historical%20Geographic%20.doc (Accessed: June 2015).
Schroeder, W.J., Zarge, J.A. and Lorensen, W.E. (1992) “Decimation of Triangle Meshes” ACM SIGGRAPH Computer Graphics
26 (2) pp.65–70. Available at: http://fab.cba.mit.edu/classes/S62.12/docs/Schroeder_decimation.pdf (Accessed: June 2015).
Steinarsson, S. (2013) “Downsampling time series for visual representation” (MSc thesis) University of Iceland Available at:

http://skemman.is/stream/get/1946/15343/37285/3/SS_MSthesis.pdf.

Sunday, D. (2012) “Polyline decimation” Available at: http://geomalgorithms.com/a16-_decimate-1.html (Accessed: May

2015).

0010-4485(90)90070-S.

Turk, G. (1992) “Re-tiling Polygonal Surfaces” ACM SIGGRAPH Computer Graphics 26 pp.55–64.
Visvalingam, M. (1990) “Trends and Concerns in Digital Cartography” Computer-Aided Design 22 (3) pp.115–130. 10.1016/

Visvalingam, M. (2015a) ‘The Visvalingam Algorithm – Metrics, Measures and Heuristics’ (Explorations in Digital
Cartography Discussion Paper 2, University of Hull) p.11 Available at: https://hydra.hull.ac.uk/resources/hull:10596.
Revised version published as Visvalingam, M. (2016) ‘The Visvalingam Algorithm – Metrics, Measures and Heuristics’
The Cartographic Journal 33 (3) pp.242–252.

Visvalingam, M. (2015b) ‘Testing Implementations of Visvalingam’s Algorithm for Line Generalization’ (Explorations in
Digital Cartography Discussion Paper 3, University of Hull) Available at: https://hydra.hull.ac.uk/resources/hull:10874.
Visvalingam, M. and Brown, C.I. (1999) “The Deconstruction of Teragons into Decogons” Computers & Graphics 23 (1)

pp.155–167.

Visvalingam, M. and Dowson, K. (1998) “Algorithms for Sketching Surfaces” Computers & Graphics 22 (2,3) pp.269–280.
Visvalingam, M. and Herbert, S.P. (1999) “A Computer Science Perspective on the Bendsimplify Algorithm” Cartography and

Geographic Information Science 26 (4) pp.253–270.

Visvalingam, M. and Whelan, J. C. (2014). ‘Implications of Weighting Metrics for Line Generalization with Visvalingam’s
Algorithm’, (Explorations in Digital Cartography Discussion Paper 1, University of Hull) p.24 Available at: https://
hydra.hull.ac.uk/resources/hull:10064. Revised version published as Visvalingam, M. and Whelan,
(2016)
“Implications of Weighting Metrics for Line Generalization with Visvalingam’s Algorithm” The Cartographic Journal 53
(3) pp.252–267.

Visvalingam, M. and Whyatt, J.D. (1990) “The Douglas-Peucker Algorithm for Line Simpliﬁcation: Re-Evaluation through

J. C.

Visualization” Computer Graphics Forum 9 (3) pp.213–225.

Visvalingam, M. and Whyatt, J.D. (1991) “Cartographic Algorithms: Problems of Implementation and Evaluation and the

Impact of Digitising Errors” Computer Graphics Forum 10 (3) pp.225–235.

Visvalingam, M. and Whyatt, J.D. (1992) “Line Generalization by Repeated Elimination of Points” (Cartographic Information
Systems Research Group Discussion Paper 10, University of Hull) p.16. Available at: https://hydra.hull.ac.uk/resources/
hull:8338.

Visvalingam, M. and Whyatt, J.D. (1993) “Line Generalization by Repeated Elimination of Points” The Cartographic Journal 30

(1) pp.46–51.

Visvalingam, M. and Williamson, P. (1995) “Simpliﬁcation and Generalization of Large-Scale Data for Roads: A Comparison
Information Science 22 (4) pp.264–275. 10.1559/

of Two Filtering Algorithms” Cartography and Geographic
152304095782540249.

Vivid Solutions (2001) “VWSimpliﬁer.java” Available at: http://sourceforge.net/p/jts-topo-suite/code/HEAD/tree/trunk/jts/

java/src/com/vividsolutions/jts/simplify/VWSimpliﬁer.java (Accessed: January 2015).

Weibel, R. (1997) “Generalization of Spatial Data: Principles and Selected Algorithms” In Kreveld, M.V., Nievergelt, J., Roos, T.
and Widmayer, P. (Eds) Algorithmic Foundations of GIS (Lecture Notes in Computer Science Volume 1340) Berlin:
Springer, pp.99–152.

Weifang, Y., and Li, J. (2012) “A Method for Rapid Transmission of Multi-Scale Vector River Data via the Internet” Geodesy

and Geodynamics 3 (2) pp.34–41.

White, E.R. (1983) “Perceptual Evaluation of Line Generalization Algorithms” (MSc thesis) University of Oklahoma.

272

M. VISVALINGAM

p.259.

Cartographers 22 (1) pp.17–25.

Whyatt, J.D. (1991) “Visualisation and Re-evaluation of Line Simpliﬁcation Algorithms” (PhD thesis) University of Hull,

Whyatt, J.D. and Wade, P.R. (1988) “The Douglas Peucker Line Simpliﬁcation Algorithm” The Bulletin of the Society of

Yang, B.S., Purves, R.S. and Weibel, R. (2004) “Implementation of Progressive Transmission Algorithms for vector Map Data
Web-based Visualization” in The International Archives of the Photogrammetry, Remote Sensing and Spatial Information
Sciences Volume 34, Istanbul, Turkey, pp.12–23. Available at: http://www.isprs.org/proceedings/XXXV/congress/comm4/
papers/310.pdf (Accessed: July 2015).

Yang, B.S., Purves, R.S. and Weibel, R. (2007) “Eﬃcient Transmission of Vector Data Over the Internet” International Journal

of Geographical Information Science 21 (2) pp.215–237.

Zhou, S. (2014) “Partition and Conquer: Improving WEA-based Coastline Generalization” GISRUK 2014, Glasgow, 16th–18th
April 2014 Available at: http://www.researchgate.net/publication/261723727_Partition_and_conquer_Improving_WEA-
based_coastline_generalization (Accessed: May 2014). Original demonstrator and the Java source code available at:
http://www.researchgate.net/publication/262487021_WEADemo-original (Accessed: August 2014).

Zhou, S. and Jones, C.B. (2004) “Shape-aware Line Generalization with Weighted Eﬀective Area” In Fisher, P (Ed.)

Developments in Spatial Data Handling Berlin: Springer, pp.369–380.

