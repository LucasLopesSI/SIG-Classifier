International Journal of Geographical Information Science
Vol. 25, No. 9, September 2011, 1347–1370

An event-based conceptual model for context-aware
movement analysis
Gennady Andrienkoa∗, Natalia Andrienkoa and Marco Heurichb

aKnowledge Discovery Department, Fraunhofer Institute IAIS (Intelligent Analysis and Information
Systems), Schloss Birlinghoven, D-35754, Sankt Augustin, Germany; bDepartment for Research
and Documentation, Bavarian Forest National Park, Grafenau, D-94481, Germany

(Received 14 October 2010; ﬁnal version received 12 January 2011)

Current tracking technologies enable collection of data, describing movements of var-
ious kinds of objects, including people, animals, icebergs, vehicles, containers with
goods and so on. Analysis of movement data is now a hot research topic. However,
most of the suggested analysis methods deal with movement data alone. Little has been
done to support the analysis of movement in its spatio-temporal context, which includes
various spatial and temporal objects as well as diverse properties associated with spatial
locations and time moments. Comprehensive analysis of movement requires detection
and analysis of relations that occur between moving objects and elements of the context
in the process of the movement. We suggest a conceptual model in which movement
is considered as a combination of spatial events of diverse types and extents in space
and time. Spatial and temporal relations occur between movement events and elements
of the spatial and temporal contexts. The model gives a ground to a generic approach
based on extraction of interesting events from trajectories and treating the events as
independent objects. By means of a prototype implementation, we tested the approach
on complex real data about movement of wild animals. The testing showed the validity
of the approach.

Keywords: trajectories; movement data; movement behaviour; spatio-temporal con-
text; relations; events; spatio-temporal data; spatio-temporal analysis; geovisualization

Introduction

1.
Recent technological progress has enabled tracking of various moving objects and col-
lection of data about the movement. In some domains, such as trafﬁc management or
tourism, movement data may be used to study general characteristics of mobility: space
use, spatial and temporal variation of objects’ presence, major ﬂows and so on. In other
domains, movement behaviours of individuals and/or groups are in focus. Examples are
animal research, iceberg studies and sports analysis.

It should be emphasized that movement behaviours can only be understood by consid-
ering various relations occurring between moving objects and the environment in which
they move. The environment, also called spatio-temporal context, includes

*Corresponding author. Email: gennady.andrienko@iais.fraunhofer.de

ISSN 1365-8816 print/ISSN 1362-3087 online
© 2011 Taylor & Francis
http://dx.doi.org/10.1080/13658816.2011.556120
http://www.tandfonline.com

1348

G. Andrienko et al.

(cid:129) complex and heterogeneous physical space, in which characteristics vary from place

to place and change over time,

(cid:129) complex and heterogeneous physical time, in which day differs from night, summer

from winter and so on,

(cid:129) static and dynamic objects existing in space, as well as
(cid:129) events occurring over time.

Tomaszewski and MacEachren (2010) suggest a conceptual model that encompasses three
aspects of context: spatial (geographical), temporal (historical) and conceptual. From these
three, the spatial and temporal aspects are in the focus of our current research. As many
kinds of objects and phenomena are simultaneously spatial and temporal, we do not sepa-
rate the spatial and temporal aspects but join them into a single concept of spatio-temporal
context. This article deals particularly with the spatio-temporal context of movement.
For the sake of brevity, we shall sometimes use the single word ‘context’ to refer to the
spatio-temporal context.

Although extensive research on analysing movement has been made in recent years,
most of the existing methods and tools focus on movement data per se with little or no
consideration of the spatio-temporal context. Our current research aims at ﬁnding ways to
involve context information in analysis of movement data. We have developed a general
approach based on treating occurrences of various relations between moving objects and
elements of the context as spatial events, that is, objects localized in space and time. These
events are extracted from movement data and context data by means of computations and
interactive ﬁltering. Extracted events are then visualized and analysed using suitable meth-
ods. As a proof of concept, we have done a prototype implementation of the approach and
tested it on real-world datasets.

In the next section of this article, we give an overview of the research on movement
analysis and demonstrate that quite little has been done so far on joint analysis of movement
data and context data. Next, we introduce the conceptual model underlying our approach
and the approach itself. After a brief description of our prototype implementation, we show
how the approach works by example of real data about movement of wild animals. This is
followed by a discussion of the results and a conclusion.

2. State of the art

A cartographic map can convey to some extent the heterogeneity of the geographical space
and various relations occurring within it (Andrienko et al. 2008). Hence, a visual repre-
sentation of movement on a map enables a human analyst to see some of the relations
between the movement and the spatial context. However, maps are weak in representing
temporal information. The existing techniques and tools for the visualization and explo-
ration of spatio-temporal data are reviewed by Andrienko et al. (2003). The most common
approach to dealing with space and time together is map animation; however, its effective-
ness is quite limited (Tversky et al. 2002). Another approach is the space–time cube, where
the horizontal plane represents space and the vertical dimension represents time. The idea
was introduced by T. Hägerstrand in the 1960s (Hägerstrand 1970) but software imple-
mentations appeared relatively recently in geovisualization and information visualization
(Andrienko et al. 2003, Kraak 2003, Kapler and Wright 2005). Both a map and a space–
time cube are limited with respect to the number of trajectories that can be effectively
explored, the length of the time period and the capacity to represent various aspects of the

International Journal of Geographical Information Science

1349

movement context: when much information is included in a display, it becomes illegible
due to the visual clutter.

As larger and larger collections of movement data become available, researchers work
on devising computational analysis methods that could cope with these amounts. One of
the possible approaches is data aggregation. A survey of the aggregation methods used
for movement data is done by Andrienko and Andrienko (2010). To study the distribution
of movement characteristics over space, movement data are aggregated into continuous
density surfaces (e.g. Dykes and Mountain 2003, Willems et al. 2009) or discrete grids
(e.g. Forer and Huisman, 2000, Andrienko and Andrienko 2010). Mountain (2005) fur-
ther processed density surfaces generated from movement data to extract their topological
features: peaks, pits, ridges, saddles and so on. Brillinger et al. (2004) aggregated move-
ment data into a vector ﬁeld using a regular grid: in each grid cell, a vector is built with the
angle corresponding to the prevailing movement direction and the length and width propor-
tional to the average speed and amount of movement, respectively. Wood and Dykes (2008)
built spatially ordered treemaps combining spatial, temporal and attributive aggregation. To
study links between places, movement data are aggregated into origin–destination matri-
ces (Guo, 2007) and ﬂow maps (Tobler 1987, 2005, Andrienko and Andrienko 2011).
Wood et al. (2010) suggested two-level spatial treemaps to represent ﬂows among loca-
tions. The existing aggregation methods operate on movement data only, that is, do not
involve any data about the spatio-temporal context. Investigation of relations between the
movement and the context is only supported by showing aggregated data on a cartographic
background for visual inspection.

Various computational analysis techniques for movement data are developed in the area
of data mining. Most of them deal with movement data alone and do not take the context
into account. Extensive research is done around the concept of similarity of movement
trajectories. A number of similarity measures and respective algorithms for computing the
similarity have been proposed (Andrienko et al. 2007, Pelekis et al. 2007, Trajcevski et al.
2007). These measures and algorithms are used for querying trajectory databases (Vlachos
et al. 2002, Pelekis et al. 2007) and for clustering trajectories (Gaffney and Smyth 1999, Li
et al. 2004, Nanni and Pedreschi 2006, Rinzivillo et al. 2008). Another research direction
is extracting particular types of movement patterns, such as frequent sequences of visited
places and transition times between them (Giannotti et al. 2009).

There are relatively few methods for analysing relations between moving objects and
elements of the movement context. Crnovrsanin et al. (2009) visualized the dynamics of
the distances of moving objects to selected locations. Lundblad et al. (2009) attached data
about weather conditions to positions of ships and visualized the data on interactive linked
displays. Yu (2006) computationally detected occurrences of three types of spatio-temporal
relations among moving objects: co-location in space, co-location in time and co-location
in both space and time. Orellana et al. (2009) detected and visualized occurrences of prox-
imity between moving objects. Laube et al. (2005) proposed methods for ﬁnding certain
types of relative movements of several objects such as concurrence, opposition, dispersion,
following, ﬂocking and so on.

ArcGIS Tracking Analyst (ESRI 2010) is a commercially available tool for movement
analysis allowing the user to visualize tracks of moving objects; modify the display by
means of highlighting, ﬁltering and other operations; and create map animations. Nothing
speciﬁc is suggested for analysing movement in context; however, the user can employ the
analytical functionality of the ArcGIS Desktop system, in particular, perform queries and
computations on two or more map layers.

1350

G. Andrienko et al.

Hence, despite the existence of extensive literature and a large number of methods and
tools for analysing movement data, quite little research and development has been done so
far concerning the analysis of movement in context. Furthermore, although there are a few
methods for detection of certain types of relations (mostly relations of moving objects to
other moving objects), no attempts have been made to support context-aware movement
analysis in a more systematic and comprehensive way. Our research aims at ﬁlling up this
gap. The next two sections introduce the main concepts we deal with and explain our
approach to supporting movement analysis.

The concept of spatial event plays a key role in our approach. Beard et al. (2008)
reviewed the deﬁnitions of events occurring in the literature and noted that a common
theme among them is that events are associated with change and localized in space and
time. Our deﬁnition of spatial events includes only the spatial and temporal localizations
as essential features; change is not a necessary part of the meaning.

3. Conceptual model
There are three fundamental sets pertinent to movement: space S (set of locations), time T
(set of instants or intervals, jointly called time units) and objects O (Peuquet 1994, 2002).
Elements of each set may have their properties, which can be represented by values of
attributes. Among others, there may be attributes whose values are elements of T, S or O,
or more complex constructs involving elements of T, S or O. Attributes that do not involve
time or space will be called ‘thematic’.

The set of objects includes various physical and abstract entities. Objects can be clas-
siﬁed according to their spatial and temporal properties. Table 1 contains the deﬁnitions
and examples of the types of objects relevant to our work: spatial object; temporal object,
also called event; spatial event; static spatial object; moving object, also called mover; and
moving event.

Changes of the spatial position of a mover over time can be represented by a mapping
T→S (in mathematical terms, a mapping, or function from set P to set Q, denoted as P→Q,
is a correspondence between elements of P and Q such that for any p∈P there is at most
one q∈Q). A mapping T→S is called trajectory. A trajectory is an object having a certain
position in space, which is the set of locations visited by the mover. Hence, a trajectory
is a spatial object, by the deﬁnition given in Table 1. When the mover is considered as a
point (i.e. the shape and size are ignored), the spatial position of the trajectory is a line in
S. A trajectory may also have a certain position in time, which is the time interval when
the positions of the mover were observed. This interval does not necessarily coincide with
the whole time of the mover’s existence. Hence, a trajectory, generally, is a spatial event,
by the deﬁnition given in Table 1.

Furthermore, a trajectory T→S consists of pairs (t,s), t∈T, s∈S. Each pair has a par-
ticular position s in space and a particular position t in time; in our classiﬁcation, it is a
spatial event. Hence, a trajectory T→S is a complex spatial event consisting of a sequence
of elementary spatial events (t,s).

Movers may also have thematic attributes, which may be static (i.e. values do not
change over time) or dynamic. The values of a dynamic attribute, such as movement speed
or direction, are mappings T→A, where A is the set of possible values of the attribute, for
example [0,100] km/h for the speed and [0,360] degrees for the direction. The pairs (t,a)
in T→A can also be considered as objects having temporal positions, that is, as events, for
example speed events, direction events and so on.

International Journal of Geographical Information Science

1351

Table 1. Types of objects according to their spatial and temporal properties.

Concept

Superior concepts

Properties

Examples

Spatial object

Object

Event (temporal

Object

object)

Building, village, river,
rainfall, deer, lynx, a
deer at a river, a lynx
chasing a deer

Rainfall, a deer at a river,
a lynx chasing a deer,
sunset, winter

Spatial event

Spatial object, event Has certain positions in

space and in time

Rainfall, a deer at a river,
a lynx chasing a deer

(spatio-temporal
object)

Static spatial object

Spatial object

The spatial position is

Building, village, river

Mover (moving

object)
Moving event

Spatial object

Mover, event

Deer, lynx, a lynx chasing

a deer

A lynx chasing a deer

Has a certain position in
space (a location or a
set of locations, not
necessarily
continuous)
Appears and/or

disappears during the
time period under
analysis, that is, has a
certain position in
time (a time unit or a
sequence of time
units)

constant; exists during
the whole time period
under analysis
The spatial position
changes over time
Exists during a sequence
of time units (i.e. not
instant); the spatial
position changes over
time

Instead of dealing with the mappings T→S and T→A separately, one can consider their
join T→S×A consisting of triples (t,s,a). Hence, an occurrence of an attribute value a at
time t has a corresponding spatial position s. More generally, when a mover has several
dynamic thematic attributes A1, . . . , An, the temporal variation of the mover’s position
and thematic characteristics can be represented by a joint mapping T→S×A1×. . .×An
consisting of tuples (t,s,a1,. . .,an). We shall use the notation (t,s,a) as a compact form of
(t,s,a1,. . .,an), meaning that a may stand for a combination of values of several thematic
attributes. Each tuple (t,s,a) is a spatial event.

A sequence of temporally consecutive events may be regarded as one larger event,
which, in turn, may be included in a higher-level event. One of the possible reasons for
uniting consecutive events (t1,s1,a1), (t2,s2,a2), . . ., (tk,sk,ak) into one event may be con-
stancy of s (s1=s2=. . .= sk) and/or a (a1=a2=. . .= ak). We shall use the term movement
events to refer to elementary and composite spatial events involved in the movement. We
shall use the notations (t,s) and (t,s,a) both for elementary and for composite movement
events. This means that t may stand either for an element of T (t∈T) or for a continuous
subset of T (t⊂T), that is, a sequence of consecutive time units. In both cases, s is the
set of spatial locations (s⊂S) and a is the set of attribute values (a⊂A, A=A1×. . .×An)
corresponding to t by the mapping T→S×A. The dependence of s and a on t may be
emphasized by transforming (t,s,a) to (t,s(t),a(t)). To denote that movement event (t,s,a)
belongs to moving object o, the notation (o,t,s,a) may be used.

Figure 1 schematically represents our view of movement as a collection of spatial
events. This extends the conceptual model of movement as a combination of stops and

1352

G. Andrienko et al.

Figure 1. Movement as a composition of spatial events.

moves suggested by Spaccapietra et al. (2008). In the latter model, stops are important
parts of trajectories associated with domain-speciﬁc semantics, whereas moves are merely
transitions between consecutive stops. In our model, stops and moves are particular types
of spatial events among other types. Any of the possible types of movement events may be
important from the application point of view.

For a selected moving object o, the spatio-temporal context C consists of the space,

time and other objects positioned in the space and/or time: C = S∪T∪O\{o}.

As we argued before, movement of an object consists of spatial events, called move-
ment events. Each event is linked to elements and subsets of the context by relations.
Spatial relations link movement events through their spatial positions to elements and
subsets of S. Other spatial objects also have positions in S; hence, spatial relations link
movement events to other spatial objects. Temporal relations link a movement event
through its temporal position to elements and subsets of T. Other events also have positions
in T; hence, temporal relations link movement events to other events. Figure 2 schemati-
cally represents the spatio-temporal context of object’s movement and how the movement
is related to the context.

The possible types of spatial and temporal relations are considered in the litera-
ture on temporal and spatial reasoning (e.g. Allen 1983, Egenhofer 1991, Frank 1992)
and on geographic information systems (e.g. Jones 1997, Longley et al. 1999). The
basic types of temporal relations include binary topological, ordering and distance rela-
tions. The basic types of spatial relations include binary topological, directional and
distance relations. Topological and ordering relations are formally represented by pred-
icates, that is, Boolean-valued functions P×Q→{true,false}. Distance relations can be

International Journal of Geographical Information Science

1353

Figure 2. Spatio-temporal context of object’s movement and relations between the mover and
elements of the context.

represented by numeric-valued functions P×Q→[0,∞] expressing spatial or temporal dis-
tances in suitable units, for example metres or seconds. Directional spatial relations can
be represented by a numeric function representing the spatial direction, for example in
degrees. Directional and distance relations can also be represented qualitatively, that is, by
predicates such as ‘near’, ‘far’, ‘north’ and so on (Frank 1992). In fact, any such pred-
icate stands, explicitly or implicitly, for a certain range of values of a numeric function.
Reciprocally, for any range (or, more generally, subset) of values of a numeric function,
one may introduce a predicate. Hence, we assume that distance and direction relations
can always be represented by a set of predicates deﬁned according to the speciﬁcs of the
application domain and the goals of the analysis.

From the basic types of relations, more complex types of relations are built such as
density (clustering, dispersion), arrangement (e.g. sequence in time or alignment in space)
and spatio-temporal relations. The latter are composed of spatial and temporal relations
and represent changes of spatial relations over time: approaching or going away, enter-
ing or exiting, following, keeping distance, concentrating or dissipating and so on. Some
researchers call such relations ‘movement patterns’ (Dodge et al. 2008) or ‘interactions’
(Orellana and Renso 2010).

Let a movement event m be linked to some element or subset c of the context by relation
R, which means that R(m,c)=true. For example, the spatial position of a deer in some time
unit is at a river. Here, the deer is the mover, the combination of the time unit and the
respective spatial position is the movement event, the river is an element of the context
and ‘at’ is a type of spatial relation. A combination (m,c,R) where R(m,c)=true is called an
instance, or occurrence of the relation type R.

Movement data are records associating movers with respective trajectories and, pos-
sibly, values of thematic attributes. Most often, movement data have the form (object
identiﬁer, time reference, spatial coordinates, attribute values). Movement data available in
other forms can be transformed to this form. Context data describing the spatio-temporal
context of the movement may have diverse forms depending on the nature of the respective
context elements. For example, geographical datasets may describe the spatial context.
Movement data containing trajectories of multiple objects describe simultaneously the
movement of each object and a part of its context consisting of the movements of the

1354

G. Andrienko et al.

other objects. Context data may also be implicit, that is, exist in the mind of an analyst. For
example, there may be no dataset describing which time of the day is light and which is
dark, but analysts may use their professional knowledge or common sense.

4. General approach

Context-aware analysis of movement implies consideration of relations between object’s
movement and the context. The number of instances of various spatial, temporal and spatio-
temporal relations between movement events and the context is inﬁnite; it is impossible to
consider them all. Usually, not all instances are interesting to analysts, that is, relevant
to analysis goals. Analysts need tools that support ﬁnding interesting instances among all
possible (m,c,R). A set of potentially interesting instances may be deﬁned by imposing
constraints on m, c and/or R. Based on which elements of the triad (m,c,R) are given
(constrained) and which of them needs to be found, we distinguish three types of tasks.
They can be symbolically represented by formulas (?,c,R), (m,?,R) and (m,c,?), where the
question mark stands for the unknown element. In Table 2, we give text interpretations to
these formulas, suggest the kinds of tools and techniques that can support the tasks and
provide examples.

The tasks (m,?,R) and (m,c,?) imply that movement events m have been previously
extracted from movers’ trajectories. In particular, extracted movement events may be a
result of the task (?,c,R). As suggested in Table 2, the task is supported by a tool that
extracts parts of trajectories having relation R to context elements c. However, not only such
events may be interesting to analysts. Analysts should also be able to extract movement
events according to values of dynamic thematic attributes, for example events of low speed
and northward movement.

Hence, we suggest a general approach to context-aware movement analysis based on

extraction of interesting events from trajectories:

Table 2. Types of queries about relations between movement and context.

Task

Interpretation

Support

Examples

(?,c,R)

Find movement events

(parts of trajectories) that
have relation R to
context element(s) c.

(m,?,R)

Find context elements that

have relation R to
movement event(s) m.

(m,c,?)

Find relations that exist
between movement
event(s) m and context
element(s) c.

Extraction of movement

events from trajectories:
for each m = (t,s)
compute predicate
R(m,c); extract such m
that R(m,c) = true.a
Visualization of the events

and the context;
aggregation of events by
context elements they are
related to.

Visualization of the events
and the context; queries
(ﬁltering) to select the
context elements of
interest.

Extract the parts of deer’s

trajectories in open areas.
Extract the parts of deer’s
trajectories in 6 hours
after the events of deer’s
proximity to lynxes.

Find in what spatial context

the events of deer’s
proximity to lynxes
occurred. Find in what
temporal context the deer
appeared in open areas.

How are the events of
deer’s proximity to
lynxes located in space
in relation to the open
areas? When did the
events of deer’s
appearance in open areas
occur in relation to the
sunrise and sunset times?

Note: aThe extracted events make a part of the spatio-temporal context.

International Journal of Geographical Information Science

1355

(cid:129) Interactive query tools allow the analyst to deﬁne what movement events are of
interest in terms of relations to elements of the context and/or in terms of values
of dynamic thematic attributes.

(cid:129) The events are extracted from the trajectories and added to the database as new
objects. In the following analysis, they may be treated as elements of the spatio-
temporal context for other movement events.

(cid:129) The extracted events are visualized together with their context on spatial, temporal

and spatio-temporal displays.

(cid:129) The extracted events are analysed using spatial and temporal queries, aggregation,
clustering and other analytical techniques suitable for spatial events as data type.

Orellana and Renso (2010) have recently suggested an approach based on representing
movement data as a collection of interactions with the context (the term ‘interaction’ corre-
sponds to ‘relation’ in our article). The main idea is to deﬁne possible types of interactions
in a knowledge base (ontology) and use automatic inference to extract interaction instances
from specially prepared data. As the authors admit, populating the ontology with data is a
difﬁcult task requiring further research.

5. Prototype implementation

As a proof of the concept, we have implemented this general approach within a geospatial
visual analytics system for interactive exploration and analysis of diverse types of spatial
and spatio-temporal data. Describing the entire system is out of scope of the article. We
focus on the tools used for the extraction of interesting movement events from trajectories.

5.1. Basic visualization and interaction tools
The basic visualization tools available in the system include cartographic map display and
space–time cube. In both displays, trajectories of movers are represented by lines. Spatial
events can be represented by points, lines or areas, depending on their spatial extent.
Events extracted from movement data are represented by singular points or multi-points
(i.e. several points represent one event). In addition to map and space–time cube, diverse
non-cartographic displays can be created, including scatterplots, parallel coordinate plots,
frequency histograms, time graphs and others.

A set of interactive tools for data ﬁltering allows the user to select portions of move-
ment data and/or context data to be visualized and analysed. A temporal ﬁlter limits the
temporal scope of the data. A spatial ﬁlter selects spatial objects ﬁtting in a user-deﬁned
area, for example bounding rectangle. An attribute ﬁlter selects objects according to values
of thematic attributes. A class-based ﬁlter selects classes or clusters of objects. An object
ﬁlter allows the user to directly select speciﬁc objects. Several ﬁlters are combined by the
logical operation AND. All visual displays dynamically react to changes of the ﬁlter con-
ditions made by the user. The ﬁlters also affect the extraction of events from trajectories:
only the data satisfying the ﬁlters are used.

Each kind of ﬁlter has its speciﬁc user interface, as illustrated in Figure 3. To set a
spatial ﬁlter, the user draws a rectangle in the map display (A). A class-based ﬁlter is
controlled through a list of classes with checkboxes (B), which are activated or inactivated
by the user. For an object ﬁlter, a list of object names is provided. The user selects one
or more list items and activates the checkbox ‘Use as ﬁlter’ (C). The user interface of
the temporal ﬁlter (D) includes a time slider (blue bar) manipulated by mouse dragging,

1356

G. Andrienko et al.

Figure 3.
temporal ﬁlter; (e) attribute ﬁlter.

Interactive data ﬁlters. (a) Spatial window; (b) class-based ﬁlter; (c) object ﬁlter; (d)

which moves the whole bar or its left or right end. There are also text ﬁelds for entering
the exact start and/or end times of the chosen interval or the desired interval duration. The
latter can be speciﬁed in user-preferred time units, from seconds to years. To choose the
time unit, the user clicks on the label denoting current unit and receives a list of possible
units for selection. Time intervals for the temporal ﬁlter can also be selected by clicking
on graphical elements representing temporal objects in spatial and temporal displays, for
example on points of trajectories in a map. The times corresponding to these elements
are used as reference times for setting the ﬁlter. In the time ﬁlter window (D), the user
speciﬁes the relative positions of the start and end of the selected interval with respect to
the reference time. For the relative positions, the same time units are used as for the length
of the time interval. In the user interface of an attribute ﬁlter (E), conditions for numeric
attributes are speciﬁed by entering the desired minimum and/or maximum values in text
ﬁelds or by dragging sliders (blue triangles). For non-numeric attributes, the user may either
select one or more of the existing values from a list, or enter the values of interest in the
text ﬁeld, or specify a substring that must be contained in attribute values.

The speciﬁc interactive query tools used for event extraction from trajectories are

described in the following sections.

5.2. Temporal view of trajectories
Temporal view of trajectories is a visual display used in one of two modes: time graph
and time bars. In both modes, the horizontal dimension of the display represents time.
In the time graph mode, the vertical dimension represents the value range of some time-
dependent numeric variable, which may be one of the following:

International Journal of Geographical Information Science

1357

(cid:129) Spatial distances: to speciﬁc trajectory points (start, end, midpoint or any other com-
putationally extracted point), to selected locations, to selected spatial objects (static
objects, movers or events);

(cid:129) Temporal distances: to the trajectory start or end, to values of a temporal attribute

(i.e. an attribute whose values are time moments), to selected events;

(cid:129) Dynamic thematic attributes: any attribute available in the movement data; attributes
derivable from positions: speed, direction, distance travelled from the beginning of
the movement, remaining trip length, distance travelled in time intervals of speciﬁed
length and so on.

Each trajectory is represented by a polygonal line (Figure 4) reﬂecting the temporal
variation of the values of the variable. This is similar to the visualization suggested by
Crnovrsanin et al. (2009); however, our display is not limited to showing distances to
selected locations. The display includes controls for choosing the variable to be currently
visualized. If the values are not available in the original data, they are immediately com-
puted, and the display is updated. A detailed description of the contents of Figures 4 and 5
is given in Section 6.2.1.

A disadvantage of the time graph view is overplotting of the lines. The time bar view
(Figure 5) removes the overplotting at the cost of precision in representing the numbers. In
this mode, which is a variation of the Gantt chart technique, trajectories are represented by
horizontal bars positioned one below another, that is, the vertical dimension does not con-
vey any meaning but is used for arranging display elements. The horizontal positions and
the lengths of the bars correspond to the temporal positions and durations of the respec-
tive trajectories. Values of the currently selected variable are represented by colours of bar
segments. For this purpose, the value range of the variable is interactively divided into
intervals. Each interval gets its colour according to one of the Color Brewer colour scales

Figure 4. The time graph mode of the temporal view of trajectories.

1358

G. Andrienko et al.

Figure 5. The time bar mode of the temporal view of trajectories.

(Harrower and Brewer 2003). Colourless segments correspond to intervals of data absence.
A similarity to the approach taken by Laube et al. (2005) and Kincaid and Lam (2006) can
be noted; however, our visualization is suited to different life times of the trajectories and
to temporally irregular data. We do not assume that values for different objects refer to the
same regularly spaced time moments or intervals.

When the user moves the mouse cursor over the temporal view, the respective temporal
position is marked by a vertical line. The same temporal position is simultaneously marked
in all instances of the temporal view that are currently present on the screen. When the
mouse cursor points on a display element representing a trajectory, the spatial position cor-
responding to this temporal position is marked in the map display by a cross-shaped cursor
and in the space–time cube by a vertical line (this can be seen in Figure 8). The time and
the corresponding value are shown by text on the top of the temporal view. Additionally, a
popup window displays general information about the trajectory.

5.3. Event extraction
Our interactive query tool for event extraction works in two stages. The ﬁrst stage is ﬁl-
tering: only the parts of the trajectories that satisfy the query conditions are shown in the
visual displays. This speciﬁc ﬁlter for trajectories is called segment ﬁlter. The user can pre-
view the events that will be extracted according to the current query and decide whether
to proceed with the extraction or to change the query conditions. The second stage, which
occurs upon pressing a special button, creates a new dataset consisting of the extracted
events.

The user interface of the segment ﬁlter is embedded in the temporal view of trajecto-
ries: this is the colour legend on the left of the plot area (Figure 5). Clicking on the coloured
rectangles unselects and selects the respective value intervals, which sets query conditions
on the values of the currently visualized variable. Hence, the user may deﬁne which move-
ment events are of interest either in terms of distances to elements of the context or in terms
of dynamic thematic attributes. The user can open several temporal views showing differ-
ent variables and set two or more segment ﬁlters simultaneously. This operation is called

International Journal of Geographical Information Science

1359

cross-ﬁltering (Weaver 2010). The ﬁlters are combined by the logical operation AND. For
example, cross-ﬁltering may ﬁnd the appearances of deer in open areas within 6 hours after
encountering lynxes.

It can be noted that the segment ﬁlter is limited concerning the types of spatial and
temporal relations that can be used in query conditions. The tool allows the user to deﬁne
arbitrary predicates on the basis of spatial and temporal distances; however, predicates in
terms of topological and directional relations are not directly supported. These limitations
are not pertinent to the approach in general but refer only to the current version of our
prototype tool, which, in principle, can be extended to other types of relations. However,
as will be shown by an example, queries by spatial and temporal distance relations are
sufﬁcient for rather sophisticated spatio-temporal analyses.

Our prototype implementation is oriented to a discrete model of the movement context,
that is, the context is represented as a combination of discrete spatial, temporal and spatio-
temporal objects with their attributes. Another possibility is to consider the context as a
spatio-temporal continuum, in which properties vary from location to location. This view
is appropriate for spatially and temporally continuous phenomena, such as weather. In the
continuous data model, the continuum is divided into compartments by means of a grid,
and the properties are represented by attribute values associated with the grid cells. Our
approach can be applied to a continuous representation of the context in the following way.
Each position of a trajectory is located in a certain cell of the space–time continuum. The
attribute values from the cell are attached to this position; hence, the movement data are
enriched with additional attributes representing the context. These context attributes are
visualized in the temporal view of trajectories. By applying the segment ﬁlter, movement
events co-occurring with selected attribute values of interest are extracted, for example
movements during harsh weather conditions.

5.4. Extraction of event-related statistics
Using the temporal view of trajectories, the analyst may obtain statistics of the values of
the currently visualized variable for speciﬁed time intervals around selected events. The
statistics include the minimum, maximum, median, mean and standard deviation of the
values. These are attached to the events as new thematic attributes, which allows the analyst
to investigate the impact of the events on the movement.

For getting event-related statistics, the user selects the dataset with the events and spec-
iﬁes the starts and ends of the time intervals of interest in relation to the start or end times
of the events, for example from 6 hours before the event starts till 12 hours after the event
ends. When the events have references to trajectories among their thematic attributes, the
user may request that the statistics for each event are extracted only from the relevant tra-
jectory. In particular, movement events previously extracted from trajectories always have
references to these trajectories. The other available options are to extract event-related
statistics from all trajectories or from the parts of trajectories being within a chosen range
of spatial distances from the events.

6. Example scenario of movement analysis
6.1. Example dataset
The dataset we use for our example scenario was collected by GPS-tracking of 72 roe deer
and 3 lynxes in the Bavarian Forest National Park (Bayerischer Wald) in Germany. The ani-
mals wear special collars with devices that measure the positions at chosen time intervals
and transmit the measurements via radio networks (Bavarian Forest 2010). Unfortunately,

1360

G. Andrienko et al.

the amounts of data that can be collected are strongly limited by the battery lives of the
tracking devices. Thus, a collar suitable for roe deer can collect about 3500 positions and
a collar suitable for lynxes about 1200 positions. To track animals over longer time, the
researchers increase the time intervals between the position measurements. Therefore, the
collected records are quite sparse in time. Furthermore, transmitted measurements are often
lost; hence, the time intervals between the records may be irregular, and large temporal gaps
may occur.

These problems are typical for data obtained by tracking wild animals. Many of the
existing methods for movement data analysis assume regular sampling of position records
and, moreover, high sampling frequency, which allows interpolation between known posi-
tions. Such methods would not be applicable to animal-tracking data. Our methods based
on event extraction do not assume temporal regularity and/or high temporal frequency of
the position records. However, in applying these methods, it should be borne in mind that
an extracted set of events of a certain type does not necessarily include all events of this
type that might have occurred in reality. The analyst should treat any extracted set of events
as a sample of real events.

The Bavarian Forest dataset contains 90,571 position records for the roe deer and 2604
for the lynxes within the period from 11 December 2004 to 21 January 2009. The time
spans of the data about individual animals vary from 5 to 1077 days. The time intervals
between the position records vary from a few minutes to several months; the median inter-
val length is about 5 hours for the roe deer. For the three lynxes, the time intervals are about
12 hours, 45 minutes and 24 hours, respectively.

The analysis has been done in cooperation with the domain experts from the Bavarian

Forest National Park, who provided their interpretations of the ﬁndings.

6.2. Analysing relations to spatial locations

6.2.1. Preferred places
Visualization of the trajectories of the animals on a map display and in a space–time cube
gives us an initial insight about their movement behaviours in relation to the space. We
see that the roe deer mostly make small movements within spatially limited areas and
very seldom travel to more distant places. The lynxes move much more actively over wide
territories.

The next questions are how far the roe deer can travel from their habitual places and
when and how often this happens. We compute the medoid of each trajectory, that is, the
point with the smallest sum of distances to all other points. It can be expected that the
medoid is located in the place of concentration of the trajectory points or in one of such
places, if there are more than one. We use the temporal view of trajectories to visualize the
spatial distances of the trajectory points to the respective medoids (Figures 4 and 5). The
time graph in Figure 4 shows that the typical pattern of value variation is small ﬂuctuations
reﬂecting small moves within limited areas. Long vertical lines indicate travels on large
distances. The lines look vertical because the horizontal dimension of the display represents
a very long time period (1504 days). An interval of several days, during which a long travel
is made, is represented by just one or two pixels. When temporal zooming is applied, the
lines representing the long trips do not look straight vertical anymore. The horizontal lines
correspond to temporal gaps in the data. In the time bar mode (Figure 5), the gaps appear
as colourless segments. As can be seen, such cases are quite numerous.

Figure 4 shows us that the largest distance of a roe deer from the trajectory medoid,
which represents the most habitual place, was 34.14 km, but only a few animals made long
travels. In Figure 5, we see that a great part of the roe deer never moved for more than

International Journal of Geographical Information Science

1361

2.5 km from their habitual places. The bars representing the trajectories that include long
travels (more than 7.5 km) are distinguished by orange- and red-coloured segments. The
times of the distant travels can be ascertained by mouse-pointing. Unfortunately, we cannot
get reliable temporal information about the travels in the cases of long time gaps between
the position records. For the remaining cases, we found out that ﬁve travels were in May,
four in November, two in December and one in July. We can conclude that the roe deer
tend to change their places before summer and before or in the beginning of winter.

Domain expert’s comment: This corresponds to two types of migration of roe deer: (1)
migration after leaving the mother’s territory, as in the case highlighted in Figure 4; (2)
winter migration when animals come to valleys with less snow cover.

6.2.2. Locations with speciﬁc properties

The next analysis task is to investigate the relations of the roe deer to open areas, that is, not
covered by forest. This is the case when movement data need to be combined with context
data. We use a dataset (map layer) with vegetation types. Applying the attribute ﬁlter to
it, we select non-forest areas. We use the interface of the temporal view to compute and
visualize the spatial distances to the selected areas (for each trajectory point, the nearest
area is found). We observe that many roe deer appeared quite often in the open areas
whereas some roe deer almost never did this (of course, this refers only to the areas that
are deﬁned in the available vegetation data).

We set the segment ﬁlter to the value 0 (interval from 0 to 0) and commit the event
extraction query. As a result, we obtain a dataset with 16,537 open area events represented
as a new layer in the map display. We can now apply various analytical tools available in
the system, such as spatial clustering. Figure 6 shows a map fragment where the spatial
clusters are represented by colouring of the circle symbols representing the events. The
symbols are drawn with 20% opacity. One of the visible clusters is located in a valley of a
river (bright purple cluster in the centre of the map fragment) whereas the others are near
villages or farms or other places of human activities. It is striking that the animals seem to
have no fear of entering such places.

Domain expert’s comment: Roe deer would probably not go into a village because they
are afraid of people. But they might go for feeding to open areas like ﬁelds or meadows
that surround villages.

Figure 6. A fragment of the map showing the spatial clusters of the open area events and diagrams
representing the variation of the event number by the hours of the day.

1362

G. Andrienko et al.

Our hypothesis is that roe deer may tend to appear in open areas in dark times. To
see how the open area events are distributed over times of the day, we use spatio-temporal
aggregation: for each spatial cluster, the system counts the events by hourly intervals of the
day. The yellow-coloured diagrams in Figure 6 show the variation of the event counts over
a day in each cluster. The horizontal dimension of the diagrams represents hours of the day
from 0 to 23 and the vertical dimension shows the event counts. It can be seen that much
more events occurred in the early morning and night hours than in the middle of the day.
Note that the cluster located at a river does not have so big differences in the number of
events between the night and day hours.

As the same time of the day may be dark in the winter but light in the summer, it
is reasonable to look whether the times of the open area events vary over a year. We are
particularly interested when the roe deer appear in the areas near the places of human
activities. Using one more dataset with context data, namely, a dataset describing built
areas (the areas are shown in Figure 6 as polygons ﬁlled in light pink), we select those
open area events that occurred in 50 m or less from the nearest built area. There are 3707
such events. We visualize the frequencies of the events by the hours of the day and the
months of the year in a two-dimensional histogram as shown in Figure 7. The horizontal
axis corresponds to the hours of the day from 0 to 23 and the vertical axis to the months of
the year from 1 (January) to 12 (December). The frequencies of the events are represented
by the circles with the areas proportional to the values. The maximal circle size corresponds
to 75 events.

The histogram shows us that the event frequencies are higher in all months in early and
late hours of the day. However, the intervals of decreased event frequencies start later and
end earlier in the winter and late autumn months (1–2 and 11–12) than in the spring and
summer months. Generally, we can conclude that the roe deer tend to appear in open areas
near villages in dark hours, depending on the season. However, we notice that the event
frequencies in the day time are somewhat higher in June and July and, to a lesser degree,
in August (months 6–8) than in the other months.

Figure 7. The open area events that occurred in 50 m or less from built areas are grouped by the
hours of the day (x-axis) and the months of the year (y-axis). The event frequencies are represented
by the sizes of the circles.

International Journal of Geographical Information Science

1363

Domain expert’s comment: This is explainable by the roe deer biology. First, female
animals have a high energy demand after giving birth (between mid-May and mid-June),
so they tend to go for browse in the meadows around villages also in the day. Second, roe
deer have their rutting period in July–August and also tend to be more active in the day.

Another interesting observation is that event frequencies get lower in the hours 1–2 and

22–23 compared with those in the hours before and after that.

Domain expert’s comment: Roe deer feed throughout the 24 hours, but long periods

may be spent ‘lying up’ between feeding bouts.

We also extracted the events of appearing in the open areas around the villages from
the trajectories of the lynxes. There were only two such events; both occurred when it was
dark. Hence, the data tell us that the lynxes tend to avoid open areas close to people but
may occasionally enter such areas in dark time.

6.3. Analysing relations among movers

We have data about two types of movers: roe deer and lynxes. The former are a prey for
the latter. Our next task is to detect and investigate their probable encounters, keeping in
mind that the data refer only to small samples of the populations of roe deer and lynxes
inhabiting the forest.

Among the variables that can be computed and represented in the temporal view is
the spatial distance to selected trajectories. We are interested in the distances from the
trajectories of the roe deer to the trajectories of the lynxes. For computing the distances,
we need to specify the temporal tolerance, that is, the maximum distance in time between
points from two trajectories when it is still meaningful to compute the spatial distance. The
temporal tolerance is needed for dealing with data where positions of different movers are
measured at diverse time moments and the time intervals between the measurements are
unequal.

We choose the temporal tolerance of 1 hour, taking into account that the data are sparse
in time. The computations are done in two temporal views, one for the roe deer (distances
to the lynxes) and the other for the lynxes (distances to the roe deer). We set the segment
ﬁlters in both views to the value interval from 0 to 1 km and commit event extraction.
Thereby, we extract 39 events of spatial proximity to lynxes from the trajectories of the
roe deer and 26 events of spatial proximity to roe deer from the trajectories of the lynxes.
Apparently, in some cases a lynx approached a group of two or more roe deer. The events of
proximity to lynxes occurred in the trajectories of 16 roe deer, and the events of proximity
to roe deer occurred in the trajectory of one lynx, named Nora.

Figure 8 illustrates the events that we have extracted. At the bottom, there are two
temporal views representing the trajectories of the lynxes (upper display) and the roe deer
(lower display). The upper display shows the distances of the lynxes to the nearest roe deer
and the lower display shows the distances of the roe deer to the nearest lynxes. In both
displays, the segment ﬁlters select the trajectory segments with the distances up to 1 km.
The map (upper left) and the space–time cube (upper right) show the extracted proximity
events. The yellow circles represent the events of the roe deer and the pink circles – the
events of the lynxes. The mouse cursor is positioned on one of the segments in the temporal
view of the trajectories of the roe deer. The corresponding temporal position is marked
in the two temporal views by yellow vertical lines. The corresponding spatial position is
marked in the map by the intersection of the black horizontal and vertical lines and in the
space–time cube by the red vertical line.

The next question is whether any of the detected approaches of the lynxes to the roe
deer resulted in killing the roe deer. We look for the events of spatial proximity to lynxes

1364

G. Andrienko et al.

Figure 8. The events of spatial proximity between roe deer and lynxes are visualized in four linked
displays: map (upper left), space-time cube (upper right), and temporal views of the trajectories of
the lynxes (middle) and roe deer (bottom).

that occurred shortly before the end times of the trajectories of the roe deer. To extract these
events, we open another temporal view of the trajectories of the roe deer and visualize the
variable ‘temporal distance to a selected time moment’; the chosen time moment is the
end time of each trajectory. Using the segment ﬁlter, we select only the segments with the
temporal distances from −24 to 0 hours to the trajectory ends. Simultaneously, the ﬁlter
in the ﬁrst temporal view selects the segments with the distances to lynxes not exceeding
1 km. By combining the two ﬁlters, we ﬁnd two events of spatial proximity to lynxes that
occurred in the past 24 hours of the trajectories of two roe deer, Harald and Heiner.

Among the data received from Bavarian Forest, there is a lookup table with general
information about the tracked animals, in particular, their fates. The record about Harald
says that it was killed. Now, we can say with a high degree of certainty that Harald was
killed by Nora. For Heiner, the lookup table says that he died in a trafﬁc accident. We guess
that Heiner might occasionally run on a road when trying to escape from Nora and was
killed there by a moving vehicle. We project the spatial position of the proximity event
between Heiner and Nora on a satellite image from Google Maps and see that the event
occurred very close to a forest road. This gives support to our hypothesis but does not
exclude other possible reasons for the accident.

International Journal of Geographical Information Science

1365

6.4. Analysing relations to events

Events may inﬂuence the behaviours of movers. When events are few, the analyst can
investigate the possible impacts solely by means of visual and interactive techniques. The
temporal ﬁlter is used for focusing on time intervals before and after the events and the
spatial ﬁlter and object ﬁlter are used for selecting the movers that were present in the
vicinity of the events when they occurred. In this way, we could trace, for example, the
movements of the lynx Nora after killing the roe deer Harald. During the following 4 days,
Nora moved several times forth and back between the place of the event and another place
located in about 2 km north of the ﬁrst place.

Domain expert’s comment: This behaviour is typical for lynxes. A lynx moves to its kill
normally in the evening. After feeding, the lynx leaves the kill to a place called daytime-
resting area. We suppose that if the kill is in a risky environment (e.g. close to human
infrastructure or outside of the National Park), the lynx moves a farther distance from the
kill to ﬁnd a secure area. If the kill is in a secure place, the lynx might rest close to it.

Purely visual and interactive exploration may be effective in case of few events and few
movers involved but not when events and/or movers are more numerous. In the latter case,
we suggest extraction of event-related statistics from the trajectories. We shall apply this
approach to explore how roe deer behave when being approached by a lynx.

Domain expert’s comment: One hypothesis is that roe deer will go to more open areas,
were the lynxes cannot ambush them. Another hypothesis is that roe deer will shift their
activity more to the daylight, when lynxes are inactive. The open issue is how roe deer
recognize lynxes and whether they communicate this to other roe deer. One possibility is
that one roe deer senses a lynx and changes its movement behaviour whereas others that do
not sense the lynx perform their normal movement. Another possibility is that the roe deer
sensing a lynx warns the others that a lynx is nearby, and the others react by changing their
behaviours. Roe deer have a bark, which they cry out when they are scared. By following
a collared lynx, we have observed that roe deer start to bark when they discover the lynx.
It might be possible that they warn others with this bark.

It is quite probable that the available data, being temporally sparse and irregular, may
not allow the ecologists to ﬁnd deﬁnite answers to their questions. Still, we want to see what
changes of the roe deer’s behaviours after probable encounters of lynxes can be detected
with our tools. Particularly, we shall try to ﬁnd out whether the roe deer begin to move more
or less actively, whether they tend to move away from the places of the events, whether they
tend to come nearer to other roe deer or to move away from them and whether they tend to
go in open areas.

We shall look at the behaviours of the roe deer before and after the 39 events of spatial
proximity to the lynxes (further referred to as ‘encounter events’) extracted with the tem-
poral tolerance threshold of 1. In the temporal view of the trajectories of the roe deer, we
visualize successively the following variables: distance to the place of the nearest encounter
event in the trajectory, movement speed, distance to other roe deer and distance to the near-
est open area. For each attribute, we obtain the statistics (minimum, maximum, median,
mean and standard deviation) of the values separately for 1 day intervals before the starts
of the encounter events and for 1 day intervals after the starts of the events. For each
event, the statistics are derived only from the trajectory from which the event was earlier
extracted.

After obtaining the statistics, we compute the differences between the values after
and before the events. The differences are expressed in percentages to the earlier values.
Figure 9 presents a display of the table describing the events. The background colouring
of the rows corresponds to the cross-classiﬁcation of the events according to the values of

1366

G. Andrienko et al.

Figure 9. The event-related statistics represent the changes of the roe deer’s behaviours after
encountering lynxes.

the attributes ‘% change of the maximum spatial distance to the encounter event’ and ‘%
change of the mean speed’. The selected value intervals for both attributes are below −10%
(large decrease), from −10 to 10% (small change) and over 10% (large increase). The leg-
end explaining the colours is on the right of the table. Light yellow corresponds to large
decreases of both the maximum spatial distance to the event location and the mean speed;
12 out of 39 events belong to this class. Greenish brown corresponds to large increases
of both attributes; 10 out of 39 events belong to this class. The remaining classes contain
from 1 to 4 events. The lengths of the coloured bars in the table cells represent the relative
positions of the respective values between the minimum and the maximum values in the
columns.

The largest class (light yellow) corresponds to reduced activity of roe deer after the
encounter events. The roe deer decreased their speeds and did not try to move away from
the places where the events occurred. The changes of the maximum distances to other roe
deer greatly vary, which means that there was no clear tendency in the relations with the
other roe deer. The second largest class (greenish brown) consists of the events after which
the roe deer became more active, that is, their speeds and the maximum distances to the
event locations increased. Like for the reduced activity class, no consistent changes of the
distances to other roe deer can be seen. When the events are classiﬁed only according to the
changes of the speed, both the reduced speed class (below −10% change) and the increased
speed class (over 10% change) consist of 15 events.

Hence, the frequencies of the reduced and increased activities of roe deer after being
approached by lynxes are very close. It is possible that the change of the movement
behaviour reﬂects the character of the interaction between the roe deer and the lynx. An
increase of the movement activity may mean that the lynx chased the roe deer and a
decrease may mean that the roe deer just sensed the presence of the predator and tried
to hide and stay still, to avoid attracting lynx’s attention. Another possible explanation is
that the roe deer that decreased their activeness did not sense the lynxes by themselves but

International Journal of Geographical Information Science

1367

were warned by barks of other roe deer, whereas the roe deer that moved more actively
did this after sensing the lynxes by themselves. The data do not allow us to ﬁnd out which
explanation is more plausible.

Concerning the behaviours in relation to open areas, there are eight encounter events
after which the roe deer entered open areas, that is, the minimal distances to open areas
were positive before the events and zero after them. In 12 cases, the minimal distances
to open areas were zeros, both before and after the events. Only in three cases the roe
deer moved from open areas to forest after the events. Hence, there is a higher tendency
towards moving to or staying in open areas after encountering lynxes than towards moving
from open areas to forest. There is no correlation between moving from/to open areas and
increasing or decreasing the movement activity.

We have seen that our tools can support the investigation of the impact of events on
movement behaviours. However, ﬁnding clearer answers to the questions of the Bavarian
Forest scientists requires data with much ﬁner temporal resolution. It would also be good
to increase the sample of tracked animals. Hopefully, the technical problems involved in
tracking wild animals will be solved in the near future.

7. Results
We suggest a general approach to accounting for the spatio-temporal context in analysing
movement data. The approach involves extracting interesting movement events from tra-
jectories and analysing these events as independent spatio-temporal objects. Particularly,
the analyst extracts the movement events (parts of the trajectories) having speciﬁc spatial
and/or temporal relations to selected elements of the context to investigate the occurrences
of these kinds of relations.

To test the approach, we implemented an interactive event extraction tool and applied
it to real data about wild animals. We could detect and extract occurrences of several kinds
of relations between the movers and different elements of the context:

(cid:129) being far from habitual places;
(cid:129) being in open areas and being in open areas close to built areas;
(cid:129) being close to other movers of the same or other class;
(cid:129) being in a certain temporal distance and temporal order (before or after) to selected

time moments (ends of the trajectories);

(cid:129) being in a certain temporal distance and temporal order to selected events.

We were able to analyse the spatial and temporal distributions of the extracted relation
occurrences and investigate how these events affect the movement.

We have implemented the tools within an existing geovisualization system, in which
a number of visual and computational tools for exploration and analysis of spatial and
temporal data (Andrienko and Andrienko 2006) were available before. These tools could be
immediately applied to the events and event-related statistics extracted from the movement
data by means of the new tools. The whole combination of tools supports sophisticated
spatio-temporal analyses in which results of earlier phases can be used for obtaining new
knowledge in further steps.

The testing has conﬁrmed the soundness of our approach. Despite the ﬂaws in the data
caused by the technical difﬁculties involved in tracking wild animals, we have uncovered a
number of behavioural patterns that agree with the existing domain knowledge and could
be interpreted by specialists. The domain experts admitted that such a deep investigation

1368

G. Andrienko et al.

of movement behaviours of wild animals would not be possible with the tools they knew
before. The experts appreciated our system as a very good instrument for visualization and
interactive exploration of movement data, which is capable to support hypothesis building
in ecology.

In this experiment, the domain experts did not use the tools by themselves. They posed
questions to the tool developers, who did the analysis. The experts then reviewed the reports
about the ﬁndings and the analysis process and provided their opinions. The collaboration
was remote. Now, the experts want to start using the tools by themselves. This requires a
training session, which is planned for the near future.

8. Conclusion

Our main innovation is that we offer a general approach to extracting and analysing rela-
tions between movement and its spatio-temporal context. The approach is based on treating
movement as a composition of spatial events, that is, objects localized in space and time.
The main idea is to supply the analyst with an interactive query tool for extracting move-
ment events based on their relations to selected context elements. The extracted events are
treated as independent spatio-temporal objects and may be analysed using various existing
methods suitable for spatial, temporal and spatio-temporal data. In particular, the events
can be computationally combined with other data for deriving new information.

We have tested the approach on a real dataset obtained by tracking movements of wild
animals. Despite the real-life complexities pertaining to the data (temporal sparseness,
irregularity and lacunae in the observations), we have been able to uncover a number of
interesting facts and behavioural patterns. The process of analysis and its outcomes have
been reviewed by domain experts and obtained their positive feedback. In the future, we
plan to work on supporting joint analysis of movement data and activity data, which are
produced by sensors measuring the acceleration of the collar. Unlike GPS positions, activ-
ity data are not transmitted by radio and become available only when the collar is taken
back from the animal that wore it. The activity data have much ﬁner temporal resolu-
tion and might ﬁll the gaps between the GPS position records. The task of combining
GPS tracks with activity data poses new challenges and requires further research and
development.

Acknowledgements
This research was supported by DFG (German Research Foundation) within the Priority Research
Program ‘Scalable Visual Analytics’ (SPP 1335). Financial support for the ﬁeld work was provided
by the EU Program Interreg IIIa and the Bavarian Forest National Park administration. We thank
Horst Burghart, Martin Gahbauer, Martin Horn, Helmut Penn, Michael Penn and Lothar Ertel for
doing the ﬁeld work.

References
Allen, J.F., 1983. Maintaining knowledge about temporal intervals. Communications of the ACM, 26

(11), 832–843.

Andrienko, N., Andrienko, G., and Gatalsky, P., 2003. Exploratory spatio-temporal visualization: an

analytical review. Journal of Visual Languages and Computing, 14 (6), 503–541.

Andrienko, N. and Andrienko, G., 2006. Exploratory analysis of spatial and temporal data: a

systematic approach. Berlin: Springer.

International Journal of Geographical Information Science

1369

Andrienko, G., Andrienko, N., and Wrobel, S., 2007. Visual analytics tools for analysis of movement

data. ACM SIGKDD Explorations, 9 (2), 38–46.

Andrienko, G., et al., 2008. Geovisualization of dynamics, movement and change: key issues and
developing approaches in visualization research. Information Visualization, 7 (3/4), 173–180.
Andrienko, G. and Andrienko, N., 2010. A general framework for using aggregation in visual

exploration of movement data. The Cartographic Journal, 47 (1), 22–40.

Andrienko, N. and Andrienko, G., 2011. Spatial generalization and aggregation of massive movement

data. IEEE Transactions on Visualization and Computer Graphics, 17 (2), 205–219.

Bavarian Forest, 2010. Tracking lynxes in the Bavarian Forest and Šumava national parks [online].

Available from: http://www.luchserleben.de/?lang=2 (accessed 10 February 2011).

Beard, K., Deese, H., and Pettigrew, N.R., 2008. A framework for visualization and exploration of

events. Information Visualization, 7, 133–151.

Brillinger, D.R., et al., 2004. An exploratory data analysis (EDA) of the paths of moving animals.

Journal of Statistical Planning and Inference, 122 (2), 43–63.

Crnovrsanin, T., et al. Proximity-based visualization of movement trace data. In: Proceedings of
the IEEE Symposium on Visual Analytics Science and Technology (VAST), 12–13 October 2009
Atlantic City, NJ, USA, 11–18.

Dodge, S., Weibel, R., and Lautenschütz, A.-K., 2008. Towards a taxonomy of movement patterns.

Information Visualization, 7 (3–4), 240–252.

Dykes, J.A. and Mountain, D.M., 2003. Seeking structure in records of spatio-temporal behaviour:
visualization issues, efforts and applications. Computational Statistics and Data Analysis, 43,
581–603.

Egenhofer, M., 1991. Reasoning about binary topological relations. In: O. Günther and H.-J. Schek,
eds. Proceedings of the Second Symposium on Large Spatial Databases, SSD’91, 28–30 August,
Zurich, Switzerland. Lecture Notes in Computer Science, vol. 525. New York: Springer-Verlag,
143–160.

ESRI, 2010. ArcGIS tracking analyst [online]. Available from: http://www.esri.com/software/

arcgis/extensions/trackinganalyst/index.html (accessed 10 February 2011).

Forer, P. and Huisman, O., 2000. Space, time and sequencing: substitution at the physical/virtual
interface. In: D.G. Janelle and D.C. Hodge, eds. Information, Place and Cyberspace: Issues in
Accessibility. Berlin: Springer-Verlag, 73–90.

Frank, A., 1992. Qualitative spatial reasoning about distances and directions in geographical space.

Journal of Visual Languages and Computing, 3, 343–371.

Gaffney, S. and Smyth, P., 1999. Trajectory clustering with mixture of regression models. In:

Proceedings of the ACM KDD, 15–18 August, San Diego, CA, 63–72.

Giannotti, F., et al., 2009. Trajectory pattern analysis for urban trafﬁc. In: Proceedings of the Second
International Workshop on Computational Transportation Science, 3 November 2009 Seattle,
Washington, New York, NY: IWCTS’09, ACM, 43–47.

Guo, D., 2007. Visual analytics of Spatial interaction patterns for pandemic decision support.

International Journal of Geographical Information Science, 21 (8), 859–877.

Hägerstrand, T.,1970. What about people in regional science? Papers of the Regional Science

Association, 24, 7–21.

Harrower, M. and Brewer, C.A., 2003. Colorbrewer.org: an online tool for selecting colour schemes

for maps. The Cartographic Journal, 40 (1), 27–37.

Jones, C.B., 1997. Geographical Information Systems and Computer Cartography. Harlow:

Longman.

(2), 136–146.

Kapler, T. and Wright, W., 2005. Geo time information visualization. Information Visualization, 4

Kincaid, R. and Lam, H., 2006. Line graph explorer: scalable display of line graphs using
Focus+Context. In: Proceedings of the International Working Conference Advanced Visual
Interfaces, 23–26 May 2006, Venice, Italy, 404–411.

Kraak, M.-J., 2003. The space-time cube revisited from a geovisualization perspective. In:
Proceedings of the 21st International Cartographic Conference, 10–16 August, Durban, South
Africa, 1988–1995.

Laube, P., Imfeld, S., and Weibel, R., 2005. Discovering relative motion patterns in groups of moving
point objects. International Journal of Geographic Information Science, 19 (6), 639–668.
Li, Y., Han, J., and Yang, J., 2004. Clustering moving objects. In: Proceedings of the ACM KDD,

22–25 August, Seattle, 617–622.

1370

G. Andrienko et al.

Longley, P.A., et al., 1999. Geographical information systems. Volume 1: principles and technical

issues. 2nd ed. New York, USA: Wiley.

Lundblad, P., Eurenius, O., and Heldring, T., 2009. Interactive visualization of weather and ship data.
In: 13th International Conference Information Visualization IV 2009, IEEE computer society,
15–17 July , Barcelona, Spain, 379–386.

Mountain, D.M., 2005. Visualizing, querying and summarizing individual spatio-temporal behaviour.
In: J.A. Dykes, M.J. Kraak, and A.M. MacEachren, eds. Exploring geovisualization. London:
Elsevier, 181–200.

Nanni, M. and Pedreschi, D., 2006. Time-focused density-based clustering of trajectories of moving

objects. Journal of Intelligent Information Systems, 27 (3), 267–289.

Orellana, D., et al., 2009. Uncovering interaction patterns in mobile outdoor gaming. In: Proceedings
of the International Conference Advanced Geographic Information Systems & Web Services,
GEOWS 2009, 1–7 February, Cancun, Mexico, 177–182.

Orellana, D. and Renso, C., 2010. Developing an interactions ontology for characterizing pedes-
trian movement behaviour. In: M. Wachowicz, ed. Movement-aware applications for sustainable
mobility: technologies and approaches. Hershey, PA, USA: Information Science Reference,
62–86.

Pelekis, N., et al., 2007. Similarity search in trajectory databases. In: Proceedings of 14th
International Symposium Temporal Representation and Reasoning (TIME 2007), 28–30 June,
Alicante, Spain, IEEE Computer Society Press, 129–140.

Peuquet, D.J., 1994. It’s about time: a conceptual framework for the representation of tempo-
ral dynamics in geographic information systems. Annals of the Association of American
Geographers, 84 (3), 441–461.

Peuquet, D.J., 2002. Representations of Space and Time. New York: Guilford.
Rinzivillo, S., et al., 2008. Visually–driven analysis of movement data by progressive clustering.

Information Visualization, 7 (3/4), 225–239.

Spaccapietra, S., et al., 2008. A conceptual view on trajectories. Data and Knowledge Engineering,

Tobler, W., 1987. Experiments in migration mapping by computer. The American Cartographer, 14

65 (1), 126–146.

(2), 155–163.

Tobler, W., 2005. Display and analysis of migration tables

http://www.geog.ucsb.edu/∼tobler/presentations/shows/A_Flow_talk.htm (accessed
February 2011).

[online]. Available from:
10

Tomaszewski, B. and MacEachren, A.M., 2010. Geo-historical context support for information for-
aging and sensemaking: conceptual model, implementation, and assessment. In: Proceedings of
the IEEE VAST (IEEE Conference on Visual Analytics Science and Technology), 24–29 October
2010 Salt Lake City, UT, USA, 139–146.

Trajcevski, G., et al., 2007. Dynamic-aware similarity of moving objects trajectories. In: Proceedings
of the ACMGIS’07, 7–9 November, Seattle, Washington, Seattle, USA: ACM Press, 75–82.
Tversky, B., Morrison, J.B., and Bétrancourt, M., 2002. Animation: can it facilitate? International

Journal of Human-Computer Studies, 57 (4), 247–262.

Vlachos, M., Kollios, G., and Gunopulos, D., 2002. Discovering similar multidimensional trajec-
tories. In: Proceedings of the 18th International Conference on Data Engineering (ICDE’02),
26 February - 1 March, San Jose, CA, IEEE, 673–684.

Weaver, C., 2010. Cross-ﬁltered views for multidimensional visual analysis. IEEE Transactions on

Visualization and Computer Graphics, 16 (2), 192–204.

Willems, N., van de Wetering, H., and van Wijk, J.J., 2009. Visualization of vessel movements.

Computer Graphics Forum (Proceedings of the EuroVis 2009), 28 (3), 959–966.

Wood, J. and Dykes, J., 2008. Spatially ordered treemaps. IEEE Transactions on Visualization and

Computer Graphics, 14 (6), 1348–1355.

Wood, J., Dykes, J., and Slingsby, A., 2010. Visualisation of origins, destinations and ﬂows with OD

maps. The Cartographic Journal, 47 (2), 117–129.

Yu, H., 2006. Spatial-temporal GIS design for exploring interactions of human activities.

Cartography and Geographic Information Science, 33 (1), 3–19.

Copyright of International Journal of Geographical Information Science is the property of Taylor & Francis Ltd

and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright

holder's express written permission. However, users may print, download, or email articles for individual use.

