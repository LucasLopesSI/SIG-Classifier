Geoinformatica (2007) 11:1–36
DOI 10.1007/s10707-006 -7635-9

Ontology-Based Descriptions for Semantic Discovery
and Composition of Geoprocessing Services

Michael Lutz

Received: 9 May 2005 / Revised: 29 September 2005 /
Accepted: 6 February 2006 / Published online: 28 July 2006
# Springer Science + Business Media, LLC 2006

Abstract The ability to process geospatial data will be a great beneﬁt for spatial data
infrastructures. This requires the ability to compose data providing services with
geoprocessing services. Discovering suitable geoprocessing services is a major chal-
lenge in this endeavour. Current (keyword-based) approaches to service discovery are
inherently restricted by the ambiguities of natural language, which can lead to low
precision and/or recall. To alleviate these problems, we propose to use an ontology-
based approach to GI service discovery, which rests on two ideas. Ontologies
describing geospatial operations are used to create descriptions of requirements and
service capabilities; matches between these descriptions are identiﬁed based on
function subtyping. We use a running example from the geospatial domain to analyse
which problems can occur in existing keyword- and ontology-based approaches and
how the discovery of geoprocessing services differs from other service discovery
tasks. The example is also used for illustrating the prototypical implementation of
the proposed approach.

Keywords GI service discovery . GI service composition .
Spatial data infrastractures . Ontologies . Matchmaking

1. Introduction

The efﬁcient use of distributed geographic information is a key factor in planning
and decision-making in a variety of domains. To facilitate the access to geographic
information, spatial data infrastructures (SDIs) [12] are currently being set up within
regions, countries and across national borders [4], [46]. They support the discovery

The work presented in this paper was carried out while the author was still working with the
Institute for Geoinformatics, University of Mu¨ nster, Germany.

M. Lutz (*)
European Commission - DG Joint Research Centre,
Institute for Environment and Sustainability,
Via E. Fermi 1, 21020 Ispra (VA), Italy
e-mail: michael.lutz@jrc.it

Springer

2

Geoinformatica (2007) 11:1–36

Fig. 1 An example for a complex service containing a geoprocessing service

and retrieval of distributed geospatial data sources and geographic information (GI)
services by providing catalogue services and syntactic interoperability standards.

In recent years, the number of GI services available on the web has been rapidly
and continually increasing. While at present, these services are generally isolated
applications, their composability is often perceived as their greatest value as this
enables more complex processing tasks [11]. First attempts at composing GI web
services have been made. However, these relied on manually and statically coupling
existing services [3] while for future applications service composition is envisioned
to be automated [35].

The component GI services from which such complex services are composed fall
into three categories: Services providing data, which are usually the starting point
for any complex GI service; geoprocessing services, which perform some kind of
computation or analysis on the provided data; and presentation services, which
present the result of a complex service to the user. The functionality of services for
both the retrieval and presentation of data are relatively limited, and service
interfaces for them are standardised (e.g., [38], [41]) and already in widespread use.
Instead, the focus of this paper is on geoprocessing services, which are only now
emerging and form the most diverse category. Figure 1 shows an example for a
complex service that contains a geoprocessing service for computing the distance
between two locations.

1.1. GI Service Discovery and Composition

The starting point for (manually or automatically) composing a complex service is
always a speciﬁc problem. Discovering services that are appropriate for solving this
problem from among a large number of available services is a central task within the
GI web services domain [10]. Descriptions of service capabilities (i.e., of what the
service does) and user requirements (i.e., what is needed to solve a given problem)
are key elements during service discovery, which is essentially about ﬁnding a match
between the two [56]. When service discovery is done as part of service composition,
the descriptions of the service and the user requirements have to match in two
aspects: (1) the semantics of the operation1 (or functionality) and (2) the semantics
of the interfaces of adjacent services. The former ensures that the service actually
does what the user expects it to do; the latter ensures that the service correctly
interprets the data it receives as input from the preceding service.

1.2. Problems in State-of-the-Art GI Service Discovery

SDIs provide catalogue services [42] for discovering appropriate data and services
for a speciﬁc task. For these catalogues, standardised metadata templates have been

1 For simplicity, we assume in this paper that a service only provides one operation.

Springer

Geoinformatica (2007) 11:1–36

3

developed, most notably those deﬁned in ISO-DIS 19115 [19] for geographic data
and 19119 [20] for GI services. Users can formulate queries using keywords and/or
spatial ﬁlters. The metadata ﬁelds that can be included in the query depend on the
used metadata schema and on the query functionality of the service used for
accessing the metadata.

Even though natural language processing techniques can increase the semantic
relevance of search results with respect to the search request (e.g., [49]), keyword-
based techniques are inherently restricted by the ambiguities of natural language.
As a result, keyword-based search can have low recall if different terminology is
used and/or low precision if terms are homonymous or because of their limited
possibilities to express complex queries [5].

Currently, a move towards using the W3C2 standards WSDL (Web Service
Description Language) [59] and UDDI (Universal Description, Discovery and
Integration) [2] for the description and discovery of GI services is being discussed
[40]. However, as these standards are largely based on free text descriptions and
service taxonomies the problems remain the same.

1.3. Hypothesis and Research Questions

To alleviate and overcome the semantic heterogeneity and interpretation pro-
blems presented in the previous section, we propose to base the descriptions of
geoprocessing services on ontologies. An ontology is an explicit formal speciﬁca-
tion of a shared conceptualization [14], [50], where a conceptualization can be
deﬁned as a way of thinking about some domain [57]. By using ontologies to
enrich the description of data sources or services, the semantics of data content
or service functionality become machine-interpretable, and users are enabled to
pose concise and expressive queries. Furthermore, logical reasoning can be used
for matchmaking between user queries and data and service advertisements in
catalogues.

It is the overall hypothesis of this paper that a methodology providing (1)
ontology-based descriptions of operations and (2) a matchmaking mechanism based
on function subtyping leads to improved recall and precision during the discov-
ery of geoprocessing services. This hypothesis leads to the following research
questions:
& Which problems during the discovery of geoprocessing services in conventional

catalogues are caused by semantic heterogeneities?

& How is the discovery of geoprocessing services inﬂuenced by the overall task of

service composition?

& Which aspects of geoprocessing services should be described using ontologies?
& Which methods can be used for matchmaking between these descriptions for the

discovery of geoprocessing services?

& What kinds of ontologies (and ontology languages) are required for these

descriptions and matchmaking methods?

2 The World Wide Web Consortium, see http://www.w3.org/

Springer

4

Geoinformatica (2007) 11:1–36

1.4. Ontology-Based GI Service Discovery

The main contribution of this paper is the proposed approach for the enhanced
discovery of geoprocessing services, which we will subsequently refer to as ontology-
based GI service discovery. In this approach, operations are represented by a so-
called semantic signature, which contains Description Logics (DL) concepts (instead
of datatypes) to represent inputs and outputs, and a speciﬁcation of pre- and
postconditions in First Order Logic (FOL). Service discovery is based on a two-step
matchmaking process between these descriptions. First, the semantic signature is
used for efﬁciently ﬁltering the potentially large number of services. This ﬁltering
is done using DL subsumption reasoning on the concepts representing inputs and
outputs and should result in a relatively small number of services. In the second
step, the pre- and postconditions of the remaining services are compared to
those speciﬁed in the query using a FOL theorem prover. In this matchmaking
step, several degrees of match (all of which are based on the idea of function
subtyping) can be tested. This allows a ﬁne-grained distinction and ranking be-
tween the services identiﬁed in the ﬁrst step.

The speciﬁcation of operations as part of domain ontologies plays an important
role in this approach. These speciﬁcations describe the input and output types and
the behaviour of the operation. Each of these parts of a speciﬁcation provides a
template for formulating descriptions of requirements and capabilities. This con-
strains the descriptions created by service providers and requesters and thus ensure
greater recall during service discovery.

For the approach to work it is required that the same domain ontology (or shared
vocabulary) be used by service providers and requesters. Therefore the basis for
specifying operations and concepts for inputs and outputs should be widely agreed-
upon standards such as the ISO 19100 series of standards or the speciﬁcations of the
OGC. The ontology of operations used in GI web services, which is presented in this
paper, is developed based on the ISO standards 19107 [17] and 19111 [18].

1.5. Overview

The remainder of the paper is structured as follows. In Section 2 we introduce the
notion of geoprocessing services and present existing approaches to GI service
discovery and composition in current SDIs. We also introduce a running example
that we use throughout the paper for illustration. Section 3 explains the notion of
ontologies and presents the logical formalisms used in this paper (FOL, DL and
Hoare Logic). It then introduces existing approaches to service discovery based on
ontologies, which provide the building blocks for the proposed methodology.
These include matching inputs and outputs described in DL and pre- and post-
conditions described in FOL as well as using shared domain vocabularies a a basis
for these descriptions. The problems associated with each of these building blocks
are also analysed. In Sections 4 and 5, the previously introduced building blocks are
adapted and combined into a new methodology for semantic service discovery,
which improves recall and precision and makes service discovery more efﬁcient.
Ontology-based descriptions of operations at the domain and application level,
which are the basis for this methodology, are introduced in Section 4. Section 5
describes the matchmaking between these descriptions. The paper concludes with a

Springer

Geoinformatica (2007) 11:1–36

5

discussion of related work in Section 6 and a conclusion and outlook to future work
in Section 7.

2. Spatial Data Infrastructures and Geoprocessing Services

Emerging spatial data infrastructures (SDIs) facilitate the discovery and retrieval of
distributed geographic information. However, some key problems caused by
semantic heterogeneity remain to be solved. In this chapter, we introduce the
notion of geoprocessing services by deﬁning their speciﬁc properties (Section 2.1).
We then present mechanisms and components for GI discovery and retrieval that
already exist in current SDIs (Section 2.2). In Section 2.3, we introduce a running
example that we use throughout the paper for illustration.

2.1. Geoprocessing Services

GI Services can be seen as web services providing functionalities that have
traditionally been provided by monolithic geographic information systems (GIS).
GIS are software systems that enable the capture, modelling, storage, retrieval,
sharing, manipulation, analysis and presentation of geospatial (geographically
referenced) data [60].

Service interfaces have already been standardised for the presentation (Web Map
Service, WMS [39]) and retrieval (Web Feature Service, WFS [38]) of geospatial
data and are in widespread use. However, the semantics of the data that can be
accessed and displayed using these service types is not always clear. An approach for
describing geographic data in these services is described in [27].

Geoprocessing Services analyse (and manipulate) geospatial data [43]3. Examples
include the following operations: buffering a geometry to create a new geometry,
measuring the distance between two geometries or intersecting two (sets of)
geometries. This list shows that the class of geoprocessing services is quite diverse
and cannot easily be standardised. However, all geoprocessing services have a few
things in common:
& They are information services [23] in the sense that they do not change the state
of the real world but only of information space. Therefore, their inputs and
outputs are important, and pre- and postconditions usually refer directly to these
inputs and outputs and not to some external states (e.g., the validity of a credit
card).

& The effect of executing a geoprocessing service is usually that a new fact becomes

known (analysis) or a known fact has been updated (manipulation).

2.2. Discovery and Composition of Geoprocessing Services in Current SDIs

A main motivation for setting up SDIs is to make the work with geographic data
more efﬁcient by addressing problems that occur with conventional GIS technology

3 In this OGC speciﬁcation, these services are now called Web Processing Services. However, we
keep the old terminology to emphasize the importance of the geospatial context.

Springer

6

Geoinformatica (2007) 11:1–36

and geographic data sets [34], [37]. For the research presented here, the most crucial
of these problems are that data sets exist in a plethora of different data formats, are
stored in a variety of different systems and that both are often not sufﬁciently or not
at all documented.

There are two main standardization efforts in the geospatial domain, whose goal
is to overcome these problems: the ISO Technical Committee (TC) 211, which
develops the 19100 series of standards, and the Open Geospatial Consortium
(OGC), whose industry standards are often adopted by ISO.

GI Discovery in SDIs.
In an SDI context, resources (geographic data and GI
services) are usually arbitrarily distributed in large networks. In such a scenario,
missing or insufﬁcient documentation makes it difﬁcult or even impossible for users to
discover resources and to assess whether they might be useful for their tasks.
Catalogues can be used to solve these problems, which makes them a fundamental
part of SDIs. They allow providers to advertise resources by registering their
metadata (push). A catalogue may also collect metadata from known service and data
providers (pull). A requester can then use the catalogue’s Blibrarian functions’’
(discovery, browsing, querying) to ﬁnd previously unknown resources that ﬁt her needs.

GI Service Composition. At present, GI services are generally isolated applications.
Nevertheless, several services may be composed to create a new service, which is of
special value for a particular question, even though they were not speciﬁcally designed
for that purpose. It is this composability (and the more complex processing tasks it
enables) that is often perceived as the greatest value of the web service paradigm [11].
In ISO terminology [20], the new complex service is called service chain, which is
deﬁned as a sequence of services where, for each adjacent pair of services,
occurrence of the ﬁrst action is necessary for the occurrence of the second action.
Three types of service chains are distinguished: User-deﬁned (transparent), work-
ﬂow-managed (translucent) and aggregate (opaque) service chains. However, apart
from the user-deﬁned chaining, the description of these types is focused on the
execution of the chain rather than on the actual service composition, which is the
focus of this paper.

A service chain consists of several services each of which contributes one part to
the overall functionality. During service composition a number of services have to
be discovered which together provide the required functionality. Service discovery is
hence a very important part of service composition, but service composition also
imposes some constraints on service discovery (Fig. 2). The component services of
the service chain that have already been discovered have to be taken into account
during the subsequent discovery steps:

& To ensure that the data exchanged between services in a chain are interpreted
correctly the outputs of a preceding and the inputs of a succeeding service have to
be considered.

& To meet the overall requirements on the chain’s functionality it has to be
considered which parts of the functionality are covered by the services which
have already been discovered.

The query resulting from these constraints can then be compared to service

descriptions registered in some catalogue service.

Springer

Geoinformatica (2007) 11:1–36

7

Fig. 2 Service discovery during service composition. The properties of services that have already
been discovered impose constraints on the queries for further services

2.3. A Running Example

To illustrate the problems that can occur when using existing approaches and to
point out the beneﬁts of the approach proposed in this paper, we use the following
example throughout the paper. Susan is searching for services for building a
complex service that computes the distance between two geographic features, e.g.,
between two airports or between a Bmissile launch location’’ and a city (to
determine whether this city is threatened). She has already discovered services
providing the locations of the features (given some ID) as point geometries. The
points are represented as a complex type consisting of two coordinates in some
coordinate system (e.g., latitude and longitude in a geographic coordinate system).
One of the requirements during Susan’s search will be that the distance operation
accepts these services’ output types.

GetLocation(someID: int): (coord1: double, coord2: double)

John is a service provider who has published a number of distance services. While

all services have the same (syntactic) signature

distance(x1: double, y1: double, x2: double, y2: double): double

the semantics of the input they require, the output they produce and the func-
tionality they provide, can differ widely. For example, the input parameters could
represent geographic or projected coordinates (in a speciﬁc coordinate reference
system) and the output could represent the distance in kilometres, miles or degrees.
Some examples for the functionality that such a service might have are shown in
Fig. 3.

Springer

8

Geoinformatica (2007) 11:1–36

Fig. 3 Different kinds of distance measures in various kinds of spaces: Euclidian distance in the
plane (upper left), shortest path in a graph (upper right), geodesic distance (lower left) and
Euclidian distance in R3 (lower right)

For the running example, we assume that John offers four services with different

functionality:

Service 1 returns the 2D Euclidian distance between two points in a plane
expressed in Cartesian coordinates (Equation 2.1), which equals the
length of a straight line between them (Fig. 3, upper left).
Service 2 returns the distance between two vertices in a graph, which equals the
length of the shortest path between them (Fig. 3, upper right). The
vertices are assumed to lie in a plane. If we consider a graph whose edge
weights represent distances (i.e., where all edge weights are greater than
or equal to zero) the shortest path can e.g., be computed using Dijkstra’s
algorithm [9].

Service 3 returns the great circle or geodesic distance between two points on a
sphere expressed in geographic coordinates4 (Equation 2.2), which
equals the length of the great circle section on the spherical surface
that is deﬁned by the two points (Fig. 3, lower left).
returns the 3D Euclidian distance between two points in R3 (Equation
2.3). To allow for the third dimension, this service’s syntactic signature

Service 4

4 For simplicity, we assume in this paper that geographic coordinate reference systems are based on
spheres rather than the actual ellipsoids.

Springer

Geoinformatica (2007) 11:1–36

has to include z1 and z2 input parameters. Thus,
syntactically from the other services.

it also differs

dEucl2Dðx1; y1; x2; y2Þ ¼

q

ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ðx2 (cid:2) x1Þ2 þ ðy2 (cid:2) y1Þ2

9

ð2:1Þ

dgeodð’1; (cid:2)1; ’2; (cid:2)2Þ ¼ arccosðsin ’1 sin ’2 þ cos ’1 cos ’2 cos $ (cid:2)Þ

ð2:2Þ

dEucl3Dðx1; y1; z1; x2; y2; z2Þ ¼

q

ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ðx2 (cid:2) x1Þ2 þ ðy2 (cid:2) y1Þ2 þ ðz2 (cid:2) z1Þ2

ð2:3Þ

We also consider different discovery scenarios for Susan. The difference between
Scenarios 1 and 2 is the kind of point returned from the GetLocation service she has
already discovered. Scenarios 2a and 2b differ in the required functionality.

Scenario 1: The GetLocation service returns points in a projected coordinate
reference system, e.g., epsg:31466 (DHDN/Gauß-Kru¨ ger, zone 2) and
Susan is looking for a service that computes distances in the
associated projection plane.

Scenario 2a: The GetLocation service returns points in a geographic coordinate
reference system, e.g., epsg:4326 (WGS84) and Susan is looking for a
service that computes distances on the associated sphere.

Scenario 2b: The GetLocation service returns points in a geographic coordinate
reference system, e.g., epsg:4326 (WGS84) and Susan is looking for a
service that computes the 3D Euclidian distance between these points
(Equation 2.45, Fig. 3, lower right).

dEucl3Dð’1; (cid:2)1; ’2; (cid:2)2Þ ¼

q

ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ðx2 (cid:2) x1Þ2 þ ðy2 (cid:2) y1Þ2 þ ðz2 (cid:2) z1Þ2

with x1; y1; z1 ¼ f ð’1; (cid:2)1; RÞ
and x2; y2; z2 ¼ f ð’2; (cid:2)2; RÞ

ð2:4Þ

If Susan relied only on syntactic descriptions of the operations (i.e., their
signatures) in her search, Services 1 to 3 would seem appropriate, because the result
of the GetLocation service (two doubles) could be fed into all of them. However,
the projected coordinates provided by the GetLocation services in Scenario 1 would
be interpreted incorrectly in services that expect geographic coordinates (e.g.,
Service 3) and vice versa (e.g., Scenario 2 and Service 1). Furthermore, Susan would
not be able to judge only from the signature what kind of distance operation a
service performs and how the result produced by the service is to be interpreted. In
one case (Scenario 2b) she would also miss a (partly) appropriate service (Service 4)
when only comparing syntactic descriptions.

5 Note that in Equation 2.4 the geographic coordinates are assumed to have been translated into
3D Cartesian coordinates using the Earth’s radius R:

Springer

10

Geoinformatica (2007) 11:1–36

3. Building Blocks for Semantic Service Discovery

This section introduces the building blocks for the proposed methodology of
ontology-based service discovery. We ﬁrst explain the notion of ontologies and
present the logical formalisms used in this paper (Section 3.1). Then we illustrate
how ontologies can be used for matching the inputs and outputs and the pre- and
postconditions of service descriptions (Section 3.2), and how this matchmaking can
be supported by shared domain vocabularies (Section 3.3). Finally, Section 3.4
analyses existing problems with each of these approaches.

3.1. Ontologies for Service Discovery

To overcome the problems described above, we propose to use ontological
descriptions. An ontology is an explicit formal speciﬁcation of a shared conceptu-
alization [14], [50]. By using ontologies to enrich the description of services, their
semantics become machine-interpretable, and users are enabled to pose concise and
expressive queries. Furthermore, logical reasoning can be used to discover implicit
relationships between search terms and service descriptions as well as to ﬂexibly
construct taxonomies for classifying services.

In the following sections we present three logical formalisms used in our work. We
ﬁrst introduce Hoare Logic as a language for specifying the behaviour of software
components. We then present First Order Logic and Description Logics, which are
employed for specifying the ontologies used in these behaviour speciﬁcations.

Hoare Logic. Hoare logic [16] is a formal system that provides a set of logical rules
for reasoning about some properties of a computer program, including determining
whether a given program provides a certain functionality. The intended function-
ality of a program Q is speciﬁed in terms of initial preconditions (P), i.e., assertions
about certain properties of the values taken by the relevant variables before the
program initiation and the relations among them, and postconditions (R), i.e.,
assertions about the values after execution. The relation between the preconditions
and postconditions is formulated as so-called Hoare triples of the form PfQgR
which can be interpreted as follows: BIf the assertion P is true before initiation of a
program Q, then the assertion R will be true on its completion.’’ [16] Speciﬁcations
based on pre- and postconditions can be used for discovering software components
or services with a required functionality (Section 3.2.3).

First-Order Logic. We use First-Order Logic (FOL)6 [48] for annotating and
matching pre- and postconditions of operations. FOL is a branch of logic that is
based on individuals and the relations (predicates) between them and permits the
formulation of quantiﬁed statements about some or all the individuals in the
universe of discourse. Predicates in FOL take only individuals as arguments and
quantiﬁers only bind individual variables.

6 FOL is also known as First-Order Predicate Logic or First-Order Predicate Calculus.

Springer

Geoinformatica (2007) 11:1–36

11

The primitive symbols of FOL are (1) parentheses, (2) variables, constants,
functions, and predicate symbols, (3) the usual logical connectors, : (not), ^ (and),
_ (or), ) (implication), , (equivalence), and (4) quantiﬁers, 8 (for all) and 9
(there exists) [13].

The goal of logic inference in FOL is to check whether a given knowledge base
KB (a collection of sentences) entails a sentence a (KB (cid:3) a ), i.e., whether a follows
logically from KB. Entailment in FOL is semidecidable, i.e., every entailed sentence
can be found, but for non-entailed sentences, it is not always possible to decide
limits, automated
whether they are entailed or not. Despite these theoretical
theorem provers can solve many hard problems in FOL. Inference procedures often
employed include resolution and term rewriting [48].

Description Logics. We employ Description Logics (DL) [7] for annotating and
matching inputs and outputs of operations. DL is a family of knowledge
representation languages that are subsets of ﬁrst-order logic (for a mapping from
DL to FOL, see e.g., [51]). They provide the basis for the Ontology Web Language
(OWL), the proposed standard language for the Semantic Web [1], which also is the
basis for OWL-S [35].

The basic syntactic building blocks of a DL are atomic concepts (unary
predicates), atomic roles (binary predicates), and individuals (constants). The
expressive power of DL languages is restricted to a small set of constructors for
building complex concepts and roles. Implicit knowledge about concepts and
individuals can be inferred automatically with the help of inference procedures [7].
A DL knowledge base consists of a TBox containing intensional knowledge
(declarations that describe general properties of concepts) and a ABox containing
extensional knowledge that is speciﬁc to the individuals of the domain. In our work,
we only use TBox language features, namely concept deﬁnition (C (cid:4) D) and concept
inclusion (C v D) with the following constructors for concepts (C; D; E):

E ! C u D
8R:C
9R:C
¼ nR j(cid:6) nR j(cid:7) nR

(intersection)
(value restriction)
(existential quantiﬁcation)
(number restrictions)

Using these features, it is also possible to deﬁne the range R and domain D of a

role S:

>
ð9 S:>Þ v D

v ð8S:RÞ

(range)
(domain)

One major advantage of (simple) DLs (like the one employed in this paper) over
FOL is that their inference procedures are decidable [51]. Of the available inference
procedures, the possibility to compute subsumption relationships between concepts
is of special importance for our work. A concept C is subsumed by a concept D with
respect to a TBox T if CI (cid:5) DI for every model I of T. This can be written as C vT D
or T (cid:3) C v D [7]. Popular DL reasoners include e.g., RACER [15] and Pellet7. For
a more detailed introduction to DL languages including different subsumption
algorithms see [7].

7 see www.mindswap.org/2003/pellet

Springer

12

Geoinformatica (2007) 11:1–36

3.2. Matching Inputs, Outputs, Pre- and Postconditions

In component-based software development, if parts selected from different suppliers
are to be matched and combined, component compatibility is a vital concern. The
notions of function subtypes, which is the basis for safe substitution of functions, has
been proposed to judge whether two components are compatible. In the following
sections, we ﬁrst introduce function subtypes (Section 3.2.1) and then describe how
they can be employed for matching inputs and outputs (Section 3.2.2) and pre- and
postconditions of service descriptions (Section 3.2.3).

3.2.1. Function Types

A function f ðxÞ ¼ y has the function type D ! C if x is of type D and y is of type C
[52]. D is called the domain8, C the codomain of the function (Equation 3.1). This
rule also applies to multi-argument functions because x can be of a product type
N (cid:8) M.

x : D ‘ y : C ) f ðxÞ ¼ y : D ! C

ð3:1Þ

A function type D1 ! C1 is a subtype (<:) of another function type D2 ! C2 if the
domain (argument type) D1 is a supertype of the domain D2 , and the codomain
(result type) C1 is a subtype of the codomain C2 (Equation 3.2). Thus, domains are
said to be contravariant (ordered in the opposite direction) and codomains are
covariant (ordered in the same direction) with respect to the subtyping relationship
between the functions [53].

D2 <: D1 ; C1 <: C2 ) D1 ! C1 <: D2 ! C2

ð3:2Þ

Subtypes are the basis for the notion of safe substitution formulated in the Liskov

Substitutability Principle [29]:

BIf for each object o1 of type S there is an object o2 of type T such that, for all
programs P deﬁned in terms of T , the behaviour of P is unchanged when o1 is
substituted for o2, then S is a subtype of T.’’

If this principle is translated into the realm of web service discovery, a function
(i.e., an operation offered by a web service) is a suitable match if it can be safely
substituted for (i.e., is a subtype of) the function described by the requester in her
query.

3.2.2. Matching Inputs and Outputs

Under the name of plug-in match, the idea of function subtyping has been applied
for web service discovery based on DL ontologies, (e.g., in [22], [45], [55]). In these
approaches, concepts from DL ontologies (Section 3.1) are used instead of the
operation’s (syntactic) input and output types to describe domains and codomains
of operations. An operation S : DS ! CS is then assumed to be a plug-in match for

8 Note that here the term domain refers to the input types of an operation rather than the domain
of a DL concept (cf. Section 3.1).

Springer

Geoinformatica (2007) 11:1–36

13

a request Q : DQ ! CQ if the concept KDS (representing DS) subsumes the concept
KDQ (representing DQ) and the concept KCS (representing CS) is subsumed by the
concept KCQ (representing CQ) (Equation 3.3). In other words, compared to the
requested operation, the input concepts of matching operations have to be more (or
as) generic and the output types have to be more (or as) speciﬁc.

matchplug(cid:2)in(cid:2)IOðS; QÞ ¼ KDQ v KDS ^ KCS v KCQ

ð3:3Þ

However, service compatibility is not just a matter of observing the conventions
on type signatures. It is equally important to know whether a service behaves in the
way expected by a user or another service using it. In addition to the service’s
signature, axioms are needed that describe its behaviour. An approach for matching
pre- and postconditions is presented in the next section.

3.2.3. Matching Pre- and Postconditions

In [64], the notion of function subtypes is applied for matching a library speciﬁcation
S and a query speciﬁcation Q, both of which are based on pre- and postconditions.
Again, the idea of function subtypes is directly implemented in a so-called plug-in
match (Equation 3.4), which ensures that the S is behaviourally equivalent to Q.

matchplug(cid:2)in(cid:2)PrePostðS; QÞ ¼ ðQpre ) SpreÞ ^ ðSpost ) QpostÞ

ð3:4Þ

The authors also relax the plug-in match in several ways to produce further
degrees of match. These can be divided into two groups: (1) types of match that
consider pre- and postconditions separately and (2) types of match that consider the
speciﬁcation as a whole. The latter types are called predicate matches.

In our work, it has proven difﬁcult to clearly separate pre- and postconditions.
Therefore, only two types of match are considered in our approach: The generalised
predicate match and the plug-in post match. Both types are presented in more detail
below. It is assumed that variables in S and Q have been renamed consistently. This
renaming is easily provided by signature matching [63]. It is also assumed that the
signatures of S and Q match.

Generalized Predicate MatchR Predicate matches relate the speciﬁcation predicates,
Spred and Qpred, in their entirety. In this work we use Spre ) Spost as a deﬁnition
for the speciﬁcation predicate Spred. An alternative (stronger) deﬁnition would be
Spre ^ Spost. The generalized predicate match (Equation 3.5) holds if the library
speciﬁcation is stronger than the query and, hence, allows for simple queries. While
speciﬁcations of library functions will be detailed, describing the behaviour of the
functions completely, queries can be simple because they focus on just the aspects of
the behaviour the requester is most interested in or those she thinks to be most likely
to differentiate among functions in the library.

matchgen(cid:2)predicateðS; QÞ ¼ Spred ) Qpred ¼ ðSpre ) SpostÞ ) ðQpre ) QpostÞ

ð3:5Þ

In contrast, the specialized predicate match allows the library speciﬁcation to be
weaker than the query. Therefore, the services it returns cannot be used directly but
only serve as a basis for implementing a matching service, which makes this type of
match unsuitable for our purposes.

Springer

14

Geoinformatica (2007) 11:1–36

Plug-in Post MatchR For cases where one is concerned with only the effects of
functions, it is a useful relaxation of the plug-in match to consider only the post-
condition (Equation 3.6). Because the precondition term is not tested, there is no
guarantee that Spre actually holds, so an additional wrapper may have to be provided
in the service chain to establish Spre before calling the function speciﬁed by S.

matchplug(cid:2)in(cid:2)postðS; QÞ ¼ ðSpost ) QpostÞ

ð3:6Þ

3.3. Shared Vocabularies

The ontologies used for making the semantics of web services explicit can be
organized in different ways. In [62] a classiﬁcation of different ontology architec-
tures for data integration is introduced. In the following, we translated the different
approaches into the domain of GI service discovery.

In multiple ontology approaches, each service or query is described by its own
local (or application) ontology. In principle, each of these local ontologies can be a
combination of several other ontologies. However, it cannot be assumed that several
local ontologies share the same vocabulary. This lack of a common vocabulary
makes it difﬁcult to compare different local ontologies.

In contrast, single ontology approaches use one global ontology, which provides a
shared vocabulary for specifying the semantics of all services and queries. Such
approaches can be applied to problems where all service descriptions available in a
catalogue have been created with a very similar view on a domain, which also has to
be shared by all requesters. Hybrid approaches also use a global shared vocabulary,
which contains basic terms (the primitives) of a domain. At the same time it allows
the semantics of each service or query to be described by its own ontology. As these
local ontologies reuse and combine the primitives from the shared vocabulary, they
become comparable to each other. In both approaches, it is assumed that the
semantics of the primitives is understood (and this understanding is shared) by all
requesters and providers in the domain. Therefore, the primitives require no further
formal deﬁnitions. Nevertheless, it can sometimes be useful to represent a shared
vocabulary as an ontology in order to impose a structure on it. Such an ontology is
called a domain ontology.

3.4. Remaining Problems

This section discusses possible problems of using the presented building blocks in a
methodology for GI service discovery.

Matching Inputs and Outputs Based on DL Concepts. Even though DL concepts
can be more expressive than simple syntactic types, simple comparisons of DL
concepts that represent inputs and outputs of an operation are still not expressive
enough for semantic service discovery. This has several reasons.

Two services with different functionality can still be represented using the same
DL concepts for annotating inputs and outputs, e.g., two distance operations
(Euclidian and geodesic), which take two gm point objects as input and return a
distance object. Specifying the functionality of an operation requires the additional
speciﬁcation of pre- and postconditions.

Springer

Geoinformatica (2007) 11:1–36

15

It is possible in DL to specify some constraints for the input and output
parameters, e.g., that the two gm point input parameters of a distance operation
have to be in some geographic coordinate system. It is, however, impossible to state
that both input parameters also have to have the same coordinate system. Similarly,
while it is possible to state that the output parameter is a distance between two
gm points, it cannot be stated that it is the distance between those gm points that
were used as inputs to the operation. Specifying such constraints requires
introducing variables and hence a more expressive language than DL.

Matching FOL Pre- and Postconditions. FOL is expressive enough to specify pre-
and postconditions and constraints over variables. However,
this increased
expressiveness comes at a cost. FOL inference is semi-decidable, i.e., for non-
entailed sentences, it is not always possible to decide whether they are entailed or
not. Also, even for entailed sentences proofs might require a long time. This is
critical as for each advertisement in the registry one implication has to be tested for
each type of match. For large numbers of services, using FOL theorem provers is
computationally too expensive.

Shared Vocabularies.
In a highly heterogeneous and distributed environment like
SDIs it has to be assumed that many different actors specify service descriptions in
order to register and query service registries. To keep these service descriptions
comparable it is crucial that they are based on a shared vocabulary. The approaches
currently proposed for semantic service discovery (e.g., [45], [55]) can be classiﬁed
as single ontology approaches. The use of ontologies at multiple levels is not
intended. In the Web Service Modeling Ontology (WSMO) approach [47], the need
to map between different ontologies by means of mediators is acknowledged.
However, how this is to be achieved, still remains unclear.

Even if shared vocabularies are used for the concepts describing inputs and
outputs of operations, comparability is still not guaranteed if the semantic
description is generated directly from an operation’s syntactic description (e.g., in
WSDL), e.g., as proposed in [22]. Syntactic descriptions can differ signiﬁcantly, even
if the operations have the same functionality. The following two signatures are a
simple example for two distance operations that could have the same functionality:

distance1(x1:double, y1:double, x2:double, y2:double): double
distance2(p1: point, p2: point): double

The input parameters of distance1 would all be semantically annotated using a
coordinate concept from a domain ontology, whereas the input parameters of
distance2 would be annotated using a gm points concept. If there is no subsump-
tion relation between these two concepts, no match will be found during signature
matching [31]. Therefore, when using an approach based on function subtypes,
functions (or operations), too, should be part of shared vocabularies. Currently, we
are not aware of any approach that uses shared vocabularies of operations.

4. Ontology-Based Descriptions of Operations

Ontology-based descriptions of operations play a crucial part in the presented
approach. There are a number of proposals for representing operations (or services)

Springer

16

Geoinformatica (2007) 11:1–36

in ontologies, most notably OWL-S9 [35] and WSMO10 [47]. As WSMO is still under
active development and subject to major revisions and because of some problems
with OWL-S (see below) we have chosen to develop a lightweight representation for
operation ontologies. Our goal was to develop a cognitively adequate, yet simple
description of operations that can be used for matching inputs, outputs, pre- and
postconditions based on the idea of function subtypes. In the following we argue
why we consider the OWL-S approach to specifying operations to be inappropriate
for our methodology and then propose a simple alternative.

4.1. A Simple Representation for Describing Operations

The OWL-S service proﬁle is a representation of the operation the service provides.
In OWL-S, operations are represented as OWL concepts, which—as all other DL
concepts—are static. The ServiceProfile concept, which describes an operation’s sig-
nature, has four functional properties: input, output, preconditions and postcondi-
tions. Service descriptions in OWL-S are instances of this concept, in which the
ﬁllers for these properties are OWL concepts.

We consider the conceptualization underlying the ServiceProfile class to be
appropriate for representing operations. However, we believe that the representa-
tion of operations in OWL-S is too complicated. To implement the matching of
operation descriptions described in Section 3.2.2 the constructs representing the
input, output, pre- and postconditions ﬁrst have to be extracted from the OWL
representation, and each has to be compared separately to its counterpart in a query.
The results of these comparisons then have to be combined following the rules of
function subtyping.

In order to facilitate this parsing step, we propose to use a lightweight
representation for operations [32]. This representation consists of a semantic
signature11 containing DL concepts (instead of datatypes) to represent inputs and
outputs and a speciﬁcation of pre- and postconditions in First Order Logic (FOL).
The operation descriptions and the associated ontologies occur at two levels:
At the domain level, they describe the generic operations of the domain and
thus provide a shared vocabulary, on which, at the application level, service
providers (or requesters) can base the descriptions of (or queries for) a particular
operation (Fig. 4). In the following, we will ﬁrst illustrate the semantic signature and
the speciﬁcation of pre- and postconditions on the domain level and then show how
to derive semantic advertisements and queries from these domain-level descriptions.
As has been shown in Section 3.4, it is crucial that the semantic signature is not
based directly on the syntactic signature (e.g., a WSDL description). Rather, there
should be an agreed-upon set of operations that is speciﬁed as a part of the shared
vocabulary in a particular domain. Similar to other domain ontologies, the operation
descriptions should, wherever possible, be based on existing standards or agree-
ments within the domain rather than designed from scratch. In the domain of

9 see www.daml.org/services/owl-s
10 see www.wsmo.org
11 The term shall express the contrast to normal (syntactic) signatures. It has been inspired by the
term Bsemantic type’’ introduced in [6] for annotating the output of data providing services with DL
concepts.

Springer

Geoinformatica (2007) 11:1–36

17

Fig. 4 Ontology-based operation descriptions and their relationships to DL and FOL ontologies at
the domain and application level

geographic information (GI), the 19100 series of ISO standards published by ISO/
TC 211 provides a comprehensive and widely used collection of GI models that can
serve as such a basis. Apart from descriptions in natural language, these standards
often contain detailed UML class diagrams. Where the UML classes in these models
contain operations, they are particularly suited as a starting point for developing
operation ontologies. For example, the distance operation deﬁned in [17] for
gm objects (and by inheritance also for gm points) can serve as a basis for an
ontological description of distance operations.

In order for the service to be executable once it has been discovered, a
correspondence has to be established between the DL concepts in the semantic
signature and the (XML schema) datatypes in the syntactic signature. So-called
registration mappings [6] can be used for this purpose. However, these are outside
the scope of this paper. For a detailed account on how to use registration mappings
in SDIs, see [30].

4.2. Ontology-Based Descriptions of Operations in the Running Example

This section illustrates in detail how semantic advertisements and semantic queries
can be generated based on an ontology-based operation description at the domain
level.

4.2.1. Ontology-Based Descriptions of Operations at the Domain Level

In this section, we illustrate how, in the proposed methodology, an operation is
described at the domain level. As an example, we use the distance operation
between points, which will serve the provider and requester in our running example
as a basis for specifying their advertisements and queries. The description is based
on the following domain-level DL concepts and FOL axioms.

Springer

18

Geoinformatica (2007) 11:1–36

DL Domain Ontology. As motivated above, we use the 19100 series of ISO
standards as a basis for building a DL domain ontology. Here, we only consider a
small subset of these models that allows us to describe the concepts occurring in
the distance operation between two points (for the relevant standards, see [17],
[18]).

A geometry object (gm object) can (but need not) be associated to one coordinate
reference system (coordRefSys) of type sc crs (Equation 4.1). Points (gm point) are
a speciﬁc kind of geometric object (as are polygons and lines). They are deﬁned as
having between 1 and 3 coordinates each of which is represented as a number
(Equation 4.2). Geographic and projected coordinate reference systems (geog crs
and proj crs ) are speciﬁc families of coordinate reference systems (Equation 4.3).
epsg 4326 is a geographic, and epsg 31466 is a projected coordinate reference system
(Equation 4.4). Note that, as our approach is restricted to TBox reasoning (Section
3.1), coordinate reference systems are modelled as concepts rather than individuals
(as in the FOL ontology presented below).

gm object v ð(cid:6) 1coordRefSysÞ

> v ð8coordRefSys:sc crsÞ

ð9 coordRefSys:>Þ v gm object

gm point (cid:4) gm object u ð(cid:7) 1 coordinatesÞ u ð(cid:6) 3 coordinatesÞ

> v ð8coordinates:numberÞ

ð9 coordinates:>Þ v gm point

geog crs v sc crs
proj crs v sc crs

epsg 4326 v geog crs
epsg 31466 v proj crs

ð4:1Þ

ð4:2Þ

ð4:3Þ

ð4:4Þ

FOL Domain Ontology. While the standards provided by ISO and OGC provide
a good basis for the DL domain concepts representing inputs and outputs of
operations, they are not much help for specifying functionality. Therefore,
in
this section, we present a conceptual model for the functionality of distance
operations.

There are several possible conceptualizations, e.g., using the mathematical
expressions presented in Section 2.3 or the notions of metric and metric space [36].
However, these present a number of difﬁculties. The former would become too
complicated for more complex operations (e.g., buffer, interpolate) and be difﬁcult
or impossible to create using standard ontology or logic languages. With the latter,
every distance operation would be (trivially) associated with a different metric. The
use ontologies for just expressing such 1:1 correspondences would be too much
overhead. And ﬁnally, neither primitives like geodesic metric nor complex
mathematical expressions can be assumed to be known or understood by the
average GI user. Thus, an alternative conceptualization is required.

The conceptualization we have adopted for our example uses a small set of
primitives: A distance is modelled as the length of a curve in 3-dimensional Euclidian
Space R3. The curve is deﬁned as being the shortest possible curve in a particular sub-

Springer

Geoinformatica (2007) 11:1–36

19

space of R3. R3 provides a reference space for this conceptualization in several
respects:

&

It is the most complex (highest dimensional) space when dealing with geographic
information.12 Therefore, any other space can be Bembedded’’ (or represented)
in it.
&
It is intuitive and well-known because it reﬂects our everyday experience.
& As we base the notion of distance on the notion of length in our conceptuali-
zation, we also have to provide a metric for measuring this length. The Euclidian
metric of R3 provides this (reference) metric.

With this conceptualisation, only one space and one metric have to be

considered, both of which are also intuitive to the average GI user.

Formally, the presented conceptualization can be based on the primitives and
associated axioms listed below. The FOL domain ontology also includes pre-
dicates and associated axioms that have been introduced as concepts in the DL
domain ontology (Section 4.2.1), e.g., gm point or distance . These are omitted here
for brevity.

curve. A ternary predicate that represents a curve between two points in R3. In
mathematics, the concept of a curve tries to capture our intuitive idea of a
geometrical one-dimensional and continuous object.
length. A unary function that returns the length of a curve.
(cid:6). A binary predicate to compare lengths of curves. To increase readability, (cid:6) is

written as an inﬁx operator in this paper.

in. A binary predicate that indicates that a point or curve is embedded in a
particular subspace of R3, i.e., in our example a road network, plane or sphere.
A curve is located in a particular space if all its points are located in this space,
too. Therefore, the in predicate for curves can be derived from the in predicate
for points (Equation 4.5).
R3. A constant that represents R3.
r3subspace. A unary predicate that represents a subspace of R3.
plane, sphere, network etc. Unary predicates that represent particular subspaces of

R3 (Equation 4.6).

shortestCurve. A quaternary predicate representing the shortest curve between two
points in a particular subspace of R3. It can be deﬁned as follows: For all curves
x between points p1 and p2 , if and only if there is no other curve y between p1
and p2 in the same space that is shorter, x is the shortest curve between p1 and p2
in that space (Equation 4.7).

Epsg_31466, Epsg_4326, etc. Constants representing coordinate reference systems.
Epsg 31466 is a projected and Epsg 4326 a geographic coordinate reference
system (Equation 4.8). Note that in the DL domain ontology, coordinate
reference systems are modelled as concepts rather than individuals.

deﬁnes. A binary predicate that links the notions of space and coordinate reference
system. For all projected coordinate reference systems crs, there exists a plane
q, in which all points and curves that have crs as a coordRefSys are located,

12 For simplicity, we do not consider time in this paper.

Springer

ð4:6Þ

ð4:8Þ

ð4:9Þ

ð4:10Þ

20

Geoinformatica (2007) 11:1–36

and crs deﬁnes q (Equation 4.9). In (Equation 4.10), a similar constraint is
deﬁned for geographic coordinate reference systems, which deﬁne a sphere s.

8c; p1; p2; s

:

curveðc; p1; p2Þ ^ ð8pn : inð pn; cÞ ) inð pn; sÞÞ ) inðc; sÞ

ð4:5Þ

8p : planeð pÞ ) r3subspaceð pÞ
8s
sphereðsÞ ) r3subspaceðsÞ
8n : networkðnÞ ) r3subspaceðnÞ

:

8c; p1; p2; s

:

curveðc; p1; p2Þ ^ inðc; sÞ^

, shortestCurveðc; p1; p2; sÞ

proj crsðEpsg 31466Þ
geog crsðEpsg 4326Þ

ð8d : curveðd; p1; p2Þ ^ inðd; sÞ ) lengthðdÞ (cid:7) lengthðcÞÞ

ð4:7Þ

8crs

: proj crsðcrsÞ ) ð9q : planeðqÞ^

½8p : coordRefSysðp; crsÞ ) inðp; qÞ ^ definesðcrs; qÞ(cid:9)Þ

8crs

:

geog crsðcrsÞ ) ð9s : sphereðsÞ^

½8p : coordRefSysð p; crsÞ ) inð p; sÞ ^ definesðcrs; sÞ(cid:9)Þ

Ontology-Based Operation Description. Based on the primitives introduced above,
a generic distance operation between the points p1 and p2 can then be deﬁned as the
length of the shortest (existing) curve in a particular subspace of R3 between p1 and
p2 (Equation 4.11). The precondition states that both p1 and p2 have to be in the
same subspace of R3, while this space can (but need not) be different from the space
containing the curve (e.g., for a Euclidian distance in R3 between two points on a
sphere).

sig
pre
post

:
:
:

distð p1 : gm point; p2 : gm pointÞ : distance
9s1 : r3subspaceðs1Þ ^ inð p1; s1Þ ^ inð p2; s1Þ
9c; s2 : r3subspaceðs2Þ^

ð4:11Þ

shortestCurveðc; p1; p2; s2Þ^
distð p1; p2Þ ¼ lengthðcÞ

4.2.2. Semantic Advertisements and Semantic Queries

In the proposed methodology, a domain-level operation description is the basis for
both a provider’s advertisement and a requester’s query for a speciﬁc service. The
input and output types speciﬁed in the domain-level description can be further
specialized by creating DL application ontologies that (further) constrain cardinalities
and ranges of roles from the domain ontology. It is important, however, that the
concepts in the application ontologies always have a taxonomic relation to the
concepts used in the domain-level description of the chosen operation. Only if this is
the case, the matching of inputs and outputs based on DL subsumption will lead to
satisfactory results (Section 3.4). Also the FOL axioms describing the pre- and

Springer

Geoinformatica (2007) 11:1–36

21

postconditions can be reﬁned. We call the reﬁned description of the operation
semantic advertisement (for registration) or semantic query (for discovery).

In the following, we illustrate the speciﬁcation of semantic advertisements and
queries for our running example based on the generic distance operation for points
(Equation 4.11).

Inputs and Outputs in Semantic Advertisements and Queries. The semantic types
representing input and output, i.e., gm point and distance are the basis for John’s
semantic advertisements. He can further specialize the input and output types by
creating DL application concepts that constrain cardinalities and/or ranges of roles
speciﬁed for these concepts. Three examples of how this can be done are shown in
Equation 4.12 for the concepts representing the input parameters of John’s distance
operations.

geog point (cid:4) gm point u ð¼ 2 coordinatesÞu

ð¼ 1 coordRefSysÞ u ð8coordRefSys:geog crsÞ

proj point (cid:4) gm point u ð¼ 2 coordinatesÞu

ð4:12Þ

ð¼ 1 coordRefSysÞ u ð8coordRefSys:proj crsÞ

3d point (cid:4) gm point u ð¼ 3 coordinatesÞ

in the domain ontology. A geog point

All concept deﬁnitions further restrict cardinalities and ranges of non-taxonomic
relations speciﬁed for gm point
is deﬁned as
having exactly (instead of at most) one geographic coordinate reference system and
exactly two coordinates. The deﬁnition of proj point is the same except that it is
restricted to projected coordinate reference systems. A 3d point is simply deﬁned
as having exactly three coordinates, and no further restrictions are introduced on its
coordinate reference system.

Susan has to follow the same steps as John in order to describe the kind of distance
service she is looking for. However, she does not have to deﬁne a new concept. She
can directly use the concept that represents the output of the GetLocation service as a
requirement in her query. The deﬁnitions of this concept in the scenarios of the
motivating scenario are presented in Equation 4.13. location1 represents a point in a
Gauß-Kru¨ ger coordinate reference system (Scenario 1), while location2 represents
a point in WGS84 (Scenarios 2a and 2b).

location1 (cid:4) gm point u ð¼ 2 coordinatesÞu

location2 (cid:4) gm point u ð¼ 2 coordinatesÞu

ð¼ 1 coordRefSysÞ u ð8coordRefSys:epsg 31466Þ

ð4:13Þ

ð¼ 1 coordRefSysÞ u ð8coordRefSys:epsg 4326Þ

Pre- and Postconditions in Semantic Advertisements and Queries. Based on the
generic speciﬁcation of a distance operation in Equation 4.11, John can derive more
speciﬁc speciﬁcations for the four distance operations introduced in Section 2.3. In
Equations 4.14 to 4.17, we show the speciﬁcations for 2D-Euclidian, network,
geodesic and 3D-Euclidian distance. Each of the curves used in the deﬁnitions has
different properties, which are stated in the post-conditions.

Springer

22

Geoinformatica (2007) 11:1–36

In addition to inputs, outputs, pre- and postconditions, these speciﬁcations also
contain variables. These become necessary if pre- and postconditions deﬁne
constraints on the same object, as in the 2D-Euclidian distance example (Equation
4.14), where the input points should be located on the same plane as the curve.
Therefore, the scope of these variables ranges over both pre- and postconditions. It
is also possible to deﬁne additional constraints on these variables (in pre- and/or
postconditions), e.g., in the network distance example (Equation 4.15), the network,
in which the input points are located, should be located in the the same plane as the
curve. For simplicity, the type of a variable (which could also be seen as such an
additional constraint) is speciﬁed in the variables section.

signature : distð p1 : proj point; p2 : proj pointÞ : distance
variables
pre
post

: p : plane
:
: 9c : shortestCurveðc; p1; p2; pÞ ^ distð p1; p2Þ ¼ lengthðcÞ

inð p1; pÞ ^ inð p2; pÞ

signature : distð p1 : proj point; p2 : proj pointÞ : distance
variables
pre
post

:
:
: 9c : shortestCurveðc; p1; p2; nÞ ^ distð p1; p2Þ ¼ lengthðcÞ

n : network; p : plane
inð p1; nÞ ^ inð p2; nÞ ^ inðn; pÞ

signature : distð p1 : geog point; p2 : geog pointÞ : distance
variables
pre
post

:
:
: 9c : shortestCurveðc; p1; p2; sÞ ^ distð p1; p2Þ ¼ lengthðcÞ

s : sphere
inð p1; sÞ ^ inð p2; sÞ

signature
pre
post

: distð p1 : 3d point; p2 : 3d pointÞ : distance
:
: 9c : shortestCurveðc; p1; p2; R3Þ ^ distð p1; p2Þ ¼ lengthðcÞ

inð p1; R3Þ ^ inð p2; R3Þ

ð4:14Þ

ð4:15Þ

ð4:16Þ

ð4:17Þ

Like John’s advertisements, Susan’s queries are based on the generic speciﬁcation
given in Equation 4.11. She can further constrain this speciﬁcation based on the
constraints the GetLocation service speciﬁes as post-conditions (which become pre-
conditions in Susan’s query) and the functionality she requires.

In Scenario 1 we have assumed that the GetLocation service returns points in
Gauß-Kru¨ ger, zone 2 (Epsg 31466). This results in the speciﬁcation shown in
Equation 4.18. Note that the postcondition requires the shortest curve between p1
and p2 to be embedded in the space that is deﬁned by the given coordinate
reference system. This means that Susan wants the distance to be measured in the
reference system’s projection plane.

signature

distð p1 : location1; p2 : location1Þ : distance

:
: (cid:2)
:

pre
post

9c; s : definesðEpsg 31466; sÞ ^ shortestCurveðc; p1; p2; sÞ^

ð4:18Þ

distð p1; p2Þ ¼ lengthðcÞ

In Scenarios 2a and 2b, the GetLocation service returns geographic coordinates
(e.g., in Epsg 4326). In Scenario 2a Susan wants the distance to be measured in the

Springer

Geoinformatica (2007) 11:1–36

space deﬁned by the reference system, i.e., along the Earth’s surface (Equation 4.19),
while in Scenario 2b it is to be measured directly in R3 (Equation 4.20).

distð p1 : location2; p2 : location2Þ : distance

9c; s : definesðEpsg 4326; sÞ ^ shortestCurveðc; p1; p2; sÞ^

distð p1; p2Þ ¼ lengthðcÞ

signature
pre
post

:
: (cid:2)
:

:
: (cid:2)
:

pre
post

signature

distð p1 : location2; p2 : location2Þ : distance

9c : shortestCurveðc; p1; p2; R3Þ^

distð p1; p2Þ ¼ lengthðcÞ

23

ð4:19Þ

ð4:20Þ

5. Enhancing Service Discovery with Ontology-Based Descriptions

After illustrating how providers and requesters can describe the operations the are
offering or searching, in this section, we take a look behind the scenes of service
discovery.

5.1. Matchmaking Between Semantic Advertisements and Queries

The matchmaking between a requester’s semantic query and all available semantic
advertisements in the registry is done as a two-step process (Fig. 5).

First, the semantic signature is used for efﬁciently ﬁltering the potentially large
number of services. This ﬁltering is done using DL subsumption reasoning on the
concepts representing inputs and outputs as described in Section 3.2.2. As the result
of this ﬁltering step should be a relatively small number of services, we currently
only consider plug-in or exact matches between semantic signatures. If the ﬁltering
turns out to be too strong, other types of matches could also be included.

In the second step, the pre- and postconditions of the remaining services are
compared to those speciﬁed in the query in order to identify those services that
provide the required functionality. This ﬁlter tests for the generalized predicate
and the plug-in post types of match introduced in Section 3.2. For each type of
match, a separate FOL proof obligation has to be derived from the speciﬁcations
of pre- and postconditions in the semantic advertisement and query. These proof
obligations are then tested using a FOL theorem prover. Each service is ﬁrst
tested for the stronger generalized predicate match. If a match is found, the
weaker plug-in post match does not have to be tested as is implied by the gen-
eralized predicate match. The strictness of the type of match can then be used to
rank the services.

Translating the Speciﬁcations into FOL Axioms. As introduced in Section 3.1, a
speciﬁcation for a component Q with precondition P and postcondition R has the
following interpretation: If P is true before initiation of Q, then R will be true after
its execution [16]. We therefore translate speciﬁcations consisting of signature, pre-
and post-conditions (Equation 5.1) into a single implication (Equation 5.2). The
implicant is a conjunction of the type constraints for all input parameters and

Springer

24

Geoinformatica (2007) 11:1–36

Fig. 5 A schematic illustration of the two-step matchmaking procedure. In the ﬁrst step, all
advertisements are ﬁltered using DL subsumption reasoning on the concepts representing inputs and
outputs. In the second step, the remaining services’ pre- and postconditions are compared to the
query using a FOL theorem prover

variables and the preconditions over the inputs and variables. The consequence is a
conjunction of the type constraint of the operation’s result and the postconditions
over the inputs, the variables and the result.

signature : opði1 : t1; . . .; in : tnÞ : tR
variables
pre
post

v1 : u1; . . .; vn : un
:
: Pði1; . . .; in; v1; . . .; vnÞ
: Rði1; . . .; in; v1; . . .; vn; opði1; . . .; inÞÞ

8i1; . . . ; in; v1; . . .; vn

:

½t1ði1Þ ^ . . . ^ tnðinÞ ^ u1ðv1Þ ^ . . . ^ unðvnÞ^

Pði1; . . .; in; v1; . . .; vnÞ(cid:9)

) ½tRðopði1; . . .; inÞÞ ^ Rði1; . . .; in; v1; . . . ; vn; opði1; . . . ; inÞÞ(cid:9)

Springer

ð5:1Þ

ð5:2Þ

Geoinformatica (2007) 11:1–36

25

To illustrate this translation rule, we show its application to the speciﬁcation of a
network distance (Equation 4.15), which results in the FOL formula shown in
Equation 5.3.

8p1; p2; n; p

:

½ proj pointð p1Þ ^ proj pointð p2Þ ^ networkðnÞ ^ planeð pÞ^

inð p1; nÞ ^ inð p2; nÞ ^ inðn; pÞ(cid:9)
) ½distanceðdistð p1; p2ÞÞ ^ ð9c : shortestCurveðc; p1; p2; nÞ^

ð5:3Þ

distð p1; p2Þ ¼ lengthðcÞÞ(cid:9)

5.2. Enhanced Discovery in the Running Example

To illustrate how keyword-based service discovery can be enhanced using ontology-
based descriptions of operations we present the results of the proposed matchmak-
ing procedure for the services and queries from the running example.

Matching Inputs and Outputs. From the examples given above, we can derive
semantic signatures describing the services offered by John (Equation 5.4) and the
queries posed by Susan (Equation 5.5). As we have so far only considered the
distance operation’s input parameters, we use the unmodiﬁed distance concept from
the domain ontology in all signatures.

Service 1 : distð p1 : proj point; p2 : proj pointÞ : distance
Service 2 : distð p1 : proj point; p2 : proj pointÞ : distance
Service 3 : distð p1 : geog point; p2 : geog pointÞ : distance
Service 4 : distð p1 : 3d point; p2 : 3d pointÞ : distance

Query 1 : distð p1 : location1; p2 : location1Þ : distance
Query 2 : distð p1 : location2; p2 : location2Þ : distance

ð5:4Þ

ð5:5Þ

The subsumption hierarchy that can be computed between the concepts used as
inputs in these signatures is shown in Fig. 6. If Susan uses Query 1 in her request, she
discovers Service 1 and Service 2 as plug-in matches (Section 3.2.2) because it can be
inferred that location1 is more speciﬁc than proj point . If she uses Query 2 instead,
she discovers Service 3 because location2 is more speciﬁc than geog point. Service 4,
however, is not discovered by any of Susan’s queries, because neither location1 nor
location2 can be proved to be more speciﬁc than 3d point.

Matching Pre- and Postconditions. Matching between the service and query
speciﬁcations containing pre- and postconditions can be used to differentiate
between the services returned from the input/output matching step. We use a ﬁrst

Fig. 6 Inferred taxonomic rela-
tionship between the applica-
tion concepts deﬁned by John
(dark grey) and Susan (light
grey) and the domain concept
gm point (white)

Springer

26

Geoinformatica (2007) 11:1–36

order logic theorem prover (SPASS, [61]) to check the different kinds of match
introduced in Section 3.2.2.

For each kind of match, a proof obligation is formulated, e.g., Qpred ) Spred for the
generalized predicate match. If it can be shown that the proof obligation is entailed
in the knowledge base, i.e., the domain ontology for distances (Section 4.2.1), a
match is assumed. As entailment in FOL is only semidecidable, it is not always
possible for non-entailed sentences to decide whether they are entailed or not. To
avoid that in such cases the proof does not terminate, a time-out (e.g., 5 sec) is set
for each testing a proof obligation. If no proof can be generated in this time, it is
assumed that the speciﬁcations do not match. While introducing a time-out will
enhance the performance of the reasoning step, it also means that true matches are
not discovered in cases where the proof simply takes a long time.

Applying the generalized predicate match in the query scenarios of the running

scenario produces the following results:
& For Scenario 1 (Equation 4.18), the operation returning the Euclidian distance in
the plane (Equation 4.14) is discovered as a match. This is because Epsg 31466 is
a Gauß-Kru¨ ger coordinate reference system, and therefore deﬁnes a plane, in
which all input points and the shortest curve are located. The other distance
operations are no match because their input points and shortest curves are
located in different subspaces of R3.

& For Scenario 2a (Equation 4.19), the operation returning the geodesic distance
(on a sphere) (Equation 4.16) is discovered as a match. This is because
Epsg 4326 is a geographic coordinate reference system, and therefore deﬁnes a
sphere, on which all input points and the shortest curve are located. The other
distance operations are no match because their input points and shortest curves
are located in different subspaces of R3.

& For Scenario 2b (Equation 4.20), none of the presented distance operations is
discovered even though the Euclidian distance in R3 would (exactly) match the
postcondition. This is because the precondition that all
input points have
Epsg 4326 as a coordinate reference system is not satisﬁed.

In order to ﬁnd a match for the last case, we also applied the plug-in post match to
the queries. As expected, this returns the same matches for the ﬁrst two queries, but
also the Euclidian distance in R3 (Equation 4.17) for Scenario 2b (Equation 4.20).
This means that this service’s functionality (as expressed in the postcondition) but
not its preconditions match Susan’s query. If Susan wants to use this service on the
results of the GetLocation service, she has to transform the coordinates from
Epsg 4326 to coordinates in R3.

Table 1 Results of the different matchmaking procedures for the queries of the running example

Scenario

Services discovered in
DL matchmaking

Services discovered with
Generalized Predicate Match

Services discovered
with Plug-in Post
Match

Service1
Service3
Service4

1
2a
2b

Service1; Service2
Service3
–

Service1
Service3
–

Springer

Geoinformatica (2007) 11:1–36

27

Table 1 summarises the results of the different matchmaking steps for the queries
and services of the running example. Note that, if the DL and FOL matchmaking
steps are executed consecutively, none of the services will be discovered in Scenario
2b because no matching results can be found in the DL matchmaking step.

6. Related Work

In recent years, a number of research groups have addressed the problem of
ontology-based service discovery. In this section, we present the approaches most
relevant to our work and point out similarities and differences to the methodology
presented in this paper.

6.1. OWL-S-Based Service Discovery

Since the OWL-S service ontology [35] is public and does not prescribe a framework
implementation it has been used as the starting point of individual efforts towards
semantic web services [8].

In [45] a tool for matching between semantic descriptions of services and user
requests is introduced that is based on OWL-S proﬁle and the UDDI registry for
web services [2]. The matchmaking is done using subsumption reasoning on the
concepts describing inputs and outputs. The results for inputs and outputs are
combined according to the rules deﬁned in Section 3.2.1 for function subtypes.
However, as this approach does not consider pre- and postconditions, no distinction
can be made between operations with the same (semantic) signature.

Another approach based on OWL-S and DL subsumption reasoning is described
in [28]. In this approach, the whole proﬁle (including inputs, outputs, pre- and
postconditions) is deﬁned as a subconcept of the DAML-S service proﬁle. This
concept is then classiﬁed in the subsumption hierarchy deﬁned by the advertised
service proﬁles using RACER [15] as a reasoning engine. Consequently, inputs and
outputs cannot be treated differently as required by the rules for function subtypes.
As has been illustrated in Section 4, this can lead to unintended results.

[28] also deﬁne an additional (very weak) type of match: The intersection match
the intersection of advertisement A and request R is satisﬁable
holds if
(:½A u R v ?(cid:9) ). The authors present experimental results that indicate that the
approach of using DL subsumption reasoning for service discovery scales up to
larger applications. This requires, however, that the TBox classiﬁcation of the
service proﬁles is done off-line before the matchmaking process starts and the
classiﬁed TBox is then used to reason about requests.

6.2. LARKS Matchmaking of Agent Capabilities

In [55] the Language for Advertisement and Request for Knowledge Sharing
(LARKS) is deﬁned, which can be used to describe the capabilities of software
agents. A capability speciﬁcation in LARKS deﬁnes the context of the speciﬁcation,
the input and output variables, the constraints on these variables, the ontological
descriptions used, and a textual description. As in OWL-S, a capability speciﬁcation
can be treated as a request or as an advertisement.

Springer

28

Geoinformatica (2007) 11:1–36

Given a request and an advertisement, the matchmaking process can apply ﬁve
different ﬁlters, which can be arbitrarily combined by the requester. This enables a
trade-off between accuracy and efﬁciency of the discovery process. In our context,
the signature and constraint ﬁlters are of particular interest. In the signature ﬁlter,
the input and output declarations of the request and the advertisement are com-
pared using subtype inference rules and subsumption reasoning. The logical im-
plications in the constraint ﬁlter are checked using subsumption reasoning for Horn
clauses. The plug-in match, which is a combination of the signature and constraint
ﬁlters, follows the rules of function subtypes as described in Section 3.2.1.

There are many similarities between the LARKS approach and the methodology
presented in this paper. Both are based on matching inputs, outputs, pre- and
postconditions based on the idea of function subtyping. Also, the use of different
ﬁlters is similar to the two steps of our approach. The LARKS approach also
includes keyword-based ﬁltering, but it considers fewer types of match. Also, while a
shared ontology is assumed for matching LARKS speciﬁcations, these ontologies do
not contain operations.
In [22], a tool

is presented, which implements the LARKS matchmaking
approach for web service discovery and is partly based on the approach described
in [45]. The Semantic Services Matchmaker (SSM) uses an extension to WSDL called
Web Service Semantic Proﬁle (WSSP), which has been inspired by the OWL-S
proﬁle, to describe the services semantically, and an (extended) UDDI registry [2] for
storing service advertisements. During the matchmaking, all ﬁlters developed in [55]
can be used. The SSM also provides a user interface, which features the automatic
generation of service description templates from the service’s WSDL document.
The service provider only has to select a matching ontology concept for each
input and output parameter. While this feature facilitates the annotation of web
services, it can create problems if the inputs or outputs of syntactic signature do
not match those of the semantic signature (as in our running example) [31]. Also,
while not stressed explicitly by the authors, the presented discovery tools can only
work if a common ontology is used as a shared vocabulary by providers and
requesters.

6.3. Service Discovery in WSMO

The Web Service Modeling Ontology (WSMO) and the associated Web Service
Modeling Language (WSML) are being developed as part of the SDK Cluster,
which aligns the research and development efforts in the areas of Semantic Web
Services between EU-funded research projects.13

The WSMO approach to service discovery14 consists of four steps [26]:

1. During goal discovery, a requester locates a pre-deﬁned goal that ﬁts her
requirements (expressed using natural language or any other means) from the
set of pre-deﬁned goals.

2. During goal reﬁnement the selected goal

is reﬁned to reﬂect additional

requirements of the requester.

13 see www.wsmo.org
14 This approach is also applied in the latest implementation of the Open University’s Internet
Reasoning Service (IRS) project, IRS-III (see kmi.open.ac.uk/projects/irs).

Springer

Geoinformatica (2007) 11:1–36

29

3.

In the service discovery step, services are discovered that can, according to their
abstract capability, potentially fulﬁl the requester goal. As abstract capabilities
do not consider the input provided by the requester nor the dynamics of the
available set of services for this input at a speciﬁc point in time, they are not
guaranteed to be correct, i.e., there might be executions of the service (concrete
services in WSMO terminology) that are models of the description but cannot
be provided. Therefore, service discovery in this step cannot ensure that the
discovered services will actually fulﬁl the requester goal.

4. During service contracting the remaining services’ contracting capability is used
to determine if the services can actually fulﬁl the requester goal. The con-
tracting capability includes the conditions that have to be fulﬁlled for a suc-
cessful service provision, as well as the relation of the required input to the
results of the service.

The proposed model does not impose any restrictions on how to implement it for
speciﬁc applications, but proposes some useful formalisms for providing such
implementation.

The methodology proposed in this paper has some similarities with the WSMO
approach, but there are also a number of differences. The notion of operation
ontologies is very similar to the notion of pre-deﬁned goals in WSMO. However,
our methodology also requires the provider to use these operations for specifying his
service descriptions in order to ensure comparability between service descriptions
and requests. The two-step process to increase efﬁciency and precision is another
similarity. However, the two steps differ slightly because the services considered in
each approach have different characteristics:

& As geoprocessing services (typically) have no effects on the real world, only

postconditions have to be considered.

& For geoprocessing services, there is no external inﬂuence on the results (e.g., the
availability of rooms at a certain time for a hotel booking service) as assumed in
WSMO. This means that every service execution can be described by the
service’s pre- and postconditions, i.e., its semantic description is correct.

& The WSMO approach is focused on goals with concrete instances (Bﬂights
between Madrid and Innsbruck’’) and on the delivered results. In contrast, we
assume that a service requester is interested in a particular functionality (kind of
computation) between types of objects (Bdistance between two points’’).

Due to these differences, we do not consider a contracting phase nor require
different intentions for output types as suggested in the WSMO approach. Rather,
we put a stronger focus on the substitutability of functionality in both discovery
steps. Also, we can take input values into account already in the ﬁrst step, which
should lead to increased precision over the WSMO approach.

6.4. Service Discovery in METEOR-S

The METEOR-S15 project aims at automating the publication, discovery, descrip-
tion and control ﬂow of web services by integrating existing web service standards
such as WSDL with Semantic Web technologies.

15 see lsdis.cs.uga.edu/Projects/METEOR-S

Springer

30

Geoinformatica (2007) 11:1–36

METEOR-S adds semantics (using ontologies) at two levels [58]: at the level of
individual web services and at the level of the registries that store the services. For
the annotation of individual web services, a bottom-up approach is followed i.e.,
WSDL message types, both inputs and outputs, are mapped to the appropriate
concepts in domain speciﬁc ontologies. In addition to the annotation of WSDL
inputs and outputs, WSDL operations are also mapped to ontological concepts from
an operations domain ontology and preconditions and effects are speciﬁed [54]. The
user goals are expressed using service templates based on the concepts from the
domain ontologies. In such templates, information about the requested operation
and its inputs and outputs, and (optionally) preconditions and effects can be
speciﬁed. The matching process uses subsumption reasoning to match operations,
inputs, outputs, preconditions and effects of the annotated services against the ones
of the template describing the request.

The aim of annotating registries is to enable the classiﬁcation of web services
based on their domain. Registries are specialized in a given domain, and store web
services related to that domain. A specialized ontology, the registries ontology, is
used for annotating registries, mapping the registries to a given domain and giving
information about the registry, relations with other registries and
additional
relations to other domains.

The annotation of registries and its specialization in domains helps to deal with a
potentially huge number of published services. However, the METEOR-S approach
to service description and discovery presents some limitations. Similarly to previous
releases of OWL-S, the METEOR-S annotation does not relate inputs, outputs,
preconditions and effects, and therefore provides an inaccurate description of the
service functionality. Furthermore, as the service descriptions are WSDL-centred,
METEOR-S can have the same problems as the SSM if the inputs or outputs of
syntactic signature do not match those of the semantic signature.

6.5. State-Oriented Service Discovery in the DIANE Project

The development of the service description and discovery procedure in the DIANE
project [24], [25] is motivated by the fact that services with identical messages ﬂows
(i.e., inputs and outputs) may offer completely different functionality, and that
services with identical functionality may use different message ﬂows to achieve this
functionality. Therefore, the proposed approach does not rely on an explicit
signature matching step (i.e., on matching inputs and outputs), but derives the
necessary messages from the comparison of state before and after the execution of
the service (which is represented as pre- and postconditions).

The DIANE service description (DSD) can be represented in three different
notations: the formally deﬁned notation f-dsd, which offers the full expressiveness of
the language and is mainly used for representation; the graphical notation (g-dsd)
which is used to facilitate user interaction; and a Java representation, which enables
to use program logic, e.g., for implementing domain speciﬁc similarity measures.

One important feature of this approach is the distinction between service and
request descriptions. Requests can be be fuzzy declarative sets of services, in which
the requester can also specify preferences. Thus, the matchmaking is no longer
based on generic heuristics (as the types of match presented in this paper) but only
checks whether a given service description is a member of the (fuzzy) query set of
the requester.

Springer

Geoinformatica (2007) 11:1–36

31

This approach uses many interesting ideas that could be used to extend the
approach presented in this work, most notably fuzzy sets for vague matching, an
easy-to-use graphical notation for interacting with users and domain-speciﬁc
similarity measures. We believe that especially the last feature could yield very
interesting results for the geospatial domain.

6.6. Process-Oriented Service Discovery

The goal of the service discovery approach presented in [5], [21] is to capture
enough service and query semantics to substantively increase precision (of keyword-
based approaches) without reducing recall or making it unrealistically difﬁcult for
people to express these semantics. The proposed approach is based on describing
services as process models, for which tasks, subtasks, mechanisms (i.e., resources
used by a process), inputs, outputs and exceptions are used as primitives. These
models (as well as their components) are Bincluded in the appropriate place’’ in a
process ontology based on the MIT Process Handbook [33]. This so-called indexing
step is based on the assumption that service providers choose a process description
from the Process Handbook, specialize this description and then manually index it
(with tool support). For details on the indexing steps and possibilities for automating
it, see [21]. Matching services are discovered using the Process Query Language
(PQL), in which constraints on types and values of and relations between processes
(and their components) can be expressed.

The approach resembles our proposed methodology in that the authors propose
to use a common operation (or process) ontology from which speciﬁc descriptions
are derived. However, their model for describing services is based on processes and
their approach for indexing process descriptions in the existing ontology is less strict
than the types of match proposed in this paper. We therefore believe that their
approach is suited for describing complex (and more abstract) services (e.g., in e-
commerce) rather than atomic geoprocessing services with subtle differences as in
our running example. It might be possible to combine both approaches to describe
more complex geoprocessing services composed of several simple ones.

The authors also criticize logic-based approaches (deductive retrieval in their
terminology) such as the methodology proposed in this paper because of (1) the
computational complexity of the proof process which can make it extremely slow,
and (2) the difﬁculty to model the semantics of non-trivial queries and services using
formal logic. The ﬁrst problem is alleviated in our approach by introducing an
effective ﬁltering step before engaging in the computationally expensive theorem
proving. In order to alleviate the second problem, we plan to devise a user interface
and/or query language that enables the requesters and providers to easily express
their requirements. This will be part of our future work.

7. Conclusions and Future Work

In this paper we have presented a methodology for ontology-based discovery of
geoprocessing services based on ontologies of geospatial operations and function
subtyping. Operations from domain ontologies are used as templates for formulating
descriptions of requirements and capabilities. This constrains the descriptions created
by service providers and requesters and ensures greater recall during service

Springer

32

Geoinformatica (2007) 11:1–36

discovery. Also, as the results achieved for the presented example indicate, the
proposed methodology enables more highly expressive service descriptions and
allows ﬁner distinctions between similar services and thus will also lead to higher
precision than keyword-based approaches to service discovery. At the same time, the
procedure is kept efﬁcient by performing service discovery in two steps–ﬁrst ﬁltering
out potential services based on their semantic signatures and only then using FOL
theorem proving for discovering the actually matching services.

Lessons Learned from the Running Example. The presented running example has
illustrated how proposed methodology improves the discovery of geoprocessing
services over existing keyword-based methods. However, it has also shown that,
even when using operation ontologies, some services might be missed because their
inputs or outputs do not ﬁt those of adjacent services that have already been
discovered. In the running example, this is the case for Service 4 which provides the
functionality required by Susan in Scenario 2b, but whose input does not match the
output provided by the GetLocation service. In such cases, the methodology should
allow greater ﬂexibility. For example,
if Susan is aware that the outputs of
GetLocation might be problematic but conﬁdent that she could solve these potential
problems (e.g., by using a coordinate transformation service) she should be able to
relax the constraints imposed by the GetLocation service’s properties. Another
solution would be to automatically search for services that could bridge the gap
between the GetLocation and the requested distance service. One possibility for
such a solution would be to use architecture patterns as proposed in [44].

The example has also shown that not all types of match introduced in [64] can be
used for our chosen conceptualization. This will also be the case for other
conceptualizations that introduce variables for stating pre- and/or postconditions
that do not refer to input or output parameters of the service. Nevertheless, the
types of match applied to the chosen examples (generalized predicate match and
plug-in post match) led to the results that are intuitively expected.

Finally, the DL and FOL domain ontologies introduced for the example could
represent a starting point for a generic domain ontology for geoprocessing operations
as many of these operations (e.g., buffer) inherently depend on a deﬁnition of
distance. Due to the problems mentioned above, however, alternative conceptual-
izations that do not require the introduction of variables, should also be considered.

Future Research. There are a number of issues that will be addressed in future
research. First, the procedure, which has so far only been tested with the simple
distance example, should also be tested with other examples. It has to be
investigated whether it also works (well) with more complex examples or how it
has to be adapted in order to do so. Such tests will also show whether (and how
easily) the used conceptualization is extendible.

In order to be usable in the context of SDIs, the methodology should be
implemented within an existing SDI architecture. This means primarily that it has to
be integrated with existing catalogues of GI services. In the course of this work, the
methodology should be combined with our approach for ontology-based discovery
and retrieval of geographic data [30]. Service requesters and providers should be
(graphically) supported in specifying their queries and advertisements to spare them
the laborious and difﬁcult task of specifying FOL and DL axioms. As some of these
axioms (e.g., on the types of inputs and outputs) have so far been stated in both the

Springer

Geoinformatica (2007) 11:1–36

33

DL and the FOL speciﬁcation, it should also be investigated how the two levels of
speciﬁcations can be more efﬁciently combined. Finally, the approach should be
aligned with OGC’s emerging Web Processing Service speciﬁcation [43] once this
has been stabilized and reached some maturity.

Two important assumptions for the presented methodology to work are that (1)
geospatial domain ontologies (including operations) exist and (2) service providers
have semantically annotated their services. To meet these assumptions, further
research is required on how to (semi-) automatically derive domain ontologies
(including operations) from existing sources such as the UML class diagrams in ISO
standards and OGC speciﬁcations. Furthermore, it should be investigated how
semantic descriptions can be derived (semi-)automatically from program code and/
or how providers and requesters can best be supported in creating semantic
advertisements and queries.

Finally, one major restriction of the presented methodology should be addressed.
In its current form it deals with operations and queries at very ﬁne level of
granularity. While the ﬁne-grained differences between operations can be of interest
for an expert user, they might not play a major role in everyday applications.
Therefore, the approach should be extended to examples at higher levels of
granularity, i.e., starting from abstract goals (e.g., BWhich countries are at threat by
some other country’s missiles?’’). For such questions, primitives might be
elementary operations (like distance) themselves, and service discovery might
consist of combining these operations. Thus, a formalism for describing composi-
tions of operations and their joint behaviour as well as a methodology for
(automatically) deriving possible compositions will be required.

I would like to thank Werner Kuhn, Sven Schade, Eva Klien, Udo Einspanier,
Acknowledgments
Herbert Kuchen, Jo¨ rn Witte and Sebastian Hu¨ bner for their input at various stages of the work
presented in this paper. The work presented in this paper has been supported by the German
Ministry of Education and Research (BMBF) as part of the GEOTECHNOLOGIEN programme
(grant number 03F0369A). It can be referenced as publication no. GEOTECH-193.

References

1. G. Antoniou and F. Van Harmelen.BWeb ontology language: Owl,’’ in S. Staab and R. Studer

(Eds.), Handbook on Ontologies, Springer, pp. 67–92, 2003.

2. T. Bellwood, L. Cle´ ment, D. Ehnebuske, A. Hately, M. Hondo, Y.L. Husband, K. Januszewski,
S. Lee, B. McKee, J. Munter, and C. von Riegen. Uddi version 3.0. published speciﬁcation, 19
July 2002.

3. L. Bernard, U. Einspanier, M. Lutz, and C. Portele. BInteroperability in gi service chains—The
way forward,’’ in M. Gould, R. Laurini, and S. Coulondre (Eds.), 6th AGILE Conference on
Geographic Information Science, Lyon, France, 2003.

4. L. Bernard. BExperiences from an implementation testbed to set up a national sdi,’’ in M. Ruiz,
M. Gould, and J. Ramon (Eds.), 5th AGILE Conference on Geographic Information Science
2002, Palma de Mallorca, pp. 315–321, 2002.

5. A. Bernstein and M. Klein. BTowards high-precision service retrieval,’’ in I. Horrocks and J.
Hendler (Eds.), The Semantic Web–First International Semantic Web Conference (ISWC 2002),
Springer: Sardinia, Italy, pp. 84–101, 2002.

6. S. Bowers and B. Luda¨ scher. BAn ontology-driven framework for data transformation in
in International Workshop on Data Integration in the Life Sciences

scientiﬁc workﬂows,’’
(DILS’04), Springer: Leipzig, Germany, 2004.

Springer

34

Geoinformatica (2007) 11:1–36

7. F. Baader and W. Nutt. BBasic description logics,’’ in F. Baader, D. Calvanese, D. Mcguinnes, D.
Nardi, and P. Patel-Schneider (Eds.), The Description Logic Handbook. Theory, Implementation
and Applications, Cambridge University Press: Cambridge, pp 43–95, 2003.

8. L. Cabral, J. Domingue, E. Motta, T.R. Payne, and F. Hakimpour. BApproaches to semantic
in 1st European Semantic Web Symposium

web services: an overview and comparisons,’’
(ESWS2004), Heraklion: Crete, Greece, 2004.

9. T.H. Cormen, C.E. Leiserson, and R.L. Rivest. BIntroduction to algorithms.’’ MIT Press, 1990.
in The 10th ACM International
10. M. Egenhofer. BTowards the semantic geospatial web,’’
Symposium on Advances in Geographic Information Systems (ACM-GIS), Institute for
Geoinformatics, Mu¨ nster, Germany, 2002.

11. U. Einspanier, M. Lutz, K. Senkler, I. Simonis, and A. Sliwinski. BToward a process model for gi
in GI-Tage (GI Days) 2003, Institute for Geoinformatics: Mu¨ nster,

service composition,’’
Germany, 2003.

12. R. Groot and J. McLaughin (Eds.). Geospatial Data Infrastructure—Concepts, Cases, and Good

Practice, Oxford University Press: Oxford, 2000.

13. H. Gallaire, J. Minker, and J.-M. Nicolas. BLogic and databases: A deductive approach.’’ ACM

Computing Surveys, Vol. 16(2):153–185, 1984.

14. T. Gruber. BToward principles for the design of ontologies used for knowledge sharing,’’

International Journal of Human-Computer Studies, Vol. 43(5/6):907–928, 1995.

15. V. Haarslev and R. Mo¨ ller. BRacer: A core inference engine for the semantic web,’’ in 2nd
International Workshop on Evaluation of Ontology-based Tools (EON2003), located at the
2nd International Semantic Web Conference ISWC 2003, Sanibel Island, FL, USA, pp. 27–36,
2003.

16. C.A.R. Hoare. BAn axiomatic basis for computer programming,’’ Communications of the ACM,

Vol. 12(10):576–583, 1969.

17. ISO/TC-211. BText for dis 19107 geogaphic information–spatial schema,’’ Technical Report,

International Organization for Standardization, 2002.

18. ISO/TC-211. BText for fdis 19111 geogaphic information–spatial referencing by coordinates,’’
Final draft version, Technical Report, International Organization for Standardization, 2002.
19. ISO/TC-211. BText for fdis 19115 geogaphic information-metadata,’’ Final draft version,

Technical Report, International Organization for Standardization, 2003.

20. ISO/TC-211. BGeographic information-services (iso 19119:2005),’’ Technical Report, Interna-

tional Organization for Standardization, 2005.

21. M. Klein and A. Bernstein. BSearching for the services on the semantic web using process
in I.F. Cruz, S. Decker, J. Euzanat, and D. Mcguinness (Eds.), The ﬁrst
ontologies.’’
Semantic Web Working Symposium (SWWS), Stanford University, California, USA, pp. 431–
446, 2001.

22. T. Kawamura, J.-A. De Blasio, T. Hasegawa, M. Paolucci, and K. Sycara. BPreliminary report of
in M.E.
public experiment of semantic service matchmaker with uddi business registry,’’
Orlowska, S. Weerawarana, M. Papazoglou, and J. Yang (Eds.), First International Conference
on Service-Oriented Computing (ICSOC 2003), Springer Verlag (LNCS 2910): Trento, Italy,
2003.

23. M. Klein and B. Ko¨ nig-Ries. BA process and a tool for creating service descriptions based on
daml-s,’’ in 4th VLDB Workshop on Technologies for E-Services (TES’03), Springer: Berlin,
2003.

24. M. Klein and B. Ko¨ nig-Ries. BCombining query and preference–an approach to fully
in IEEE International Conference on Web Services

automatize dynamic service binding,’’
(ICWS’04), San Diego, California, USA, IEEE Computer Society, pp. 788–791, 2004.

25. M. Klein and B. Ko¨ nig-Ries. BCoupled signature and speciﬁcation matching for automatic
service binding,’’ in L.-J. Zhang (Ed.), European Conference on Web Services (ECOWS’04),
Erfurt, Germany, Springer, pp. 183 –197, 2004.

26. U. Keller, R. Lara, H. Lausen, A. Polleres, and D. Fensel. BAutomatic location of services,’’ in

2nd European Semantic Web Conference 2005, Heraklion: Greece, 2005.

27. M. Lutz, U. Einspanier, E. Klien, and S. Hu¨ bner. BAn architecture for ontology-based discovery
and retrieval of geographic information,’’ in P. Dadam, and M. Reichert (Eds.), Informatik
2004—Informatik verbindet, Beitrage der 34. Jahrestagung der Gesellschaft fur Informatik e.V.
(GI), Band 2, Gesellschaft fu¨ r Informatik: Ulm, Germany, pp. 574–578, 2004.

28. L. Li and I. Horrocks. BA software framework for matchmaking based on semantic web
technology,’’ in The Twelfth International World Wide Web Conference, Budapest, Hungary,
ACM Press, New York, NY, USA, pp. 331–339, 2003.

Springer

Geoinformatica (2007) 11:1–36

35

29. B. Liskov. BData abstraction and heirarchy,’’ ACM Sigplan Notices, Vol. 23(5):17–34, 1987.
30. M. Lutz and E. Klien. BOntology-based retrieval of geographic information,’’ International

Journal of Geographic Information Science, Vol. 20(3):233–260, 2006.

31. M. Lutz. BNon-taxonomic relations in semantic service discovery and composition,’’ in 1st
BOntology in Action’’ Workshop, in conjunction with 16th Conference on Software Engineering
and Knowledge Engineering (SEKE 2004), Banff, Canada, pp. 482–485, 2004.

32. M. Lutz. BOntology-based service discovery in spatial data infrastructures,’’ in Workshop on
Geographic Information Retrieval (GIR 2005), Bremen, Germany. ACM Press: New York,
2005.

33. T.W. Malone, K. Crowstone, and G.A. Herman. BOrganizing business knowledge: The MIT

process handbook,’’ MIT Press: Cambridge, MA, USA, 2003.

34. L. Mckee. BWho wants a gdi?’’

in R. Groot and J. McLaughlin (Eds.), Geospatial data
infrastructure–Concepts, cases, and good practice, Oxford University Press, New York, pp. 13 –
24, 2000.

35. D. Martin, M. Paolucci, S. McIlraith, M. Burstein, D. McDermott, D. McGuinness, B. Parsia, T.
Payne, M. Sabou, M. Solanki, N. Srinivasan, and K. Sycara. BBringing semantics to web services:
The owls approach,’’ in First International Workshop on Semantic Web Services and Web Process
Composition (SWSWPC 2004), San Diego, CA, USA, 2004.

36. J. Munkres. Topology. 2nd edition, Prentice Hall: Englewood Cliffs, NJ, USA, 2000.
37. D. Nebert. BDeveloping spatial data infrastructures: The SDI cookbook, Version 1.1.,’’ Global

Spatial Data Infrastructure, Technical Comittee, 2001.

38. OGC. BWeb feature service implementation speciﬁcation,’’ version 1.0.0 (opengis implementa-

tion speciﬁcation), Technical Report OGC 02-058, Open GIS Consortium, 2002.

39. OGC. BWeb map server interface implementation speciﬁcation,’’ version 1.1.1 opengis project,

2002.

40. OGC. BOws1.2 uddi experiment,’’ Technical Report OGC 03-028, OpenGIS Consortium, 2003.
41. OGC. BWeb coverage service (wcs)’’, version 1.0.0 (ogc implementation speciﬁcation), Technical

Report OGC 03-065r6, Open Geospatial Consortium, 2003.

42. OGC. BCatalogue services speciﬁcation,’’ version 2.0 (ogc implementation speciﬁcation),

Technical Report OGC 04-021r2, Open GIS Consortium, 2004.

43. OGC. BWeb processing service (wps) speciﬁcation,’’ version 0.2.1 (ogc discussion paper),

Technical Report OGC 05-007, Open Geospatial Consortium, 2005.

44. J. Penix and P. Alexander. BToward automated component adaptation,’’ in 9th International

Conference on Software Engineering and Knowledge Engineering, 1997.

45. M. Paolucci, T. Kawamura, T.R. Payne, and K. Sycara. BSemantic matching of web service
capabilities,’’ in I. Horrocks and J. Hendler (Eds.), 1st International Semantic Web Conference
(ISWC2002), Lecture Notes in Computer Science 2342, Sardinia, Italy, Springer, pp. 333–347,
2002.

46. J. Riecken, L. Bernard, C. Portele, and A. Remke. BNorth-rhine westphalia: Building a regional
sdi in a cross-border environment/ad-hoc integration of sdis: Lessons learnt,’’ in 9th EC-GI and
GIS Workshop—ESDI: Serving the User, A Corun˜ a: Spain, 2003.

47. D. Roman, H. Lausen, U. Keller, J. de Bruijn, C. Bussler, J. Domingue, D. Fensel, M. Kifer, J.
Kopecky, R. Lara, E. Oren, A. Polleres, and M. Stollberg. BWeb service modeling ontology
(wsmo),’’ version 1.1, 2005.

48. S. Russel and P. Norvig. Artiﬁcial Intelligence: A Modern Approach. 2nd edition, Prentice-Hall:

Englewood Cliffs, NJ, USA, 2003.

49. R. Richardson and A.F. Smeaton. BUsing wordnet in a knowledge-based approach to
information retrieval (technical report ca-0395),’’ Technical Report, Dublin City University,
1995.

50. R. Studer, V.R. Benjamins, and D. Fensel. BKnowledge engineering: Principles and methods,’’

Data and Knowledge Engineering, Vol. 25(1-2):161–197, 1998.

51. U. Sattler, D. Calvanese, and R. Molitor. BRelationships with other formalisms,’’ in F. Baader,
D. Calvanese, D. Nardi, and P. Patel-Schneider (Eds.), The Description Logic Handbook. Theory,
Implementation and Applications, Cambridge University Press, Cambridge, pp. 142–183, 2003.
52. A.J.H. Simons. BThe theory of classiﬁcation. part2: The scratch-built typechecker,’’ Journal of

53. A.J.H. Simons. BThe theory of classiﬁcation. part4: Object types and subtyping,’’ Journal of

Object Technology, Vol. 1(2):47–52, 2002.

Object Technology, Vol. 1(5):27–35, 2002.

54. K. Sivashanmugam, K. Verma, A. Sheth, and J. Miller. BAdding semantics to web services
standards,’’ in D. Fensel, K. Sycara, and J. Mylopoulos (Eds.), The SemanticWeb—ISWC 2003.

Springer

36

Geoinformatica (2007) 11:1–36

2nd International Semantic Web Conference (LNCS 2870), Sundial Resort, Sanibel Island,
Florida, USA, Heidelberg, Springer-Verlag, pp. 395–401, 2003.

55. K. Sycara, S. Widoff, M. Klusch, and J. Lu. BLarks: Dynamic matchmaking among
in First International Joint Conference on

heterogeneous software agents in cyberspace,’’
Autonomous Agents and Multi-Agent Systems, Bologna, Italy, Kluwer, pp. 173–203, 2002.
56. D. Trastour, C. Bartolini, and J. Gonzalez-Castillo. BA semantic web approach to service
description for matchmaking of services,’’
in I.F. Cruz, S. Decker, J. Euzenat, and D.
McGuinness (Eds.), The ﬁrst Semantic Web Working Symposium, Stanford University,
California, USA, pp. 447– 461, 2001.

57. Uschold M. (1998) BKnowledge level modelling: Concepts and terminology.’’ The Knowledge

Engineering Review, Vol. 13(1):5 –29, 1998.

58. K. Verma, K. Sivashanmugam, A. Sheth, and A. Patil. BMeteor-s wsdi: A scalable p2p
infrastructure of registries for semantic publication and discovery of web services,’’ Journal of
Information Technology and Management, 2004.

59. W3C. BW3c: Web services description language (wsdl) 1.1,’’ Technical Report, W3C, in http://

60. M. Worboys and M. Duckham. BGIS–A computing perspective,’’ CRC Press: Boca Raton, FL,

www.w3.org/TR/wsdl, March 2001.

USA, 2004.

61. C. Weidenbach. BCombining superposition, sorts and splitting,’’ in Handbook of Automated

Reasoning, Elsevier and MIT Press, pp. 1965-2013, 2001.

62. H. Wache, T. Vo¨ gele, U. Visser, H. Stuckenschmidt, G. Schuster, H. Neumann, and S. Hu¨ bner.
BOntology-based integration of information–a survey of existing approaches,’’ in IJCAI-01
Workshop: Ontologies and Information Sharing, CA, Seattle, WA. Morgan Kaufmann Publish-
ers: San Francisco, CA, pp. 108–117, 2001.

63. A.M. Zaremski and J.M. Wing. BSignature matching: A tool for using software libraries,’’ ACM

Transactions on Software Engineering and Methodology, Vol. 4(2):146–170, 1995.

64. A.M. Zaremski and J.M. Wing. BSpeciﬁcation matching of software components,’’ ACM

Transactions on Software Engineering and Methodology, Vol. 6(4):333 –369, 1997.

Michael Lutz
holds a M.Sc. degree in Landscape Ecology and a Ph.D. in Geoinformatics from the
University of Mu¨ nster, Germany. His research interest is in the area of semantic modelling of geo-
spatial operations and processes for supporting the discovery and access of geographic infor-
mation and geoprocessing services in Spatial Data Infrastructures (SDIs). He is currently working
as a research fellow in the Spatial Data Infrastructures Unit of the European Commission’s Joint
Research Centre in Ispra, Italy.

Springer

