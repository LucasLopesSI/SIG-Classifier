This article was downloaded by: [Anadolu University]
On: 21 December 2014, At: 10:28
Publisher: Taylor & Francis
Informa Ltd Registered in England and Wales Registered Number:
1072954 Registered office: Mortimer House, 37-41 Mortimer Street,
London W1T 3JH, UK

International Journal of
Geographical Information
Science
Publication details, including instructions for
authors and subscription information:
http://www.tandfonline.com/loi/tgis20

Search algorithms for
multiway spatial joins
Dimitris Papadias & Dinos Arkoumanis
Published online: 10 Nov 2010.

To cite this article: Dimitris Papadias & Dinos Arkoumanis (2002) Search
algorithms for multiway spatial joins, International Journal of Geographical
Information Science, 16:7, 613-639, DOI: 10.1080/13658810210138733

To link to this article:  http://dx.doi.org/10.1080/13658810210138733

PLEASE SCROLL DOWN FOR ARTICLE

Taylor & Francis makes every effort to ensure the accuracy of all
the information (the “Content”) contained in the publications on our
platform. However, Taylor & Francis, our agents, and our licensors
make no representations or warranties whatsoever as to the accuracy,
completeness, or suitability for any purpose of the Content. Any
opinions and views expressed in this publication are the opinions and
views of the authors, and are not the views of or endorsed by Taylor
& Francis. The accuracy of the Content should not be relied upon and
should be independently verified with primary sources of information.
Taylor and Francis shall not be liable for any losses, actions, claims,
proceedings, demands, costs, expenses, damages, and other liabilities
whatsoever or howsoever caused arising directly or indirectly in
connection with, in relation to or arising out of the use of the Content.

This article may be used for research, teaching, and private study
purposes. Any substantial or systematic reproduction, redistribution,
reselling, loan, sub-licensing, systematic supply, or distribution in any
form to anyone is expressly forbidden. Terms & Conditions of access
and use can be found at http://www.tandfonline.com/page/terms-and-
conditions

Downloaded by [Anadolu University] at 10:28 21 December 2014 int. j. geographical information science, 2002
vol. 16, no. 7, 613–639

Research Article

Search algorithms for multiway spatial joins

DIMITRIS PAPADIAS
Department of Computer Science, Hong Kong University of Science and
Technology, Clear Water Bay, Hong Kong; e-mail: dimitris@cs.ust.hk

and DINOS ARKOUMANIS
Department of Electrical and Computer Engineering, National Technical
University of Athens, Greece, 15773; e-mail: dinosar@dbnet.ece.ntua.gr

(Received 20 August 2001; accepted 4 October 2001)

Abstract. This paper deals with multiway spatial joins when (i) there is limited
time for query processing and the goal is to retrieve the best possible solutions
within this limit (ii) there is unlimited time and the goal is to retrieve a single
exact solution, if such a solution exists, or the best approximate one otherwise.
The (cid:142) rst case is motivated by the high cost of join processing in real-time systems
involving large amounts of multimedia data, while the second one is motivated
by applications that require ‘negative’ examples. We propose several search algo-
rithms for query processing under theses conditions. For the limited-time case we
develop some non-deterministic search heuristics that can quickly retrieve good
solutions. However, these heuristics are not guaranteed to (cid:142) nd the best solutions,
even without a time limit. Therefore, for the unlimited-time case we describe
systematic search algorithms tailored speci(cid:142) cally for the eYcient retrieval of a
single solution. Both types of algorithms are integrated with R-trees in order to
prune the search space. Our proposal is evaluated with extensive experimental
comparison.

1.

Introduction
A multiway spatial join can be expressed as follows: Given n datasets D1 , D2 , ... Dn
and a query Q, where Qij is the spatial predicate that should hold between Di and
Dj, retrieve all n-tuples {(r1,w, ..., ri,x , ..., rj,y , ..., rn,z)|Y i, j : ri,x Î Di, rj,y Î Dj and ri,x
Qij rj,y }. Such a query can be represented by a graph where nodes correspond to
datasets and edges to join predicates. Equivalently, the graph can be viewed as a
constraint network (Dechter and Meiri 1994) where the nodes are problem variables,
and edges are binary spatial constraints. In the sequel we use the terms variable/
dataset and constraint/join condition interchangeably. Following the standard ter-
minology in the spatial database literature we assume that the standard join condition
is overlap (intersect, non-disjoint). In this case the graph is undirected (Qij=Qji) and,
if Qij=True, then the rectangles from the corresponding inputs i, j should overlap.

Internationa l Journal of Geographical Information Science
ISSN 1365-8816 print/ISSN 1362-308 7 online © 2002 Taylor & Francis Ltd
http://www.tandf.co.uk/journals
DOI: 10.1080/13658810210138733

Downloaded by [Anadolu University] at 10:28 21 December 2014 614

D. Papadias and D. Arkoumanis

Figures 1(a) and 1(b) illustrate two example queries: the (cid:142) rst one has an acyclic (tree)
graph, and the second one has a complete (clique) graph.

We use the notation vi Î ri,x to express that variable vi is instantiated to rectangle
ri,x (which belongs to domain Di). A binary instantiation {vi Î ri,x , vj Î rj,y } is
inconsistent if there is a join condition Qij, but ri,x and rj,y do not overlap. A solution
is a set of n instantiations {v1 Î r1,w , ..., vi Î ri,x , ..., vj Î rj,y, ..., vn Î rn,z } which, for
simplicity, can be described as a tuple of values (r1,w, ..., ri,x , ..., rj,y, ..., rn,z ) since the
order of variables is implied. The inconsistency degree of a solution is equal to the
total number of inconsistent binary instantiations, i.e. the number of join conditions
violated. A solution with zero inconsistency degree is exact; otherwise it is approxi-
mate. Figures 1(a) and 1(b) illustrate an exact solution for each type of query.
Figure 1(c) shows two approximate solutions for the clique. The left one violates
only one condition (Q23 ), while the right one violates two (Q13 and Q23 ). The lower
the inconsistency degree, the higher the similarity of the solution.

The goals of multiway spatial join processing are determined by the three para-
meters illustrated in (cid:142) gure 2. The x-axis refers to the type of solutions to be retrieved,
the y-axis to the number of solutions and the z-axis speci(cid:142) es the time available for

1

4

2

3

r

1,1

r

2,1

3,1r
4,1r

1

4

2

3

r

1,1

r

2,1

4,1r

r

3,1

r

2,1

4,1r

r

1,1

r

3,1

r

2,1

4,1r

r

1,1

r

3,1

(a) chain (tree) query

(b) clique query

(c) approximate  solutions for clique

Figure 1. Example queries and solutions.

y - number of solutions 

all

subset of solutions

Case 1

Case 2

one solution

x-inconsistency degree

exact
solutions

approximate
solutions

 limited time

Case 3

no time limit

z- time limit 

Figure 2. Goals of multiway spatial join processing.

Downloaded by [Anadolu University] at 10:28 21 December 2014 Search algorithms for multiway spatial joins

615

query processing. The three numbers in the diagram correspond to cases of
particular interest:

1. The goal is the retrieval of all exact solutions with no time limit for query
processing. Existing work on multiway spatial joins (discussed in the next
section) deals mostly with this case. Depending on the query and data proper-
ties, however, exhaustive processing of multiway spatial joins can be prohibit-
ively expensive. Furthermore, if any exact solutions do not exist, the result
will be empty. In architectural applications, for instance, queries often involve
numerous variables and the database may not contain con(cid:142) gurations that
match all the query constraints. The best approximate solutions are then
desirable.

2. The shortcomings of the (cid:142) rst case motivate the second one. The goal is the
retrieval of the best possible (exact or approximate ) solutions within a time
threshold. Fast retrieval of sub-optimal solutions is the only way to deal with
the vast (and ever increasing) amounts of multimedia information for several
real time systems. Related work has been carried out in the context of spatial
similarity retrieval where queries can be modeled as multiway self-joins.
3. The goal in the third case, is the retrieval of the best (single) solution with no
time limit. Some applications require the retrieval of negative examples. For
instance, a possible VLSI design can be invalidated if it matches an existing
faulty one. In some engineering and industrial CAD applications several object
con(cid:142) gurations are prohibited. If a proposed plan is topologically similar to
an illegal one,
it should be altered or rejected. Retrieval of all similar
con(cid:142) gurations is not needed, since a single match suYces.

This paper deals with multiway spatial join processing involving the last two
cases. For the second case we propose some non-deterministic search heuristics that
can quickly retrieve good solutions. However, these algorithms are not guaranteed
to (cid:142) nd the best solutions, even without a time limit. Therefore, for the third case we
propose systematic search algorithms tailored speci(cid:142) cally for the eYcient retrieval
of a single exact solution (if such a solution exists), or the retrieval of the best
approximate solution. For this case we also present a two-step method, which
combines systematic and heuristic search, and may reduce processing time by orders
of magnitude.

The rest of the paper is structured as follows: §2 overviews related work and §3
proposes search heuristics (case 2) based on the concepts of local search, guided
local search and evolutionary algorithms. §4 discusses systematic search algorithms
and their integration with R-trees for multiway spatial join processing. §5 contains
a comprehensive experimental evaluation using several data sets and query
combinations. §6 concludes the paper with a discussion of future work.

2. Related work

Previous work on pairwise-join processing, can be classi(cid:142) ed in two categories.
The (cid:142) rst one includes algorithms applicable when both relations to be joined are
indexed on the spatial attributes. The most in(cid:143) uential technique in this category is
R-tree-based Join (RJ) (BrinkhoV et al. 1993), which presupposes the existence of
R-trees for both relations. RJ is based on the enclosure property: if two intermediate
R-tree nodes do not intersect, there can be no objects below them that intersect. The
algorithm starts from the roots of the trees to be joined and for each pair of

Downloaded by [Anadolu University] at 10:28 21 December 2014 616

D. Papadias and D. Arkoumanis

overlapping entries inside them, it is recursively called until the leaf levels where
overlapping entries constitute solutions. Huang et al. (1997), extend RJ by introdu-
cing an on-the-(cid:143) y indexing mechanism to optimize, in terms of I/O cost, the execution
order of matching at intermediate levels. Theodoridis et al. (2000) present formulae
for cost estimation in terms of node accesses.

The methods of the second category treat non-indexed inputs (e.g. when there is
another operation, such as selection, before the spatial join). If there is an R-tree for
only one input, processing can be done by (i) indexed nested loop, (ii) building a
second R-tree for the non-indexed input using bulk loading and then applying RJ,
(iii) the sort and match algorithm (Papadopoulos et al. 1999 ), (iv) the seeded tree
algorithm (Lo and Ravishakar 1994) which works like (ii) but builds the second
R-tree using the existing one as a skeleton (seed), (v) the slot index spatial join (SISJ )
(Mamoulis and Papadias 1999) which is an improved version of (iv). If both inputs
are non-indexed, some methods (Patel and DeWitt 1996, Koudas and Sevcik 1997)
partition the space into cells (a grid-like structure) and distribute the data objects in
buckets de(cid:142) ned by the cells. The spatial join is then performed in a relational hash
join fashion. A similar idea is applied by the spatial hash join algorithm (HJ) but,
instead of regular space partitioning, the buckets are determined by the distribution
of objects in the probe input (Lo and Ravishakar 1994). Another method (Arge et al.
1998) (cid:142) rst applies external sorting to both (cid:142) les and then uses an adaptable plane
sweep algorithm, considering that in most cases the ‘horizon’ of the sweep line will
(cid:142) t in main memory.

As in the case of relational joins, multiway spatial joins can be processed by
combining pairwise join algorithms. The pairwise join method (PJM) (Mamoulis and
Papadias 1999) considers a join order that is expected to result in the minimum cost
(in terms of page accesses). Each join order corresponds to exactly one execution
plan where: (i) RJ is applied when the inputs are leaves i.e. datasets indexed by
R-trees, (ii) SISJ is employed when only one input is indexed by an R-tree, and (iii)
HJ when both inputs are intermediate results. As an example of PJM, consider the
query in (cid:142) gure 1(a) and the plans of (cid:142) gure 3. Figure 3(a) involves the execution of
RJ for determining R3 c R4 . The intermediate result, which is not indexed, is joined
with R2 and (cid:142) nally with R1 using SISJ. On the other hand, the plan of (cid:142) gure 3(b)
applies RJ for R1 c R2 and R3c R4 , and HJ to join the intermediate results.
Unfortunately, PJM and any method based on pairwise algorithms, cannot be

SISJ

HJ

R1

SISJ

RJ

RJ

R2

RJ

R1

R2 R3

R4

R3

R4

(a) right-deep plan

(b) bushy plan

Figure 3. Alternative plans using pairwise join algorithms.

Downloaded by [Anadolu University] at 10:28 21 December 2014 Search algorithms for multiway spatial joins

617

extended for approximate retrieval since if no exact solution exists, the results of
some joins should contain non-intersecting pairs of objects. Therefore, PJM cannot
be applied for retrieval of cases 2 and 3.

Two alternative methodologies for multiway spatial joins, motivated by algo-
rithms for constraint satisfaction problems (CSPs), were proposed in (Papadias et al.
2001). Synchronous traversal (ST ) can be thought of as the generalization of RJ to
arbitrary query graphs, i.e., starting from the roots of the R-trees, ST (cid:142) nds combina-
tions of entries that satisfy the query constraints. For each such combination the
algorithm is recursively called, taking the references to the underlying nodes as
parameters, until the leaf level is reached. The calculation of combinations of the
n
qualifying nodes for each level is expensive, as their number can be as high as C
(where C is the node capacity, and n the number of query variables). In order to
avoid an exhaustive search of all combinations, the authors use search algorithms
and optimization techniques. The second methodology, called window reduction (W R)
integrates the ideas of backtracking and index nested loop algorithms. When the
(cid:142) rst variable gets a value v1 Î r1,w, this rectangle (r1,w) is used as a query window
to (cid:142) nd qualifying entries in the second dataset. If such entries are found, the second
variable is instantiated to one of them, i.e., v2 Î r2,w. The algorithm proceeds forward
using the values of instantiated variables as query windows. Assuming for instance,
that all variables v1 to vi - 1 have been instantiated, the consistent values for vi, must
overlap the assignments of all vj, j=1 ... i - 1 such that Qij=True. If no such rectangle
can be found, the algorithm backtracks to the previous variable and tries another
value for it.

ST and W R have been applied for approximate retrieval of multiway spatial
joins involving various spatial predicates (Papadias et al. 1998 ); W R was found
superior because ST induces numerous false hits at the high tree levels when the
query involves relaxed constraints. Nevertheless, methods, like ST or W R, that search
systematically in the solution space are not suitable for retrieval under limited time
(case 2) because they may initially spend a lot of time in regions with low quality
solutions, failing to quickly (cid:142) nd some good ones. Furthermore, the algorithms of
(Papadias et al. 1998) are restrictive for general retrieval in case 3 because they
assume soft constraints (which can be partially violated) and that the user speci(cid:142) es
a target similarity, which should be exceeded by the solutions to be retrieved. If
the target similarity is too high no solutions will be found, while if it is too low
the algorithms will retrieve too many useless solutions (unnecessarily deteriorating
performance). In section 4 we propose alternative techniques, based on the main
concept of W R, which (cid:142) nd the best solution without assuming a target similarity.

Also related to this paper, is previous work on spatial (or con(cid:142) guration) similarity
retrieval. The corresponding queries describe some prototype con(cid:142) guration and the
goal is to retrieve arrangements of objects matching the input exactly or approxi-
mately. Petrakis and Faloutsos (1997) solve such problems by mapping images
(datasets) and queries into high-dimensional points, which are then indexed by
R-trees. Similarity retrieval is processed by nearest neighbour search. The method,
however, assumes medical images with about 10 objects, and cannot be employed
for even the smallest datasets normally found in spatial databases. In general,
techniques based on high-dimensional indexing and nearest neighbour similarity
search are not applicable due to the huge number of dimensions required to represent
the problem.

A number of techniques are based on several variations of 2D strings (Lee and

Downloaded by [Anadolu University] at 10:28 21 December 2014 618

D. Papadias and D. Arkoumanis

Hsu 1992, Lee et al. 1992), which encode the arrangement of objects on each
dimension into sequential structures. Every database image is indexed by a 2D string;
queries are also transformed to 2D strings and similarity retrieval is performed by
applying appropriate string matching algorithms (Chang et al. 1987 ). Although this
methodology can handle larger datasets (experimental evaluations usually include
images with about 100 objects) it is still not adequate for real-life spatial datasets.

Papadias et al. (1999) deal with approximate retrieval of similarity queries under
limited time (i.e. case 2) by using search heuristics based on local search, simulated
annealing and genetic algorithms. Their evaluation suggests that local search, the
most eYcient algorithm, can retrieve good solutions even for large problems (images
with about 105 objects). In the next section we propose heuristics based on similar
principles, for multiway spatial joins. However, unlike (Papadias et al. 1999 ) where
the presented algorithms were a straightforward adaptation of local and evolutionary
search for similarity retrieval, the following methods take advantage of the spatial
structure of the problem and existing indexes to achieve high performance. For the
rest of the paper we consider that all datasets are indexed by R*-trees (Beckmann
et al. 1990) on minimum bounding rectangles (MBRs) and deal with the (cid:142) lter step
of intersection joins. The proposed techniques are easily extensible to other spatial
predicates, such as north, inside, meet etc.

3. Non-systematic search heuristics

Retrieval of the best (exact or approximate) solutions of multiway spatial joins
is essentially an optimization problem. Since such problems are in general exponential
in nature, several search heuristics have been proposed for the eYcient retrieval of
sub-optimal solutions. These heuristics are non-systemati c in the sense that their
search method includes some randomness. Although they are not guaranteed to (cid:142) nd
the best solution, usually they perform well in limited time. Their performance
depends on the application and the special characteristics of the problem. In our
case, the existence of spatial indexes facilitates the processing of much larger problem
sizes than usual. The integration of search heuristics with spatial indexes, however,
is not trivial and requires some careful design in order to take full advantage of the
indexes. In this chapter we propose three such heuristics: indexed local search, guided
indexed local search and a spatial evolutionary algorithm.

3.1. Indexed local search

The search space of multiway spatial joins can be considered as a graph, where
each solution corresponds to a node having some inconsistency degree. If all domains
n nodes. Two nodes/solutions are
have the same cardinality N, the graph has N
connected through an edge if one can be derived from the other by changing the
instantiation of a single variable. Excluding its current assignment, a variable can
take N - 1 values; thus, each solution has n ´(N - 1) neighbours. A node that has
lower inconsistency degree than all its neighbours, is a local maximum. Notice that
a local maximum is not necessarily a global maximum since there may exist solutions
with higher similarity in other regions of the graph.

Local search methods start with a random solution called seed, and then try to
reach a local maximum by performing uphill moves, i.e. by visiting neighbours with
high similarity. When they reach a local maximum (from where uphill moves are
not possible) they restart the same process from a diVerent seed until the time limit
is exhausted. Throughout this process the best solutions are kept. Algorithms based

Downloaded by [Anadolu University] at 10:28 21 December 2014 Search algorithms for multiway spatial joins

619

on this general concept have been successfully employed for a variety of problems.
Indexed local search (IL S) also applies this idea, but uses R*-trees to improve the
solutions. The pseudocode of the algorithm is illustrated in (cid:142) gure 4.

Motivated by con(cid:143) ict minimization algorithms (Minton et al. 1992), we choose
(line 4) to re-instantiate the ‘worst’ variable, i.e. the one whose current instantiation
violates the most join conditions. In case of a tie we select the one that participates
in the smallest number of satis(cid:142) ed constraints. If the worst variable cannot be
improved, the algorithm considers the second worst; if it cannot be improved either,
the third worst, and so on. If one variable can be improved, the next step will
consider again the new worst one; otherwise, if all variables are exhausted with no
improvement, the current solution is considered a local maximum.

Consider, for example the query of (cid:142) gure 5(a) and the approximate solution of
(cid:142) gure 5(b). The inconsistency degree of the solution is 3 since the conditions Q1,4 ,
Q2,3 , and Q3,4 are violated (in (cid:142) gure 5(b) satis(cid:142) ed conditions are denoted with bold
lines and violated ones with thin lines). Variables v3 and v4 participate in two
violations each; v3 , however, participates in one satis(cid:142) ed condition, so v4 is chosen
for re-assignment.

Find best value will (cid:142) nd the best possible value for the variable to be
re-instantiated, i.e. the rectangle that satis(cid:142) es the maximum number of join conditions
given the assignments of the other variables. In the example of (cid:142) gure 5(b), the best
value for v4 should overlap both r1,1 and r3,1 . If such a rectangle does not exist, the
next better choice should intersect either r1,1 , or r3,1 . The pseudo-code for (cid:142) nd best
value is illustrated in (cid:142) gure 6; the variable to be re-instantiated is vi. Essentially this
is like a branch-and-boun d window query, where there exist multiple windows and
the goal is to retrieve the rectangle that intersects most of them. The windows are

WHILE NOT (Time limit) {

S := random seed
WHILE NOT(Local_Maximum) {
determine worst variable vi
value := find best value (Root of tree Ri, vi)
IF better value THEN

Indexed Local Search
1
2
3
4
5
6
7
8
9
10

} /* END WHILE NOT Local_Maximum */

} /* END WHILE NOT Time Limit */

Figure 4.

Indexed local search.

S = S = { vi Î Value }
IF S among the best solutions found so far THEN keep S

2

3

1

4

r

3,1

2,1r

1,1r

4,1r

1,1r

2,1r

3,1r

4,2r

2,2r

1,1r

3,1r

4,2r

(a) example query

(b) initial solution

(c) after re-instantiation of v4

(d) local maximum

Figure 5. Example of ILS.

Downloaded by [Anadolu University] at 10:28 21 December 2014 620

D. Papadias and D. Arkoumanis

FOR EACH Qij such that Qij = True

IF ex intersects wj THEN conditionsx=conditions x+1
x

    
Sort all entries e  (such that conditions >0) with respect to conditions  in list E
x
IF N intermediate node
FOR each ex Î E

maxConditions=0
bestValue=Æ
Find best value (Node N, integer i)//initially N is the root of tree Ri
1. FOR EACH entry ex of N
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.

IF conditionsx > maxConditions THEN Find best value (ex, i)

maxConditions=conditions x
bestValue=ex

           IF conditionsx > maxConditions THEN

FOR each ex Î E

 ELSE //leaf node

x

Figure 6. Find best value.

the assignments of all variables vj such that Qij=True (for the current example there
exist two windows w1=r1,1 and w3=r3,1 ).

The algorithm starts from the root of the corresponding tree and sorts the entries
according to the conditions they satisfy (i.e. how many windows they overlap). The
entries with the maximum number are visited (cid:142) rst because their descendants are
more likely to intersect more windows. At the leaf level, an entry is compared with
the maximum number of conditions found so far (maxConditions). If it is better, then
this is kept as bestV alue, and maxConditions is updated accordingly. Notice that if
an intermediate node satis(cid:142) es the same or a smaller number of conditions than
maxConditions, it cannot contain any better solution and is not visited.

Figure 7 illustrates this process for the example of (cid:142) gures 5(a) and 5(b). Find best
value will retrieve the rectangle that intersects the maximum number of windows, in
this case w1=r1,1 and w3=r3,1 . Suppose that the node (of R-tree R4 ) considered has
three entries e1 , e2 and e3 ; e1 is visited (cid:142) rst because it overlaps both query windows.
However, no good values are found inside it so maxConditions remains zero. The
next entry to be visited is e2 which contains a rectangle (r4,2 ) that intersects w3 .
MaxConditions is updated to 1 and e3 will not be visited since it may not contain
values better than r4,2 (it only satis(cid:142) es one condition). r4,2 becomes the new value
of v4 and the inconsistency degree of the new solution ((cid:142) gure 5(c)) is 2 (Q3,4 is now
satis(cid:142) ed). At the next step ((cid:142) gure 5(d)), a better value (let r2,2 ) is found for v2 using
(cid:142) nd best value (R2 , 2). At this point, the algorithm reaches a local maximum. The

1e

3e

w
1

4,1r

2e

3w
4,2r

Figure 7. Example of (cid:142) nd best value.

Downloaded by [Anadolu University] at 10:28 21 December 2014 Search algorithms for multiway spatial joins

621

violation of Q1,4 cannot be avoided since, according to (cid:142) gure 7, there is no object in
the fourth domain that intersects both r1,1 and r3,1 .

3.2. Guided indexed local search

There have been many attempts to include some deterministic features in local
search and achieve a more systematic exploration of the problem space. ‘Memory’
mechanisms guarantee that the algorithm will not (cid:142) nd the same nodes repeatedly
by keeping a list of visited nodes (Glover and Laguna 1997). These nodes become
forbidden (tabu) in the graph, forcing the algorithms to move to new neighbourhoods .
A limitation of this approach for the current problem is the huge number of nodes,
n solutions a signi(cid:142) cant percentage of which may be visited. Other
since there exist N
approaches (Davenport et al. 1994) try to avoid revisiting the same maxima by
storing their features (e.g. the route length in travelling salesman problem). Solutions
matching these features, are not rejected, but ‘punished’. As a result, the probability
of (cid:142) nding the same maximum multiple times is decreased. The trade-oV is that,
sometimes, unrelated nodes that share features with visited local maxima, are avoided
too and some good solutions may be missed.

Guided indexed local search (GIL S) combines the above ideas by keeping a
memory, not of all solutions visited, but of the variable assignments at local maxima.
When a local maximum (r1,w, ..., ri,x , ..., rj,y, ..., rn,z ) is found, some of the assignments
v1 Î r1,w , ..., vi Î ri,x, ..., vj Î rj,y, ..., vn Î rn,z get a penalty. In particular, GIL S
penalizes the assignments with the minimum penalties so far; e.g. if v1 Î r1,w already
has some punishment from a previous local maximum (while the others do not),
only the rest of the assignments are penalized in order to avoid over-punishing
v1 Î r1,w . The code for GIL S ((cid:142) gure 8) is similar to IL S since both algorithms
re-instantiate the worst variable for improving the current solution. Their diVerence
is that GIL S only generates one random seed during its execution (line 1, outside
the while loops) and has some additional code (lines 10–13) for penalty assignment.
The penalty is used to increase the inconsistency degree of the current local
maximum, and to a lesser to degree of solutions that include a subset of the
assignments. In particular, for its similarity computations GIL S applies the eVective
inconsistency degree which is computed by adding the penalties

n
l · å
i=1

penalty (vi Î ri,x)

to the actual inconsistency degree (i.e., the number of condition violations) of a
solution. The penalty weight parameter l is a constant that tunes the relative impor-
tance of penalties and controls the eVect of memory in search. A large value of l
will punish signi(cid:142) cantly local maxima and their neighbours causing the algorithm
to quickly visit other areas of the graph. A small value will achieve better (local)
exploration of the neighbourhoods around maxima at the expense of global graph
exploration.

The results of this punishment process are:

(i ) search does not restart from various random seeds but continues from local
maxima. This is because the penalty increases the eVective inconsistency
degree of the current local maximum (sometimes repeatedly) and eventually
worse neighbours appear to be better and are followed by GIL S. The intuition

Downloaded by [Anadolu University] at 10:28 21 December 2014 622

D. Papadias and D. Arkoumanis

IF better value THEN

Guided Indexed Local Search
1 S := random seed
2  WHILE NOT (Time limit) {
3        WHILE NOT(Local_Maximum) {
4              determine worst variable vi
5              value := find best value (Root of tree Ri, vi)
6
7
8
9
10
11
12
13} /* END WHILE NOT Time limit */

     penalty(vi ¬ ri,x)= penalty(vi ¬ ri,x) + 1

} /* END WHILE NOT Local_Maximum */

S = S Ù { vi ¬ Value }
IF S among the best solutions found so far THEN keep S

  P = among the assignments of the current local maximum, select the ones with the minimum penalty
  FOR EACH assignment  vi ¬ ri,x in  P

Figure 8. Guided indexed local search.

behind this is to perform some downhill moves, expecting better local maxima
in subsequent steps.

(ii) solutions that share many common assignments with one or more local
maxima have high eVective inconsistency degrees and usually are not chosen
during search. Thus, possible visits to the same regions of the search space
are avoided.

Like IL S, GIL S uses (cid:142) nd best value, to select the new object for the variable to
be re-instantiated. The process is modi(cid:142) ed in order to deal with penalties as follows:
after the calculation of the inconsistency degree of a leaf object, the penalty value of
this assignment is added, and compared with the best found so far. Find best value
is identical with the one for IL S when it operates at intermediate nodes.

For small problems, the penalties are kept in a two dimensional (n ´N) array
where the cell (i, j) stores the penalty of assigning the ith variable with the jth value
in its domain (vi Î ri,j). This array is, in general, very sparse since only a small subset
of the possible assignments are penalized (most of the cells contain zeros). For large
problems, where there is not enough main memory to keep such an array, we build
an in-memory hash table which only stores the assignments with positive penalties.

3.3. Spatial evolutionary algorithm

Evolutionary algorithms are search methods based on the concepts of natural
mutation and the survival of the (cid:142) ttest individuals. Before the search process starts,
a set of p solutions (called initial population P) is initialized to form the (cid:142) rst
generation. Then, three genetic operations, selection, crossover and mutation, are
repeatedly applied in order to obtain a population (i.e. a new set of solutions) with
better characteristics. This set will constitute the next generation, at which the
algorithm will perform the same actions and so on, until a stopping criterion is met.
In this section we propose a spatial evolutionary algorithm (SEA) that takes advantage
of spatial indexes and the problem structure to improve solutions.

Selection mechanism: This operation consists of two parts: evaluation and oVspring
allocation. Evaluation is performed by measuring the similarity of every solution;
oVspring generation then allocates to each solution, a number of oVspring propor-
for oVspring allocation include ranking,
tional
proportiona l selection, stochastic remainder etc. The comparison of (Blickle and Thiele
1996) suggests that the tournament method gives the best results for a variety of

similarity. Techniques

to its

Downloaded by [Anadolu University] at 10:28 21 December 2014 Search algorithms for multiway spatial joins

623

problems and we adopt it in our implementation. According to this technique, each
solution Si competes with a set of T random solutions in the generation. Among the
T +1 solutions, the one with the highest similarity replaces Si. After oVspring
allocation, the population contains multiple copies of the best solutions, while the
worst ones are likely to disappear.

Crossover mechanism is the driving force of exploration in evolutionary algorithms.
In the simplest approach (Holland 1975), pairs of solutions are selected randomly
from the population. For each pair a crossover point is de(cid:142) ned randomly, and the
solutions beyond it are mutually exchanged with probability mc (crossover rate),
producing two new solutions. The rationale is that after the exchange of genetic
materials, the two newly generated solutions are likely to possess the good charac-
teristics of their parents (building-block hypothesis, Goldberg 1989). In our case,
randomly swapping assignments will most probably generate multiple condition
violations. Especially for latter generations, where solutions may have reached high
similarities, random crossover may lead to the removal of good solutions.

In order to limit the number of violations, we propose a variable crossover point
c(14c<n) which is initially 1 and increases every gc generations. When a solution
S is chosen for crossover, c variables will retain their current assignments, while the
remaining n - c will get the assignments of another solution. A small value of c
means that S will change dramatically after crossover, while a value close to n implies
that only a small part will be aVected (e.g. if c=n - 1 only one variable will change
its assignment). This leads to the desired result that during the early generations,
crossover has a signi(cid:142) cant eVect in generating variety in the population, but this
eVect diminishes with time in order to preserve good solutions.

Given the value of c, a greedy crossover mechanism uses a set X to store the c
best variables in S, i.e. the ones that have relatively low inconsistency degrees and
should not change their assignment during crossover. Initially variables are sorted
according to the number of satis(cid:142) ed join conditions in S. In case of ties the variable
with the smallest number of violations has higher priority. The (cid:142) rst variable in the
ordered list is inserted into X. From this point on, the variable inserted, is the one
that satis(cid:142) es the largest number of conditions with respect to variables already in
X. Ties are resolved using the initial order. The process stops when c variables are
in X. The rest of the variables are re-instantiated using the corresponding values of
another solution.

Figure 9 illustrates a solution where satis(cid:142) ed (violated) conditions are denoted
with bold (thin) lines. Assume that c=3, meaning that three variables will keep their
current assignments. The initial sorting will produce the order (v6 , v4 , v2 , v1 , v3 , v5 ).
The insertion order in X is v6 , then v4 (because of Q4,6 ) and (cid:142) nally v1 (because of
Q1,6 and Q1,4 ). Intuitively this is a very good splitting because the sub-graph involving

1

2

3

4

5

6

Variable
v6
v4
v2
v1
v3
v5

Conditions Satisfied
4
3
2
2
2
1

Conditions Violated
0
1
1
2
2
2

Figure 9. Example of solution splitting during crossover.

Downloaded by [Anadolu University] at 10:28 21 December 2014 624

D. Papadias and D. Arkoumanis

v1 , v4 and v6 is already solved. Now another solution is chosen at random and v2 ,
v3 and v5 obtain the instantiations of this solution.

Notice that there exist several alternative options for crossover. For instance,
instead of choosing the second solution at random, we could (cid:142) nd the one that has
the maximum number of satis(cid:142) ed conditions among v2 ,v3 and v5 . Going one step
further we could perform exhaustive search in order to (cid:142) nd the optimal way to
combine solutions. However, such methods introduce signi(cid:142) cant computational over-
head and should be avoided. The elementary operations, including crossover, must
be as fast as possible in order to allow the initial population to evolve through a
large number of generations.

Mutation mechanism: Although it is not the primary search operation and some-
times is omitted, mutation is very important for SEA and the only operation that
uses the index. At each generation, mutation is applied to every solution in the
population with probability mm , called the mutation rate. The process is similar to
IL S; the worst variable is chosen and it gets a new value using (cid:142) nd best value. Thus,
in our case mutation can only have positive results.

Figure 10 illustrates the pseudo-code for SEA. During the initial generations
crossover plays an important role in the formation of new solutions. As time passes
its role gradually diminishes and the algorithm behaves increasingly like IL S, since
mutation becomes the main operation that alters solutions.

Unlike IL S (which does not include any problem speci(cid:142) c parameters), and GIL S
(which only contains l), SEA involves numerous parameters, namely, the number T
of solutions participating in the tournament, the crossover (mc ) and mutation (mm )
rates, the number of generations gc during which the crossover point remains con-
stant, and the number p of solutions in each population. Furthermore, these para-
meters are interrelated in the sense that the optimal value for one depends on the
rest. Careful tuning of the parameters is essential for the good performance of SEA,
and evolutionary algorithms in general (Grefenstette 1986). In the next section we
explore parameter tuning with respect to the problem characteristics.

P := generate initial set of solutions {S1,..,S p}
WHILE NOT (Time limit) {

compute crossover point c /* increase the value of c by 1 every gc generations */
FOR EACH Si in P /*evaluation */

evaluate Si
IF Si among the best solutions found so far THEN keep Si

FOR EACH Si in P /* offspring allocation */
                         compare Si with T other random solutions in P

 replace Si with the best among the T+1 solutions

FOR EACH Si in P /*crossover*/

with probability mc change  Si as follows

determine set of c variables to keep their current values
re-instantiate the remaining variables using their values in Sj  (Sj Î P and i¹j)

Spatial Evolutionary Algorithm
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18

FOR EACH Si  in P  /* mutation */

with probability mm change  Si as follows
determine worst variable vk
value := find best value (Root of tree Rk, vk)

}/* END WHILE NOT Time limit */

Figure 10. Spatial evolutionary algorithm.

Downloaded by [Anadolu University] at 10:28 21 December 2014 Search algorithms for multiway spatial joins

625

3.4. Parameter tuning

In order to provide a general set of parameters, applicable to a variety of problem
instances, we perform the tuning based on the size of the problem. The size s of a
problem denotes the number of bits required to represent the search space (Clark
et al. 1998), i.e. the number of bits needed to express all possible solutions:

n
s=log2 · P
i=1

Ni

For all experiments on parameter tuning we used two queries; a chain applied
on 25 uniform datasets with density d=0.155 and a clique applied on 5 uniform
datasets with density d=0.025. All datasets contain 100 000 objects and the above
density values are such that the resulting problems have one exact solution (the
motivation is discussed in §5). These settings were chosen so that they represent two
extreme cases of constrainedness and query size. Acyclic queries are the most under-
constrained, while cliques the most over-constrained . As shown in the sequel, the
best parameter values are the same or very close for the two queries, implying that
these values provide good performance for most other queries as well.

The following experimental results represent the average of 100 executions for
each query (since the heuristics are non-deterministic the same query/data combina-
tion usually gives diVerent results in diVerent executions). The time of every execution
is proportional to the query size and set to 10.n seconds. In order to have a uniform
treatment of similarity, independent of the number of the constraints, similarity is
computed as 1-(#violated constraints/#total constraints).

The (cid:142) rst experiment aims at adjusting the penalty weight l of GIL S. We used
values of l in the range 10 - 12 ·s, 10 - 10 ·s, 10 - 8 ·s and so on until 10 - 2 ·s. Figure 11
displays the average (over 100 executions) best similarity found for each value of l.
In both query types the best performance is achieved for l=10 - 10 ·s. Smaller values
of l will cause the algorithm to spend most of the available time in the neighbourhood
of the (cid:142) rst local maximum visited. On the other hand, large values will prevent
exploration of the neighbourhoods around local maxima missing some good solu-
tions. The value 10 - 10 ·s provides a good trade-oV between these two cases.

The rest of the experiments involve the SEA algorithm. Due to the large number
of parameters and their interrelationships, we performed the experiments in two
rounds. Through the (cid:142) rst round (omitted here) we determined a starting point for
the parameter values as follows: population size p=100 ·s, number of solutions in
tournament T =0.05 ·s, crossover rate mc=0.5, gc=10·s and mutation rate mm =0.8.

similarity

0.65

0.63

0.61

0.59

0.57

0.55

similarity
0.40

0.36

0.32

0.28

0.24

0.20

0.16

s*1E-12

s*1E-10

s*1E-8

s*1E-6

s*1E-4

s*1E-2

s*1E-12

s*1E-10

s*1E-8

s*1E-6

s*1E-4

s*1E-2

penalty weight parameter

penalty weight parameter

(a) Chain query with 25 variables

(b) Clique query with 5 variables

Figure 11. Penalty weight parameter tuning for GIL S.

Downloaded by [Anadolu University] at 10:28 21 December 2014 626

D. Papadias and D. Arkoumanis

Then a second round of experiments was conducted to (cid:142) ne-tune each parameter
individually by keeping the values of the other ones (cid:142) xed. The (cid:142) rst experiment (of
the second round) attempts to (cid:142) nd the best value for the crossover rate by trying
values from 0.1 to 0.9. Figure 12 shows the average best similarity as a function of mc.
The highest similarity is achieved for values between 0.5 and 0.7 and for the following
experiments we set mc=0.6.

Given the value of crossover rate, we try to (cid:142) nd the best value of gc, i.e. the
number of generations that the population must evolve before the variable crossover
point is increased by one. We experimented with orders of magnitude of s: 0.1·s, s
and 10·s. Larger values are pointless since the algorithm reaches the time limit before
100 ·s generations. As shown in (cid:142) gure 13, the best results are obtained for gc=10.s,
meaning that SEA works better when it only keeps the instantiations of a few, but
very good variables. This implies that the crossover has a rather strong eVect in the
performance of the algorithm.

The following experiment involves the mutation rate. SEA was executed for
values of mm in the range [ 0.1, 1] , and according to (cid:142) gure 14 the best results were
obtained for mm =1. This was expected since mutation uses the index to quickly
re-instantiate the worst variable to the best value in its domain, signi(cid:142) cantly improv-
ing solutions. We also experimented with mutation of a random (but violating at
least a constraint ) variable. The motivation is, given that we may have multiple
copies of the same solution in one generation (due to oVspring allocation), it might
pay oV to re-instantiate diVerent variables in order to create larger variety in the

similarity

similarity

0.91

0.90

0.89

0.88

0.87

0.86

0.85

0.91

0.90

0.89

0.88

0.87

0.86

0.85

0.94

0.90

0.86

0.82

0.78

0.74

0.94

0.92

0.90

0.88

0.86

0.84

0.82

0.80

0.1

0.3

0.5

0.7

0.9

0.1

0.3

0.5

0.7

0.9

Crossover probability

Crossover probability

(a) Chain query with 25 variables

(b) Clique query with 5 variables

Figure 12. Crossover probability tuning for SEA.

similarity

similarity

0.1s

s

10s

0.1s

s

10s

variable crossover point

variable crossover point

(a) Chain query with 25 variables

(b) Clique query with 5 variables

Figure 13. Tuning of gc for SEA.

Downloaded by [Anadolu University] at 10:28 21 December 2014 Search algorithms for multiway spatial joins

627

similarity

0.94

0.92

0.90

0.88

0.86

0.84

0.82

0.80

similarity

0.95

0.90

0.85

0.80

0.75

0.70

0.65

0.60

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

mutation probability

mutation probabilit y

(a) Chain query with 25 variables

(b) Clique query with 5 variables

Figure 14. Mutation probability tuning for SEA.

population. The results, however, have shown that mutation on the worst variable
is signi(cid:142) cantly more eVective. Crossover provides a better way for altering solutions
and achieving variety than mutation on random variables.

After having obtained the optimal values for the other parameters, in the last
experiment we examine values 0.1·s, s, 10·s, 100 ·s and 1000 ·s as potential population
sizes p. The larger the population, the higher the percentage of the search space
covered by solutions, but the lower the number of generations permitted for evolution
within a time limit. As shown in (cid:142) gure 15, the best value is p=100 ·s for chains and
p=1000 ·s for cliques. This is because, due to the larger problem size in the case of
chains, values larger than 100·s only permit an insuYcient number of generations
and evolution is not complete within the time limit. Since p=100 ·s provides good
results for cliques as well, we choose this value.

We could continue the process of (cid:142) ne-tuning SEA using some additional rounds
of experiments (possibly in higher granularity) in order to (cid:142) nd even better parameter
values. This, however, is beyond the scope of the paper, since our goal is mainly to
measure the applicability of the algorithm and observe its relative performance with
respect to the others. Summarizing, the following set of values will be used in the
experimental comparison: l=10 - 10 ·s, T =0.05 ·s, mc =0.6, gc=10·s,mm =1, and p=
100 ·s. The next section describes a diVerent type of algorithms that, unlike the
previous search heuristics, are deterministic (given a query and a set of inputs they
always produce the same output following the same steps at each execution) and do
not require any parameter tuning.

similarity
1.00

0.80

0.60

0.40

0.20

0.00

similarity
1.00

0.80

0.60

0.40

0.20

0.00

0.1s

s

10s

100s

1000 s

0.1s

s

10s

100s

1000 s

Population

Population

(a) Chain query with 25 variables

(b) Clique query with 5 variables

Figure 15. Population size tuning for SEA.

Downloaded by [Anadolu University] at 10:28 21 December 2014 628

D. Papadias and D. Arkoumanis

4. Systematic search algorithms

The two algorithms proposed in this section are aimed at the retrieval of the
solution(s) with the highest similarity (without a time limit). Both search system-
atically in the solution space and can be classi(cid:142) ed under the window reduction
methodology in the sense that they apply variations of backtracking and query
windows to instantiate variables. The algorithms diVer in the way that they instantiate
variables: (i) the (cid:142) rst one chooses the (cid:142) rst good value in the domain, quickly moving
forward to the next variable (ii) the second algorithm spends more time at the current
variable, trying to instantiate it to the best value in its domain.

4.1. Indexed look ahead

Indexed look ahead (IL A) combines backtracking with the tree search process,
in order to move forward and instantiate all variables with the minimum amount of
computation. The outcome is a doubly recursive algorithm without any memory
requirements. As shown is (cid:142) gure 16, IL A starts by initializing two variables:
minV iolations (initially set to 2 ) is the total number of violations of the best solution
found so far, and violations[i] is the current number of violations when the (cid:142) rst i
variables get instantiated (initially violations[1] =0). The algorithm then assigns to
the (cid:142) rst variable each value in its domain, and for every instantiation, it calls go
ahead function which performs the search. The current assignment of v1 , becomes a
query window w1 for all subsequent variables vj such that Qij=True.

Go ahead starts from the root of the next variable to be instantiated (initially the
second one) and for each entry ex checks whether it intersects the existing windows
of instantiated variables. Every violation increases its violationsx count by one. Entries
producing a total number of violations equal or greater than the best solution so
far, are rejected. The rest are followed recursively to the leafs. Once a qualifying leaf
entry (i.e. actual object) is found, it gets immediately assigned to the current variable
and the same process is repeated for the next variable. When the last variable gets
instantiated, minV iolations is updated.

i := 1 /* pointer to the current variable */
violations[1] := 0; minViolations := `
FOR EACH object r1,x of the first domain D1

; bestSolution := Æ

Indexed Look Ahead
1
2
3
4
5

Assign v1/ r1,x
Go Ahead (root of R2, 2)

Go Ahead (Node N, integer i)
1
FOR EACH entry ex of N
2
3
4
5
6
7
8
9
10
11
12
13

        ELSE // leaf node

FOR EACH Qij such that Qij = True and 1£j<i

IF ex does not intersect wj THEN violationsx=violationsx+1
IF violationsx + violations[i-1]‡ minViolations THEN GOTO to next entry

IF N is intermediate node THEN Go Ahead (ex, i)

Assign vi/ ex
violations[i] := violations[i-1]  + violationsx
IF i < n THEN Go Ahead (root of Ri+1, i+1)

ELSE /* the last variable has been instantiated */

minViolations := violations[i]
bestSolution=current assignment
IF minViolations=0 THEN return current solution and stop

Figure 16.

Indexed look ahead.

Downloaded by [Anadolu University] at 10:28 21 December 2014 Search algorithms for multiway spatial joins

629

In order to comprehend the functionality of IL A, consider the three domains of
(cid:142) gure 17, and a clique query (Q1,2 =Q1,3 =Q2,3 =True). Each domain is indexed by
an R*-tree with node capacity 3. Assume that entries in the same node are accessed
in the order speci(cid:142) ed by their ids (e.g., r1,1 , r1,2 , r1,3 or N1,1 , N1,2 , N1,3 ). Variable v1
is (cid:142) rst instantiated to r1,1 , and calls go ahead (root of tree R2 , 2). Because at this
point the value of minV iolations is 2 , no entries can be pruned out since they can
all lead to qualifying solutions. Thus go ahead (N2,1 , 2) is called and the (cid:142) rst object
(r2,1 ) inside N2,1 becomes the assignment of v2 . Notice that since r2,1 does not
intersect r1,1 , the partial solution has one violation (violations[ 2] =1). Rectangles
r1,1 and r2,1 become windows w1 and w2 , respectively, for search in the third tree.
Then, the calls go ahead (root of tree R3 , 3) and go ahead (N3,1 , 3) produce the
instantiation v3 Î r3,1 . Since r3,1 intersects both r1,1 and r2,1 , minV iolations=1. From
now on, the algorithm will only search for exact solutions.

Then the other entries of N3,1 are rejected since they both produce a larger
number of violations than minV iolations. Go ahead(N3,1 , 3) terminates and control
resumes to go ahead (root of tree R3 , 3). Entry N3,2 is immediately rejected and the
algorithm backtracks to go ahead(N2,1 , 2). Because no entry in N2,1 can generate an
exact solution, go ahead(N2,1 , 2) terminates and go ahead(root of tree R2 , 2) resumes.
Since neither N2,2 , nor N2,3 , intersect r1,1 , the algorithm backtracks once more and
re-instantiates the (cid:142) rst variable to a new value (r1,2 ).

The order in which variables get instantiated is very important for the eYciency
of IL A (and backtracking algorithms in general). A good order can quickly guide
to a solution with a small number of violations so that a large part of the entries
can be pruned out early during search. For generating such an order we follow again
a greedy approach: the variable that participates in the largest number of conditions
is instantiated (cid:142) rst. The ith variable to be selected is the one, which participates in
the largest number of conditions with respect to the already chosen i-1 variables. In
case of a tie, the variable with the most join conditions is favoured.

4.2. Indexed branch-and-boun d

When instantiating a variable, IL A selects the (cid:142) rst value in its domain that may
possibly lead to solutions with similarity higher than the best solution found so far.
Although this strategy allows the algorithm to quickly move forward, it may not be
a good choice in the long term since it may cause unnecessary work. Consider, for
instance, that the similarity of the best solution found so far is rather low, and there
exist two potential instantiations for the current variable that can exceed this similar-
ity: the (cid:142) rst satis(cid:142) es 5 constraints with respect to already instantiated variables and
the other satis(cid:142) es 10. IL A will assign the (cid:142) rst value (if it is found before the second
one) although the second will most probably lead to a better solution.

Indexed Branch-and-Bound (IBB) on the other hand, will sort all qualifying values

5

4

3

2

1

1,2r

1,1N
1,2r

1,1r

1,6r

1,2N
1,4r

1,5r

1,7r

1,8r

1,3N

1,9r

2,1r

2,3r

2,1N
2,2r

5

4

3

2

1

2,7r

2,8r

2,3N

2,9r

2,4r
2,5r

2,6r

2,2N

5

4

3

2

1

3,2r

3,3r

3,1r

3,1N

3,4r
3,2N

3,5r

1

2

3

4

5

6

7

8

9

1

2

3

4

5

6

7

8

9

1

2

3

4

5

6

7

8

9

Figure 17. Example of IL A.

Downloaded by [Anadolu University] at 10:28 21 December 2014 630

D. Papadias and D. Arkoumanis

according to the number of conditions that they satisfy with respect to rectangles of
instantiated variables, and then assign the one that satis(cid:142) es the most conditions.
Figure 18 illustrates the pseudo-code for IBB. Like IL A, the algorithm works in a
backtracking-base d function; their main diVerence is that, through the similarity
search function, IBB computes the complete domain of the current variable vi, i.e.
the set of values that can lead to a solution better than the one found so far. Then,
this set is sorted so that the best values are assigned (cid:142) rst, leading quickly to good
solutions (a similar idea is applied by (cid:142) nd best value in non-systemati c search). The
trade-oV is the space requirements for keeping the domains and the computational
cost for sorting. The order of variables is determined using the same heuristic as IL A.
As an example of IBB, consider again the clique query and the datasets of
(cid:142) gure 17. Assume that initially v1 is instantiated to object r1,6 . Similarity search
(R2 , 2) will be called to retrieve the possible values for v2 . Since at this point no
solution has been found, v2 could take any value in its domain (IL A would pick the
(cid:142) rst rectangle found). Similarity search, however, performs a window query (using
the value r1,6 ) and retrieves r2,4 (it is the only object that overlaps r1,6 ) which gets
assigned to v2 . The next step (instantiation of v3 ) will try to (cid:142) nd rectangles in the
third dataset that intersect r1,6 and/or r2,4 . These rectangles are then sorted according
to the number of conditions that they satisfy (i.e. the number of windows they
overlap). In the current example, there is no rectangle that intersects both windows,
so r3,5 (which intersects r2,4 , but not r1,6 ) gets assigned to v3 , and the value of
minV iolations becomes 1. Since no other value for the second variable can lead to a

i := 1 /* pointer to the current variable */
violations[0] := 0; minViolations := `
domain[1] := All objects of the first domain D1
WHILE (TRUE) {

 ; bestSolution := Æ

IF domain[i] = Æ THEN GOTO 18 /* backtrack */
ex := get next value in  domain[i]
Assign vi/ ex
violations[i] := violations[i-1]  + violationsx
IF violations[i] < minViolations THEN

IF i < n-1 THEN

Indexed Branch and Bound
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

}  /* END WHILE */

ELSE /* the last variable is been instantiated */

minViolations := violations[i]
bestSolution=current assignment
IF minViolations=0 THEN RETURN
IF i=1 THEN RETURN  /* end of algorithm  */
i:=i-1/* Backtrack */

i :=  i+1 /* successful instantiation: go forward */
Similarity Search(root of R, i)
sort entries ex in domain[i] in ascending order with respect to violationsx

Similarity Search (Node N, integer i)
FOR EACH entry ex of N
1
2
3
4
5
6
7

ELSE

FOR EACH Qij such that Qij = True and 1£j<i

IF ex does not intersect wj THEN violationsx=violationsx+1
IF violationsx + violations[i-1]‡ minViolations THEN GOTO to next entry

IF N is intermediate node THEN Similarity Search (ex, i)

Domain[i]=Domain[i]È{ex}

Figure 18.

Indexed branch and bound.

Downloaded by [Anadolu University] at 10:28 21 December 2014 Search algorithms for multiway spatial joins

631

better solution, the algorithm will immediately backtrack to re-instantiate the (cid:142) rst
one. The experimental evaluation will show whether the overhead of computing and
sorting the domains in IBB pays oV.

5. Experimental evaluation

Since the goal is not retrieval of all exact solutions, we chose to compare the
algorithms, not using the standard spatial database settings, but according to
the common CSP and optimization methodology with problem instances in the,
so-called, hard region. It is a well known fact, that over-constrained problems do
not have exact solutions and it is usually easy to determine this. On the other hand,
under-constrained problems have numerous solutions which can be easily found.
Between these types occurs a phase transition. Many studies on systematic search
algorithms (Crawford and Auton 1993, Smith 1994) and non-systematic heuristics
(e.g.
local search, Clark et al. 1998) in a variety of combinatorial problems,
experimentally demonstrate that the most diYcult problems to solve are in the (hard)
region de(cid:142) ned by the phase transition. This hard region occurs when the expected
number of exact solutions is small, i.e. in the range [ 1, 10] .

In order to generate such problem instances we need analytical formulae for the
number of exact solutions. The generalized formula for the expected output size of
multiway spatial joins is:

Sol=#(possible tuples)·Prob(a tuple is a solution)

The (cid:142) rst part of the product equals the cardinality of the Cartesian product of
the n domains, while the second part corresponds to multiway join selectivity.
According to (Theodoridis et al. 2000) the selectivity of a pairwise join over two
uniform datasets Di and Dj that cover a unit workspace is (|ri|+|rj|)2 , where |ri| is
the average MBR extent in each dimension for Di. For acyclic graphs, the pairwise
probabilities of the join edges are independent and selectivity is the product of
pairwise join selectivities. Thus, in this case the number of exact solutions is:

n
Sol= P
i=1

|Ni|·

P
Yi,j:Q(i,j)=TRUE
When the query graph contains cycles, the pairwise selectivities are not independ-
ent anymore and the previous equation is not accurate. Based on the fact that if a
set of rectangles mutually overlap, then they must share a common area, Papadias
et al. (2001) propose the following estimation for Sol, in case of clique joins:

(|ri|+|rj|)2

n
Sol= P
i=1

n

|Ni|·A å

i=1

n
P
j=1
i
jë

|rj|B2

The above formulae are applicable for queries that can be decomposed to acyclic
and clique graphs. For simplicity, in the rest of the paper we assume that all (uniform)
datasets have the same cardinality N and MBR extents |r |. Under these assumptions,
and by substituting average extents with density values, the formulae can be trans-
formed as follows. The density of a set of rectangles is the average number of
rectangles that contain a given point in the workspace. Equivalently, d can be
expressed as the ratio of the sum of the areas of all rectangles over the area of
the workspace. Density is related with the average rectangle extent by the equation

Downloaded by [Anadolu University] at 10:28 21 December 2014 632

D. Papadias and D. Arkoumanis

d=N |r| 2 (Theodoridis et al. 2000). For acyclic queries, there are n - 1 join
conditions. Thus, the number of solutions is:

Sol=Nn·(2·|r|)2 · (n - 1)=N·22 · (n - 1)·d

n - 1

Similarly, for cliques the number of solutions is:

Sol=Nn·n2 ·|r |2 · (n - 1) =N ´22 ·d

n - 1

The importance of these equations is that by varying the density of the datasets
we can create synthetic domains such that the number of solutions can be controlled.
In case of acyclic graphs, for instance, the value of density that produces problems
with one expected solution is d=1/4·n - 1
ã N, while for cliques this value is
ã N ´n2 . In the rest of the section we experimentally evaluate the proposed
d=1/
algorithms starting with non-systematic heuristics and continuing with systematic
search. The following experiments were executed by Pentium III PCs at 500 MHz
with 512MB Ram.

n - 1

5.1. Comparison of non-systemati c heuristics

The (cid:142) rst experiment measures the quality of the solutions retrieved by the
algorithms as a function of the number of query variables. In particular we con-
structed uniform datasets of 100 000 objects and executed acyclic and clique queries
involving 5, 10, 15, 20 and 25 variables. (To the best of our knowledge, there do not
exist 5 or more real datasets covering the same area publicly available). Depending
on the number of variables/datasets involved and the query type, we adjusted the
density of the datasets so that the expected number of solutions is 1. Since the
expected number of solutions does not always coincide with the actual number, we
had to repeat the generation of the datasets until the actual number was also 1. This
is needed for the comparison of systematic algorithms. Each query was allowed to
execute for 10·n seconds. Figure 19 illustrates the similarity of the best solution
retrieved by the algorithms as a function of n, for chain and clique queries (average
of 100 executions). The numbers in italics (top row) show the corresponding
density values.

The second experiment studies the quality of the solutions retrieved over time.
Since all algorithms start with random solutions (which probably have very low

ILS

GLS

SEA

Chains

Cliques

0.014

0.069

0.109

0.136

0.155

density
values

similarity
1.00

0.025

0.167

0.298

0.398

0.474

density
values

similarity
1.00

0.80

0.60

0.40

0.20

0.00

0.80

0.60

0.40

0.20

0.00

5

10

20

25

15
Query Size

5

10

15

20

25

Query Size

Figure 19. Best similarity retrieved as a function of n.

Downloaded by [Anadolu University] at 10:28 21 December 2014 Search algorithms for multiway spatial joins

633

similarities), during the initial steps of their execution there is signi(cid:142) cant improve-
ment. As time passes the algorithms reach a convergence point where further
improvement is very slow because a good solution has already been found and it is
diYcult for the algorithms to locate a better one. In order to measure how quickly
this point is reached, we used the data sets produced for the 15-variable case and
allowed the algorithms to run for 40 (chains) and 120 (cliques) seconds. Since chain
queries are under-constrained , it is easier for the algorithms to quickly (cid:142) nd good
solutions. On the other hand, the large number of constraints in cliques necessitates
more processing time. Figure 20 illustrates the (average) best similarity retrieved by
each algorithm as a function of time.

The third experiment studies the behaviour of algorithms as a function of the
expected number of solutions. In particular, we use datasets of 15 variables and
gradually increase the density so that the expected number of solutions grows from
1, to 10, 100 and so on until 105 . Each algorithm is executed for 150 seconds (i.e.
10·n). Figure 21 shows the best similarity as a function of Sol.

The ubiquitous winner of the experiments is SEA, which signi(cid:142) cantly outperforms
IL S and GIL S in most cases. T he solutions retrieved by the algorithm are often perfect
matches. This is very important since as we will see shortly, systematic search for
exact solutions may require several hours for some problem instances. According to
(cid:142) gure 21 the performance gap does not decrease considerably as the number of
solutions increases, meaning that the structure of the search space does not have a
serious eVect on the relative eVectiveness of the algorithms.

The poor performance of IL S (and GIL S) is rather surprising considering that
local search signi(cid:142) cantly outperformed a genetic algorithm in the experimental
evaluation of (Papadias et al. 1999) for con(cid:142) guration similarity. This can be partially
caused by the diVerent images sizes (on the average, about an order of magnitude
smaller than the datasets used in our experiments), version of the problem (soft
spatial constraints that can be partially violated ), implementation and parameter

similarity

1.00

0.80

0.60

0.40

0.20

0.00

0.80

0.60

0.40

0.20

0.00

0

5

10

15

20

25

30

35

40

Time (sec)

0

10

20

30

40

50

60

70

80

90 100 110 120

Time (sec)

Figure 20. Best similarity retrieved as a function of time.

similarity
1.00

0.109

0.129

0.152

0.18

0.212

0.25

density
values

similarity
1.00

0.298

0.352

0.415

0.489

0.576

0.679

density
values

1

10

100

1000

1000 0

10000 0

1

10

100

1000

1000 0

10000 0

Solutions

Solutions

Figure 21. Best similarity retrieved as a function of the expected number of solutions.

similarity
1.00

0.80

0.60

0.40

0.20

0.00

0.80

0.60

0.40

0.20

0.00

Downloaded by [Anadolu University] at 10:28 21 December 2014 634

D. Papadias and D. Arkoumanis

choices. The main reason, however, is that the proposed approach has some substan-
tial improvements that aVect relative performance: (i) we use indexes to re-assign
the worst variable with the best value in its domain, while in (Papadias et al. 1999 )
variables were re-assigned with random values, and (i) we apply a sophisticated
crossover mechanism that takes into account the quality of assignments in order to
split solutions, while the genetic algorithm of (Papadias et al. 1999) involves a
random crossover mechanism. The (cid:142) rst improvement enhances the performance of
both local and evolutionary search, since indexes are used by SEA, for mutation,
and by IL S (and GIL S) for variable re-instantiation. Therefore, the main diVerence
in relative eYciency is generated by the crossover mechanism. The careful swapping
of assignments between solutions produces some better solutions, which in sub-
sequent generations will multiply through oVspring allocation and mutate to better
solutions.

IL S and GIL S are still useful

in cases where there is very limited time for
processing since, as shown in (cid:142) gure 20, they reach their convergence point before 5
and 10 seconds for chains and cliques respectively (for chains, within 5 seconds IL S
visits about 60 000 local maxima!). Although SEA will eventually outperform them,
it requires longer time to reach high quality solutions due to the application of the
genetic operations on a large population of solutions. Especially in the case of cliques,
the crossover mechanism is not as eYcient as for chains, because the constraints
between all pairs of variables are very likely to generate large numbers of inconsisten-
cies during the early steps where solutions have low similarities. IL S, in general,
performs better than GIL S, except for queries involving 20 and 25 variables. For
large queries the similarity diVerence between a local maximum and its best neigh-
bours is relatively small (due to the large number of constraints, each violation
contributes little to the inconsistency degree of the solution), and good solutions are
often found in the same neighbourhood. So while IL S will retrieve one of them and
then restart from a completely diVerent point, the punishment process of GIL S leads
to a more systematic search by achieving gradual transitions between maxima and
their neighbours.

Summarizing, SEA shows the best overall performance provided that it has
suYcient time to converge. Since the performance gap is signi(cid:142) cant for both chains
and cliques and all query sizes and data densities tested, the same results are expected
for any problem instance. Furthermore, we anticipate further improvements by more
re(cid:142) ned, and possibly application-dependent , parameter tuning. IL S and GIL S are
preferable only in applications where the response time is more crucial than the
quality of the solutions. If, for instance, in a military application an urgent decision
is to be taken according to the best information available, IL S could be executed
and return the (cid:142) rst local maximum found within milliseconds. GIL S outperforms
IL S only for large queries. In addition to their usefulness as independent retrieval
techniques, the above heuristics can be applied as a preliminary step to speed up
systematic algorithms.

5.2. Comparison of systematic algorithms

In order to measure the performance of IL A and IBB we performed another set
of experiments, using the datasets of the previous section. In particular, the (cid:142) rst
experiment ((cid:142) gure 22) illustrates the time required by the algorithms to locate the
best solution as a function of n, for chain and clique queries. Similar to (cid:142) gure 21,

Downloaded by [Anadolu University] at 10:28 21 December 2014 Search algorithms for multiway spatial joins

635

ILA

IBB

Chains

Cliques

5

10

20

25

15
Query Size

5

10

20

25

15
Query Size

Figure 22. Time to retrieve the exact solution as a function of n.

the second experiment in (cid:142) gure 23 illustrates the processing time as a function of
the expected number of solutions using the same datasets and queries of 15 variables.
The performance of the algorithms is similar (in the same order of magnitude)
with IBB being slightly better. As shown in (cid:142) gure 23, both algorithms are sensitive
to the expected number of solutions; the processing time drops signi(cid:142) cantly as
solutions multiply. For large number of solutions IL A has a slight advantage over
IBB because by choosing ‘blindly’ the (cid:142) rst good value for a variable there is a high
chance that it will eventually reach a good solution without the overhead of sorting.
The important outcome of these experiments, however, refers more to the actual
processing times rather than the relative performance of the algorithms. Notice in
(cid:142) gure 22, that chain queries involving up to 15 datasets are answered very fast (in
less than 10 seconds); thus non-systemati c heuristics are not necessary for these cases.
Even chains with 25 variables require about 1000 seconds which may be acceptable
time given the size of the problem. On the other hand, even the smallest clique (5
datasets) needs more than 100 minutes. Cliques involving 25 variables take several
days to terminate!

Approximate retrieval of over-constrained queries is extremely time consuming
because (i) it is diYcult for the algorithms to quickly (cid:142) nd good solutions that will
prune the search space, and (ii) even solutions with relatively high similarity may
involve numerous violations (in contrast, if the goal were retrieval of exact solutions
only, the processing time would decrease with the constrainedness of the query graph
because once a violation was found the algorthms would immediately backtrack).
Thus, partial solutions can only be abandoned during the instantiation of the last
few variables. In order to overcome the (cid:142) rst de(cid:142) ciency (i.e. the slow-start problem)
and speed up performance of IL A and IBB for diYcult problem instances, we (cid:142) rst

Time (sec)

10000000

1000000

100000

10000

1000

Time (sec)
100000

10000

1000

Time (sec)

10000.0

1000.0

100.0

10.0

1.0

0.1

Time (sec)
10

8

6

4

2

0

1

10

100

1000

10000

100000

1

10

100

1000

10000

100000

Solutions

Solutions

Figure 23. Time to (cid:142) nd an exact solution as a function of the expected number of solutions
(n=15).

Downloaded by [Anadolu University] at 10:28 21 December 2014 636

D. Papadias and D. Arkoumanis

apply a non-systematic heuristic to quickly locate a good solution. This solution
provides an initial target for systematic search; any partial solution that cannot reach
this target will be abandoned. We follow two approaches in this two-step search
method. The (cid:142) rst one executes IL S and returns the best local maximum visited,
while the second executes SEA for a predetermined time threshold during which
SEA has enough time to retrieve a very good solution. IL S is very fast, while SEA
needs more time, which is hopefully compensated by the quality of the target solution
(the higher the similarity, the more pruning of the search space during systematic
search).

Figure 24 illustrates the total time (sum for systematic and non-systematic search)
required to retrieve the exact solution using the two-step approaches for clique
queries. The results are averaged over 10 executions because the quality of the
solution returned by non systematic search diVers each time due to their non-
deterministic nature. Notice that often, especially for small queries, the exact solution
is found by the non-systematic heuristics (usually SEA) in which case systematic
search is not performed at all. The threshold for SEA is again 10·n seconds, which
are suYcient for its convergence (see (cid:142) gure 20), while IL S is executed for 1 second
(during this time it visits about 12 000 maxima and returns the best).

Although even the incorporation of IL S improves the performance of systematic
search signi(cid:142) cantly (compare with (cid:142) gure 22(b)), the major diVerence is caused by
SEA. The high similarity of the solution returned by SEA speeds up both algorithms
1–2 orders of magnitude with respect to simple systematic search. The improvement
is more substantial for IBB because once a good target similarity is found, its branch-
and-bound search strategy will lead it fast to the best solution. For instance, the
25-variable clique can now be processed in about 104 seconds as opposed to about
106 seconds in (cid:142) gure 22 (b). On the other hand, IL A is more sensitive to the total
number of violations in the solution returned by non-systematic search. For 15 or
more query variables, even good solutions may have several violations, which do
not permit the pruning of a large part of the search space.

In the last experiment we compare SEA-IL A and SEA-IBB for various query
types. In particular we use the 15 datasets originally created for cliques (d=0.298 )
and apply increasingly tight queries. (For 15 variables, the least constrained (acyclic)
graph has 14 conditions, while the most constrained one (clique) has 105. We do not
consider non-connected query graphs, as these can be processed by solving connected
sub-graphs and computing their Cartesian product.) In order to generate such queries
we start with a random one involving 15 conditions (contains a cycle) and at each
step we add another 15 conditions at random. Figure 25 illustrates the time required

Time (sec)

ILS-ILA

SEA-ILA

Time (sec)

ILS-IBB

SEA-IBB

10000000

1000000

100000

10000

1000

100

10

1000000

100000

10000

1000

100

10

5

10

15

20

25

5

10

15

20

25

Query Size

(a) ILA

Query Size

(a) IBB

Figure 24. Processing time of two-step strategies as a function of n for clique queries.

Downloaded by [Anadolu University] at 10:28 21 December 2014 Search algorithms for multiway spatial joins

637

SEA-ILA

SEA-IBB

Time (sec)

10000

1000

100

15

30

45

60

75

90

105

Number of join conditions

Figure 25. Processing time of SEA-IL A and SEA-IBB as a function of

the query.

constrainedness (n=15 ).

by the algorithms to (cid:142) nd the (cid:142) rst exact solution as a function of the join conditions.
The results are again averaged over 10 executions and include the time for both
systematic and non-systematic algorithms.

For queries with 15 and 30 join conditions there is no diVerence because SEA
retrieved exact solutions in all 10 executions. This not surprising because, as datasets
are dense and queries are sparse, there exist numerous exact solutions. When the
query constrainedness increases, the number of solutions drops since density remains
constant. For 45 or more conditions, the cases where SEA (cid:142) nds an exact solution
gradually decrease, and the relative performance of IL A and IBB becomes important.
As shown, SEA-IBB clearly outperforms its IL A counterpart, and their performance
gap widens with the number of conditions. Similar diVerences were also observed
with several other query topologies.

Summarizing, the integration of systematic and non-systematic search, SEA-IBB
in particular, is the best approach for dealing with retrieval of the solution with the
highest similarity. The extension for retrieval of all such solutions is trivial. Notice
that, if somehow we know that there exist exact solutions, previous methods for
multiway spatial join processing (e.g. PJM) are preferable. This, however, is rather
uncommon because even if the datasets are dense and the queries under-constrained ,
there may exist no solutions due to skewed data distributions. Present analytical
formulae for the expected number of solutions only apply to uniform datasets.

6. Discussion

In this paper we propose several algorithms for multiway spatial join processing
when the goal is (i) retrieval of the best solutions possible within limited time, (ii)
retrieval of the best existing solution without time limit. For the (cid:142) rst goal we propose
heuristics based on local and evolutionary search that take advantage of spatial
indexes to signi(cid:142) cantly accelerate search. The best algorithm, SEA, can usually (cid:142) nd
optimal solutions even for diYcult problems. For the second goal we propose
systematic algorithms that combine indexes with backtracking. In addition, we
integrate systematic and non-systematic search in a two-step processing method that
boosts performance up to two orders of magnitude.

To the best of our knowledge, our techniques are the only ones applicable for
approximate retrieval of very large problems without any restrictions on the type of
datasets, query topologies, output similarities etc. As such, they are useful in a variety
of domains involving multiway spatial join processing and spatial similarity retrieval,
including VLSI design, GIS and satellite imagery etc. Another potential application

Downloaded by [Anadolu University] at 10:28 21 December 2014 638

D. Papadias and D. Arkoumanis

is the WWW, where the ever-increasing availability of multimedia information will
also require eYcient mechanisms for multi-dimensional information retrieval.

Regarding future directions, (cid:142) rst we believe that the excellent performance of
SEA, could be further improved in many aspects. An idea is to apply variable
parameter values depending on the time available for query processing. For instance,
the number of solutions p in the initial population may be reduced for very-limited-
time cases, in order to achieve fast convergence of the algorithm within the limit.
Other non-systematic heuristics can also be developed. Given that, using the indexes,
local search can (cid:142) nd local maxima extremely fast, we expect its eYciency to increase
by including appropriate deterministic mechanisms that lead search to areas with
high similarity solutions. Furthermore, several heuristics could be combined; for
instance instead of generating the initial population of SEA randomly, we could
apply IL S and use the (cid:142) rst p local maxima visited as the p solutions of the (cid:142) rst
generation. Although we have not experimented with this approach, we expect it to
augment the quality of the solutions and reduce the convergence time. For systematic
search, we believe that the focus should be on two-step methods, like SEA-IBB, that
utilize sub-optimal solutions to guide search for optimal ones.

Acknowledgments

This work was supported by the Research Grants Council of the Hong Kong

SAR, grants HKUST 6090/99E, HKUST 6070/00E and HKUST 6081/01E.

References
Arge, L., Procopiuc, O., Ramaswamy, S., Suel, T., and Vitter, J., 1998, Scalable sweeping-
based spatial join. In Proceedings of V L DB Conference (New York City: Morgan
Kaufmann), pp. 570–581.

Beckmann, N., Kriegel, H. P., Schneider, R., and Seeger, B., 1990, The R*-tree: an eYcient
and robust access method for points and rectangles. In Proceedings of ACM SIGMOD
Conference (Atlantic City, NJ: ACM Press), pp. 322–331.

Blickle, T., and Thiele, L., 1996, A Comparison of Selection Schemes used in Genetic
Algorithms, 2nd Edition, TIK-Report No. 11, (Zurich: Computer Engineering and
Communication Networks Lab (TIK), ETH).

Brinkhoff, T., Kriegel, H. P., and Seeger B., 1993, EYcient processing of spatial joins using
R-trees. In Proceedings of ACM SIGMOD Conference (Washington, DC: ACM Press),
pp. 237–246.

Chang, S., Shi, Q., and Yan, C., 1987, Iconic indexing by 2-D String. IEEE PAMI, 9, 413–428.
Clark, D., Frank, J., Gent, I., MacIntyre, E., Tomov, N., and Walsh, T., 1998, Local
search and the number of solutions. In Proceedings of Constraint Programming
Conference (Pisa, Italy: Springer LNCS 152), pp. 325–339.

Crawford, J., and Auton, L., 1993, Experimental results on the crossover point in satis(cid:142) ability
problems. In Proceedings of AAAI Conference (Washington, DC: AAAI Press),
pp. 21–27.

Davenport, A., Tsang, E., Wang, C., and Zhu, K., 1994, GENET: A Connectionist architec-
ture for solving constraint satisfaction problems by iterative improvement. In
Proceedings of AAAI Conference (Seattle, Washington: AAAI Press), pp. 325–330.

Dechter, R., and Meiri, I., 1994, Experimental evaluation of preprocessing algorithms for

constraint satisfaction problems. Arti(cid:142) cial Intelligence, 68, 211–241.

Glover, F., and Laguna, M., 1997, T abu Search. (London: Kluwer).
Goldberg, D., 1989 Genetic Algorithms in Search, Optimization and Machine L earning

(Reading: Addison-Wesley).

Grefenstette, J., 1986, Optimization of control parameters for genetic algorithms. IEEE

T ransactions on Systems, Man and Cybernetics, 16, 122–128.

Holland, J., 1975, Adaptation in Natural and Arti(cid:142) cial Systems (Ann Arbor: University of

Michigan Press).

Downloaded by [Anadolu University] at 10:28 21 December 2014 Search algorithms for multiway spatial joins

639

Huang, Y. W., Jing, N., and Rundensteiner, E., 1997, Spatial joins using R-trees: breadth
(cid:142) rst traversal with global optimizations. In Proceedings of V L DB Conference (Athens,
Greece: Morgan Kaufmann), pp. 396–405.

Koudas, N., and Sevcik, K., 1997, Size separation spatial join. In Proceedings of ACM

SIGMOD Conference (Tuscon, Arizona: ACM Press), pp. 324–335.

Lee, S., and Hsu, F., 1992, Spatial reasoning and similarity retrieval of images using 2D

C-strings knowledge representation. Pattern Recognition, 25, 305–318.

Lee, S., Yang, M., and Chen, J., 1992, Signature (cid:142) le as a spatial (cid:142) lter for iconic image

database. Journal of V isual L anguages and Computing, 3, 373–397.

Lo, M-L., and Ravishankar, C. V., 1994, Spatial joins using seeded trees. In Proceedings of

ACM SIGMOD Conference (Minneapolis, MN: ACM Press), pp. 209–220.

Lo, M-L., and Ravishankar, C. V., 1996, Spatial hash-joins. In Proceedings of ACM SIGMOD

Conference (Montreal, Canada: ACM Press), pp. 247–258.

Mamoulis, N., and Papadias, D., 1999, Integration of spatial join algorithms for processing
multiple inputs. In Proceedings of ACM SIGMOD Conference (Philadelphia, PA: ACM
Press), pp. 1–12.

Minton, S., Johnston, M., Philips, A., and Laird, P., 1992, Minimizing con(cid:143) icts: a heuristic
satisfaction and scheduling problems. Arti(cid:142) cial

repair method for constraint
Intelligence, 58, 161–205.

Papadias, D., Mamoulis, N., and Delis, V., 1998, Algorithms for querying by spatial structure.

In Proceedings of V L DB Conference (New York: Morgan Kaufmann), pp. 546–557.

Papadias, D., Mantzourogiannis, M., Kalnis, P., Mamoulis, N., and Ahmad, I., 1999,
Content-based retrieval using heuristic search. In Proceedings of ACM SIGIR
Conference (Berkeley, CA: ACM Press), pp. 168–175.

Papadias, D., Mamoulis, N., and Theodoridis, Y., 2001, Constraint-based processing of

multiway spatial joins. Algorithmica, 30, 188–215.

Papadopoulos, A., Rigaux, P., and Scholl, M., 1999, A performance evaluation of spatial
join processing strategies. In Proceedings of SSD Conference (Hong Kong: Springer
LNCS 165), pp. 286–307.

Patel J. M., and DeWitt, D. J., 1996, Partition based spatial-merge join. In Proceedings of
ACM SIGMOD Conference (Montreal, Canada: ACM Press), pp. 259–270.
Petrakis, E., and Faloutsos, C., 1997, Similarity searching in medical image databases. IEEE

T KDE, 9, 435–447.

Smith, B., 1994, Phase transition and the mushy region in constraint satisfaction problems.
In Proceedings of ECAI Conference (Amsterdam, The Netherlands: Springer LNCS
890), pp. 100–104.

Theodoridis, Y., Stefanakis, E., and Sellis, T., 2000, EYcient cost models for spatial queries

using R-trees. IEEE T KDE, 12, 19–32.

Downloaded by [Anadolu University] at 10:28 21 December 2014 