International Journal of Geographical Information Science
Vol. 23, No. 5, May 2009, 561–580

Research Article

Service chaining architectures for applications implementing distributed
geographic information processing

ANDERS FRIIS-CHRISTENSEN*, ROBERTO LUCCHI, MICHAEL LUTZ and
NICOLE OSTLA¨ NDER
European Commission – Joint Research Centre, Institute for Environment and
Sustainability, Ispra, (VA), Italy

(Received 14 January 2008; in final form 25 November 2008)

Service-Oriented Architectures can be used as a framework for enabling distrib-
uted geographic
information processing (DGIP). The Open Geospatial
Consortium (OGC) has published several standards for services. These can be
composed into service chains that support the execution of workflows constituting
complex DGIP applications. In this paper, we introduce a basic architecture and
building blocks for building DGIP applications based on service chains. We
investigate the issues arising from the composition of OGC services into such
service chains. We study various architectural patterns in order to guide applica-
tion developers in their task of implementing DGIP applications based on service
chains. More specifically, we focus on the control flow and data flow patterns in
the execution of a workflow. These issues are illustrated with an example from the
domain of risk management – a forest fire risk mapping scenario.

Keywords: Distributed geographic information processing; Service chaining;
Control flow; Data flow; SDI 2.0

1.

Introduction

Service-Oriented Computing (SOC) represents a new generation Distributed
Computing Platform (DCP) whose architectural model is called a Service-Oriented
Architecture (SOA). The OASIS Reference Model for SOA (OASIS 2006) defines
such an architecture as ‘a paradigm for organising and utilising distributed capabil-
ities that may be under the control of different ownership domains’ and sees services
here as ‘the mechanism by which needs and capabilities are brought together’. Web
services and the protocols and mechanisms for their description, discovery, and
invocation are today’s most prominent SOA example.

SOAs are open and interoperable environments based on reusability and standar-
dised components. As loosely coupled service architectures, SOAs provide data and
processing capabilities required for a given processing activity not locally, but decen-
tralised, i.e., close to the source of production. In consequence, the SOA approach to
application development can produce applications that can be flexibly adapted to
changing requirements and technologies. In the domain of geographic information
(GI), the SOA ideas have been taken up, creating a technology evolution from
standalone GIS applications, where often only a small percentage of the available

*Corresponding author. Email: anders.friis@jrc.it

International Journal of Geographical Information Science
ISSN 1365-8816 print/ISSN 1362-3087 online # 2009 Taylor & Francis
http://www.tandf.co.uk/journals
DOI: 10.1080/13658810802665570

562

A. Friis-Christensen et al.

functionalities are used, towards a loosely coupled and distributed model based on
interoperable GI services that can be composed into applications that provide users
with just the functionality they need (ESA 2004, Nebert 2004).

Through collections of technologies and organisational agreements, Spatial Data
Infrastructures (SDIs) provide the framework for optimising the creation, mainte-
nance and distribution of GI services (Nebert 2004). At present, most SDIs are still at
an early stage in their development, just starting to offer geoportals and/or spatial web
portals (Yang et al. 2007) that integrate on-line map viewers and search services for
their data holdings (Bernard et al. 2005, European Commission 2005). In later
development phases, they can also serve as frameworks for easy and flexible devel-
opment of GI applications by providing standardised data access interfaces as well as
mechanisms for composing the offered GI services into service chains (Kiehle et al.
2007).

A number of authors have addressed the issue of service chaining in SDIs, and more
particular, the use of distributed processing services that can be combined into value-
added service chains to serve as specific GI applications (e.g., Alameh 2003, Granell
et al. 2005, Lemmens et al. 2006, 2007, Bernard and Ostla¨ nder 2007, Friis-Christensen
et al. 2007, Kiehle et al. 2007, Stollberg and Zipf 2007). However, these papers mainly
address the issue at a conceptual level. The contributions of these papers will be
discussed in Section 3. It is the goal of this paper to investigate issues that occur
when developing an application implementing distributed geographic information
processing (DGIP) adopting the SOA paradigm. We propose an architectural frame-
work, and based on this, study various architectural patterns in order to guide
application developers in their task of implementing DGIP applications based on
service chains. More specifically, we focus on the control flow and data flow patterns
in the execution of a workflow.

The issues to consider when implementing an application based on a GI service
chain are related to service chaining in general as well as to aspects that are specific to
the domain of GI (Lemmens et al. 2006, Granell et al. 2008). To describe and execute
service chains, several languages have been developed. A prominent example is the
Business Process Execution Language (BPEL) specified by OASIS (OASIS 2007). As
this is widely regarded as the de facto standard for creating executable workflow
descriptions, we base our investigations on BPEL as a workflow language. This
leads to a number of requirements, mainly that services provide a service description
expressed using the Web Services Description Language, WSDL (W3C 2001).
Requirements that result from our focus on GI are mainly that (1) DGIP applications
often have to deal with large amounts of data (Tu et al. 2004, Lemmens et al. 2006),
and (2) the standards that exist within the domain – here the work within the Open
Geospatial Consortium (OGC) – that introduce technical constraints on service
composition (Granell et al. 2008). This will be discussed in detail in Section 3.

A forest fire application prototype serves as a use case in order to illustrate the
problems and challenges that have to be taken into account when implementing a
DGIP application based on distributed GI services. However, it is outside the scope of
this paper to investigate the suitability of DGIP for different use cases. The prototype
has been fully implemented utilising service chains and is part of one of the demon-
strators from the ORCHESTRA project: Pan-European Assessment of Natural
Hazards1. A more detailed description of the functionalities supplied by the forest
fire application and used components is available in Klopfer and Kanellopoulos
(2008).

Service chaining architectures

563

The remaining article is structured as follows: The use case is described in section 2.
Section 3 introduces the notion of service orchestration and presents the basic
components and architectural framework for implementing DGIP applications.
Sections 4 and 5 describe the issues that have to be tackled by application developers
related to control flow and data flow, respectively. Finally, in Section 6 we conclude
on our findings and briefly outline future research topics.

2. Use case

The use case that is used throughout this article for illustration focuses on mapping
the risk of forest fires. Forest fires are particularly affecting the southern European
countries such as Spain, Portugal, Italy and Greece. Each year, the fires cause damage
to the environment, infrastructure, economic sectors and private property. European
Commission (2006) provides an overview of the forest fires in Europe for 2005.

Information on fire outbreaks has been collected by some EU member states and
reported to the European Commission since the 1980s. The reported information
includes the ignition point, the cause of the fire, the time it was detected and extin-
guished and the burnt area. By analysing these data, forest fire hazard and risk maps
can be created. These maps support decisions on measures for risk prevention on a
European scale.

The use case shall be implemented through a service-based application for forest
fire risk assessment. The application shall be based on data access services providing
the national forest fire data and a range of geoprocessing2 services, which can be
flexibly combined into value-added service chains. The application shall support the
following types of analyses, which can be selected by the user:

l Hazard mapping through forest fire frequency based on the number of fires per
administrative units such as communes (NUTS3 5), regions (NUTS 3) or coun-
tries (NUTS 0) and forest fire density describing the normalised fire frequency as
fire frequency per square kilometre.

l Risk mapping through the classification of forest fire frequency or density into

forest fire risk classes.

The application shall allow users to provide information on the area of interest
(spatial selection) and a period of interest (temporal selection) for which to perform
these analyses.

Figure 1 illustrates a conceptual workflow with the steps for the use case. In steps 1
and 2 of the analysis, the forest fire data and administrative units (NUTS level 0, 3 or
5) are retrieved. Then, the number of forest fires in each administrative unit is
calculated (step 3). The result of this step is the forest fire frequency, which in step 4
is normalised by the area of each administrative unit yielding the forest fire density.
Finally, based on this result, forest fire risk classes can be defined (step 5). The results
of steps 3–5 represent the results of the analyses to be provided by the application. To
visualise these results, they can be rendered using a specific symbology (steps 6 and 7).

3. Components for applications implementing distributed geographic
information processing

In this section, we introduce the notion of service orchestration and present the basic
architecture and components that provide the setting for developing service-based DGIP
applications.

564

A. Friis-Christensen et al.

7. Render

1. Retrieve 
NUTS data

Forest Fire Risk Map

NUTS (0/3/5) Data

6. Create 
symbology

5. Classify

e   R is k
e s t  F i r
n t
s s e s s m e
A

r

o

F

2. Retrieve 
forest fire data

Forest Fire Records

4. Normalise

3. Join and 
aggregate

Forest fire risk classes

Forest Fire Density

Forest Fire Frequency

Figure 1. The conceptual workflow for assessing forest fire risks.

3.1 Orchestration of services

Combining simple GI services into value-added service chains is seen as one of the
great benefits of SDIs (Einspanier et al. 2003). One problem of existing work on
service chaining is that terminology is not always very clear and terms are used
differently in different contexts. Therefore, in the following, we provide definitions
for the terms used in this paper. Service chaining is a generic term that we use to refer
to the domain of ‘combining services in a dependent series to achieve larger tasks’
(ISO 2005). A workflow is an ‘automation of a business process, in whole or part,
during which documents, information or tasks are passed from one participant to
another for action, according to a set of procedural rules’ (ISO 2005). A service chain
instance is an implementation of a workflow. The term service chain is used synony-
mously. Orchestration is the process of composing a workflow of service activities. A
workflow description is an explicit description of a workflow expressed in some work-
flow language (e.g. BPEL) that can be executed by a workflow engine. A workflow
execution is one specific execution of a workflow, e.g. by executing a BPEL process on
a workflow engine. Control flow is the aspect of a workflow related to the sequence of
requests to the involved services. Control flow aspects are further addressed in
Section 4. Data flow is the aspect related to how data is transferred among the services
involved in a workflow. Data flow aspects are investigated in Section 5.

As mentioned in Section 1, we use BPEL for describing and executing service
chains. It is important to emphasise, however, that BPEL and BPEL-based imple-
mentations are not designed specifically for GI applications. ISO 19119 (ISO 2005)
proposes several design patterns that can be taken in the condition and execution of
service chains. These alternatives are also discussed in detail in a study by Alameh
(2003). Note that in this article, we only consider the latter two patterns.

Service chaining architectures

565

l User-defined chaining: the human user creates the service chain and manages its

execution.

l Workflow-managed chaining: the human user invokes a workflow management
service that controls the service chain. The user can interact with the execution of
the individual services that are part of the service chain (hence the alias of
translucent chaining).

l Aggregate service: the service chain appears as a single service, which handles all
coordination of the individual services that are part of the chain. The user may or
not be aware that there is a set of services behind the aggregate service but has no
possibility of monitoring the execution of the individual services (hence the alias of
opaque chaining).

In a study by Granell et al. (2005), a methodology is proposed for developing
service compositions based on abstract descriptions of services and workflows, from
which an executable (BPEL) workflow description is automatically derived. This
translation method is also used in the (ontology-based) service composition approach
described in a study by Lemmens et al. (2006, 2007). However, these papers do not
describe the translation step to BPEL in great detail, and the design decisions and
required user interaction for the translation remain unclear.

Some examples of implementing DGIP applications based on OGC Web
Processing Services already have been reported in the literature. Kiehle et al.
(2007) present applications for groundwater vulnerability assessment and auto-
mated land parcel information. However, the authors do not point out architectural
alternatives to the presented implementations. Bernard and Ostla¨ nder (2007) pro-
pose an SDI-based framework for the assessment of vulnerability to climate change.
The combination of several geoprocessing operations using a workflow engine is,
however, left for future research. Friis-Christensen et al. (2007) present an applica-
tion that calculates forest fire statistics based on land cover entities. Here, architec-
tural alternatives are (conceptually) discussed, namely an asynchronous interaction
pattern and several ideas to improve the efficiency of geoprocessing services.
Stollberg and Zipf (2007) present a DGIP application for a bomb threat scenario.
Also here, the authors describe several architectural alternatives, most importantly
the concepts of ‘Centralized Service Chaining’ and ‘Cascading Chaining’. An in-
depth discussion of these concepts and their implications for application develop-
ment is given in Section 4.

3.2 Components and architecture

As a framework for implementing the forest the risk assessment application, we con-
sider a generic architecture, which is an extension of the architectures presented by
Friis-Christensen et al. (2007), Bernard and Ostla¨nder (2007) and Kiehle et al. (2007). It
is based on standardised service interfaces, so that it can be used to implement not only
the presented use case, but also any other service-based DGIP application. The com-
ponents of the architecture are depicted in Figure 2. They are divided into layers
according to the type of functionality they provide. For each layer, we have included
as examples the components used as building blocks for implementing the risk assess-
ment application. Generic components are shown in light grey, while components that
have been specifically developed for the use case implementation are show dark gray.
The top layer of the architecture represents the client application that uses the

566

A. Friis-Christensen et al.

Forest Fire Risk 
Assessment

Create Symbology Description (SLD)

WMS: Render

Client 
application

Visualisation
operations

Geoprocessing
operations

WPS: Join and Aggregation

WPS: Normalise

WPS: Classify

Data access

WFS

WFS

WFS

WFS

Geodata 
repositories

Forest Fire 
Records

NUTS 
Region0

NUTS 
Region3

NUTS
Region5

Figure 2. Architecture for an application calculating forest fire risks.

O
r
c
h
e
s
t
r
a
t
i
o
n
 
(

B
P
E
L
)

visualisation operations in order to render the outcome of the analyses. The geoproces-
sing operations are used in order to provide the required results. The processing opera-
tions use data access services to obtain access to the geodata repositories. The
architecture also contains an orchestration component that links the visualisation,
geoprocessing and data access layers. The following OGC4 standards exist for the
various layers in our architecture:

Data access. Distributed data sources can be accessed through Web Feature
Services (WFS) (for vector data) or Web Coverage Services (WCS) (for raster data).
Vector data is provided using the Geography Markup Language (GML) as a common
exchange format. For the use case, we only consider vector data offered through
WFSs: the national forest fire records and administrative units (NUTS 0, 3 and 5).

Geoprocessing operations. To enable the processing of data, recently the Web proces-
sing service (WPS) interface has been specified. It offers one generic interface that can be
used to invoke a large variety of geoprocessing operations. For the use case, a join and
aggregation, a normalisation and a classification function have been implemented as
WPS operations.

Visualisation operations. The Web Map Service (WMS) interface can be used to
visualise data accessible through data access services such as WFS or within the
WMS itself. The data can be visualised using predefined or user-defined symbology
defined in an external Styled Layer Descriptor (SLD) document. SLDs can be used to
send external data, e.g., processing results, to a WMS for visualisation. For the use case,
a WPS operation has been created for generating an SLD for a given dataset (e.g., a
processing result) based on a given symbology.

Orchestration. The workflow language used is BPEL, which allows for definition of
complex workflows including parallel activities (e.g., service invocations or internal
operations on messages), conditional behaviours, activities related to events and
exceptions and, finally, the definition of Web service operations used to exhibit
implemented functionalities. In our architecture, the defined BPEL workflows have
been executed using the ActiveBPEL engine5 that is an open source tool.

The design choice of using BPEL as workflow language and ActiveBPEL as workflow
engine has two consequences on the component requirements. BPEL requires all services
in a workflow to be described using WSDL. Unfortunately, all listed OGC service

Service chaining architectures

567

interface standards do not include WSDL descriptions. Therefore, for the implementa-
tion of the use case, we have created WSDL descriptions for the WFS, WPS and WMS.
The ActiveBPEL engine requires the services in the workflow to have SOAP (W3C
2003) bindings. As current implementations of the listed OGC services currently only
provide HTTP Post and Get bindings (as required by the specifications), we implemented
wrapper components providing SOAP interfaces. A generic approach for SOAP wrap-
ping of OGC services is proposed in an OGC discussion paper (OGC 2007c).
Furthermore, in order to support passing by reference (see Section 5.2) using SOAP,
the functionality and consequently the interface of the WFS has been extended. This
extension allows the WFS to return a URL reference as a response to a getFeature request
in addition to the option of returning the data directly (as specified in the WFS specifica-
tion). To enable this, the GML data have to be stored locally with the WFS.

4.

Issues related to control flow

Workflows can be described and executed using different control flow patterns.
Section 4.1 presents the centralised control flow pattern, whereas Section 4.2 deals
with the cascaded control flow pattern. Finally, a comparative analysis between the
two approaches based on implementation issues is presented in Section 4.3.

4.1 Centralised control flow pattern

The centralised control flow pattern describes the workflow of services activities under
the perspective of a single endpoint controlling the invocations to all used services.
This implies that the workflow execution could be controlled by a single component
and, consequently, that it is not necessary to distribute details about the workflow to
other SOA components.

BPEL and XLANG (Thatte 2001) are examples of workflow languages based on this
pattern. The execution of a workflow in these languages is supported by workflow
execution engines that provide access to the service chains they offer through a specific
service interface. Such services can thus be considered as aggregate services as defined in
ISO 19119, i.e., they implement the opaque chaining pattern. On the contrary, such
workflow engines also allow the user to follow the workflow execution, thus following
the translucent chaining pattern. This illustrates that there is not necessarily a clear-cut
distinction between these two patterns.

Besides using workflow languages the centralised control flow can also be realised
implementing a client application-controlled chain. In this approach, the workflow
description is hard-coded in the client application, which then controls the execution
flow of the chain. However, this approach is particularly difficult to sustain: any
changes to the workflow require updates in the application code that can be difficult
to manage. Such changes include changing the endpoint service references, updating
the used service interface or redesigning the workflow to incorporate new improved
service funcionalities such as data quality or performance.

In the following section, we present the implementations of the Forest fire risk
assessment application based on both the client application-controlled flow and the
engine-controlled flow of the workflow conceptually described in Figure 1.

4.1.1 Client-controlled service chain. Figure 3 presents the implemented architecture
of the client-controlled service chain. In this case, the client application performs all
user interaction and the risk assessment by controlling the conceptual workflow,

568

A. Friis-Christensen et al.

WMS1

WFS1

7. Render

1. Retrieve NUTS data

WPS4

6. Create
symbology

Forest Fire
Risk Assessment
Client Application

2. Retrieve forest
fire data

WFS2

5. Classify

3. Join and aggregate

WPS3

4. Normalise

WPS1

WPS2

Figure 3. Architecture and workflow in a client-controlled scenario.

which is hard-coded in the application code. The sequence of the service operation
calls follows that of the conceptual workflow, which is hard-coded in the application
code. The sequence of the service operation calls follows that of the conceptual
workflow shown in Figure 1. The implemented client–user interface runs inside a
common Web browser. The modules on the server side use Apache Tomcat6 as a
servlet engine. This implementation of the workflow uses Mapbuilder7 as a core
module, which communicates with the services (i.e., WFS, WPS and WMS) by
means of Java Connectors. To support a flexible installation, the developed client
provides a number of configuration parameters (e.g., services endpoints, processing
operations names and attribute names) that the user can change.

4.1.2 Workflow engine-controlled service chain. The same application has been
developed using a workflow engine. In our implementation, we have chosen to control
only a part of the entire conceptual workflow through the workflow engine. More
precisely, it controls the data retrieval and the processing operations, whereas the
services for visualising the result are controlled by the client. Thus, the service chain
response contains the result of the data processing that, in order to be visualised, must
be rendered. Although this approach still leaves some of the activities under the control
of the client, it permits us to make the processing functionality more re-usable for the
following reasons: (1) other applications that differ in the way they visualise the data
could use the same service chain, and (2) the processed data returned by the workflow
execution could be used for further processing by other chains or applications.

Figure 4 depicts the architecture of the implemented application and the interac-
tions with the used services. The service created by the workflow engine is called Fire
Risk Assessment Service (FFRAS). It exhibits a service interface, which is described in
WSDL, and is based on a service chain that executes the workflow. The client (again
implemented using Mapbuilder) formulates all queries towards the FFRAS and
manages any interaction with the user. It only contains connectors for three services,
the FFRAS, the WPS used to create the symbology and the WMS for the rendering of
the results. ActiveBPEL is used as the engine for executing the workflow. The BPEL
document uses the WSDL specifications of the WFS and WPS services in order to

Service chaining architectures

569

WMS1

8. Render

Forest Fire
Risk Assessment 
Client Application

7. Create
symbology

WPS4

1. Forest Fire Risk Classes

2. Retrieve NUTS data

WFS1

Forest Fire
Risk Assessment 
Service

3. Retrieve forest
fire data

WFS2

6. Classify

4. Join and aggregate

WPS3

5. Normalise

WPS1

WPS2

Figure 4. Architecture and workflow in an engine-controlled scenario.

define the service invocations controlled by the chain. The input parameters received
by the service chain are used to prepare the required requests.

Table 1 lists the FFRAS interface definition. The interface contains three opera-
tions corresponding to the functionalities offered by the application. All the opera-
tions return processed data, more precisely a reference to such data. As an example,
we detail the ForestFireRiskClasses operation input parameters in Table 2. On the
basis of these parameters, the ForestFireRiskClasses retrieves the forest fire and
administrative unit data from WFS1 and WFS2 (steps 2 and 3). These data are passed
to WPS1, WPS2 and WPS3 to create the analysis results (steps 4–6). The visualisation
steps (steps 7 and 8) are the same as described for the client-controlled workflow.

For the viewpoint of sustainability, the benefits of using workflow engine con-

trolled chains are that

l the service chain instance can be re-used by different applications (or chained as

a single service in new chains),

l the service chain business logic, used services endpoints and related details can be

replaced without affecting client applications.

Table 1. Forest Fire Risk Assessment service interface.

Operation

Description

ForestFireFrequency

Computes the number of forest fires aggregated by administrative

unit

ForestFireDensity
ForestFireRiskClasses

Computes the number of forest fire frequency per square kilometre
Computes the forest fire risk through the classification of forest

fire frequency or forest fire density into risk classes

570

A. Friis-Christensen et al.

Table 2. ForestFireRiskClasses input paramaters.

Parameter

Description

nutsData

Information about administrative unit features (geometry property name,

forestFireData Information about forest fires features (geometry property name, feature type

query

Parameters (bounding box, date constraints) required to create the WFS

procInput

Input used for the processing operations that must be defined by the clients

(e.g., classification rules used for the risk mapping)

feature type name)

name, date property name)

requests for retrieving the data

4.2 Cascaded control flow pattern

The cascaded control flow pattern describes the workflow using the so-called back-
ward chaining approach. In this approach the service providing the required end
result is invoked directly. The remaining service invocations that are necessary for
retrieving the input parameters are handled by the invoked service. This service then
becomes responsible for the control flow of the remaining part of the workflow.
Following this pattern, it is possible to insert further levels of service invocations
thus implementing a cascading control flow of the workflow execution.

The input parameters can be passed in two possible manners: (1) by value and (2) by
passing the information on how to obtain the input data, potentially by means of
additional service invocations. A concrete example of such approach is invoking a
WPS operation where one input is obtained by retrieving data through a WFS
getFeature request; a more detailed and complex example will be presented in
Section 5.2.

Figure 5 shows the architecture and workflow for implementing the FFRAS. Here,
the control flow is distributed, i.e., the execution propagates recursively through the
various service components. A request to WPS3’s classify operation is made contain-
ing four requests that are to be propagated further. req2 is the normalise request to

WFS1

4. req4: getFeature()

Forest Fire
Risk Assessment
Service

WFS2

1. req1: classify(req2(req3(req4,req5)))

5. req5: getFeature()

WPS3

WPS1

2. req2: normalise(req3(req4,req5))

WPS2

3. req3: joinAndAgg(req4,req5)

Figure 5. Architecture and workflow in a cascaded control flow scenario.

Service chaining architectures

571

WPS2, which further contains req3 (the joinAndAggregate request) and req4 and
req5 (the getFeature requests to the WFS1 and WFS2). It is worth noting that,
although the workflow execution is controlled in a cascaded way, the FFRAS
service holds the complete workflow description and, at run-time, appoints the
used services to execute and control parts of such description by passing them in
the service invocation.

4.3 Comparative analysis

This section presents our experience based on the implementation of the use case and
compares the centralised and cascaded control flow patterns introduced above. When
considering the benefits and problems of the centralised control flow, we only con-
sider the engine-based approach, because, as discussed above, it is more suitable from
the viewpoint of re-usability and sustainability.

Current tools for BPEL facilitate the composition of services by means of graphical
tools and, based on WSDL service interface definitions, provide static type checking.
This facility helping developers to define (at least syntactically) correct workflows is
not provided when describing workflows using the cascaded control flow pattern.
Here, the creation of the service operation request including all the required cascading
service invocation has to be prepared manually.

Another aspect strictly related to service interfaces is that service chains typically
use (part of) the responses of service invocations as input for others. Therefore, it
might be necessary to perform some message adaptations between input and output
of chained services. To exemplify this aspect, consider the use case illustrated in this
article, where processed features are used as input by other processing service. More in
detail, for instance WPS3 uses the features processed by WPS2. These features are
contained in the WPS executeResponse message, which includes additional informa-
tion. Therefore, it is necessary to include the instructions for extracting pieces of
information from the various processing service invocation responses. In this respect
the centralised control flow enables a centralized handling of such data extractions
and message adaptations. Instead, in the case of cascaded control flow, these have to
be performed by the service executing the service invocation. Thus, these services have
to support sophisticated forms of code mobility (for more details see also in the
following part where dynamic conditional behaviour aspect
is concerned).
However, these aspects are less critical in the domain of SDIs compared with other
application domains. Despite some limitations that will be stated in Section 5.1.2, the
standardised OGC service interfaces and message schemas facilitate the handling of
data extraction and message adaptations.

An additional important issue is the capability of monitoring the workflow execu-
tion state. Since, with BPEL, all workflow steps are controlled in a single place, these
functionalities can be easily supported. The ActiveBPEL engine provides a console
for graphically monitoring the execution state of BPEL workflows. Thus, as men-
tioned earlier, the service chain can be considered as opaque (because it is provided as
a single aggregate service) or translucent (because its execution can be monitored).
Monitoring a workflow execution state of an application using the cascaded control
flow is more complex. For example, for verifying whether the joinAndAggregate
processing step of WPS1 is still running, it is necessary to verify whether the two
WFS getFeature operations have been completed and that the WPS2 is still waiting
for the input from WPS1 (see Figure 5).

572

A. Friis-Christensen et al.

The two approaches also differ considerably with respect to error handling. All the
run-time exceptions (e.g., invalid getFeature requests or missing input parameters)
can be easily managed by the programmer using the centralised control flow pattern,
where each invocation response is received by the workflow engine. Furthermore,
workflow languages as BPEL and XLANG provide specific mechanisms for the error
handling (Lucchi and Mazzara 2007) including the compensations that should be
done in case of faults. When using a cascaded control flow, it can often happen that
the received exception message is misinterpreted. Consider, for instance, the case
where one of
shown in Figure 5 returns an exception
(e.g., unsupported query language). In this case, WPS1 cannot successfully complete
the processing operation and returns an error message to the WPS2, which will do the
same with WPS3. It is clear that tracing the origin of the exception can be a very
complicated and time-consuming task for the programmers. Furthermore, the hand-
ling of the first raised exception might potentially occur at a very late stage of
execution (e.g., in the case of unsupported query language only the client submitting
the request to WPS3 can deal with the problem).

the two WFSs

Another important aspect in the comparison of the two patterns is the dynamic
handling of cases in which the workflow behaviour depends on intermediate data. In
certain situations it can be necessary to follow different branches in the workflow or to
execute certain operations depending on the values of certain parameters that are only
known at runtime. In the case of centralised control flow, such dynamic behaviour can
be directly controlled by the workflow engine. In the case of cascaded control flow, the
workflow of all subsequent services to be called after the invocation of a certain
service have to be passed as input parameters to that service. To implement condi-
tional behaviour, the condition would also have to be passed as an input parameter.
This means that services used for cascaded control flow would have to support strong
forms of code mobility [for a survey on mobility in SOC see Guidi and Lucchi (2007)],
which would greatly complicate the development of each service.

Table 3 summarises the comparative analysis. In the remaining part of the article,
additional consideration will be presented, and in particular in Section 5.1.1 perfor-
mance aspects related with data transfer will be discussed.

Table 3. Centralised versus Cascaded control flow.

Aspect

Centralised

Cascaded

Workflow languages

Mature languages and tools

No design and validation tools,

I/0 handling

High flexibility for schema

manipulation

exceptions

activities

Error handling

Immediate compensation at

Potential delayed compensation at

Execution monitoring

Simple for centrally controlled

Complex for cascading activities
(as much as error handling)

Dynamic control flow

Centralised execution state

Complex because it requires

Data transfer

makes it simple to program

Potential redundant data

complex forms of code mobility
Data retrieval only when necessary

limited expressiveness
(e.g., conditions or exceptions)
Requires complex forms of code

mobility

exceptions

transfer passing through the
central coordinator

Service chaining architectures

573

5.

Issues related to data flow

In this section, we present the challenges and issues we have identified concerning the
data flow of a service chain. Although we have faced a number of minor technical
challenges, in this section we concentrate on two overall issues. Firstly, the encoding
of data, which has implications for the expected input/output of services involved in a
chain. Secondly, the pattern for transporting data among involved services, either by
reference or by value. The pattern has consequences for the amount of data trans-
ferred over the network.

5.1 Encoding of data

Basing the architecture on existing OGC standards for services has some conse-
quences on data encoding. In particular, the features provided by WFS (i.e., forest
fires and administrative units data) exchanged among services are encoded using
GML. Although GML is a standard and is well-defined, it has some implications
for the execution of workflows. In the following, we consider two significant types of
issues: Performance-related issues and issues related to GML data types at the inter-
face level.

5.1.1 Performance-related issues. In general, several performance related issues can
be listed. Firstly, when executing a workflow, the computational time has to be
considered. The computational time required to execute a complete workflow may
be so long that an asynchronous control pattern has to be used in order to prevent,
e.g., timeout issues for the invoker or long wait for a response. Secondly, the time
required to parse and validate a certain GML data stream has to be considered. This is
particularly true for large amounts of data, and again this may lead to the selection of
other control patterns. Finally, the transport of the data itself may impact perfor-
mance. This is the performance issue, which we discuss here.

As GML is text-based, it consequently has a substantial overhead when represent-
ing geographic data compared with a binary representation. An example that illus-
trates this fact is that 26.000 point data entries each representing a forest fire will
require 20 MB represented in GML compared with, e.g., less than 4 MB which is
required for an ArcGIS shapefile. Considering that 26.000 fires is the number of forest
fires for 1 year (2002) in Portugal, it easily exemplifies the magnitude of data required
in order to cover all countries in Europe for, e.g., 10 years. Even more problematic is
polygon data with high precision (e.g., NUTS5). These have a large number of
vertices, which in GML becomes much more space demanding compared with,
e.g., a shapefile as mentioned before.

It is clear that transportation of large amounts of data over the Internet does not
guarantee a high system scalability in terms of performance. The problem could be
addressed by compressing the data before transferring it among services (Yang et al.
2005). However, this requires that the format of exchanged data (e.g., GML or
compressed GML) can be specified in the service request. In the case of WFS, this
would require changes to a well-known service interface and inhibit interoperability.
An alternative solution based on a different data flow pattern is discussed in
Section 5.2.

5.1.2
Interface level issues. When composing a workflow, the application developer
has to be aware of the schema of the output data produced by a service (e.g., a WFS)
as well as the schema of the input data expected by a consuming service (e.g., a WPS).

574

A. Friis-Christensen et al.

Typically, these two schemas will not match exactly, and part of the output data have
to be extracted and transformed to match the input schema. In BPEL, this can, e.g., be
done using XPath (W3C 1999a) and XSLT (W3C 1999b) expressions. In the BPEL
description implementing the described use case, such transformation statements
constitute the main part of the document.

One problem of OGC services is that in some cases the interface specifications rely
on generic data types when defining input and output operation parameters. The
specific schemas used are specified by service providers for each service instance, and
they are offered through dedicated operations. This is the case, for instance, of the
WFS and WPS for the getFeature and execute operations, respectively. If, on the one
hand, this approach permits us to have a common abstract interface for all WPS and
WFS, on the other hand, it raises some problems when dealing with service composi-
tion. In the following we base our discussion on this issue using the WFS and WPS
examples.

In the WFS specification, the getFeature output is specified to be a GML feature
collection. The GML specification, however, only defines a feature at an abstract level;
the specific schema for each feature type has to be specified in a GML application schema
(OGC 2007a). Thus, the problem is to define a static output type for a WFS output.
Because each feature type is associated with its own application schema, a standard
interface for the output type of the WFS cannot be defined. Thus, there is no concrete
feature type schemas specified in the WSDL describing the WFS, which is required as
part of the BPEL description. Currently, the only way to find out about a feature type’s
application schema is by calling the WFS’s describeFeatureType operation.

The use of the generic GML feature collection schema is also a problem when it is
included in the input parameters of a service operation. The invoker of such service
operation will expect to use a document that conforms to the service (generic)
signature and might send feature collections that do not pass a validation process.

Similarly to the problems described above, the schemas for the WPS execute
operation request and response messages do not define any specific input and output
parameters as they are generic and can be used for any geoprocessing operation that is
offered. For instance, in the XML schema describing the execute operation, complex
input paramaters are to be included within a specific input field whose type is defined
as xs:anyType, i.e., any XML structure is acceptable. In the WPS, the exact schema
(or more precisely, an XML document template) of each processing operation request
and response can be obtained using the describeProcess operation.

The issues with the WPS show that the problem is not limited to the use of GML at
the interface level. It is a more general issue, where the design choice is based on
dynamic service descriptions (obtained in this case by means of specific operations
such as describeProcess or describeFeatureType) rather than having well-described
interfaces with well-defined data types. Whereas such designs may be advantageous in
some situations, it clearly complicates application implementations relying on strong
typing and well-described interfaces (such as BPEL workflows).

The main drawback of the ‘weak typing at interface level’ approach in a services
composition implemented in BPEL, is that no static type checking can be performed
on the BPEL document. That means that errors will only become apparent at run-
time. Also, service providers are free to change the schema of a feature type or the
signature of a geoprocessing operation without having to change the interface of the
service providing access to them. In this case, a BPEL process that has previously
worked fine might after the change cause an error during the execution.

Service chaining architectures

575

5.2 Data flow patterns

In Section 4, we outlined the aspects related to the control flow of an executable
workflow description. Concerning data flow, several patterns for how data are
transported, represented, and utilised in workflows have been identified, see
e.g., Russell et al. (2004). Two overall patterns relevant for the implementation of
our use case are identified: Data passing by value and data passing by reference. Data
passing by value imply that data are transferred among each participant in the
workflow. A shared address space and unique identification of data is not required.
Data passing by reference imply shared data. Most importantly it requires that a
shared store is available and additionally that each source is uniquely identifiable by a
reference. An issue is how to maintain the shared store, i.e., the responsible entity for
the shared data and the decision of when to purge it. It could be the job of a centralised
control engine; however, it can also be the ‘creator’ component (the owner).

5.2.1 Data flow in centralised control workflows. In Figure 6, we illustrate the data
flow for the service chain that is featured in the use case. Only a subset of the service
chain has been depicted for simplicity reasons. More specifically, the two WFS
requests for data and the first call to the joinAndAggregation WPS have been
included. This corresponds to the ‘Forest Fire Frequency’ analysis. In Figure 6(a),
the data flow matches the control flow, i.e., the data are transferred by value through
the controlling entity (in this case a central one). The two first invocations of the WFS
with getFeature operations return GML data (GML1 and GML2), which has to be
stored in the FFRAS. These transactions are (or at least can be) data intensive as also
the WPS and the
mentioned in Section 5.1.1.The
JoinAndAggregate operation assumes two GML datasets as input, which are
included in the invocation request (GML1 and GML2). The operation returns yet
another GML data stream (GML3). It is clear that this data flow pattern is highly data
intensive; in summary, for this service chain subset, five of the parameters transmitted
over the network contain GML data. Considering a possible architecture with dis-
tributed services on the Internet, the data transmission times may greatly reduce
performance of the overall execution of a given workflow.

third invocation of

Figure 6. Data flow patterns using a centralised control flow.

576

A. Friis-Christensen et al.

WFS1

GML1

2. getFeature()

1. join&Agg()

url1 (to GML3)

WFS1

GML3

3. getFeature()

WFS2

GML2

Forest Fire
Risk Assessment 
Service

request
request (data intensive)
response
response (data intensive)

Figure 7. Data flow pattern using a cascaded control flow.

In Figure 6(b), the data flow is decoupled from the control flow meaning that the data
are not necessarily transferred through the controlling entity. Here, the two getFeature
invocations return a URL to GML data (URL1 and URL2), which are then passed to
the WPS in the JoinAndAggregate request. The GML date (GML1 and GML2) are
then retrieved by the WPS itself. After processing, the WPS returns a reference to the
result (URL3). In this pattern, only two data intensive transmissions have been per-
formed (three in the case that a client retrieves the data as also indicated in the figure). In
conclusion, for data intensive workflow executions, the decoupling of data and control
flow is beneficial for performance reasons. Decoupling of data and control flow can be
achieved using the data passing by reference data flow pattern.

It is important, however, to mention the implications at the interface level when
using data passing by reference. The type that occurs in the interface description of the
services (and hence in the BPEL process) is xs:anyURI, whereas the data being
referenced is of another type. This means that the actual data type is hidden at the
interface level, which complicates a type checking and further validation/parsing. The
problem is equivalent to the interface level issues presented in Section 5.1.2.

5.2.2 Data flow in cascaded workflows. As discussed in Section 4.2, another control
flow pattern is the decentralised cascaded workflow execution (Figure 5). The data flow
pattern for this control flow is depicted in Figure 7. It can be seen that the data flow
matches the control flow. This is always true because it is an implication of the back-
ward chaining approach, no matter if the data are passed by value (as shown for GML1
and GML2) or are passed by reference (as shown for GML3).

Another interesting point is that the data flow presented in Figure 7 is the same as
the data flow presented in Figure 6(b). However, the control flow patterns are
completely different. For discussions of the properties of various control flow pat-
terns, we refer to Section 4.

6. Conclusions and outlook

In this article, we investigated SOA for DGIP through value-added service chains. To
achieve this, we have introduced a basic architecture for developing DGIP applica-
tions for forest fire risk analysis. The architecture is based on OGC Web services and

Service chaining architectures

577

orchestration using BPEL. We have illustrated a number of architectural alternatives
when designing the control and data flow for a GI service chain. To provide a proof-
of-concept, the architecture alternatives have been tested in a forest fire application
prototype. This prototype is not suitable for quantitative analyses such as for perfor-
mance and scalability, but these analyses are clearly a logical part of our future work.
However, by discussing conceptual design choices and their problems and benefits, we
hope to provide guidance to developers implementing distributed applications based
on service chains.

Regarding the control flow aspect, the application developer has to decide on
whether to choose a centralised or a cascaded control pattern. The benefits and
drawbacks associated with each of these options have been discussed in Section 4.3
where it clearly emerges that having a centralised control flow facilitates execution
monitoring, conditional behaviour and error handling. Besides these aspects, this
article also points out that having a dedicated service, exhibiting the functionalities
offered by a workflow, simplifies the application design. In particular, this is true for
the client implementation as also concluded in a study by Kiehle et al. (2007).

An important issue concerning the data flow is the architectural choice of sending
data by reference or by value. For service chains that involve large amounts of data
and/or many data transfers (see example in Section 5.1.1 on forest fire data), we
recommend separating the data flow from the control flow, i.e., to use the ‘send data
by reference’ pattern. It reduces the data to be sent through the network substantially,
without losing the possibility of monitoring the execution of a workflow. The same
data flow could be obtained by a cascaded control flow. However, as described in
Section 4.2, the possibility to centrally manage, e.g., exception handling, is lost. In
conclusion, in DGIP, using a BPEL-based implementation, we recommend to send
data by reference using a centralised control flow.

It is worth emphasising that the discussed architectural alternatives regarding
control and data flow patterns and the corresponding advantages and disadvantages
are independent of both the workflow language and of the platform. This means that
the proposed architectural alternatives could be implemented using advanced SOAs
devoted to massive computing like using grid services. For instance, in Chen et al.
(2009), an abstract language for describing information processes based on workflows
is used as specification for creating executable BPEL processes generating new GI by
invoking grid services and Web services. Their approach could be complemented by
considering the proposed control and data flow patterns (see Sections 4 and 5) when
creating executable service chains.

Still unresolved are the interface level problems presented in Section 5.1.2.These
mainly concerns the lack of a strongly typed interface that inhibits, e.g., the validation
of service input/output (in particular GML feature collections). The WPS specifica-
tion (OGC 2007b) goes a step in this direction by offering (optionally) the possibility
to describe each offered geoprocessing operation by its own WSDL document.
Another way to address the problem is to define complex request and response
types including a schemaLocation attribute that points to the schema defining the
type. Thus, a validation could be handled on the fly for each feature collection
instance. The general question remains whether the approach to keep the service
interface generic and hide the data types is beneficial or whether it actually inhibits
interoperability.

Finally, another important aspect is related to the computational time used by service
chains: The total amount of time used to execute a workflow can be very long, thus

578

A. Friis-Christensen et al.

requiring the usage of an asynchronous control pattern. To avoid users having to wait
for the response, the asynchronous interaction pattern provides a mean for separating
the service invocation from the retrieval of the processing result. We have already
discussed this pattern in a study by Friis-Christensen et al. (2007) and are currently
working on an alternative implementation of the FFRAS based on event notification
(in our case, by Email). Investigating asynchronous interaction more closely, including
possible other solutions for asynchronous interaction such as polling and operation
callback, will be part of our future research.

Acknowledgement
The work presented in this article has been supported by the European Commission
through the ORCHESTRA project (grant number IST-2002-511678). We also thank
Angelo Quaglia for providing input on GML validation and parsing and our collea-
gues from Intecs for providing the implementation of the client(s) referred to in the
article.

Notes
1. Available at http://www.eu-orchestra.org/links.shtml
2. We use geoprocessing and GI processing interchangeably.
3. The Nomenclature of Territorial Units for Statistics (NUTS) is provided by Eurostat as a
single uniform breakdown of territorial units for the production of regional statistics for the
European Union (see also http://ec.europa.eu/comm/eurostat/ramon/nuts/home_regions_
en.html).

4. All adopted OGC standards are available from http://www.opengeospatial.org/standards
5. http://www.active-endpoints.com. It is worth noting that any findings in the paper are
independent of the used BPEL engine. The choice is mainly based on the fact that
ActiveBPEL is free software and that it is fully compliant with the BPEL specification.

6. http://tomcat.apache.org/
7. http://communitymapbuilder.osgeo.org/

References
ALAMEH, N., 2003, Chaining geographic information Web services. IEEE Internet Computing,

7(5), pp. 22–29.

BERNARD, L. and OSTLANDER, N., 2007, Assessing climate change vulnerability in the arctic
using geographic information services in spatial data infrastructures. Climatic Change,
Special Issue – BALANCE: an attempt to assess climate change impacts in the Barents
Sea Region.

BERNARD, L., KANELLOPOULOS, I., ANNONI, A. and SMITS, P. 2005, The European Geoportal –
one step towards the establishment of a European spatial data infrastructure.
Computers, Environment and Urban Systems, 29, pp. 15–31.

CHEN, A., et al., 2009, Use of Grid computing to model virtual geospatial products.
International Journal of Geographic Information Science, 23(5), pp. 581–604.
EINSPANIER, U., et al., 2003, Toward a Process Model for GI Service Composition, pp. 31–46

(Mu¨ nster, Germany: Institute for Geoinformatics, University of Mu¨ nster).

ESA, 2004, Service support environment. Architecture, model and standards. whitepaper.

Technical report, European Space Agency.

EUROPEAN COMMISSION, 2005, Spatial data infrastructures in Europe, state of play Spring 2005:
Summary Report of Activity 5 of a Study Commissioned by the EC (EUROSTAT &
DGENV) in the Framework of the INSPIRE Initiative. Technical report, European
Commission, Brussels.

Service chaining architectures

579

EUROPEAN COMMISSION, 2006, Forest fires in Europe 2005. Official Publication of the European

Communities EUR 22 321 EN (Ispra, Italy: European Commission).

FRIIS-CHRISTENSEN, A., OSTLA¨ NDER, N., LUTZ, M. and BERNARD, L., 2007, Designing service
for distributed geoprocessing: challenges and future directions.

architectures
Transactions in GIS, 11(6), pp. 799–818.

GRANELL, C., GOULD, M. and ESBRI´, M.A., 2008, Geospatial web service chaining. In H.A.

Karimi (Ed.), Handbook of Research on Geoinformatics (Hershey, PA: IGI Global).

GRANELL, C., GOULD, M. and RAMOS, F., 2005, Service composition for SDIs: integrated

components creation. Copenhagen, Denmark: IEEE, 475–479.

GUIDI, C. and LUCCHI, R., February 2007, Formalizing mobility in service oriented computing.

Journal of Software (JSW), Academy Publisher, 2(1), pp. 1–13.

ISO, 2005, ISO 19119:2005 Geographic information – services. International standard, ISO TC

211.

KIEHLE, C., GREVE, K. and HEIER, C., 2007, Requirements for next generation spatial data
Infrastructures-standardized web based geoprocessing and web service orchestration.
Transactions in GIS, 11(6), pp. 819–834.

KLOPFER, M. and KANELLOPOULOS, I. (Eds), 2008, ORCHESTRA. An Open Service Architecture
for Risk Management. ISBN 978-3-00-024284-7. ORCHESTRA Consortium, available
online at: http://www.eu-orchestra.org/docs/ORCHESTRA-Book.pdf (accessed 30
October 2008).

LEMMENS, R., et al., 2006, Integrating semantic and syntactic descriptions to chain geographic

services. IEEE Internet Computing, 10(5), pp. 42–52.

LEMMENS, R., et al., 2007, Enhancing geo-service chaining through deep service descriptions.

Transactions in GIS, 11(6), pp. 849–871.

LUCCHI, R. and MAZZARA, M., 2007, A pi-calculus based semantics for WS-BPEL. Journal of

Logic and Algebraic Programming, 70(1), pp. 96–118.

NEBERT, D.D., 2004, Developing Spatial Data Infrastructures: The SDI Cookbook, available
online at: http://www.gsdi.org/docs2004/Cookbook/cookbookV2.0.pdf (accessed 30
October 2008).

OASIS, 2006, Reference model

for service oriented architecture 1.0. Technical report,

Organization for the Advancement of Structured Information Standards.

OASIS, 2007, Web services business process execution language (WS-BPEL), version 2.0.
Technical report, Organization for the Advancement of Structured Information
Standards.

OGC, 2007a, Geography markup language (GML) encoding standard v3.2.1. Technical report

OGC 07-036, Open Geospatial Consortium Inc.

OGC, 2007b, Web processing service v1.0.0. Implementation specification OGC 05-007r7,

Open Geospatial Consortium Inc.

OGC, 2007c, Wrapping OGC HTTP-GET and -POST services with SOAP - discussion paper.

Technical report OGC 07-158, Open Geospatial Consortium Inc.

RUSSELL, N., et al., 2004, Workflow data patterns. QUT Technical report FIT-TR-2004-01,

Queensland University of Technology.

STOLLBERG, B. and ZIPF, A., 2007, OGC Web Processing Service Interface for Web Service
Orchestration – Aggregating Geo-Processing Services in a Bomb Threat Scenario, pp.
239–251 (Cardiff, UK: Springer).

THATTE, S., 2001, XLANG: Web Services for Business Process Design, available online at:
Corporation

http://msdn.microsoft.com/en-us/library/aa577463.aspx, Microsoft
(accessed 30 October 2008).

TU, S., FLANAGIN, M., WU, Y., ABDELGUERFI, M., NORMAND, E., MAHADEVAN, V., RATCLIFF, J.
and SHAW, K., 2004, Design strategies to improve performance of GIS Web services.
ITCC (2)IEEE Computer Society, 2, pp. 444–448.

W3C, 1999a, XML path language (XPath), version 1.0. Technical report, W3C.
W3C, 1999b, XSL transformations (XSLT), version 1.0. Technical report, W3C.

580

A. Friis-Christensen et al.

W3C, 2001, W3C: web services description language (WSDL) 1.1. Technical report, W3C.
W3C, 2003, SOAP version 1.2. Technical report, World Wide Web Consortium.
YANG, C., WONG, D., YANG, R., KAFATOS, M. and LI Q., 2005, Performance improving
techniques in WebGIS. International Journal of Geographical Information Science,
19(3), pp. 319–342.

YANG, P., EVANS, J., COLE, M., MARLEY, S., ALAMEH, N. and BAMBACUS, M., 2007, The
emerging concepts and applications of the spatial web portal. PE&RS, 73(6), pp.
691–698.

