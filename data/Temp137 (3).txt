bs_bs_banner

Research Article

Transactions in GIS, 2014, 18(S1): 109–125

Modeling Users’ Behavior for Testing the Performance of
a Web Map Tile Service

Xuefeng Guan, Bo Cheng, Aihong Song, and Huayi Wu

Wuhan University

Abstract
Web Map Tile Services (WMTS) are widely used in many ﬁelds to quickly and efﬁciently visualize
geospatial data for public use. To ensure that a WMTS can successfully fulﬁll users’ expectations and
requirements, the performance of a service must be measured to track latencies and bottlenecks that may
downgrade the overall quality of service (QoS). Traditional synthetic workloads used to evaluate WMTS
applications are usually generated by repeated static URLs, through randomized requests, or by an access
log replay. These three methods do not take request characteristics and users’ behaviors into considera-
tion, while access logs are not available for systems still under development. Thus, the evaluation out-
comes obtained by these methods cannot represent the real performance of online WMTS applications.

In this article a new workload model named HELP (Hotspot/think-timE/Length/Path) is proposed to
measure the performance of a prototype WMTS. This model describes how users browse a WMTS map
and statistically characterizes complete map navigation behaviors. Then, the HELP model is implemented
in HP LoadRunner and used to generate a synthetic workload to evaluate the target WMTS. Experimen-
tal results illustrate that the performance representation of the HELP workload is more accurate than that
of the other two models, and how a bottleneck in the target system was identiﬁed. Additional statistical
analysis of request logs and “hotspots” visualizations further validate the proposed HELP workload.

1 Introduction

Tile-based Web mapping services are becoming increasingly popular for providing fast visuali-
zation of large-scale geospatial data over the Web. The Open Geospatial Consortium (OGC)
released a speciﬁcation for tile-based Web mapping services, the Web Map Tile Service
(WMTS) (Masó et al. 2010). Instead of creating a new image for each request in the Web Map
Service (WMS) implementation, the WMTS directly returns small pre-generated images to
users. WMTS provides an open-source alternative to proprietary Web mapping services, such
as Google Maps and Microsoft’s Bing Maps.

The exponential growth in the number of map users over the past few years has saturated
the capability of Web servers causing a performance downgrade in hosted Web services. There-
fore, to maintain the quality of service (QoS), it is important to understand the statistical prop-
erties of Web trafﬁc so as to develop realistic trafﬁc models to evaluate the performance of
Web applications.

Performance evaluation is a technique whereby synthetic workloads are submitted to a
target system in a controlled environment (Hashemian et al. 2012). In order to evaluate
WMTS applications, synthetic workloads are typically generated by repeated static URLs,

Address for correspondence: Aihong Song, Wuhan University State Key Laboratory of Information Engineering in Surveying, Mapping
and Remote Sensing Wuhan, China. E-mail: songaihong@whu.edu.cn
Acknowledgements: This work is supported by the Natural Science Foundation of China (Grant: 41301411) and the National High Tech-
nology Research and Development Program of China (Grant: 2012AA121401).

© 2014 John Wiley & Sons Ltd

doi: 10.1111/tgis.12123

110

X Guan, B Cheng, A Song and H Wu

randomized requests, or access log replays. However, there are many unique patterns in the
user requests to the WMTS, such as hotspots or navigation paths. These generation methods
do not involve request characteristics and user behaviors except for access log replays, but
these access logs are usually unavailable for systems which are still in development. Thus per-
formance measures obtained by these three evaluation methods cannot match the real perfor-
mance of the actual online WMTS application.

This article describes a novel approach to evaluate one prototype WMTS by constructing
an accurate synthetic workload that mimics user navigation behaviors. The new workload,
named HELP (Hotspot/think-timE/Length/Path), simulates the steps in the whole navigation
sequence of browsing a WMTS map, and statistically characterizes request patterns, including
hotspots, session length, think time, and session path. These workload pattern characteriza-
tions are based on those observed either in real Web map applications or in practice during
map interactions.

A comparative experiment was carried out to test the performance of the target WMTS
using different workloads, including static workload, random workload, and the proposed
HELP workload. Experimental results illustrate that the performance representation of the
HELP workload is more accurate than that of the other two models and that a system bottle-
neck was identiﬁed.

The remainder of the article is organized as follows. Section 2 presents a review of work-
load generation approaches and performance evaluation tools. The new evaluation workload
for the target WMTS system is explained in Section 3. Section 4 presents the results and a dis-
cussion of the experiments. Section 5 closes the article with our conclusions.

2 Background and Related Work

2.1 Workload Generation Approaches

The performance of a Web service has a direct impact on user experience. In addition to
service optimization (Yang et al. 2005, Masó et al. 2011) performance evaluation is indispen-
sable when developing an understanding of system capacity efﬁciently to further improve user
experience. The key issue in performance evaluation is how to pressure these systems under
realistic workload conditions before online operation. Generated workloads must be repre-
sentative of real online workloads and preserve the important characteristics of real trafﬁc.
There are several approaches to generate a stream of Web requests for performance evaluation.
These workload generation approaches fall into two categories, request-based or session-
based.

Most of the currently available request-based methods usually generate a workload by
constructing sequential HTTP requests from benchmark clients. These sequential HTTP
requests are formed from either repeated static URLs or dynamic randomized URLs. If there
are pre-recorded access logs from Web servers, these logs can also be replayed to generate
benchmark requests. For request-based methods, the generated sequential requests are sent
to the target system in a batch mode with no dependence between requests. Request-
based methods test the maximum capacity of a Web server by requesting objects as quickly as
possible.

In contrast to request-based methods, session-based workload generation approaches
model real users and simulate individual request sessions. Dependencies are very common
between requests in a Web service session. The core of the session-based evaluation method is
session modeling. In a session-based approach, workload characteristics are usually speciﬁed

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

Modeling Users’ Behavior for Testing the Performance of a Web Map Tile Service

111

by several mathematical probability distributions (Andreolini et al. 2002). These probability
distributions are then used to generate random values that reproduce all the statistical charac-
teristics of the request stream during each performance evaluation round. The parameters of
these probability distributions are studied and taken as inputs to guarantee accuracy of the
generated workload. Many researchers have focused on Web workload characterization,
including document size, transfer times, request arrivals, session length, think times (Barford
et al. 1999, Iyengar et al. 1999, Busari and Williamson 2002, Latouche and Remiche 2002,
Williams et al. 2005, Ortega and Aguillo 2010).

However, these evaluation approaches cannot be directly used to test WMTS applications.
The request-based approach is straightforward to implement but lacks the ﬂexibility required
to generate different workloads under different conditions. The session-based approach uses
mathematical models for the workload characteristics and offers a lot of ﬂexibility, but the
access patterns for Web map services are very different from the non-geospatial Web services,
which are typically evaluated using session-based approaches. In a Web map service, individ-
ual map users browse areas of interest by zooming in, zooming out, and panning in the tiled
pyramid space. Many users focus on the same places of interest and concentrate their interac-
tions on only a small part of total tiles. Therefore, an evaluation workload suitable for Web
map services must be designed to address the special access patterns.

2.2 Performance Evaluation Tools

Numerous performance evaluation tools for Web applications have been developed, e.g.
httperf (Mosberger and Jin 1998), SURGE (Barford and Crovella 1998), S-Client (Banga and
Druschel 1999), WAGON (Liu et al. 2001), and SWAT (Diwakar 2006), Siege, Tsung, Apache
Bench(AB), Webbench(WB), WebStone(WS), Web Polygraph(WP), etc. Most of them are free,
open-source tools with centralized or distributed architectures. In a centralized architecture an
instance of the workload generator runs on a single node, while for distributed architectures
the workload can be generated across multiple nodes. In addition to these free tools, powerful
commercial testing tools are also available for users, e.g. HP LoadRunner (HP LR).

HP LoadRunner is the industry standard for application performance testing. Using
limited hardware resources, it can simulate hundreds or thousands of concurrent users so as to
put the application through the rigors of real-life user loads. HP LoadRunner is extremely ﬂex-
ible to customize and enables users to test a range of applications including HTML 5, mobile,
.NET, and Java.

A comparison of the currently available testing tools is provided in Table 1 according to
and model

architecture, workload model,

including usage

license,

features,
their
customization.

3 HELP Workload for WMTS Performance Evaluation

This section describes a novel workload structure for the target WMTS. Section 3.1 describes
the unique characteristics of the WMTS request workload. The workload model and request
generation system are described in Section 3.2.

3.1 Characteristics of WMTS Requests

Traditional Web applications lead users logically between different pages by hyperlinks. A
WMTS map does not contain hyperlinks, so users zoom and scroll in the tile pyramid without

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

112

X Guan, B Cheng, A Song and H Wu

Table 1 A comparison of mainstream testing tool features

Features

Httperf Siege AB Tsung WB WS WP HP LR

License

Open-source
Commercial
Centralized
Distributed
Workload Model Trace-based

Architecture

Platform

Customization

Session-based
Linux/Mac
Windows
Model Customization

✓

✓

✓
✓
✓

✓

✓

✓

✓
✓

✓ ✓

✓

✓
✓ ✓
✓
✓ ✓
✓

✓

✓

✓

✓

✓
✓

✓

✓

✓

✓

✓

✓
✓
✓
✓

✓

✓
✓

✓
✓

✓
✓

clicking hyperlinks. The basic unit for individual users browsing a WMTS map is a map page.
One map page usually contains up to 20∼30 map tiles which are shown in the rectangular
computer screen. From opening to closing the WMTS map, all the map pages that one user
browses form a single session.

Requests to a WMTS system are typically characterized using the following four attrib-
utes: session length, session path, think time, and tile popularity (hotspots). The ﬁrst three
attributes can be used to describe the behavior patterns of individual WMTS users. The last
attribute represents the whole application dynamic, i.e. aggregated user behaviors.

3.1.1 Session length

We deﬁne a k-session as a sequence of k map pages browsed by one unique user. It is therefore
important to characterize the probability distribution of session length k. Several studies pre-
senting analyses of real Web server workloads suggest that session length follows a Weibull
distribution, one of the heavy-tailed distributions (Ortega and Aguillo 2010). The probability
density function of session length can be expressed by Equation (1):

where f0 is the normalized initial probability of session length, and λ is the decay coefﬁcient of
the heavy-tailed probability density curve.

(
f k
;

,λ

) =

f

0

f

0

× ×
λ
e k

(1)

3.1.2 Session path

For each user session, the center tile of k continuous pages can form a k-step navigation path
in the tile pyramid. The center of each tile can be located by a coordinate tuple: the layer level
l in the pyramid (l is 0 to lmax from the top to the bottom), the row number r and column
number c in the level l. For one step in a k-step session path, each operation direction (zoom-
in, zoom-out or pan) will determine the center tile of the next map page. The following empiri-
cal patterns can be observed in the practical operational experience of users:

1. When l is 0, the operation a user can zoom in; when l is lmax, the user can zoom out to the

upper levels or pan into the bottom level.

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

Modeling Users’ Behavior for Testing the Performance of a Web Map Tile Service

113

Figure 1 The three operation trends during a WMTS map navigation process

2. When l is small, a user commonly zooms in to ﬁnd more detailed information around a
point of interest. As the level l increases, the trend of a zoom-in operation decreases.
3. As the level l increases, the trend for pan and zoom-out operations will increase together,

but the trend of pan operation increases more sharply.

According to these empirical patterns, we can formulate three probability distributions

(listed as Equation 2, 3, and 4) to model one user’s operation direction:

Zoom In:

(
f l

;

) = − ⎛
λ
1
⎝

λ

⎞
⎠

l

l

max

(

l

=

0
,

f

=

1
;

l

=

l

,
max

f

=

)

0
;

:
Zoom Out

(
f l w
;

,

λ

) =

w

*

(

l

=

0
,

f

=

0
;

l

=

l

,
max

=
f w

;

)

Pan:

(
f l w
;

,

λ

) =

−(
1

w

(

l

=

0
,

f

=

0
;

l

=

l

,
max

f

= −
1

)

w

;

λ

⎞
⎠

l

l

max

⎛
⎝

l

)⎛
⎝

l

max

λ

⎞
⎠

(2)

(3)

(4)

where w is the proportion of a zoom-out operation trend on a pan operation trend at each
pyramid level, and λ is the decay coefﬁcient of the probability density curve of a zoom-in
operation.

Figure 1 illustrates each operation trend during the navigation process when a single user

is browsing a WMTS map (e.g. w = 0.9, λ = 3).

3.1.3 Think time

Think time refers to the time taken by a user to request a new page when beginning to view
the current map page. Several studies of actual Web workloads have suggested a heavy-tailed
distribution for think time (Barford and Crovella 1998, Crovella and Bestavros 1997). The
cumulative distribution function of think time can be modeled as in Equation (5).

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

114

X Guan, B Cheng, A Song and H Wu

Figure 2 A Hotmap from Microsoft Bing Maps (Fisher 2007)

where k is the empirical mean think time, and α is the heavy-tail coefﬁcient of probability
density curve of think time. The probability distribution for think time can be obtained by
Equation (6):

(
F x k
;

, α

) = −
1

α

⎛
⎝⎜

⎞
⎠⎟

k
x

(

;
f x k

) =
, α α α
k x

− +(
α

)1

3.1.4 Tile popularity

The tile popularity attribute describes the relative popularity of different tiles at different
pyramid levels. Tile popularity impacts performance since popular tiles can be served from the
Web server system’s caches (e.g. processor cache, physical memory) as opposed to being served
from a physical disk. Recent studies of real WMTS request workloads have shown that tile
popularity follows a Zipf-like distribution (Garcıa et al. 2011, Li et al. 2012). A Zipf-like dis-
tribution for tile popularity means a very small set of tiles in the pyramid account for a large
fraction of user requests. Speciﬁcally, the number of requests for the i-th most popular ﬁle is
inversely proportional to iα (the Zipf exponent α is non-negative), illustrated by Equation (7).
Larger α values deﬁne greater concentration of requests for a few popular ﬁles.

(
f i

; α

) =

C
α
i

Hotmap (Fisher 2007) provides a world view of tile popularity in Microsoft’s Bing Maps.
Illustrated by the Hotmap (Figure 2), tile popularity tends to follow human population density.
The more populated areas in the world receive more tile requests in the tile pyramid. However,
there are some exceptions to population distribution because users usually ﬁnd features of
interest, e.g. roads, shorelines, and the boundaries of available imagery.

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

(5)

(6)

(7)

Modeling Users’ Behavior for Testing the Performance of a Web Map Tile Service

115

3.2 Realistic WMTS Request Load Generation

The proposed HELP workload model is composed of four important features that mimic one
WMTS request session, i.e. starting point, session length, think time and session path. In this
model, the starting point together with a predeﬁned level can deﬁne the center tile of the ﬁrst
map page; session lengths are generated following the probability distribution; and a full
session can be built by generating a sequence of map pages connected by continuous naviga-
tion directions between each page. Think time is used by HP LoadRunner when issuing each
page URLs of one session to the target WMTS system.

3.2.1 Selection of the ﬁrst center tile

The starting level is usually pre-deﬁned to a default level, which is the most suitable level for
displaying the whole data set on a single computer screen. Furthermore, as illustrated by
Hotmap the request number for one tile in the pyramid is nearly proportional to the popula-
tion density; the hotspots in Hotmap typically cover places that people are interested in
viewing.

The point-of-interest (POI) dataset and residential population data of the target WMTS
data coverage are integrated to determine the starting navigation point. The input POI dataset
is split and assigned to each administrative region, e.g. county or state. The selection probabil-
ity for each administrative region is calculated using its current population data, and then a
starting point is randomly chosen from the subset POIs for the selected state. After the starting
point is chosen, the latitude and longitude coordinates are transformed into the column and
row numbers at a predeﬁned level by the following Equations (8) and (9):

⎛
⎜
⎜
⎜
⎜
⎝

⎛
⎜
⎜
ln tan
⎜
⎝

⎛
⎝⎜

×

lat

180

π
⎞
⎠⎟ +

1
lat

×

π
⎞
⎠⎟

180

cos

⎛
⎝⎜

π

⎞
⎟
⎟
⎟
⎠⎠

⎞
⎟
⎟
⎟
⎟
⎠

row

=

2

level

−

1

−

1

col

=

(

lon

+

) ×

level

2

180
360

(8)

(9)

3.2.2 Generation of session length and think time

From Sections 3.1.1 and 3.1.3, an empirical cumulative distribution function (CDF) for session
length and think time are established. The actual value for session length and think time for
each request session are randomly generated by the “Inverse Transform Sampling” method
(Devroye 1986), which can generate sample numbers at random from any probability distribu-
tion given its cumulative distribution function.

3.2.3 Determination of the complete session path
After the ﬁrst center tile and session length k are deﬁned, the next k − 1 center tiles can be
determined by the three empirical equations for the operation directions. Assuming that the
current center tile is in (l1, r1, c1), if the user’s operation is a zoom-in or zoom-out, the level of
the next center tile will be l1 + n or l1 − n, respectively (n is the number of jump levels, n = 1, 2,

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

116

X Guan, B Cheng, A Song and H Wu

. . .), and the coordinates of the next center tile (r2, c2) for the new level will be re-calculated
from the geographical coordinates of the former tile by Equations (8) and (9); if the user’s
operation is pan, the level of the next center tile will not be changed and the pan direction
(north, south, east, or west) will be determined by another random value. Through k − 1 steps
in direction calculation, a complete request session path will be determined.

3.2.4 Integration of the HELP workload with HP LoadRunner

Due to its powerful customization capability, the HELP workload model is implemented in HP
LoadRunner. The session generator in LoadRunner uses the HELP model to produce a large
collection of valid tile requests. These valid tile requests are ﬁrst organized as a sequence of
map pages, and all the map pages are then organized into a unique request session.

Each session generated by LoadRunner behaves as a virtual user by issuing the page
requests according to the predeﬁned session length, and then waiting for an inactive period
before issuing the next page request. The inactive periods are equal to the randomly generated
think time.

4 Evaluation Experiments

4.1 Experimental Environment and Datasets

The experiments described in this article are conducted on a prototype WMTS application
which will go live online in the future. The WMTS server is conﬁgured with two Intel quad-
core Xeon processors; 32 GB RAM, and a 500 GB hard disk. The operating system is CentOS
6.2. The outbound network interface of the WMTS server is directly connected by a dedicated
1 Gbps Ethernet link.

The WMTS application was implemented by customizing the open source Java project,
GeoWebCache, while the Java Web container for the WMTS is Apache Tomcat. The
maximum memory of the Java virtual machine (JVM) for Tomcat was increased from 256 MB
to 2,048 MB. The thread pool of Tomcat for incoming request connections was also opened
and the pool size was set to 1,000.

The experimental tile dataset is from the Landsat image of the contiguous USA. It covers
the extent from 20 to 48 degrees north latitude and from -72 to -132 degrees (west) longitude.
The whole data has 15 levels and contains 91,330,776 tiles in total. The average size of one
tile (256 pixels by 256 pixels) is about 12KB with a total data size of about 1 TB. Detailed
information about the tile dataset is listed in Table 2. The corresponding point-of-interest
(POI) dataset of the contiguous USA can be downloaded from the Internet, and is a part of the
Esri ArcGIS Sample Data (http://www.baruch.cuny.edu/geoportal/data/esri/esri_usa.htm). The
POI dataset contains 370,710 points, including cities, scenic spots, recreational areas, schools,
hospitals, etc. The 2012 USA population data was obtained from the US Census Bureau
website.

One example tile request URL is listed as follows; the WMTS map is displayed by the
Openlayers client and can be seen in Figure 3. (http://192.168.0.30:8080/geospeed/service/
wmts?request=GetTile&version=1.0.0&layer=Shanghai&style=default&format=image/jpeg&
TileMatrixSet=EPSG:900913&TileMatrix=EPSG:900913:3&TileRow=x&TileCol=y)

4.2 WMTS Performance Representation by Different Workloads

The ﬁrst experiment was carried out to evaluate the performance of the target WMTS with
different workloads. The workloads include not only the new HELP workload, but also the

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

Modeling Users’ Behavior for Testing the Performance of a Web Map Tile Service

117

Table 2 The tile data information for the different pyramid levels

Level

Rows

Columns

Tiles

Size (GB)

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

1
2
3
4
7
13
26
50
99
197
393
785
1,568
3,136
6,270

2
2
3
6
12
22
43
86
172
342
683
1,366
2,732
5,462
10,923

2
4
9
24
84
286
1,118
4,300
17,028
67,374
268,419
1,072,310
4,283,776
17,128,832
68,487,210

2.1431E-05
4.3293E-05
9.76667E-05
0.000258568
0.000932785
0.003370382
0.013629335
0.051477337
0.196899891
0.805088253
3.225658244
13.07745007
46.14761879
192.7241897
720.786522

traditional static and random workloads. In the static workload the tile location parameters (l,
r, c) are constant, i.e. all the URLs generated by the static workload are turned to request one
ﬁxed tile. The random workload does not ﬁx the location parameters of each generated tile
request, but the location parameters (l, r, c) are determined by three uniform random genera-
tors just before this tile request is sent by LoadRunner. Each tile request in the static and
random workloads is independent and all the requests are issued to the server in a sequential
way.

The evaluation process uses a 20 second ramp-up period and a 10 minute stable period
for data collection with LoadRunner. The metrics used to quantify the performance include
server-centric metrics and a network-centric metric. The server-centric metrics contain page
load time (PLT) and tile throughput. The page load time is the whole time from when one user
issues a map page request, the system processes the request tiles in the map page, and the client
receives all the return tiles. The tile throughput is the number of WMTS tiles the system can
process in a given period. The network-centric metric only includes network throughput.

The starting level was deﬁned as level six, in which the entire continental US is shown in a
single computer screen. All the probability parameters for three attributes, session length,
think time, and operation direction are pre-deﬁned as in Table 3.

The test results show performance representation differences between the three different

workloads, as illustrated by Figures 4 through 6.

As illustrated in Figure 4, the PLT of the static workload is the lowest among the three
workloads. The PLT increases very slowly when the users are less than 1,100. When the user
number exceeds 1,100, the PLT increases much faster. However, even when the number
increases to 4,000, the PLT is still about nine seconds. When the number is less than 1,000, the
PLT of the HELP workload is a little higher than that of the random workload. When the user
number is over 1,000, the PLT of the HELP workload is much lower than that of the random

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

118

X Guan, B Cheng, A Song and H Wu

Figure 3 A WMTS map displayed by the Openlayers client

Table 3 The probability parameters for the three variables in the HELP workload

Variables

Law

Probability parameters

Session length
Think time
Operation Direction

Weibull distribution
Power law distribution
Power law distribution

k = 0.311, α = −0.2912
k = 1, α = 1.5
w = 0.9, λ = 3

workload. The maximum difference between these two workloads is about ﬁve seconds when
the concurrent users increase to 4,000. The PLT of the HELP workload is always one second
higher than that of the static workload.

The tile throughput and network throughput have a similar pattern. In the tile dataset the
average tile size is about 12 KB. Therefore the total network throughput nearly equals the tile
throughput multiplied by the average tile size. As illustrated in Figure 5, the network through-
put for the static workload is the highest among the three workloads when the user number
exceeds 1,000, while the throughput of the random workload is the lowest.

In Figure 4, when the number of concurrent users exceeds 1,000, the PLT for the static
increases dramatically. The network throughput graph (Figure 6) shows that

load model

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

Modeling Users’ Behavior for Testing the Performance of a Web Map Tile Service

119

Figure 4 Page load time measured by three different workloads

Figure 5 Tile throughput measured by three different workloads

network throughput caused by the static workload reaches the upper bound of network band-
width, because the effective network bandwidth of a 1 GB Ethernet is about 100 MB (about
80% of total network bandwidth). This result will lead to a conclusion that the bottleneck of
the experimental system is the network bandwidth for 1,000 users above, i.e. the maximum
capacity is about 1,000 concurrent users.

In Figure 4, however, when the number of concurrent users exceeds 1,000, the PLT for the
HELP and random workloads also increases dramatically; the network throughput in Figure 6
does not reach the upper bound of network bandwidth. In contrast to the former results, these
results show that the bottleneck in the experimental system is not the network bandwidth.
This conclusion can be explained by other factors (e.g. Input/Output speed) which downgrade
WMTS performance since the Web servers cannot cache all the requested tiles for the HELP
and random workloads.

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

120

X Guan, B Cheng, A Song and H Wu

Figure 6 Network throughput measured by three different workloads

Table 4 Parameter variations in the three attributes of the HELP workload

HELP0
HELP1
HELP2
HELP3
HELP4
HELP5
HELP6

Session Length

Think Time

Session Path

f0 = 0.311, λ = −0.2912
f0 = 0.15, λ = −0.2912
f0 = 0.311, λ = −0.65
f0 = 0.311, λ = −0.2912
f0 = 0.311, λ = −0.2912
f0 = 0.311, λ = −0.2912
f0 = 0.311, λ = −0.2912

k = 1, α = 1.5
k = 1, α = 1.5
k = 1, α = 1.5
k = 0.5, α = 1.5
k = 1, α = 1
k = 1, α = 1.5
k = 1, α = 1.5

ω = 0.9, λ = 3
ω = 0.9, λ = 3
ω = 0.9, λ = 3
ω = 0.9, λ = 3
ω = 0.9, λ = 3
ω = 0.4, λ = 3
ω = 0.9, λ = 1

4.3 Parameter Sensitivity Experiments

Since it is very difﬁcult to know precisely what a real workload’s characteristics will be, this
proposed workload generator must provide the ﬂexibility to tune the attributes in a workload
model. A sensitivity analysis was conducted to characterize how various workload attributes
will affect system performance representation. During each round of analysis, one workload
attribute is changed while all other attributes are kept the same. Table 4 presents an overview
of how these attributes are changed in the experimental design.

When f0 and λ decrease (as shown in Figures 7a and 7b), the probability density curve of
the session length will become ﬂatter, i.e. the shorter session length is less probable while the
longer session length still might be generated. Thus, the randomly generated mean session
length will increase as f0 and λ decreases. As the mean session length increases, the average
page load time will increase correspondingly.

The decrease of k results in the decrease of the mean value of randomly-generated think
times; while the decrease of α results in the increase of the mean think time inversely according

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

Modeling Users’ Behavior for Testing the Performance of a Web Map Tile Service

121

a

b

Figure 7 Effect of parameter variation on session length distribution (a: decrease in initial length
probability; b: decrease in length decay coefﬁcient)

to Equation (5), illustrated in Figures 8a and 8b, respectively. The increase of mean think
time causes more idle concurrent connections in the web server at a given time. More idle con-
nections consume less of the web server’s capability and then decrease the average page load
time.

Figures 9a and 9b illustrate that variation in the two parameters of navigation probability
equations does not affect the page load time for clients. This can be explained in that the start-
ing point of each navigation path is selected from the given POI dataset; after several

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

122

X Guan, B Cheng, A Song and H Wu

a

b

Figure 8 Effect of parameter variation in the think time model (a: decrease in empirical mean think
time; b: decrease in time decay coefﬁcient)

rounds of evaluations, all the tiles around the POIs are cached by the target WMTS applica-
tion. The cost of fetching tiles in the cache is nearly identical.

From the comparative results presented in this section, we can infer that system perfor-
mance can be sensitive to the session length and think time. These ﬁndings also conﬁrm that
different workload attributes have a signiﬁcant effect on the outcome of performance testing.
The absence of detailed understanding of workload attributes jeopardizes the usefulness of
performance testing experiments.

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

Modeling Users’ Behavior for Testing the Performance of a Web Map Tile Service

123

a

b

Figure 9 Effect of parameter variation in the navigation direction model (a: decrease in the propor-
tion of zoom-out over pan; b: decrease in zoom-in decay coefﬁcient)

4.4 Validation of the Synthetic HELP Workload

The purpose of validation is to ensure that the synthetic workloads produced by LoadRunner
have realistic quantitative characteristics. The validation task is accomplished in three steps:
(1) analyzing the request log produced by the HELP workload; (2) deriving the needed statis-
tical data about tile popularity; and (3) visualizing the hotspots’ distribution in the HELP
workload.

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

124

X Guan, B Cheng, A Song and H Wu

Figure 10 The tile access frequency of different tile ranks produced by the HELP workload

Figure 11 The visualization of “hotspots” produced by the HELP workload

Figure 10 displays tile popularity curves produced by the HELP workload (in the log–log
coordinates). The tile popularity curves are quite close to being a straight line (except for the
highest and lowest ranked tiles), indicating that tile popularity can be characterized as a Zipf-
like distribution. Hotspot visualization of the synthetic HELP workload composed by the Esri
ArcGIS Point density tool (shown in Figure 11) has similar spatial aggregate patterns with a
Hotmap from Microsoft’s Bing Maps.

5 Conclusions

Without accurate modeling and generation of realistic workloads, it is difﬁcult to measure the
true performance of a future online WMTS application. This article describes a new WMTS
workload model termed HELP and its application for performance evaluation. The HELP
workload simulates the way clients interact with a WMTS map and statistically characterizes
whole tile request patterns, including session length, think time, session path, and tile popular-
ity (hotspots).

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

Modeling Users’ Behavior for Testing the Performance of a Web Map Tile Service

125

The proposed HELP workload together with traditional static and random workloads was
constructed in HP LoadRunner and used to evaluate one WMTS application. The results of
these three workload models provided differing assessments of the performance of the experi-
mental WMTS system. The performance representation of the HELP workload is more accu-
rate than that of the other two workloads. A bottleneck revealed by the HELP workload will
further direct system administrators when tuning the WMTS system. Additional validation of
tile popularity and the spatial distribution of requests show that the HELP workload demon-
strates patterns similar to that of empirical Web trafﬁc.

References

69–83

Andreolini M, Cardellini V, and Colajanni M 2002 Benchmarking models and tools for distributed Web-server
systems. In Calzarossa M and Tucci S (eds) Performance Evaluation of Complex Systems: Techniques and
Tools. Berlin, Springer-Verlag Lecture Notes in Computer Science Vol. 2459: 208–35

Banga G and Druschel P 1999 Measuring the capacity of a Web server under realistic loads. World Wide Web 2:

Barford P, Bestavros A, Bradley A, and Crovella M 1999 Changes in Web client access patterns: Characteristics

and caching implications. World Wide Web 2: 15–28

Barford P and Crovella M 1998 Generating representative Web workloads for network and server performance
evaluation. In Proceedings of the 1998 ACM SIGMETRICS Joint International Conference on Measure-
ment and Modeling of Computer Systems, Madison, Wisconsin: 151–60

Busari M and Williamson C 2002 ProWGen: A synthetic workload generation tool for simulation evaluation of

Web proxy caches. Computer Networks 38: 779–94

Crovella E and Bestavros A 1997 Self-similarity in World Wide Web trafﬁc: Evidence and possible causes. IEEE

Transactions on Networking 5: 835–46

Devroye L 1986 Sample-based non-uniform random variate generation. In Proceedings of the Eighteenth Con-

ference on Winter Simulation, New York, New York: 260–65

Diwakar K 2006 A synthetic workload generation technique for stress testing session-based systems. IEEE

Transactions on Software Engineering 32: 868–82

Fisher D 2007 Hotmap: Looking at geographic attention. IEEE Transactions on Visualization and Computer

Graphics 13: 1184–91

Garcıa R, Castro J P, Verdu M J, Verdu E, Regueras L M, and Lopez P 2011 A descriptive model based on the
mining of Web map server logs for tile prefetching in a Web map cache. International Journal of Systems
Applications, Engineering and Development 5: 469–76

Hashemian R, Krishnamurthy D, and Arlitt M 2012 Web workload generation challenges: An empirical investi-

Iyengar A, Squillante M, and Zhang L 1999 Analysis and characterization of large-scale Web server access pat-

gation. Software: Practice and Experience 42: 629–47

terns and performance. World Wide Web 2: 85–100

Latouche G and Remiche M 2002 An MAP-Based Poisson cluster model for Web trafﬁc. Performance Evalu-

ation 49: 359–70

Li R, Guo R, Xu Z, and Feng W 2012 A prefetching model based on access popularity for geospatial data in a
cluster-based caching system. International Journal of Geographical Information Science 26: 1831–44
Liu Z, Niclausse N, and Jalpa-Villanueva C 2001 Trafﬁc model and performance evaluation of Web servers. Per-

Maso J, Pomakis K, and Julia N 2010 OpenGIS Web Map Tile Service Implementation Standard. Wayland,

formance Evaluation 46(2–3): 77–100

MA, Open Geospatial Consortium

Maso J, Paula D R, Xavier P F, Jose L M P, Joan S S, and Francesc A L 2011 Impact of user concurrency in
commonly used OGC map server implementations. In Proceedings of the First International Conference on
Advanced Communications and Computation, Barcelona, Spain: 179–86

Mosberger D and Jin T 1998 Httperf: A tool for measuring Web server performance. ACM SIGMETRICS Per-

Ortega J and Aguillo I 2010 Differences between Web sessions according to the origin of their visits. Journal of

formance Evaluation Review 26(3): 31–7

Informetrics 4: 331–7

Williams A, Arlitt M, Williamson C, and Barker K 2005 Web workload characterization: Ten years later. In

Tang X, Xu J, and Chanson S (eds) Web Content Delivery. New York, Springer: 3–21

Yang C, Wong D W, Yang R, Kafatos M, and Li Q 2005 Performance-improving techniques in web-based GIS.

International Journal of Geographical Information Science 19: 319–42

© 2014 John Wiley & Sons Ltd

Transactions in GIS, 2014, 18(S1)

Copyright of Transactions in GIS is the property of Wiley-Blackwell and its content may not
be copied or emailed to multiple sites or posted to a listserv without the copyright holder's
express written permission. However, users may print, download, or email articles for
individual use.

