frnnsadions in GjS,  1996, d. 1,  f70.  I, p .  13 

Communicating uncertainty in spatial databases 

GARY J  HUNTER AND MICHAEL F GOODCHILD 

Gary J Hunter Centre for Geographic Information  Systems and Modelling,  Department of Geornatics, The 
University of Melbourne, Parkvile, Victoria,  Australia  3052. e-mail:  gary_hunte~mac.unimelb.edu.au 
Michael F Godchild National Centre for Geographic Information and Analysis,  35 10 Phelps Hall, 
University of California,  Santa Barbara, California, USA 93 106. e-mail:  good@ncgi~geog.uub.cdu 

Introduction 

i o d  art,  making a good 
Part science and part d t
map [or  nport or am+&]  is like making a good wine. 
produced b a f;w nrpm  f i r   the  be@ 
of alL  The 
GISproduct b contrast is mow like what comes out of 
a kitfir ab-it-yourse~chmimy nrpm‘mmts: it can be 
raibnd  to  on&  &sin,  it  is &dy 
m’prking, fiequcnt4  hard  to  undmtand, sometimes 
insidious4  hthal  and  the  (amateur)  maker  and 
(naive) user a n  o f r ,  one and the m e .  

vaned  o& 

(Couddis  1992: 6) 

It is now widely accepted that one of the major limitations 
of spatial databases is the lack of appropriate methods for 
transmining  the  uncertainty  associated  with  database 
outputs to users, and as Dutton (1 99 1 : C-56) aptly notes. 
‘No branch of science can bear fruit unless its findings can 
be  qualified  by  the  various uncertainties  to  which  the 
measurement and  analysis  of  its  data  are subject.’ This 
need has arisen due to factors such as, 1) the introduction 
of  mandatory  reporting  of  data  quality  in  many 
international  spatial data  transfer  standub (Modering 
1991); 2)  che  need  to  p r o t m  decisions made by  public 
agencies  in  which spatial  data  have  becn  used;  3)  the 
importance of preserving public confidence and integrity 
of the reputations of chose agencies (Prisley 1994); and 4) 
the  growing  trend  towards  liugarion  as  a  means  of 
resolving disputes relating to the use of perceived inferior 
quality data  and  the  harm  deemed  to  have  arisen from 
such use. 

For  novices  to  the  field  this may  not  be  such  a 

problem since, as Coudelis suggests above, they may wcll 
remain in blissful  ignorance of the consequences of their 
actions (although the  &&as  of  their  acrions m a y  cause 
problems for ochers). O n  the other hand, for experienced 
usen the situation is recognized as far more serious since 
not only arc they unable to make comparisons of database 
the  requirements  of  their tasks 
product qualities @t 
(the  ‘fimess fbr  use’  concept),  but  the  decisions  upon 
which that information  may be  based (whether in part or 
in full)  may be  in jeopardy  - particularly in cases where 
organizations musr  develop  regulatory  policies  chat  arc 
subject to judicial  review.  In  addition,  with information 
increasingly bung  viewed  as a  saluble  c o m m d t y ,  the 
potcndal for litigation is now far greater than when spatial 
dwbves were  in  their  infancy  and  while  invmigating 
product uncertainty may not be a ‘money-making’ issue, 
failure  to  cope adequardy with it  may  well  makc  it  a 
‘money-losing’ one. 

Accordingly, this paper rcvicws the m a s  by which 
both  error  and  uncertainty  may  be  communicated  to 
users of  spatial databases, although  the  treatment  of  the 
lamer is dominant throughout  the paper given  that there 
are  so fcw  models  of  spatial  data  error  that  are  widely 
recognized and accepted. At this point, it should be noted 
thar  ‘uncertainty’ has  been  ddibcratdy  chosen  here  to 
denote  the  fact  thar  relatively  litde  formal  knowledge 
aciscs  about spatial darabase ‘error’ p m  se  (in the fixm of 
models  describing  its  manifestation  and  subsequent 
propagation  through  spatial  processing),  and  hence 
‘uncerrainry’  represents  a  more appropriate  term  to  be 
used  in  the interim  period  until  chis  situation  improves. 
As  such, ‘uncertainty’ indicates that  it  is  our own  l.a&  of 

1361-1682/96/0001-0013  0 Parson Profcrrional limiicd  19% 

13 

G I Hunter and An  F G d c b ; l d  

knowledge about data quality which is  often  responsible 
for  OUT  hesitancy in using spatial data without question, 
rather than  it  bcing a  problem associated with the  dara 
itself. 

Subsequent  sections  of the  paper  aaminc:  1) 
traditional uncertainty reporting methods for  hard-copy 
maps, 2) communiation techniques applicable to spatial 
databases. 3) advanced  methods now appearing,  and  4) 
some of the  issues  to  be  dealt  with  in  zwssing  the 
effectiveness  of alternative  uncertainty  communication 
methods. 

Traditional uncertainty communication 
methods for hard-copy maps 

(these  being 

Traditionally, the  practice of hard-copy map production 
provided only a limited mcans of communicating spatial 
data uncertainty to map users. Certainly, there have long 
been horizontal and vcrdcal positiod accwacy estimates 
placed on maps, but thcx tended  to  be  global in  n a w  
and  the  question  of attribute  uncertainty  was  often 
overlooked.  In  addition,  positional  ;~ccu1;1cy indicators 
usually only applied to well-defined points and not to the 
positions of linear or polygonal features. Moa of the other 
(now) commonly accepted components of spatial  data 
quality 
lineage,  logical  consistency, 
completeness, and currency) generally relied upon a wr’s 
intuition  and  knowledge  of the  accepted  practices  and 
l i t a t i o n s  associated with mapping the particular theme 
involved,  with  the  exception  of currency  which  was 
invariably handled by the addition of a map revision date. 
Map reliability diagrams were often included in the 
margins  and  were  useM  in  showing  not  only  any 
variations in the map revision process, but also differences 
in the survey procedures employed and the data used  (for 
instance,  with  aerial  photography)  during  the  map 
compilation process (Flowudcw 1991; Van der Wel  ct al 
1994). However,  these  diagnms only indicated where  a 
map might be unreliable or of doubtful d d i t y  (which, in 
any case, was subjm to interpretation by the map ruder), 
and did not n c c d y  divulge the size or exact location 
of local errors. In  addition,  there was  the deficiency that 
map  reliability dmgrams  could  not  be  used  to  t r a n s m i t  
information about the quality of any further information 
or  analyses  derived  from  the  map.  Clearly,  there  is 
potential here for &tal  versions of reliability diagrams to 
be  employed,  and  Luncrta  ct  al  (1991)  discuss  their 
possible uscfulncss in describing the integration of remote 
sensing imagery with spatial databases, bur there has been 
little rexarch in this direction to date. 

In  some  cases,  efforts  were  made  to  convey  the 
imprecision of individual f e a m s  and Fisher (1991a) cites 
the  use  of symbolization  in  topographic  maps  (for 
example,  the  different  depiction  of permanent  and 

14 

i n t u m i t t ~ ~ t  w a t c ~ u r s c s ,  and uncuuin contours being 
shown as dashed ha). This approach has also been used 
in geological maps to depict rock faults and conram such 
as a solid line ( o b d ) ,  a dashed line (not obsuved, but 
&ly  ccrclin) and domed lines  (inferred). Similarly, early 
1940s m a p s  of the American Geographical Society  were 
coded  to  suggest  uncertainty,  and  ‘P.D.’ (position 
doubtful)  or  ‘ED.’  (existence  doubtful)  arc  examples 
(McGranaghan 1993). A dashed Line  may also be  used to 
illusmte an  uncertain political boundary and  sene as a 
warning  to  users, but  it  provides  no  quantitative 
information. 

In  general,  however, 

traditional  error  and 
uncertainty communication methods for hardcopy maps 
tended to bc global rather than local, qualitative instead of 
quantit?cive. and presumed a high  levcl of intuitive skill 
on the part  of  the  map  reader. There was  as0 the  tacit 
understvlding (at least in the map producer’s mind) that 
paper maps were invariably out of date by  the time they 
were printed, and that the laborious process of producing 
and reviting complete map series meant that maps would 
often be  10-20  ycars old bcfore updating occumd. 

In c&ct,  these data  quality  indicato~ served  as 
caveats and only signalled the likclihood of variation from 
‘ n o d  conditions.  In  some  cases,  talung  cartographic 
generahation as an aample, no mention was made of the 
positional errors &rced  by  the  map  producers and  it 
was  only  through experience  that  WCK  became  more 
cognizant of a map’s inherent accuracy and how fir they 
could trust i n  representation of reality. Of course, for the 
novice  there was lidc assistance  provided even  though 
these  were  the  USCK  who  were  most  likely  to  need 
education and guidance. 

Communicating error and uncertainty in 
spatial databases 

With the advent of digital spatial databases the hardcopy 
map  was  no longer the  only  product  capable of  being 
generated, but instead simply one of a hmily of possible 
representations of the database. T h e  WYSIWYG principle 
(What You See Is What  You Get)  no longer applies  to 
digital data, and it is now possible for users to apply dara 
in ways in which it was not originally intended to be used. 
Thii has both positive and negative side effects and Beard 
(1989a) and Epmein and Roianan  (1987) have discussed 
and  documented  examples  of  the  misuse  and 
misintcrpmation that can occur. 

In  developing  a  taxonomy  of error  in  spatial 
databases, Hunter and Bard (1 992) identified in excess of 
I SO different potential sources of error in the general arcas 
of data collection and compilation, data processing, and 
data usage. These, in rum, are responsible for the forms of 
error  (positional and  attribute error, logical  consistency 

and  completeness) that  can occur  in  spatial  databases, 
which  then  contribute,  either  in  combination  or 
separately, to give final product  emr(s) which  w r s  will 
ultimately want to assess. In some cases, formal models of 
spatial  data  error  already  exist  and  appropriate  error 
statistics can be  generated; however, in many other cases 
such  mod&  are  yct  to  be  found  and  techniques  are 
required  to  estimate  and  convey  the  uncertainty 
associated with the data set. 

Clmrly, the development of formal error models is 
the preferred approach to dealing with the issue of spatial 
data  error  since  they  provide  us  with  rigourous, 
quantifiable, and  statistically-based  measures.  H o w e r ,  
there  are  relatively  fcw  such  models  in  existence  and 
Goodchild (1 993)  suggests that the known and accepted 
techniques we possess for describing and measuring error 
arc limited to the following cases: 

1  the accuracy of the location of a single point 
(through use of the circular normal model of 
positional error) 
the accuracy of a single measured attribute 

2 
3  the probability that a point  at a randomly chosen 
location anywhere on a map has been  misdassificd 
(through use of the misclassification matrix) 

4  the e f f m s  of digitiiing error on measures of length 

and area 

5  the propagation of errors in  raster-based area dass 
maps through  GIS operations such as overlay 
6  the error associated with measures of area derived 

from dot counting 

Even with such error models in place there can s t i l l  
be problems with  communication of  their meaning and 
implication.  Firstly,  they pertain  more  to  rhe  form  or 
shape that the error takes, rather than the processes which 
are responsible for its occurrence (Goodchild et al 1994a). 
An  example  of  this  can  be  found  in  field  testing  for 
positional error in topographic maps to produce a statistic 
(such  as  the  root  mean  square  error) which,  while 
containing useful  information  about  the  final product, 
says  nothing  about  the  numerous  contributing  factors 
that  may  have  played  a  role  in  the  overall  process. 
Secondly, the meaning of a statistic may not be intuitively 
understood  by  all  and  a  user  invariably  needs to  have 
specialist  knowledge  when  applying  it.  In  addition, 
staristics  by  their  very  nature  imply  that  error  is 
quantifiable,  which is  rarely the  case - particularly when 
dealing  with  natural  phenomena  and  their  variation 
where  the  validity  of  spatial  data  is  often  recorded 
qualitatively.  Another  problem  is  that  error often  varies 
spatially  throughout  a  map  and  its  physical  distribution 
may bc of more importance t h a n  just the average value for 
the map as a whole. For example, the calculation of slope 
aspect  is  known  to  be  especially  sensitive  to  elevation 

Communicating unterfainiy in spafiaf &abases 

changes in flamer terrain and thus needs to be shown as it 
varies throughout  a  data  set.  This  may  l a d   uxrs  to 
consider areas where they might necd to recollm: data at 
a higher accuracy in order to reduce the ~nccrtainry of the 
final product. 

visual techniques 

seeking 

Gmphics  and  imugmy  arr  particukzrly  usq%l  to 
investigators 
to  understand  physical 
phenomm  npmenvd  numerical!  The  suppIy  of 
numcrical  data  has  increased  rxplosively  with  the 
imphentation  of computational mo&h  and  high- 
resolution  m o t e  sming  h i r e s .   The  k n d  f i r  
cfferctivr  graphic  mrthodc f i r   &ta  analysis  and 
presentation has inmascd concomitant&  collective^ 
there mrthodr have come to be known as visurrlisation. 
(DiBiase et al  1992) 

Just as visualization a n  be  used  to represent  data 
effectively, it can also  be used to represent rhc validity of 
that data and any derived products. This applies both  to 
measurable  error  and  estimates  of  uncertainly.  The 
benefits  of  visualization in  general  have  becn  noted  by 
DeFmnti et al (1989) who consider that it has the capacity 
abstract concepts into meaningful displays, 
to  1) or@ 
2)  transform  numerical  values  into  understandable 
images, and 3) permit manipulation of geometry, colour, 
and  motion.  Other benefits  indude  speed  of  panem 
recognition, ease of motion and change detection, and the 
ability to see the intangible (for example, with vegetation 
vigour in remote sensing) or the inaccessible (Buntenfield 
and Beard  1994). In addition, visualization a n  help act in 
an education role. 

While  it  has  already  becn  mentioned  that  it  is 
imporrant  to  detect  the  spatial variation of  uncertainty, 
and visualization obviously lends itself to chis task, it can 
also yield an advantage over humans who may not detect 
subtle variations in  unccruinty,  or  else  do  not have  the 
resources necessary to examine large, complex data sets in 
d e d  (Monmonier  1991). Visual  quality diagrams might 
also assist users in assessing the appropriateness of a data 
set  before obtaining it for their own purposes, and at the 
same time fiord the opporrunity to help educate them in 
data quality  awareness. Figure  1 has  becn  adapted  from 
Gillag  (1991)  and  ably  demonstrates  the  differences 
between  the  visual/psychological approach  to  presenting 
uncertainty and its modeUing/mathcmatical counrcrpan. 
Both  are  valid,  it  just depends  on  who  the  intended 
audience  is  and  how  the  information  is  required  to  be 
presented. 

T h e  well-known  visual  variables  described  by 
B&n 
(1983)  of size, value,  texture, colour, orientation, 
and  shape,  provide  valuable  guidelines  not  only  for 
traditional  map  products  but  also for new  ones  such  as 

15 

G J  Hun?cr and M F GcuclchiM 

Question:  What is the unccrtuinty? 

ANmr  1:  Modalling/- 

‘Col 

Don’t you  see? It’s 
206+(ocD0+~) / (EclIq - AH) !! 

uncertainty displays. McGranaghan (1993) added several 
variables for representing unmainty in maps to  B e d s  
original list of variables, these  being symbol presence (or 
absence), location  (where  it  is  placed), time (when  it  is 
shown), focus and realism  (for otunplc.  contours versus 
hill-shaded  Digid  Elevations Models @EMS)). These 
variables then serve as the basis for consideration of both 
static and dynamic displays of uncertainty. 

Static dLpkays 
In the static domains, size and orientation have long been 
used, for cxample, when depicting error ellipses associated 
with the  precision  of  geodetic  measurements.  O n  the 
other hand,  other variables such as texture should also be 
considered  and  might  be  applied coarsely  to  give a  mat 
surface for very uncertain  data,  but  more smoothly via a 
shiny surface fir dam that users are less hesitant to accept. 
While  grey-scale  shading  can  be  used  to  display 
uncertainty  ranges, the  use  of  colour  has  fir  greater 
potential  although  its  correct  use  can  be  difficult.  For 
instance, a standard hue- or valuebased colour range may 
be  used  to  display data values, while  uncertainty can  be 
depicted  by  variation  in  colour  saturation - leading to 
bold  colours having high  ce~ainty and  31in  or ‘washed 
out’ colours having low ccrtaincy.  An example of this is 
given  by  Hassan  (1993) when  showing transition zones 
between  diffuent  soil classes.  Difkcnt  colour  p a l c r t ~ ~  
might also be adopted with colours such as red being used 
to  indicate  high  Variability  and  with  green  for  low 
variability  (McGranaghan  1993). However,  caution  is 
nccdcd  to  ensure  users  do  not associate, for  instance, 
grccn with  pasture land-use,  and to prevent the  possible 

16 

misunderstanding  that a  blank  area  is  not ‘normal’, but 
rather of unknown quality. For detecting residual polygon 
slivers,  solid  colour-fill  quickly  and  easily  shows  any 
polygons  which  aceed  a  given  threshold  ratio  of 
perimeter  l a g &  divided  by  their area, and  the  same 
simple process of shadmg quickly illustrates any polygons 
which  haw not becn mathematically closed  or  have  not 
been  assigned  certain  attributes  and  thus  remain 
unshaded. 

Cartographic line weights  can be  used for discrete 
data such as point and line farurcs, and the epsilon band 
is  an  extension  of  this  approach  in  which  a  zone  is 
considered to exist around the future which  contains all 
possible variations of ics  position (Durton 1992). Instead 
of a circle or parallel band, another approach is  to apply a 
‘cloud’ of points with increasing density towards the core, 
and  the  lineal analogy is  a  braided  lie (McGranaghan 
1993). Alternatively,  h d  lines can  be  substituted  by 
funv ones in cases of imprecise natural variation and left 
as  hard  lines  when  describing  well-defined  artificial 
f a m .  This aLso  leads to the concept of fuzzy logic and 
classification, in which  each cell  in  a  raster  file  has  the 
potential  to  have  membership  of  several  classes,  for 
example  ‘90%  soil  class  A  and  10%  soil  dass  B’. 
Goodchild  ct al  (1994b) have  worked arrensively with 
this model and have developed the means to visualize and 
process fuay-dwified  maps and scenes within  a  spatial 
duabax. 

Other  authors  have  cackled  the  problem  of 
variation of homogeneity in soils as wcll,  with M a d r a n  et 
a l   (1993) choosing  to  c o n m a   variability  diagrams 
which arc developed after  analping detailed information 
contained  in  the  original  soil  survey  reports.  The 
variability maps  are  then used  in conjunction  with  the 
original digitized soil maps to give users a measure of the 
uncenainty within  the  map. As tg as the  soil mapping 
process i d f  is conccmed, Brcgt  (1991) finds it useful to 
examine  the  uncertainty  associated  with  the  kriging 
process and uses  the error estimates provided to produce 
choropleth maps of probability together with isoline maps 
containing confidence limits for subsqucnt applications 
of  the  data  (see  also  Mackaness  and  Beard  1993). 
Similarly, Englund  (1993) has  aamined  the  uncertainty 
associated with spatial simulation, and instead of showing 
a  map  of  estimated  variances  computed  from  the 
interpolation  procedure  in  conjunction  with  the  mean 
surface  he  chooses  to  display  a  range  of  different  yet 
qually probable  maps which  vary  about  the mean  (that 
is,  the  derived  surface).  For land  suitability  analyses, 
Lowell  (1992) has  also  examined  the  creation  of 
uncertainty surfaces and argues that there should be such 
a surface (or secondary map) developed for every layer in 
a spatial database. 

Visual methods  indude  the  use  of  fogging or de- 

k i n g  in  arcas  of  poorer  quality  to  provide  effects 
similar to that of torture variation.  In addition, the use of 
3-D visualization permits the integration  of data quality 
information with the data to which it relates, for example 
by  draping  it  over perspective views.  Three-dimensional 
techniques can  be  used  for  stereoscopic viewing of  data 
and  several  s p a d   database  padc;lg.r  now  havc  this 
capability.  The  use  of  black  and  white  or  colour 
photographic backgrounds may also help visualivtion  of 
data  quality  by  lending  a  measure  of  realism  to  the 
conceptual  models  being  employed  (for  instance when 
displaying  uncertainty  in  vegetation  classification 
polygons over an orthophoto image of the region). 

In  order to view  uncertainty  there  must  a i s r   the 
capacity to automatically generate the appropriate data on 
demand or else havc it stored ready for use. Accordingly, 
Hetrick  (1991)  describes  the  development  of  a  data 
q d t y  matrix for raster data in which information can be 
coded  and  stored  to  represent  missing  data,  data 
acquisition  which  is  incomplete  or erroneous, bad  data 
(where the fault is  either known  or unknown), bad  data 
which has been replaced (by an estimate, an average value 
based  on its  neighbours,  by  regression, or by  a  given 
formula).  T h e   matrix  can  be  visually  inspected  or 
automatically queried  by  analysts. Another  possibility is 
to  store spatially variable data  quality  information  in  a 
manner  similar  to  the  quadrree  method,  so that  each 
quadrant  has  a  homogeneous  (pure)  level  of  quality 
(Beard  et  al  1991). While  some  users might argue that 
storing quality data adds to storage overheads, particularly 
in  the  c u e  of  storing  individual  probability vectors  for 
every  pixel  in  an  image,  hardware  capabilities  are 
advancing at  such  a  rate  that  such concerns should not 
dominate our thinking. 

Working from another direction, Frank (1 993) has 
developed  a  means  by  which 
the  effects  of  grid 
interpolation  may be  depicted  to  users.  By  applying the 
same  interpolation  techniques  and  control points  to  an 
associated reference grid as will apply to  the  actual data, 
unusual  or unwanted  distortions  that  OCCUT  in  the  data 
which would ordinarily be hidden are clcarly registered by 
the  reference  grid.  In this way,  users can  observe  the 
results of their  interpolation  process  before  they actually 
apply it to rhe observed data, and thus test the effecrs by 
aperimenring with different grid resolutions and control 
point locations and numbers. Similarly, Paradis and Beard 
(1 994) have developed a ‘data quality filter‘ in which users 
set their parameters for an error budget, and data are then 
filtered on the basis of those same parameters - with only 
chose data rhat  pass  the filter being displayed. 

Couclelis (1 992)  presents  an  interesting approach 
to communicating uncertainty  by linking visual forms to 
everyday conversational metaphor.  For  instance, adverbs 
like  ‘exactly’, ‘completely’, ‘approximately’,  and  ‘more or 

Cammunicuting uncwfainty in spotiof dafobases 

less’ might be allied to sharpness or fuzziness in displayed 
fhrures, whereas hedgcs such  as ‘I  think’  and  ‘I  believe’ 
could be represented by colour saturation lcvels with grey 
denoting the most doubtful htures. Similarly, proddings 
comparable to  ‘is  that  right?’ and  ‘arc you  sure?’ denote 
disbelief  and  might be  represented by  prompts,  special 
symbols or flashing marks chat call for Wer analysis. An 
exrension  of  this lamer  thinking  is  that  data  quality 
information should alert  the user in  a  ‘hey, look at me!’ 
fashion so that the quality assessment approach  becomes 
proactive rather than  reactive, and that graphs and charts 
can  assist  visual  representations,  although  such  a 
technique  assumes  error models  to  already be  in  place 
(Beard et al  1991). Wood (1994) adopts this rnulri-visual 
approach in assusing interpolation error in DEMs, using 
a combination of maps and graphs to p o m y  a variety of 
aspects associated with the DEM. 

In  other research, Hunter  and  Goodchild  (1995a) 
havc  investigated the  ermr  estimates supplied  by  DEM 
producers  and  applied  them  to  display  visually  the 
uncertainty (in the form of probabilities) of outputs such 
as derived  contour lines. For other  quantities,  such  as 
slope  gradient  and  aspect  estimates,  Hunter  and 
Goodchild  (submimcd)  have  employed  a  model  of 
uncenainty which uses a stochastic (that is, probabilistic) 
process  capable  of  generating  a  population  of  distorted 
versions of the same reality, with each realization k i n g  a 
sample  from  the  corresponding  population.  In  other 
words,  the data set is  perturbed using a knowledge of the 
producer‘s  error estimate  and,  with  the  inclusion  of  a 
spatial  autocordation  parameter,  produces  a  series  of 
maps which show the variation in output as a result of  1) 
the uncertainty in  the  original data, 2)  the intcmiediatc 
algorithms  used  to  process  the  data,  and  3)  any 
uncertainty propagation &ects.  Originally, the procedure 
was  confined  to  use  with  grid-d 
data;  however,  a 
modified version of the model has now been produced  to 
cater for  pemvbing  vector  data  by  the  application  of 
random,  independent  shifts  to  each node  and verta in 
the  data  set  (Hunter  and  Goodchild  1995b).  Fisher 
(1991b. 1992) handles viewshed  uncertainty in a similar 
manner  by  producing  simulated  outcomes  of  reality 
under terms of uncertainty. 

Dynamic dqkzys 
The combination  of digital spatial data  and  high speed 
computers  also  raises  the  possibility  of  dynamic  (or 
animated) displays, of  which  there are M basic  forms 
possible: those that are positional in nature, and those that 
are radiometric, where motion is through a colour palette 
(Beard  er  al  1991). Animation  permits  depiction  of the 
dependence  of  the  data  upon  time,  and  an  excellent 
aample is  given  by  Weber and  Bumenfield  (1993)  who 
have  used  this technique  to  show  sequences of average 

features  by  varying 

annual  tunpcrarures for  the  48 contiguous states  of the 
US over the past 90 ycars, in which sharp inconsistencies 
are asily detected. With regard to the previous suggestion 
of using  fogginess  to  indicate  uncertainty, its  dynamic 
counterpart would bc a moving fog which would appear 
to  mist  out  uncertain 
their 
background colour saturation, while more certain fkarurcs 
would  bc hardly  zffectcd  at  dl  (McGranaghan  1993). 
Similarly, in  applying  the  use  of  colour  to  suggcst 
uncertainty  a  river  fearwe  might  oscillate bctwcen blue 
and grcen where its existence is wdl known, and between 
blue and red when it is less certain. Ar  the same time,  the 
river  may vuy through a range of colours depending on 
the level of knodcdgc about its discharge rate. 

(ar 
Dynamic  approaches  could  indude  to&g 
user  selected  frqucncies)  bcwcen  the  map  and  its 
associated  uncertainty  display  to  either  isolate  or 
‘combine’ the two images in a user’s  mind (Goodchild et 
al  19941).  They  might  also  be  powcrfui  in  showing 
different  repraentations  of  o b j m   at  different  d e s  
when interactively zooming in on a database display. One 
stacittical meuure,  the  Circular Map Accuncy  Standard 
(CMAS) described by  Goodchild (1991) which is used  to 
represent the uncertainty associated with the position of a 
point  feature  (surrounded  by  a  circle  of  given  radius 
equivalent  to  its  uncertainty), may  be  more  usefully 
applied if  the point could  be  s e n  moving around inside 
the circle - never stopping long at any one point  so that 
the user does not come to regard its position as being fixed 
at any particular location. 

Fisher 

(1993,  1994a.  1994b)  has  already 
implemented  this. concept  in  which  uncertainty  is 
conveycd to  users  by  randomly  varying data displays in 
real  time.  He  presents  cxamplcs  dealing  with  dot 
mapping, portrayal of soil inclusions in soil mapping, and 
classification of  remotely  sensed  images.  In  the  former 
case, the positions of dots representing populations within 
polygons arc continuously changed to convey to users the 
fact  that  the  dot  refers  to  a  distribution  throughout  an 
a r d  unit  and nor  just  the location where it  happens  to 
appear.  For  soil mapping  inclusions, grid  cdl  displays 
which contain  more  than one soil rype are  continuously 
varied on  the basis  of the propomons  in which each soil 
dass  exists.  With  this  technique,  users  are  able  to 
discriminate  between  the  area  bcing  mapped  and  the 
‘noise’  (or uncertainty)  within  the  data.  Finally,  the 
variability of pixel classification in remote sensing has also 
been  examined  and  Fisher  (1994b)  has  chosen  to 
randomly  assign  pixel  displays  (again in  ral time)  in 
proportion  to their probability of being correct. 

Disadvantages of  visual techniques 
while the foregoing discussion would appear to promote 
strongly the  application  of visualization techniques  they 

18 

are not without their dis?dvmtagcs. F d y ,  they tend  to 
be indiuave rather than quantitative, and  although  the 
highlighting of areas  &biting  high  uncertainty a n  be 
amunely valuable,  wzs  will  s t i l l   be  required to  srudy 
such areas in  further d c d .  while this is not necessarily 
bad and places responsibility fbr accepting or rejecting the 
data  (rightfully)  back  into  the  uteri  hands,  it  is 
ncvcrrhclcss a limitation of the o v d  p‘ocess. 

In addition,  visualization techniques  need  to  be 
wcll planned,  and are  just  as susceptible to  poor design 
principles  as  other spatial  database  products.  In  some 
cases,  they may not be pvdcularly useful wherc numerical 
precision is  rquired, and tabular reports might be  better 
suited to the task In this respm, Beard (1991) notes that 
one negative aspect of visualization can be ambiguity, and 
she cites the case of march into the use of graphs which 
has shown that users grasp concepts more quickly but less 
accurately  than  when  using  tables  of  dam  Finally,  a 
restriction on the  use of visual techniques is  that  nor all 
models of uncertainty are easily visualized. 

Alternative communication tools 

qyour ody  tool is a hammn; you  trnd to see  every 
p r o b h  a a nuiL 

(anon.) 

As  shown  in  the  preceding  section,  while  visualivtion 
has  many  possible  strengths  which  are  still  to  bc fully 
exploited, it is not necessarily suited to every application. 
Indeed.  it  is  not the  only  solution available and scvcnl 
other  approaches  are  bcing  tentatively  aplored  as 
possible  solutions  to  the  problem  of  communicating 
uncertainty  in  the  future. The quotation  at the  start of 
this  section  aptly  states the  problem  and  users should 
remain open-minded  to new concepts and methods. 

One option is the use of our aural sulses to d e t m  
variations  in  pitch,  volume,  and  other sound  variables 
which might correspond to different lcvclc of uncertainry. 
Such  an approach  could  be  applied  by  a  user  either 
moving a cursor or ‘brush‘ across the computer screen or 
else automatically scanning through  a file while watching 
the  cursor  and  listening  to  the  corresponding  sound 
the  programming 
output  (Krygier  1994).  Given 
capabilities of the various window-based systems now in 
use,  the technical considerations do not prcsent a serious 
barrier  to  this  approach  and Veregin  et  al  (1993)  have 
included  this  feature  in  an  automated  system  chat 
facilitates interactive ‘exploration’ of data quality, which 
they liken to a ‘gcigcr counter’ - since a clicking sound is 
emitted at a rate proportional  to the data q d k y  vahe at 
each  location  of  the  cursor.  Fisher  (1992)  too,  is 
investigating the  technique  and has  included  the  use of 
rhythm  to  develop  tones  that  have  silent  pauses 

interspersed indicating the  lcvd  of uncertainty. A  rapid 
pulse can be a warning to indicate stress in the data, while 
a  slower,  more  relaxing  pulse  may  represent  high 
certainty. A combination of rhythms and tones could be 
used  to communicate  multiple  amibutes of uncertainty. 
While sonic methods may not be suited to all problems, 
such  as when  a  single global  error estimate  has  been 
applied to  a DEh4, there  may well be  other applications 
to  which 
suited,  particularly  when 
communicating spatial variation. 

they  are 

The  multiple  window  approach  discussed  earlier 
might be funher extended so  that  different modules of a 
spatial  database  each  have  their  own  window.  T h e  
indusion  of  data,  the  statistical  analysis,  and  quality 
windows for example, logidly leads to the multi-media 
approach  and  Goodchild  et  al  (1 994a)  suggcst  that  it 
might soon be applied to query features by bringing up a 
variety  of  information  such as  t a t   reports  on  data 
lincagc,  statistical  charts,  and  details  of  generalization 
algorithms applied. This technique could be mended to 
cover  not just  single feacures but  also groups of selected 
features  and  the  entire  database.  One  well-known 
application  that  combines multi-media  and  GIS  is  the 
Domesday  Project,  produced  by  a  team  of  British 
geographers, which incorporated  in digital form, a series 
of  maps,  images,  photos,  videos,  and  t e x d  data  for 
Great  Britain  (Openshaw  and  Mounsey  1987).  This 
technique  has  already been  implemented  by  Niemann 
(1993) who  has  used  a hypcrtar/hypermcdia approach 
embedded 
to 
communicate  both  mcradata  and  space-time-depth 
variability  and  uncertainry 
in  Chesapeake  Bay 
monitoring data. 

in  a  desktop  mapping  package 

As for  other methods,  it  is  only  a marcer  of  time 
before  uncertainty  displays  begin  to  take  their  place 
alongside lineage  reports  and  vim  of  dam  sets  being 
browsed by potential users on the World Wick Web, and 
clearly  there  is  no  technologid  reason  why  static 
methods  of  communicating  uncertainty  cannot  be 
implemented  for display over the Internet. As for the use 
of virtual reality to explore spatial data and its associated 
uncertainty,  while  at  this  stage  its  most  common 
application is in video games it is known that researchers 
are already studying its  application  to  spatial databases. 
T h e  important  item  to  note  here  is  that  hardware 
development  has  progressed 
far  beyond  sofrware 
development  and  there  are  many  technologies  in 
existence  which  are  ready  and  waiting  for  suitable 
applications. 

Assessing  the effectiveness of communication 
methods 

Clearly, 

the  success  of  our  research  efforts 

in 

Gmrnunicating wtcertainty in sP0t;of  &abases 

communicating uncertainty  will depend on how  well we 
understand and deal with the way in which users perceive 
and  understand  the  various communicltion  techniques 
available.  While  this is  not  such  a  problem  for  formal 
error  models,  since  knowledge  of  their  application  is 
usually  only  gained 
through  formal  education,  it 
reprcscnts a problem  for  some of  the  newer  techniques 
discwed earlier. 

Cognitive  testing  offers  one  means  of  assessing 
communication  effectiveness.  Buncnfidd  and  Beard 
(1 994) have already conducted experiments in testing the 
effect  of  symbolizing both  cumulative  and  annual  tree 
ring growth in an animated map. They found that while 
users tended  to  associate more easily  Cumulative growth 
with  increasing gradations  in  symbol  size,  they  usually 
required  further  clviCication  in  order  to  wociare  the 
quality of growth with variation in colour saturation (that 
is,  the variation in  the  annual  rare  of change caused  by 
different  growing conditions).  Goodchild  (1991)  tested 
different  designs  (such  as  fuzziness,  colour,  and 
movement)  to  represent  positional  uncertainty  of point 
locations and found that: 

1  moving objects tend  to be associared with  movement 

in reality, not of uncertainty 

2  there is  a threshold density when creating cloudy or 
fuzzy images to show uncertainty - above this 
threshold it looks f k z y  and appears to work d l ,  bur 
bdow the &hold 
not communicate uncertainty well 

it presents as a swarm and does 

3  the cloud for each of the points must be generated 
independcnily or else the eye casily s e a  the pancrns 
as a standard symbol, thereby defeating the purpose 
of the cxcrcisc 

4  the eye casily perceives concentric circles when 
piecewise approximations are used to represenr 
circular probability density functions 
the size of a colour filled circle tends to be &A  as 
a measure of aruibutc magnitude rather than its 
uncertainty, whcrcas unfilled circles more casily 
represent positional uncertainty 

5 

information 

In  addition,  researchers  need  to  know  whether 
quality 
is  best  understood  when 
superimposed (for example, the bivariatc mapping of data 
quality together  with  the  data),  sequenced  (alternating 
berween one and the other, via toggling) or shown side by 
side with  the data. Anorher question which  needs to  be 
investigated  is  whether  users  can  cope  with  complex 
visual/audio displays and whether the tools that are being 
developed are outside the range of human perception. 

Obviously, training  will  be  required  to  use  some 
tools and it should not be assumed that all displays will be 
intuitively dear  to all users. For example, the use of error 
ellipses  to  communicate  the  precision  of  geodetic 

19 

observations  is  a  n a d  concept  to  suwyors,  but  to 
others some preliminary a p h a r i o n  is required to assist 
in  understanding  what  the  concept  represents.  Clearly, 
there  is a need for further rescudl into the link between 
psychology and  displays of spatial data, and Hamshaw 
'recognition  of  the 
(1994: 198) comments 
similarities  and  diffircnces  of  the  various  [types  of] 
displap can lead to bmer undcrstandmg of the data, but 
only if the validity of the interpretations of the displays arc 
understood.’ 

that 

O n   the  other  hand,  cognitive  testing  may  not 
always  provide all  the  answers and  it  may  be  better  to 
adopt  a  heuristic  approach,  in  which  users arr  given  a 
toolbox of communicauon  alternatives and left to decide 
for  themselves which  approaches  bcst  fit  thcir  needs. 
There  is  also  a  certain  element  of  ‘democracy’  in  this 
approach,  since  it  is  the  usm  who  will  ultimately  be 
applying the  techniques,  and  Machchrcn ct al  (1993) 
describe the  use  of such  a  toolbox  offering a  variety of 
possible  manipulations  for visualizing  the uncuclinty of 
spatial data associated with Chesapeake Bay.  Of coursc, a 
further alternative might  be  to  adopt a hybrid  approach 
consisring of basic cognitive testing to eliminate obviously 
unacceptable methods, while leaving a set  of techniques 
which  users can selm  at will. 

Variation in user skills 
Other  considerations  to  be  faced  when  deciding which 
uncertainty communication methods should bc used, are 
the need  to place them in their correct context for  1) the 
given  level  of  user  skills, 2)  the  nature  of  the  intended 
applications, and 3) the types of decisions to be made. 

In  discussing variation  in user  skills, Stringer  et al 
(1 99 1)  note that  first-generation users of new computer 
technologics tend  to  be  expem  in  both  computers  and 
their own task-dated activities (in other words, the initial 
devotees). Thereafter. those with task  skills who did not 
i n i d l y  take up  the  technology often  embncc it with  a 
sense of frustration due to their lack of computing literacy 
and  their high  expectations that  the  technology will do 
exactly what they want without  too much  &OK  on their 
part. Alternativdy, there are those enruing the field with 
computing  experrise  who  lack  a  solid understanding  of 
the  task  area  and  have  only  a  limited  view  of  the 
technology  from  the  system  management  perspcccive. 
Finally, there ax the uuc beginners, such as students, who 
are  trying  to  embrace  both  arcas  at  once  through 
combined  studies.  Each  group  will  have  their  own 
requirements for uncertainty communication, which will 
change with time as they acquire increasing skills. 

Stringer et al  (1991) also  note that  the reason why 
expem  are  bener  than novices  at  dealing with  compla 
information  proccssing in visual displays, is  because they 
have  superior  pattern  recognition  skills. They quote  the 

20 

example of a  tat performed to  study  the  novidexpen 
approach to  d y s i n g  maps,  in which it was found  that 
while novices looked  at a topognphic map and saw only 
nama  and  map  farura, “ p c ~  saw ternin  features, 
transport pattCmS, and urban  and rural d e m e n t s  - by 
looking for the underlying pamm represented in the map 
symbolization.  McGuiness  (1994) has  also  tested  this 
hypothesis in the conten of GIS and arrived at a similar 
conclusion.  Of  course,  assessing product  uncerrainry is 
nor  so difficult for apm users, since they tend to know 
what  questions  to  ask  and  when  to  ask them but  the 
situation  can  be  quite  difkrcnt at  the  other end  of  the 
specuum  and  can  vary  widely  amongst  users  b e m n  
these  cwo extremes. 
B d

 on  Bcdvdi  (1987) work, Coward  and 
Hcywood  (1991) interpreted 
in 
uncertainty  as  a  measure of  meta-uncertainty  (in  othu 
words, the  lcvd  of knowledge about  uncertainty).  They 
argued that  there are threc phases of gaining knowledge 
about  spatial  databases  (the  ignorance,  learning,  and 
knowledgeable  phases).  Initial  USCK  a h i b i t   very  lide 
knowledge  of  uncertainty.  This  is  followed  by  a 
considerable  rise  once  they  learn  to  question  their 
products, and then finally decrrves in the knowledgcable 
phase as they  become experienced enough  to wess  and 
account for uncertainty. 

this  difference 

To  cope  with  this  variable,  Miller et  a l   (1989) 

suggcst that dif&rent visualization approaches be used for 
diffcrenr  WK.  For instance,  novices  might  find  fuzzy 
boundary  dcpicrion  useful  to  remind  them  of  the 
positional  uncertainty  of  soil  polygon  boundaries. 
Alternatively,  skilled  users  may  prefer  to  use  spatial 
statistics and derailed data lineage repom. Similarly, there 
may  be  differences bctwccn  how  senior  executives deal 
with  uncertainty  and how analysrs cope with the matter. 
Different  visualization  approaches  mighr  be  required 
because of variatiom  in  their respecrive decision-making 
rola and penpccrives. 

At  the same time,  this distinction  between typcs of 
user  raises  the  issue  of whether  it  is  the  analyst  or the 
It 
decision maker who most  neeb to  assess  unc&ry. 
can  bc  argued  that  displays  dirmed  at  the  analyst  are 
more  useful, since  that  person  is better placed  to  advise 
the  decision  maker  on  the  consequences  of  using  a 
particular product - to avoid weighing down the decision 
maker  with  unnecessvy  information.  However,  some 
pcople  would  see  this  situation  as  dangerous when 
information  is  withheld  from  those  persons  responsible 
for policy decisions  and  suggest  that  less  complex  tools 
will be required in this case to portray uncertainty. 

Variation in applications 
It  is  already  wdl  established that  different  applications 
place  different  levels  of  importance  on  data  quality 

components  (positional  accuracy,  attribute  accuracy, 
currency,  logical  consistency,  and  completeness)  and 
sepvare approaches to visualizing the uncertainty of each 
of  these  may  need  to  be  adopted.  Various authors  have 
developed taxonomies of spatial database usage, and Tablc 
1 shows the results of a study by Bard (1989b) in which 
different  application  zrras  haw  been  grouped  around 
common uses. 

To illustrate the different forms of uncertainty that 
apply for some of these categories, consider the following 
examples:  navigation  exercises  are  primarily  concerned 
with positional unccrtainry; siting activities are aKccred by 
uncertainty in both position and artribute; the integrity of 
census  inventories can be  seriously affected by  amibute 
uncertainty; network routing  tasks depend on high  levcls 
of complacness and logical consistency in the database. 

The database output will also have a bearing on the 
means by which uncerrainty is communicated, since there 
can  be  a  marked difference bcNvecn  displays  for  analysis 
and displays for illustration. While in the latter case there 
may be a need for the standard 16.7 million colour palette 
to  provide the  subde shadings  required for high  quality 
cartographic ourput,  chis is  unlikely  to  be  necessary for 
intermediate scientific analysis. uncertainty  displays may 
well  be more  applicable to  rhc former case,  but  different 
tools may still be  needed in cach instance. 

Similarly, some  users might  be  more interested in 
the uncertainty associated with data collection, such as in 
soil  mapping,  while  others  may  need  different  tools for 
assessing  the  products  derived  from  those  maps.  In 

Communicating uncertainty in spatiof dotobases 

addition,  users  tend  to  look for  uncertainty  di&ru~tly 
depending  on  the  rype  of final  product  required.  For 
instance, it may be accepted that spending morr money on 
the production of a land-use map will improve ia accuncy 
and therefore it is important to understand its uncertainty 
befort  committing  more  resources  to  its  improwment. 
Howew in the case of culsus data the users 
forced to 
accept ics uncertainty because they undmstand thax it is the 
best  data  obtainable  and  there  is  no  opportunity  to 
recollect data to improve its quality (Beard et al  1991: 24). 

Variation in utilization of the database 
Readers will be familiar with typical definitions of spatial 
databases which indude a statement to the effm that they 
are  designed  to  provide  improved  or  more  &ccrive 
decision making, but as Z m  (1 99 1) points out, in many 
cases  the  actual  impaa  these systems  have  on  decision 
making  is  simply  not  known. In  discwing  impact 
craluation, it  is  argued  that  the  following ovo questions 
must be answered: 

1  Is the inznnation produred by a ( v a t i d  database] 
used in muking a &&on.  and ifso, how i s  it used? 
2  In what k i d  of &cisions  is (theJ inyhnation used 
and do these, in mrn, contribute to t h e j i r ~ K m m t  
of  the airision maker: goal or the pmgmmj a i m ?  
(Zwarr  1991: 79-80) 

This variation in  impact is  represented in  Figure 2 
which  illustrates  the  degrees  of  utilization  that  any 
information system  (in  genual)  might  artain  within an 
organization. Ac  the lowcsr level  the database is  not evcn 
referred  to,  while  at  the  other  extreme the  system lends 
support to decisions or may even change them  (although 
Zwart  suggcsts  this  does not  happen  as often  as people 
might believe). 

Placing Zwarr’s work into the contorr of this paper, 
the  importance  of  understanding  spacial  database 
uncertainty should  be  greatest for  those  databases  that 
impact  upon  decision  making  ar  lev&  3  or  4  (SIX 
Figure 2). As for levds 1 and 2, databascs in this siiuation 
arc either new and will take time to gain acceptance within 
an  organization, or  dx arc failing  b a a w  they  ‘cannot 

Nor needing  to  ask 

Tablc  1. A  taxonomy of spaull information  usage. 

Sou=  hhn Lbd  M K 1989b Dimcmonr  of YY and nluc of geographic 
informarion  In Gucrnr H. Onrrud H and Obcmcyer N (cdr) Rcpn of  rht 
lnirunu 4 S p d m  Mmmr  List d V d w  of G q v q h ~  
Uni*cnrry of Wlfornu. NCClA Tcchnid Rpcr 89-7  8-10 

Iafi-rr 

Sann  B h n .

 

Figure 2. Dcgrccs of system utilhuo n. 

Sowcr Afru Zwur P 1991 Somc  mdmton to m a s u m  rhe rmpaa of land 
lnbmurion ~yncmr m dcwurn A n g  h n & p   URIU  91 
 1991 4  77-89 
G~+G Sm h c o ,

21 

G i Hunter and M F GoodchiM 

e

the  currency 

 
it  are  too  old  (that  is, 

deliver appropriate applications and products to users.  Of 
course one r e w n  for poor urilivdon might bc a lack of 
corhdencc in  the  system.  implying  uscrs  either  cannot 
obtain  sufficient  information  about  the  quality of the 
database to overcome the risk of using its products, or CLK 
they find the lcvel of error in the database unxcepable. 
It  is  often  heard  that  USCIS  arc dissatisfied with a 
of reasons such as 1) the data contained 
database h
within 
is 
unacceptable), 2)  the  featurrs  have  not  been  dqgtizcd 
accuratdy enough (positional uncertainty too low), or else 
3) not  enough  is  known about  the  origins  of  the  data 
(linugc  unknown  and  therefore  integrity doubtful). 
Another  a s p  worth  considering is  the  nature  of the 
decisions fbr which  the products  are to  be  used  and,  as 
Beard  (1989b)  points  out, decisions may vary anywhere 
between  extremes 
as  routine/non-routine. 
political/non-political,  minimal 
risk, 
risklhigh 
conuovusiaI/non-conr.roversial, and  locd  implications/ 
global  implications  - with  the  nced  to  measure  and 
manage  uncertainty  likely  to  be  difirent in  each w. 
Clearly, more emphasis should be placed upon measuring 
IMCCKainty afecting decisions which carry politid, high 
risk, controversial or global implications. 

such 

Finally, 

the  various 
the  effectiveness  of 
communication  options  will nced  to  bc tested  and  this 
accrcice will nced to be p l d  in the context of the Icvcl 
of user skills prcsent, the applications and products to bc 
developed,  and  the  degree  of  dwbve  utilizvion  and 
types  of  decisions  to  be  made.  Regardless  of  this 
rcquirunent,  thcrc  is  considerable  rsevcb now  being 
un-n 
in  a l l   arras of  uncMainty communiution. 
and tools arc a l d y  starting to  appear which  will allow 
users  to  come  to  terms  with this  important  aspea  of 
database usage in the future. 

Acknowledgments 

Acknowledgment  is  gratefully  made  of  the  funding 
support for this  raearch  from the Australian Kcy Centre 
for  Land  Information  Studies  (AKCLIS),  and  the 
National Centre for Geographic Information and Analysis 
(NCGIA), Santa  Barbara,  Caiornia. The NCGIA  is 
supported by the National Science Foundation, grant SES 
88-10917  and  this  research  constitutes  part  of  the 
Centre’s  ILsearch  Initiative #7  on  Vicualization  of the 
Quality of Spatial Dam. 

Conclusions 

References 

This  paper  has  discwed  various  methods  available  for 
communicating  uncertainty 
in  spatial  databases. 
Traditional  approaches  associated with hard-copy  maps 
indude the use of cartographic  symbolization, &&ty 
diagrams,  and  positional  accuracy statements, but  these 
from being global in n a m  and serving as 
tend to s&er 
caveats rather than providing local, quantitative atimates. 
With  the advent of digital data came the dnrclopmcnr of 
new accuracy mcas- 
and while they have the advantage 
of being quantitative, their &advantag&  uc that they arc 
often difficult to understand  by unuained users,  they do 
not necessarily r d m  spatial variation in  uncertainty, and 
they prctumc  that  formal  models of spatial error already 
exist which is not yet the case for many spatial operations. 
On the  other hand, visual  methods are inhcrcndy 
more  communicative  and  provide  the  opportunity  to 
counteract  many  of  the  disadvantages  associated  with 
non-visual methods. The use of variables such as colour, 
toccuze,  size, shape, and pattern  all have the potential to 
provide  useful  tools  in  both  the  dynamic  and  static 
modes,  although 
than 
quantitative and users  will most likely require training in 
their application. Other means might also be  adopted in 
the future to supplement visual approaches, such as a d  
tools,  multi-media  approaches,  use  of the  World  Wide 
Web and virtual reality, but their potential remains largely 
unknown  at this time. 

they  are  indicative  rather 

Beard  M  K  1989a  Use  error:  T h e  neglected  error 
component.  Proceedings  Ninth  International 
Symposium  on  Computer-Assisted  Clrrtograph 
Baltimore, 1989. (AUtoGrto 9): 808-17 
Bard  M  K  1989b  Dimensions  of  use  and  value  of 
geographic information. In Calkins H, Onsrud H 
and Obenneyer N  (cds) wort  of the Initiative  4 
Sperialit  Meeting:  Uu and  Vaue  of  Geopphic 
Information.  Santa  Barbara,  University  of 
California, NCGIATtchnical Rcpon 89-7: 8-10 
Bevd  M  K  1991 Position  statement  on visualisation of 
data quality. In Beard M  K,  Buttcnficld B P and 
the  Initiative  7 
Clapham  S  B  (eds)  wort  of 
Sperialisr  Meeting:  V i l i u r t i o n   of S p d  Data 
Quality  Santa Barbara, University of California, 
NCGIA Technical Paper 9 1-26: C- 1 1 to C-I6 

Beard K M, Burrenfield B P and Clapham S B (eds) 1991 
wort  of  the  Initiative  7  Specialist  Meeting: 
Viiualiultion  of  Spatial  Data  Quality  Santa 
Barbara,  Univcrsiry  of  California,  NCGLA 
Technical Paper 91-26 

Bedad Y 1987 Uncertainties in land information systcms 
I n  temationa I 
databases.  Proceedings  Eighth 
Symposium  on  Computer-Assisted  Cartograph 
Bahimon, 1987. (AUtoCarto  8): 175-84 
Berth J  1983 Snniotbgy of p p h i a .  Madison, University 

of Wisconsin Press 

22 

Bregt  A  K  1991 Mapping  uncertainty  in  spatial  dam 
on  G I s  

Proceedings Second  European  Con+ce 
(EGIS  91), BtrcsKL 1991 VOI. 1 : 149-54 
Bunenfield  B  P  and  Beard  M  K  1994 Graphical  and 
geographical  components  of  data  quality.  In 
Hearnshaw  H  M  and  Unwin  D  J 
(cds) 
V m h t i o n  in Geogmphical Infirmarion Sytems. 
Chichestcr, Wdcy:  150-57 

Couclelis  H  1972 Geographic  knowledge  production 
through  GIs:  Towards  a  model  for  quality 
monitoring.  Two  Pmpectivcs  on  Data  Quality 
Santa  Barbara, University of California, NCGIA 
Technical &port  92-12 

Coward P and Heywood I  179 1 Aspects O f  UIKeKainty in 
spatial  decision  making,  Proceedings  Second 
European  Con$knce on  G I s  (EGIS  Yl), Brurrelr 
1991 vol.1: 23342 

Gillag  F  1791 Position  paper:  Visualization  of  data 
quality.  In  Beard  M  K,  Buttenfield  B  P  and 
Clapham  S  B  (eds)  wort  of  the  Initiative  7 
Specialist  Mem.ng:  Vinralizrrtion  of Spatial  Data 
Q u d q  Santa Barbara, University of  California, 
NCGIA Technical Paper 91-26: C-44  to C-47 

DeFranti T A,  Brown  M D  and McCormidc B  H  1987 
Visualization:  Expanding  the  scientific  and 
engineering research opportunities.  Computer 22 
(6): 27-38 

DiBiasc D, MacEachren A M, W e r

 J B and Reeves C 
1992 Animation  and  the  role of map  design  in 
scientific 
and 
Geographic Information  Systnns 17 (4): 201-14, 
265-6 

visualization. 

Cartography 

Dunon G  1771 Probability filtering for f k y  features. In 
Beard M  K,  Burrenfield  B P  and  Clapham S  B 
(eds) wort  of  the  Initiative  7 SpeciaIist Meeting 
Vuualization  of  Spatial  Data  Quality.  Santa 
Barbara,  university  of  California,  NCGIA 
Technical Paper 91-26: C-50  to C-62 
Dunon  G  1992 Handling  positional  uncertainty  in 
spatial  databases.  Proceedings  Ftyh  Inimutional 
Symposium on Spatial Data Handling,  Charlrston, 
1992 2: 46069 

Englund  E  1793 Spatial simulation.  In Goodchiid M  F, 
Parks B 0 and Steyaert L T (eds)  Environmental 
Modcling with GIs. New York, Oxford University 
Press: 432-37 

Epstein  E  F  and  Roitman  H  1787 Liability  for 
information.  Proceedings  LIRISA  '87 Conference, 
Fort Larrdmlak, 1991 4: 1 1  5-25 

Fisher P F 1991a Spatial data sources and data problems. 
In Maguire D J, Goodchild M F and Rhind D W 
(eds)  Geographical Infinnation  Systems:  finc;Plrs 
and Applications  1. Harlow, Longman: 175-89 

Fisher  P  F  1991b  First  experiments  in  viewshed 

Gmmunicating uncertainty in 3p3tiu1 &abases 

uncertainty  T h e  accuncy  of  the  v i w h e d  area. 
Photogrammetric  Engineering and Remote Sensing 
57(10): 1321-27 

Fisher  P  F  1992  First  experiments  in  viewshed 
uncertainty:  Simulating 
fizzy  viewsheds. 
Photogrammetric Engineering and Rrmotr  Sming 
58 (3): 345-52 

Fisher  P F  1993 Visualizing uncertainty in  soil maps by 
animation.  Cnrtographica 30 (2-3): 20-27 
Fisher  P  F  19941 Animation  and  sound  for  the 
visualization of uncertain spatial informarion.  In 
Hearnshaw  H  M  and  Unwin  D  J 
(cds) 
V i i l i u t t i o n  in  Geopphical Infinnation S y s m .  
Chichmer, Wdcy: 181-85 

Fisher  P  F  1994b Visualizacion  of  the  r d i i l i t y   in 
images.  Photo- 
classified  remotely  sensed 
grammetric  Enginem'ng  and  &mote  Snm'ng  60 
(7): 905-10 

Flowerdew R 199 1 Spatial data integration. In Mapire D 
J,  Goodchild  M  F  and  Rhind  D  W' (eds) 
Geographical Infirmation  $stmu:  Principb  and 
Applications  1. Harlow, Longman: 375-87 
Frank S  1973 Using visualization techniques  to  examine 
the  effects  of  random  control  points  on grid 
interpolation. Proceea!ings GISILIS '93 Confimce, 
Minnrapolic,  1993 1: 226-32 

Goodchild M F 1991 Issues of quality and uncertainty. In 
M d c r  J-C  (ed) Advances in Cnrrography Clxford, 
Elsevier: 11QO 

Goodchild  M F  1993 Data  models and  data  qualiry: 
Problems  and  prospecrs.  In  Goodchiid  M F, 
Parks B 0 and Stcyacrt L T (eds)  Environmental 
Modrling with GIs. Ncw York, Oxford University 
Press: 94-103 

Goodchild M F,  Bunenfitld B and Wood J  1794a Issues 
of validity.  In  Hearnshaw H  M  and Unwin  D J 
(eds)  Visualization  in  Geographical  Infirmation 
Systm. Chichester, Wdey: 14149 

Goodchild M F,  Lin C-C and hung Y 1994b Visualizing 
fizzy maps. In Hearnshaw H M and Unwin D J 
( e b )   V d z a t i o n  in  Geographical  Injbmation 
Systm. Chichester, Wdq 158-67 

Hassan K 1973 Visualisation of soil boundaries in a cd- 

based model.  Proceedings GISLIS '93 C o n f m c e ,  
Minneapolis,  1993 1: 93-301 

Hearnshaw H M 1994 Psychology and displays in GIs. In 
Hearnshaw  H  M  and  Unwin  D  J 
(cds) 
VGuaIization in Geographical Infinnation  Systems. 
Chichestcr, Wiey: 193-9 

Hecrick  V  R  1991 An  approach  to  spatial  data  quality 
using standard visualization tools. In Beard M K, 
Bunenfield B P and  Clapham S B  (eds) &port  of 
the Inirinnve  7 Specialist Mem.ng:  Visuahztion of 
Spatial Data  Qualit,  Santa Barbara, University of 

23 

G 1 Hunter and M F Goodchifd 

California,  NCGIA  Technical  Paper  91-26: 
C-85 to C-91 

Hunter G J  and Bard M K  1992 Undcmanding umr in 
spatial darabucs.  The r4lcmnlian Survyor 37  (2): 
108-119 

HuntcrGJandGoodchildMF 1995aDcd1ngwithmr 
in  spatial  databases:  A  simple  case  study. 
Phoqmmmehc Enginem'ng and  h t c  Smsing 
61  (5): 529-37 

Hunter G J  and Godchild M  F 1995b A new model for 
handling  vaxor  data uncertainty  in  geographic 
information  systems.  Proceedings  URIU 
'95 
C o n f k c e ,  Skn Anmio, I995 1: 420-33 
Hunter G J and Goodchild M F [submitted] M o d d i g  the 
uncertainty of dope grad~ent and aspect a h t a  
in spatial databases. c c o g m p h i r a l ~  
Kryg~er J  B  1994 Sound and geographic visulliution.  In 
MacJkhrcn  A  M  and  Taylor  D  R  F  (cds) 
V d z a t i o n  in  M& 
CartograpLy  Oxford, 
Elscvicr: 149-66 

Lowell K E 1992 On the incorporation of uncertainty into 
spatial  data  systems.  Roceedings  GIYLZS  '92 
Confknce, &n  Jose,  1992 1: 485-93 

Lunetta R S, Congalton R G, Fenrrcrrmkcr L K, JCILKII J 
R  and  T i i c y  L  R  1991  h o r c  sensing  and 
geographic information systems: Error sou~ces and 
rescarch  issues,  Photogrmnmmic Enginerring  and 
Rnnote Sensing 57 (6): 677-87 

MacJkhren A M, Howard D, Von Wyss M, Askov D and 
Taormino T  1993  Visualising  the  health  of 
Chesapeake  Bay:  An  uncertain  endeavour. 
Proceedings GISLIS  '93  Conjkme, Minneapolir, 
1993 1: 49-58 

Mackaness  W  and  Beard  M  K  1993  Viualkation  of 
interpolation  accuracy.  Proceedings  Elcvrnth 
Intmrational  Symposium  on  Computer-Assisted 
Grtvppb Minneapolic,  1993  (htoGm0  11) 
228-37 

MacLevl A L DAvelloT P and Sharon S G 1993Thc use 
of  variability  diagram 
the 
intcrprctaaon  of  digital  soil  maps  in  a  GIs. 
Photogrammmic  Enginem'ng and  Remote  Solsing 
59 (2): 223-8 

improve 

to 

McGranaghan M  1993 A cartographic view of spatial data 

quality. C a m p p h i c a  30 (2-3): 8-19 
McGuincss  C  1994  JZxpcrt/Novice  use  of  vis&tion 

tools. In MxEachrcn A M and Taylor D R F (eds) 
Vkulizution  in  Modrm  Cartograp4  Oxford, 
Elsevier: 185-99 

Miller  R  G,  Karimi  H  and  Feuchrwangcr  M  1989 
Uncertainty and  its  management  in  geographic 
information systems.  Proceedings  CISM  National 
Confimce on GIs, Onawls 1989 252-60 
Moellering H (ed) 199 1  Spatial databare mn$r  mndara5: 

24 

Gmt i n t e m a t b d m t u r .  Ncw York, Elscviu 

Monmonia M  1991 Kcy issues in the use of a p e r i e n d  
graphics for exploring data quality. In Bard M K. 
Bunenfield B P and  Clapham S B (eds) Rrport of 
the Initiative 7 Spmalrst Mem'ns  V i
 of 
S p d  Dara  QuLJIty Santa Barbara. University of 
Cdifbrnia, NCGIATcchnid Papa 91-26: C-135 
to C-142 

n

o

Niemann  B  L  1993 Integration  of  m& 

and  space- 
timc-dcpth  variability  and  uncertainties 
in 
Chesapeake  Bay  monitoring  data fbr  improved 
visualisation  and  spatial  analysis.  Proceedings 
G N U S   '93  Conference  Minneapolis  1993  2: 
567-76 

Opcnshaw  S  and  Mounscy  H  1987  Geographic 
inhrmadon  systems  and  the  BBC's  Domaday 
Interaaivc  Videodisk  International  Joumrrl  of 
Geographical Injirrrrmtra Systems 1  (3): 173-9 

Paradis J and B a d  M K 1994 ViiualLadon of spanal data 
quality for the decision m h :  A data quality filrer. 
URISA J ~ d 6  

(2): 25-34 

Prislcy  S  P  1994  Why  n a n d   resour= 

information 
managers  must  be  concerned  about  spatial 
accuracy.  hceea!ings  I n m n a t i o d  Symposium  on 
the Spatial Armmy of  Nutuml Rammr Data Bum, 
WKjamrburg IEM 24-34 

Stringer  P,  McGuincss  C  and  Van  Wench  A  1991  User 
issues in  a  GIS  environment.  In  B a r d   M  K, 
B u t t d e l d  B P and  Clapham S B (A) wort  of 
the Initiative 7 Spe&list  Meeting: Vkdizarion of 
S p d  Data Q d r ,  Santa Barbara, University of 
California,  NCGLA  Technical  Paper  91-26: 
C-154 to C-160 

Van dcr Wel  F J M, Hootsman R M  and OrmelingF 1994 
Viualisarion of data quality. In MacEadmn A M 
and Tayior D  R  F  (cds)  V i o n  in Modmr 
cartogmphy oxbrd, Eixviu: 313-31 

Vcrcgin H, Krause P, Pandya Rand Rocthlisbergu R 1993 
Design and development of an intcracrivc 'Geiger 
Counter'  for  exploratory analysis  of  sparial data 
quality.  Proceedings  GIS/LIS 
'93  Confrmce, 
Minneapolir, 1993  2  701-10 

Weba  C  R  and  Buttenfield  B  P  1993  A  cartographic 
animation  of  average yearly surface  r e m p c r a w  
for the 48 contiguous United  Stata:  1897-1986. 
Cartoppby and GIs. 20 (3): 141-50 

Wood  D 1994 V i u a l i i g  contour interpolation accuracy 
in  digital  elevation models.  In Heamshaw  H  M 
and Unwin D J (eds) Vinralization in Geographical 
In$mtion  Sjxtmu. Chichater, Wilcy: 16-0 
Zwan P  1991  Some indicators to  measure the impact of 
land  information  systems  in  decision  making. 
Proceedings  URISA  '91  Conjmzce, San  Fran&co, 
1991 4: n-89 

