 
 

 
 

 
 

 

 

 
 

 

 
 

 
 

 
 

 
 

 
 

 
 

 
 
 

Transactions in GIS

, 2003, 7(4): 485–504

Research Article

A Non-geographical Application of Spatial 
Information Systems in Pupillometry

Brett A Bryan
GISCA – The National Centre for 
Social Applications of GIS 
University of Adelaide

Benjamin P Stone
Department of Psychology 
University of Adelaide

Abstract
Spatial analysis and spatial information systems have great potential in many non-
geographic domains. This paper presents an example of the utility of spatial analysis
in a non-geographic domain. A technique of pupillometry using digital infrared video
loosely coupled with a Spatial Information System and a spreadsheet is developed
to  accurately  quantify  pupil  dilation  magnitude  and  constriction  onset  latency  for
participants of different cognitive ability and under different cognitive loads. Spatio-
temporal  pupil  dynamics  of  participants  are  recorded  using  digital  infrared  video.
The  pupil  to  iris  area  ratio  is  calculated  for  over  470,000  temporally  sequenced
de-interlaced  video  ﬁelds  by  automatic  feature  extraction  using  a  combination  of
threshold  analysis,  spatial  smoothing  and  areal  ﬁltering.  Pupil  dilation  magni-
tudes  and  constriction  onset  latencies  are  calculated  through  post-processing  in  a
spreadsheet. The study identiﬁes inadequacies in current spatial analytical techniques
for automatic feature extraction not necessarily evident in geographic applications.
Issues  impeding  the  employment  of  spatial  analysis  in  non-geographic  domains
including the lack of a generic spatial referencing system are identiﬁed and discussed.

1 Introduction

spatial

geographic
Over  recent  years,  the  term 
amongst many aspects of the profession and science of spatial information. Part of the
Information Systems (SIS) rather
justiﬁcation for the increased usage of the term 
geographic 
is
than 
on the other
semantically limited to phenomena pertaining to the earth. The term 

Information Systems (GIS) has been the realisation that 

  has  proceeded  to  replace  the  term 

Geographic 

Spatial 

spatial 

Address for correspondence:
 Brett A Bryan, GISCA – The National Centre for Social Applications
of  GIS,  The  University  of  Adelaide,  North  Terrace,  Adelaide,  South  Australia  5005,  Australia.
E-mail: brett.bryan@adelaide.edu.au

© 2003 Blackwell Publishing Ltd, 9600 Garsington Road, Oxford OX4 2DQ, UK and 
350 Main Street, Malden MA 02148, USA.

 

 

 
 
 

 

486

B A Bryan and B P Stone

hand, encapsulates a much broader suite of applications. Whilst countless studies attest
to the wide utility of SIS in analysing geographic phenomena, SIS can also be useful for
visualising  and  analysing  the  spatial  characteristics  (for  example  –  area,  distance  and
shape) of a wide variety of phenomena not pertaining to the earth. Nearly a decade and
a  half  ago,  Dangermond  and  Smith  (1988,  p  309)  envisaged  the  wider  application  of
spatial technologies to the mapping and visualisation of non-geographic domains: 

It  is  possible  that  the  wider  availability  of  automated  mapping  technology  will
encourage users to map – in the cartographic or GIS sense – the human brain, the
way  in  which  the  AIDS  virus  travels  through  the  human  body  or  the  natural
environment of bacteria at a scale of perhaps 10,000,000:1. Using this technology,
users may begin to map the seeming aspatial worlds of human decision making or
crowd phenomena, or more effectively map the multiple dimensions of time, space
and self perception in which every human being exists.

Spatial  information  is  used  in  a  wide  range  of  non-geographic  applications  that
do  not  use  the  earth  as  a  spatial  reference  point.  Probably  the  largest  usage  of  non-
geographic  but  spatial  information  occurs  in  architectural  and  engineering  design.
Architects  commonly  create  plans  and  scale  drawings  of  buildings  and  other  construc-
tions that make use of distance, area and other inherently spatial calculations. Engineers
and designers also routinely produce scale drawings of objects. In these and other similar
ﬁelds,  the  integrity  of  the  spatial  dimensions  of  the  object  is  important  and  inﬂuences
the success of future activities which rely on the drawings. Commonly, features within
these non-geographic but spatial representations are referenced to some arbitrary point
or are relative to the object itself. Usually, the value of the spatial information in these
applications  is  simply  in  creating  an  accurate  scale  representation  of  the  object  under
study for visualisation and reference. 

Visualisation  of  the  spatial  distribution  of  other  non-geographic  phenomena  has
been employed in the medical ﬁeld. The BodyViewer software uses a spatial information
system  to  map,  on  a  human  body,  the  frequency  of  different  body  parts  affected  by
diseases  and  injuries  (www.geohealth.com).  Old  (2001)  used  a  SIS  to  visualise  the
structure of the information science discipline using author citation data that had been
subject to Multidimensional Scaling. The Kohonen Self-Organizing Map neural network
architecture  and  correspondence  analysis  are  examples  of  other  techniques  used  in  the
spatial visualisation of data from a wide range of phenomena. 

Beyond visualisation, spatial analysis is being employed in the ﬁeld of medical imag-
ing in the form of automatic analysis of images of human and animal body parts from
X-ray computed tomography (CT), magnetic resonance imaging (MRI), ultrasound and
other  technologies.  Glasbey  et  al.  (1996)  and  Glasbey  and  Robinson  (1999)  have
reported techniques for the automatic detection of sheep lumbar tissue and calculation
of bone volume in the automated search for abnormalities from medical images. 

However,  publication  of  the  extension  of  spatial  analysis  and  Spatial  Information
Systems  to  non-geographic  problems  in  the  GIS  literature  has  been  limited  to  date.  In
this paper we aim to demonstrate the wider utility of spatial analysis and SIS in quanti-
fying  spatial  characteristics  and  metrics  beyond  the  geographical  realm.  We  present  a
very different, non-geographic application of SIS in the ﬁeld of cognitive psychology. We
,
pupillometer
loosely couple digital infrared video, a SIS, and a spreadsheet to create a 
and use it to quantify the spatio-temporal reﬂex dynamics of the human pupil under
different experimental conditions. 

© Blackwell Publishing Ltd. 2003

 

 

 
 
 

 

Pupillometry: A Non-geographical Application of SIS

487

This paper presents a method of pupillometry used as part of a broader study. The
general hypothesis underlying the broader study is that pupil reﬂex dynamics are related
to cognitive ability. In the experimental design, participants were asked to perform three
tasks  of  increasing  cognitive  difﬁculty  in  a  darkened  room  whilst  being  periodically
exposed to a light stimulus. During the experiment, the pupil responses of participants
were recorded using infrared digital video and the data imported into a SIS. The extent
of the pupil in each de-interlaced ﬁeld of each frame is extracted from the digital video
using  threshold  analysis,  the  pupil  extent  is  reﬁned  using  a  boundary  smoothing  algo-
rithm and areal ﬁltering, and the area of pupil is calculated using zonal operations, all
within a SIS. Temporal sequences of pupil dynamics are analysed in a spreadsheet. The
data produced by this technique are used to assess relationships between pupil dynamics
and  cognitive  ability.  Some  background  on  the  relationship  between  cognitive  ability,
the pupil reﬂex and pupillometry is provided initially, followed by a brief outline of the
broader  experimental  design.  The  remainder  of  the  paper  describes  and  discusses  the
combination  of  digital  infrared  video  with  automatic  feature  extraction  in  a  SIS  in
pupillometry  and  the  implications  for  the  extension  of  spatial  analysis  and  SIS  into
non-geographic applications.

2 Cognitive Ability, the Pupil Reﬂex and Pupillometry

The search for biological correlates with intelligence has been an active ﬁeld of research
in  cognitive  psychology  for  some  time  (Brody  1992).  Brain  nerve  conduction  velocity
(Reed  and  Jensen  1991),  electroencephalogram  (EEG),  and  event-related  potentials
(ERP) (see Deary 2000) are some of the measures of biological activity that have been
used  to  investigate  individual  differences  in  intelligence  as  measured  by  psychometric
test performance.

Associations  have  been  found  between  human  reﬂexes  and  measures  of  cognitive
ability  (Kimmel  et  al.  1967,  Siddle  and  Glenn  1974,  Smyth  et  al.  1999).  Speciﬁcally,
pupil reﬂexes have been related to a vast array of cognitive abilities including short-term
memory  (Kahneman  and  Beatty  1966,  Peavler  1974),  long-term  memory  (Kahneman
and Beatty 1966), choice reaction time (Richer et al. 1983), language processing (Beatty
and  Wagoner  1978,  Schluroff  1982,  Hyönä  et  al.  1995,  cited  in  Beatty  and  Lucero-
Wagoner  2000),  attention  (Beatty  1982),  mathematical  task  complexity  (Mentz  1985,
Hienrich  1896,  Roubinovitch  1900,  Hess  and  Polt  1964,  Boersma  et  al.  1970,  Ahern
and Beatty 1979, Schaefer et al. 1968, Steinhauer et al. 2000), and individual differences
in  cognitive  ability  tests  (Boersma  et  al.  1970,  Peavler  1974,  Ahern  and  Beatty  1979).
These  studies  have  consistently  found  that  greater  pupillary  dilation  is  observed  when
cognitive  task  difﬁculty  is  increased  and  pupil  dynamics  is  claimed  to  generally  reﬂect
human information processing load (Beatty and Lucero-Wagoner 2000).

The magnitude of pupil dilation has been related to the difﬁculty of mathematical
tasks being performed (Hess and Polt 1964, Schaefer et al. 1968, Bradshaw 1968, Ahern
and Beatty 1979, Steinhauer et al. 2000) and differences in individual cognitive ability
(Hess and Polt 1964, Peavler 1970, Ahern and Beatty 1979). Pupillary dilation latency
has been related to the difﬁculty of mathematical tasks and inversely related to cognitive
ability (Boersma et al. 1970). Evidence suggests that pupil constriction latency may also
be  related  to  mathematical  task  difﬁculty  (Steinhauer  et  al.  2000),  and  therefore,  may
also  be  related  to  cognitive  ability.  The  broader  study  by  Stone  et  al.  (in  preparation)

© Blackwell Publishing Ltd. 2003

 

 

 
 
 

 

488

B A Bryan and B P Stone

investigates relationships between pupil dynamics under mathematical tasks of varying
difﬁculty and cognitive ability as measured by psychometric tests.

Pupillometry was coined by Hess in 1965 to describe a new research ﬁeld that has
focused  on  the  quantiﬁcation  of  pupillary  dynamics  (Hess  1972).  At  the  start  of  the
twentieth  century,  German  psychologists  interested  in  pupil  size  made  qualitative
judgments  on  the  extent  of  pupillary  dilation  during  experimental  tasks  (Mentz  1895,
Heinrich 1896, Roubinovitch 1900). In the 1960s the science of pupillometry advanced
to  encompass  the  quantitative  measurement  of  the  extent  of  pupil  dilation.  Hess  and
Polt (1964) used a ‘motor-animated camera’ to record the extent of participant’s pupil
dilations  at  a  rate  of  2  images  per  second.  These  researchers  then  made  a  manual
measurement of pupil size in each image.

Nguyen  and  Stark  (1993)  developed  a  pupillometer  that  utilised  an  infrared  video
camera  and  purpose-built  software  to  capture  and  analyse  the  frames  on  an  AT-386
computer  programmed  in  Turbo-C.  Their  automatic  feature  extraction  algorithms
include auto-thresholding with masking. More recently, advanced technologies such as
the  IS-CAN,  Inc.,  Model  RK-406  pupillometer  (used  by  Steinhauer  et  al.  2000)  have
enabled  the  fast  (60  images  per  second),  accurate,  and  automated  assessment  of  pupil
dynamics. However, these machines are uncommon and the price is extremely prohib-
itive  to  most  research  laboratories.  Hence,  the  need  for  alternative  strategies  for  the
robust measurement of pupil dynamics is apparent.

3 Experimental Design Summary

Whilst  providing  full  detail  of  the  experimental  and  psychological  detail  of  the  overall
study  is  beyond  the  scope  of  this  paper,  a  summary  is  provided  here  for  context.  The
major  hypotheses  to  be  tested  by  the  data  collected  by  the  pupillometer  are  that
increased cognitive task difﬁculty will elicit larger pupil dilation and longer light-evoked
pupil constriction onset latencies. In addition, when occupied by mathematical tasks, a
higher IQ group will, on average, have smaller pupil dilations and shorter light-evoked
pupil constriction onset latencies than a lower IQ group.

Forty-eight  university  students  and  employees  volunteered  and  were  accepted  to
take part in the study. Experimental difﬁculties (discussed later) meant that it was only
possible to complete analyses on 37 participants. All participants underwent psycho-
metric  and  chronometric  testing  to  assess  cognitive  ability.  Pupillometric  testing  was
then conducted to assess pupil reﬂexes under differing cognitive loads. Participants were
secured in a head brace in a darkened room with a digital infrared video and red light
stimulus situated directly in front of them (Figures 1 and 2). 

Participants were assigned three mathematical tasks of varying difﬁculty in random
order.  These  tasks  consisted  of  a  No  Task  condition,  a  paced  series  add  1  (Add  1)
condition, and a paced series subtract 7 (Subtract 7) condition. The No Task condition
was a control condition in which the participants were asked to stare at the camera and
not  think  of  anything.  For  the  latter  two  tasks  participants  were  assigned  a  randomly
generated number between 250 and 1000 and were required to add 1 to, or subtract 7
from (respectively), this number sequentially (e.g. Subtract 7 – 357, 350, 343, 336 . . . )
approximately once every two seconds.

After two minutes in the darkened room participants were presented with a random
number and the mathematical task was set randomly. Approximately ﬁve seconds later,

© Blackwell Publishing Ltd. 2003

 

 

 
 

Pupillometry: A Non-geographical Application of SIS

489

Figure 1 Photograph of the experimental setup

 

Figure 2 Schematic drawing of the dimensions of the experimental setup

a sequence of 11 light ﬂashes was presented lasting for one second each and separated
by  three-second  intervals  of  darkness.  This  was  repeated  for  all  three  tasks.  The  same
procedure was utilised for each of the 15 cases used to assess the test/retest reliability of
the pupil measure.

The above procedure was recorded using a Sony CVX-V18NSP closed-circuit camera
with  high  power  zoom  lens  and  infrared  night-shot  capacity  onto  a  Sony  DVCAM

© Blackwell Publishing Ltd. 2003

 

 

 
 
 
 
 

 
 

 

 
 

490

B A Bryan and B P Stone

Digital Video Cassette Recorder (DSR-V10P). The camera emits an infrared light source
 630 nm) light emitting diode (LED) display was
during nightshot operation. A red (
used as the light stimulus to elicit the pupillary light reﬂex. 

λ
 

≅

4 Digital Video and SIS Pupillometry

The full method of conducting pupillometry using digital infrared video and automatic
feature  extraction  in  a  SIS  is  described  below.  The  method  involves  loosely  coupled
technologies integrated to provide an accurate measure of the spatio-temporal dynamics
of the pupil under the differing experimental conditions. The process involves capturing
and deinterlacing digital infrared video of the participants, automatically extracting and
quantifying the pupil extent with a SIS and analyzing the data in a spreadsheet.

4.1 Capturing and Deinterlacing Digital Infrared Video

To  induce  the  pupillary  responses  to  light  stimuli  required  in  this  study,  dark  experi-
mental  conditions  are  required.  Infrared  data  capture  was  used  for  its  ability  to  detect
pupil dynamics well in both darkness and lighted conditions. In addition, human pupils
generally have a high reﬂectance/emittance in the infrared spectrum compared to the iris
which enhances the capacity for automatic feature detection. The nightshot function of
the  Sony  video  camera  was  used  to  capture  pupillary  responses  of  participants  in  the
infrared spectrum.

The Australian Standard Phase Alternation by Line (PAL) video format was used at
a  rate  of  25  frames  per  second,  or  one  frame  every  40  milliseconds  (ms).  In  the  PAL
standard,  each  frame  image  is  a  composite  of  two  image  ﬁelds.  Each  ﬁeld  is  a  half
picture,  composed  of  alternate  horizontal  lines  (Figure  3)  captured  every  20 ms.  Fields
are  engineered  so  that  each  ﬁeld  presents  every  other  alternate  horizontal  line  when
compared to the ﬁeld immediately before it and two consecutive ﬁelds are interlaced to
form  a  frame.  Through  this  process  of  presenting  50  half  pictures  per  second  humans
gain the perception of ﬂuid motion in video and television images, whilst the amount of
data  required  is  minimised.  This  feature  is  used  to  enhance  the  temporal  sampling
resolution in this study.

Initially,  digital  infrared  video  data  for  each  participant  was  imported  from  the
camera  through  the  Super  Video  port  of  a  Silicon  Graphics  Indy  R5000  using  the

Figure  3 An  illustration  of  4  ﬁelds,  each  ﬁeld  is  a  half  picture  displaying  every  alternate
line  captured  every  20msec.  Fields  presented  in  temporal  order  to  enhance  the  perception
of ﬂuid motion in moving pictures

© Blackwell Publishing Ltd. 2003

 

 

 
 
 

 

Pupillometry: A Non-geographical Application of SIS

491

Figure  4 Comparison  of  the  circular  pupil  shape  of  the  interlaced  frame  of  the  digital
infrared video (left) with the elliptical pupil shape of the deinterlaced ﬁelds (right). Note the
high pupil/iris contrast present in the infrared response

capture function in the Media Recorder (Version 1.2.0) software. The PAL format video
 288 pixels), thereby
was captured in SGI raw (uncompressed) format at half size (384 
reducing data handling and computation time with acceptable loss of spatial accuracy.
The Media Recorder software was also used to both split and deinterlace the frames of
the  digital  video,  and  save  them  as  separate  3-band,  24-bit  colour,  Tagged  Image  File
Format (TIFF) image ﬁles.

×

The  40  ms  temporal  sampling  unit  provided  by  the  digital  PAL  format  video  was
too coarse to accurately quantify pupil dynamics which operate in the order of hundreds
of milliseconds. However, by deinterlacing the frames, a doubling of the temporal resolu-
tion  of  the  data  can  be  achieved  with  the  tradeoff  being  a  change  in  the  dimensional
ratio  of  the  image  (Figure  4).  Using  deinterlaced  ﬁelds  compresses  the  image  along
the Y axis such that each distance unit in the Y direction is equivalent to two distance
units in the X direction. Thus, deinterlacing the frames has a major effect on the spatial
integrity  of  the  features  in  the  image.  Instead  of  appearing  roughly  circular,  pupils
appear as ellipses whose horizontal (or semi-major) axis is roughly twice as long as its
vertical (or semi-minor) axis (Figure 4). However, this dimensional change is consistent
across all frames for all participants and the effects are predictable. Hence, the tradeoff
for a doubling in temporal resolution is acceptable.

The  result  of  the  splitting  and  de-interlacing  process  was,  for  each  participant,  a
temporal  series  of  TIFF  images  of  around  320  kilobytes  each,  corresponding  to  the
frames  of  the  digital  PAL  video.  Within  each  frame  image,  the  two  ﬁelds  from  each
frame were stacked, with the top ﬁeld preceding the bottom ﬁeld by 20 ms (Figure 5).

© Blackwell Publishing Ltd. 2003

 

 

 
 
 

 
 

 
 

 
 

 

492

B A Bryan and B P Stone

Figure 5 A TIFF image frame containing temporally stacked ﬁelds. The top ﬁeld precedes
the bottom by 20 ms, illustrated by the beginning of a blink in the bottom ﬁeld

For each pupillometric test there was approximately two and a half minutes (3,750 TIFF
frames, 7,500 ﬁelds) of data captured, requiring a total storage space of 1.2 gigabytes.
A  total  of  63  tests  were  conducted  and  157.5  minutes  of  video  captured.  These  63
included initial tests for each of the 48 participants, and retests of 15 participants taken
to  examine  test-retest  reliability  of  the  pupillometric  measure.  In  total,  approximately
236,250  TIFF  frames  were  captured  (76.5  gigabytes  of  data)  containing  472,500
stacked  ﬁelds.  The  extent  of  the  pupil  needs  to  be  extracted  from  each  ﬁeld  and  the
spatial  metrics  of  the  pupil  need  to  be  quantiﬁed.  The  next  few  sections  describe  the
automated technique devised to perform this task.

4.2 Programme and Data Structures

Extract

The de-interlaced TIFF frame images of the responses of each participant to the experi-
mental conditions were analysed in a process of automatic feature extraction using ESRI’s
  was  written  in  Arc  Macro
ArcGIS  8.1  software.  A  macro  programme  called 
Language that automatically extracts the extent of the pupil from each ﬁeld and calcu-
lates pupil area. The programme can be run in graphical mode which displays the result
of every feature extraction for every ﬁeld (used for diagnostics and troubleshooting), or
 program quantiﬁes the
in non-graphical mode which is signiﬁcantly faster. The 
iris diameter, pupil area, and the status of the light stimulus in each ﬁeld of digital video. 
The coordinate systems of the spatial data layers in the analysis are relative coordin-
ate systems with no relation to actual distance measures. Each pixel and grid cell has a
resolution of 1 distance unit and spatial metrics are measured based on this fundamental
unit.  Similarly,  due  to  the  experimental  design  where  participants  were  secured  in  the
head-brace  and  looked  directly  into  the  camera  lens,  each  image  was  assumed  to  be
orthogonal to the look angle of the camera and the radial distortions of the camera were
assumed to be negligible. Hence, no spatial correction or projection was performed on
the raw data.

Extract

Data structures were set up such that the TIFF ﬁles for each participant are stored
  is  designed  to  analyse  one

in  a  separate  folder  on  the  computer  hard  drive. 

Extract

© Blackwell Publishing Ltd. 2003

 

 

 
 
 

 
 

 
 

 

Pupillometry: A Non-geographical Application of SIS

493

participant at a time and run from the Arc command line prompt within the workspace
 programme identiﬁes all TIFF ﬁles within
of the participant under analysis. The 
the folder and sets up a programmatic loop to cycle through and analyse each sequential
TIFF ﬁle and ﬁeld within each ﬁle. 

Extract

4.3 Preprocessing and Setting the Analysis Environment

Initially,  the  red,  green,  and  blue  colour  bands  are  extracted  from  the  TIFF  ﬁle  and
converted  to  ESRI  grid  format.  The  output  grids  have  the  same  number  of  rows  and
columns as the input TIFF image, and the value of each output grid cell for each band
is equal to the colour intensity value for the corresponding band in the TIFF image (an
had to be shifted to a new origin (0, 0)
integer between 0 and 255). These
to align perfectly with the TIFF image.

 image grids 

The  ﬁrst  objective  of  the  automated  feature  extraction  process  is  to  interactively
create a user-deﬁned analysis extent and mask to both enable feature extraction and to
reduce processing time. These processing environments are set once for each participant
at  the  beginning  of  the  programme  run.  The  ﬁrst  TIFF  image  in  the  series  for  each
participant  is  presented  to  the  user  in  a  display  window  who  is  prompted  to  identify,
using  the  mouse,  the  left,  top,  right,  and  bottom  extent  of  a  rectangle  deﬁning  the
general iris extent (Figure 6). The analysis extent for the top ﬁeld is snapped to the TIFF
image  such  that  the  rectangle  aligns  perfectly  with  pixel  edges.  An  analysis  extent  is
automatically created for the bottom ﬁeld simply by subtracting 144 (half of the number

Figure  6 Interactive  user-speciﬁed  analysis  extent  and  mask.  The  user  ﬁrst  identiﬁes  the
extent of the rectangular analysis window, and then traces a mask polygon to restrict analysis
to inside the iris area

© Blackwell Publishing Ltd. 2003

 

 

 
 
 

 
 

 
 

 

494

B A Bryan and B P Stone

Figure 7 Interactive calculation of the iris diameter for a participant

of image rows) from the Y units of the analysis extent of the top ﬁeld. The cell size for
all  subsequent  analysis  is  set  to  that  of  the  image  grids  (1  distance  unit).  The  display
window is updated with both the top and bottom ﬁeld masks (Figure 6) and the user is
prompted to either continue or recreate the mask.

On continuing, the display window zooms into the analysis extent of the top ﬁeld
and  the  user  is  prompted  to  create  an  analysis  mask.  The  user  interactively  traces  a
polygon  around  the  inside  of  the  iris  (Figure  6)  using  the  mouse  and  hits  9  when
ﬁnished. A polygon coverage is created for the mask which is then converted to a grid
with matching origin and extent of the analysis mask, and a cell size matching the image.
A mask is also created for the bottom ﬁeld by shifting a mask grid down by 144 units.
The user is prompted to either recreate the mask or continue. This static analysis mask
was successful in restricting the analysis to the iris area where the contrast in brightness
between the pupil and iris was generally large thereby enhancing the automatic feature
extraction  of  the  pupil.  Breaching  of  the  mask  area  by  the  pupil  was  rare  due  to  the
experimental design which ensured the limited participant eye movement.

Calculation of the iris diameter is another fundamental step in pre-processing. It is
assumed that the iris diameter of each participant remains constant under the different
experimental conditions and hence, is only measured once for each participant. This is
accomplished  interactively  with  the  user  instructed  to  mouse-click  on  the  left-most
extreme of the iris, then on the right-most extreme (Figure 7). A simple equation is used
to calculate the iris diameter as the distance in grid cells between these points.

4.4 Identifying Pupil Threshold Value

One ﬁnal piece of pre-processing involves the interactive query of grid cell values. As is
described below, the green band performed best for pupil extraction. After the iris width
 enables the user to query the value of grid cells in and around the
is calculated 
pupil area to guide the selection of the threshold value for feature extraction.

Extract

A number of techniques were trialled for efﬁciency in identifying the extent of the
pupil including using all three image grids, and converting all three bands to brightness
values.  However,  the  identiﬁcation  of  pupil  area  was  best  accomplished  using  the
) alone
grid of the green band of the TIFF image (hereafter referred to as the 
which  displayed  greatest  pupil/iris  contrast.  Typical  grid  values  for  the  pupil  are  very
similar to those of the sclera (the ‘whites’ of the eye) and eyelids (Figure 8). The analysis
mask  was  able  to  restrict  analysis  to  within  the  iris  which  successfully  overcame  the

green grid

© Blackwell Publishing Ltd. 2003

 

 

 
 
 

 

Pupillometry: A Non-geographical Application of SIS

495

Figure 8 Typical green grid values of features of the eye area. Green grid values for pupils
are  generally  higher  than  for  the  iris  (scale  0 –255)  when  sensed  using  infrared  video.
However, pupil values are very similar to those produced by the sclera and eyelid. Also note
the low value cells in the centre of the pupil caused by reﬂection of the light

problem  presented  by  the  similarity  between  values  of  the  pupil  and  other  parts  of
the eye area.

To derive an appropriate value threshold for distinguishing between pupil and iris,
grid cell values were queried from several frames for each participant covering the full
range  of  pupil  dynamics.  As  the  pupil  constricts  under  the  varying  task  conditions  it
tends to become less bright. Hence, to ensure accurate feature extraction under the full
range  of  pupil  dynamics,  the  threshold  value  needs  to  exceed,  but  only  slightly,  the
highest surrounding iris values.

This value is then used in a threshold analysis to identify the extent of the pupil using
an  automated  feature  extraction  process.  The  thresholds  set  varied  between  particip-
ants from 90 to 178 on a scale of 0 to 255; however, thresholds were most commonly
set in the low 100s. Much of the variance in these threshold values can be explained by
different exposure levels set to maximise picture quality on the Sony video camera.

4.5 Automatic Feature Extraction of Pupil Extent

After  the  pre-processing,  setting  the  analysis  environment,  and  determination  of  the
value  threshold,  the  process  of  automatic  feature  extraction  begins.  A  primary  loop  is
used  to  cycle  through  the  TIFF  image  frames  for  the  participant  under  analysis  and  a
secondary loop is used to analyse both ﬁelds within each frame. Within each frame the
top  ﬁeld  in  analysed  ﬁrst,  then  the  bottom  ﬁeld.  The  following  analysis  is  performed
individually on each ﬁeld.

The ﬁrst task involves the collection of base data for later automatic determination
of whether the light is on or not. This was accomplished by setting the analysis extent
to the entire top ﬁeld and calculating the mean value of the grid of the red band of the
TIFF image (red grid) for all cells. When the light was on, the mean value of cells in the

© Blackwell Publishing Ltd. 2003

 

 

 
 
 

 
 

 
 

 
 

 

496

B A Bryan and B P Stone

Figure 9 Example of the automatic pupil feature extraction process. The grid of the green
band from the TIFF image is subject to threshold analysis, then the edges are smoothed using
boundaryclean and ﬁnally, the remaining smaller areas are removed using areal ﬁltering

red grid was higher than when the light was off. Formal identiﬁcation of when the light
was on and off was performed in post-processing.

The analysis extent and mask are then set to the user-speciﬁed areas for the top ﬁeld
and a series of raster operations performed to identify the pupil extent. Firstly, threshold
analysis  is  performed  by  setting  all  cells  with  values  less  than  the  threshold  value  to
NODATA.  The  areas  classiﬁed  as  pupil  by  threshold  analysis  tend  to  include  multiple
distinct  zones  and  exhibit  spatial  irregularities  such  as  irregular  edges  and  holes  or
boundaryclean
islands caused by reﬂection of the light in the pupil (Figures 8 and 9). A 
spatial smoothing function is used to eliminate the islands and smooth the edges of the
zones  classiﬁed  as  pupil  area  (Figure  9).  The  boundaryclean  function  uses  an  ‘expand
and shrink’ method to remove these islands. First, every cell value is expanded to replace
lower  value  neighbouring  cells  in  all  eight  directions.  If  the  new  grid  value  is  not  sur-
rounded on all eight sides by the same value, it is then shrunk back to its original value,
otherwise the new value is retained (ESRI 2001). This was very successful in reﬁning the
threshold analysis to a solid elliptical shape and consistently enhanced the accuracy of
pupil feature extraction (Figure 9).

zone

Commonly, more than one contiguous area (or 

) was classiﬁed as pupil as the
threshold analysis identiﬁes all grid cells with values greater than the speciﬁed threshold
value as pupil. If there are small clusters of non-pupil cells classiﬁed as pupil, such as areas
of sclera, eyelid or small areas with higher values in the iris, the boundaryclean operation
does not eliminate them. Erroneous zones tend to be much smaller in area than the actual
pupil area and are removed using a process of areal ﬁltering. Areal ﬁltering involves identi-
 function and calculat-
fying each contiguous zone classiﬁed as pupil using the 
 function. The area of the largest contiguous
ing the area of each zone using the 
pupil  zone  is  identiﬁed  using  the  describe  function  and  this  becomes  the  ﬁnal  measure

regiongroup

zonalarea

© Blackwell Publishing Ltd. 2003

 

 

 
 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 

 

Pupillometry: A Non-geographical Application of SIS

497

of pupil area. Areal ﬁltering is used to set all cells not contiguous with the largest zone
to NODATA, which leaves only the largest contiguous area of pupil (Figure 9).

Identifying  and  calculating  pupil  area  for  each  ﬁeld  of  each  image  frame  is  the
 programme.
fundamental feature extraction and analysis task performed in the 
Other secondary metrics are also calculated such as the pupil to iris fraction (described
below). A series of values are then output to a Comma Separate Values (CSV) text ﬁle
which can be directly imported into Microsoft Excel. Output values include frame and
ﬁeld  number,  time  in  milliseconds,  mean  redness,  pupil  area  and  pupil  to  iris  fraction
for each ﬁeld. Spatio-temporal pupil dynamics were analysed further outside of the SIS
using a spreadsheet.

Extract

After  writing  these  output  values  for  the  top  ﬁeld  of  the  ﬁrst  frame,  the  analysis
extent and mask are switched to the bottom ﬁeld and the same automatic feature extrac-
tion and analysis is performed and outputs written. The programme cycles through each
ﬁeld in every frame for each participant. A snapshot of every 50th ﬁeld image (one per
second)  of  the  pupil  feature  extraction  results  is  saved  to  disc  for  inspection  and  trou-
bleshooting  purposes.  The  snapshots  enable  reﬁnement  of  pupil  thresholds  and  assess-
ment of the limitations with the methodology.

4.6 The Measure: The Pupil to Iris Fraction

Several studies have proposed a pupil to iris fraction to correct for differences in pupil
size  between  participants  (Fotiou  et  al.  2000,  Lanting  et  al.  1990,  Sacks  and  Smith
1989). Usually, a ratio of the radius of the pupil divided by the radius of the iris is used
(Fotiou  et  al.  2000).  Similarly,  to  calibrate  a  measure  of  relative  pupil  size  that  allows
inter-individual comparisons to be made in this study, the ratio of the pupil area to iris
area (P/I area ratio) is used as the pupil to iris fraction.

The calculation of the P/I area ratio is performed automatically in 

. The area
contained within the circumference of the iris is calculated from an initial measurement
of the diameter of the iris made interactively by the user (see above). This estimation is
performed  only  once  under  the  assumption  that  iris  area  remains  constant.  A  second
assumption was made that the iris, as recorded in interlaced video, is circular, and that
deinterlacing the frames changes the shape of the iris to an ellipse whose semi-major axis
is  twice  as  long  as  the  semi-minor  axis.  Given  these  assumptions,  the  calculation  used
to deﬁne the ellipsoidal area of the iris in each ﬁeld is given in Equation 1:

Extract

i  
A

 =

π 2
D
8

(1) 

=

A
i 

  the  ellipsoidal  area  of  the  iris  and 

  the  diameter  of  the  iris  as  entered
where 
interactively by the user. The P/I area ratio is simply the ratio of pupil area to iris area
as calculated by these methods.

 
D

=

5 Post-processing and Analysis

5.1 Identiﬁcation of the Light Stimulus

As mentioned above, the mean value of cells in the red grid was used to identify whether
the light stimulus was on or off in each ﬁeld. In ﬁelds where the light stimulus is on, the
mean red grid cell value is approximately 10 units higher. Formal determination of the

© Blackwell Publishing Ltd. 2003

 

 

 
 
 

 
 

 
 

 
 

 
 

 

 
 

498

B A Bryan and B P Stone

light status was made from the red grid brightness values stored in the output CSV ﬁle
using the Microsoft Excel spreadsheet. For each participant, the maximum mean bright-
ness value from the 140 ﬁelds in the three-second light-off period between the presenta-
tion of the ﬁrst and second light stimuli was calculated. The light stimulus was deemed to
be  ON  for  ﬁelds  with  mean  redness  values  exceeding  this  maximum  mean  brightness
value by more than 2 units, otherwise the light was deemed to be OFF. This proved to be
a very accurate method of light identiﬁcation through cross-checking the raw image data.

5.2 Calculating Mean Pre-Light Pupil Dilation

Hess  (1972)  has  prescribed  the  use  of  a  mean  pupil  dilation  score  generated  from  20
sequential  images.  Pre-light  pupil  dilation  was  calculated  using  a  standard  measure  of
the mean pupil to iris fraction over the 20 ﬁeld images that precede the presentation of
each light stimulus using Microsoft Excel. 

5.3 Calculating Pupil Constriction Onset Latency

 
,
pupil constriction onset latency

To  measure  the  time  from  presentation  of  the  light  stimulus  to  the  beginning  of  pupil
it was necessary to deﬁne precisely when
constriction or 
the pupil started to constrict. To automatically deﬁne pupil constriction onset, 20 ﬁeld
moving averages and standard deviations for P/I area ratio are calculated. A z-score is
calculated for the P/I fraction in each ﬁeld based on the average and standard deviation
of  the  P/I  fractions  of  the  20  preceding  ﬁelds.  When  the  P/I  fraction  had  decreased  by
more  than  one  standard  deviation  for  nine  consecutive  ﬁelds  or  more,  and  the  light
stimulus was deemed to be on, the pupil was deﬁned to have started constriction in the
ﬁeld the decrease was ﬁrst detected. Calculation of the pupil constriction onset latency
was a simple calculation of subtracting the time the light stimulus was presented from
the time of constriction onset.

6 Example Results

As  discussed  above,  the  output  or  results  of  the  combination  of  digital  infrared  video
with  the  automatic  pupil  feature  extraction  is  manifest  as  a  table  of  numbers  for  each
participant. The table of numbers includes a time stamp, mean ﬁeld redness, and the
P/I area ratio for each frame. When graphed, this data provides insight into the spatio-
temporal  pupil  dynamics  of  each  participant  in  response  to  the  light  stimulus  and
tempered by cognitive load (Figure 10). Post-processing in the spreadsheet identiﬁes the
light status for each frame and calculates the mean pupil dilation and constriction onset
latency for each participant. In the broader study, the mean pupil dilation and constric-
tion  onset  latency  were  summarised  for  each  participant  and  used  in  the  statistical
comparison of pupil dynamics under different cognitive loads with cognitive ability.

7 Discussion

On  the  whole,  the  method  of  pupillometry  outlined  in  this  paper  was  very  successful.
The  combination  of  digital  infrared  video  and  the  automatic  pupil  feature  extraction

© Blackwell Publishing Ltd. 2003

Pupillometry: A Non-geographical Application of SIS

499

 

 

 
 
 

 

Figure 10 Example graphical output of the automatic feature extraction process. The light
status can clearly be seen in the oscillating high and low mean image redness value. Pupil
dilation  and  constriction  dynamics  are  illustrated  by  the  P/I  ratio  and  constriction  onset
latencies  are  reﬂected  in  the  time  lag  between  presentation  of  the  light  stimulus  and
constriction  onset.  Note  the  spike  in  P/I  area  ratio  caused  by  periodic  blinking.  The  data
presented is the subtract 7 task for retest participant 7

and analysis procedure in a SIS and spreadsheet provided an inexpensive, accurate and
reliable  pupillometry  technique.  The  quantiﬁcation  of  pupil  dynamics  using  this  tech-
nique  provided  a  suitably  rigorous  output  for  the  broader  study  of  the  relationship
between the pupil dynamics and cognitive ability published elsewhere. 

However,  several  factors  resulted  in  error  in  the  automatic  feature  extraction  and
quantiﬁcation of pupil area. Error resulting from both the analytical process and human
procedural-based problems made the automatic analysis of some or all of the data from
some participants difﬁcult or impossible. The major problem in the automatic analysis
technique is the identiﬁcation of pupils exhibiting a low pupil to iris contrast in infrared.
Human  procedural-based  problems  include  moving  pupils  and  ‘sleepy-eyes’.  These  are
discussed below and solutions are suggested.

7.1 Sources of Analytical Error

Automatic  pupil  feature  extraction  was  difﬁcult  for  participants  with  relatively  low
contrast between the pupil and the iris. For most participants, the pupil appears brighter
than the iris in infrared and automatic pupil feature extraction is successful. However,
for six participants this clear distinction between pupil and iris brightness values could
not be made (Figure 11). In addition, four participants had pupils which appear darker
than the iris when viewed in infrared (Figure 11). Finally, some participants had bright
pupils when dilated and on constriction would decrease in brightness to become similar

© Blackwell Publishing Ltd. 2003

500

B A Bryan and B P Stone

 

 

 
 
 

 
 

Figure 11 In infrared, the pupils of most participants were brighter than the iris (left). The
pupil  was  very  similar  in  brightness  to  the  iris  for  a  few  participants  (right),  and  others
exhibited darker pupils than iris (centre). On the right is an example of the erroneous pupil
feature extraction for a participant with low contrast between pupil and iris (the white area
is classiﬁed as pupil)

Extract

to,  or  even  darker  than,  the  iris.  Whilst,  in  all  of  the  above  cases,  the  pupils  were  still
clearly  distinguishable  with  the  human  eye,  the  automatic  feature  extraction  process
 programme resulted in serious errors when automatically analysed.
used in the 
This difﬁculty in automatic feature extraction of low contrast pupils is a combina-
tion  of  shortcomings  in  the  data,  the  analysis  design,  and  the  limitations  of  current
spatial analytical techniques. Firstly, the data are captured in infrared under experimental
conditions  of  total  darkness  (except  when  the  light  stimulus  is  on).  A  greater  range  of
spectral sampling could well be used to detect differences between the pupil and the iris.
Certainly, under lighted conditions, few people have pupils the same colour as their iris.
If  this  distinction  is  detectable  under  lighted  conditions  there  is  a  good  possibility  that
it may also be detectable in darkness using combinations of different parts of the electro-
magnetic  spectrum  than  were  used  in  this  study  in  a  multi-spectral  analysis.  Further
to this, spectral enhancement techniques and transforms also offer potential to increase
pupil detectability in low contrast cases.

Secondly, the threshold analysis used in this study as the basis of automatic feature
detection is simplistic. Although it works well in the majority of cases, a more sophistic-
ated  heuristic  or  numeric  classiﬁcation  using  all  three  bands  of  the  infrared  data,  or  if
available, multi-spectral data as described above, could improve the classiﬁcation accur-
acy  of  participants  with  low  contrast  pupils.  Other  techniques  may  also  assist  feature
extraction  including  shape  analysis  as  we  know  that  the  pupil  is  elliptical,  and  edge
detection as the change in values at the iris/pupil interface will be greatest. It may also
be  possible  to  develop  a  dynamic  classiﬁcation  algorithm  where  the  threshold  changes
according to the size of the pupil and other intelligent, dynamic classiﬁcation rules.

Thirdly,  established  analytical  methods  and  tools  routinely  available  in  spatial
information  systems  and  image  analysis  software  have  not  developed  sufﬁciently  to
include  algorithms  capable  of  detecting  from  image  data  features  that  are  distinguish-
able  with  the  human  eye,  but  are  of  low  contrast  with  the  surrounding  environment.
Developments in image analysis techniques need to mimic better the way humans detect
features and patterns from images.

7.2 Human Procedural-Based Problems

During  the  experiment,  movement  and  ﬁdgeting  by  two  participants  made  automatic
pupil  feature  extraction  difﬁcult  to  assess  accurately  and  prone  to  error.  Movement  of

© Blackwell Publishing Ltd. 2003

Pupillometry: A Non-geographical Application of SIS

501

the  pupil  in  the  order  of  more  than  around  0.5  cm  through  a  combination  of  body  or
eye movement, was enough for the pupil to breach the analysis mask set at the beginning
of the analysis. The result of this is an underestimate of pupil area. To properly evaluate
these moving pupils the analysis mask would have to be dynamically adjusted to follow
the  eye  movement  of  the  participant.  This  is  technically  possible  by  comparing  the
centroids  of  the  analysis  mask  and  of  the  pupil  area  after  analysis  of  each  ﬁeld  and
shifting  the  analysis  mask  by  the  distance  of  centroid  separation  after  each  iteration.
However, this would add to the processing time signiﬁcantly.

Another  problem  was  that  of  ‘sleepy  eyes’,  which  arose  because  three  participants
were unable to keep their eyelids open above their pupils. This obstruction of the pupil by
the eyelid caused an overestimation of pupil area. Due to the similarity between pupil and
eyelid image values (Figure 8) the area classiﬁed as pupil included large areas of eyelid
which were difﬁcult to mask out. Sampling different spectral regions with digital video
could assist in the distinction between eyelid and pupil especially in the thermal infrared
as it is possible that the two features may emit signiﬁcantly different thermal responses.

7.3 Future Development

Work  is  currently  underway  to  tightly  couple  and  indeed  integrate  the  technologies
used in this study. The methodology presented here is based on ESRI’s ArcGIS software
but is general enough to be implemented in most raster GIS, some of which are available
at  very  low  cost  or  free  of  charge.  A  major  problem  with  the Extract  programme  was
inefﬁcient analysis. Data from each participant took over 24 computer hours to analyse
on  a  Pentium  III  600.  However,  tasks  other  than  data  analysis,  such  as  library  access,
took  up  the  vast  majority  of  run  time.  Current  work  involves  the  development  of
non-proprietary softcopy pupillometry software which performs all the tasks described
in  the  above  process  including  importing  and  de-interlacing  the  digital  infrared  video,
automatic feature extraction and analysis of pupillometric measures. It is expected that
analysis times will be greatly reduced.

7.4 Implications for Spatial Analysis and Spatial Information Systems

Applications  of  spatial  analysis,  including  the  quantiﬁcation  of  fundamental  spatial
metrics of objects such as length, distance, area and shape, to non-geographic phenom-
ena are uncommon. One reason for this may be due to the requirement of assumptions
made about the spatial integrity of the data. The widespread use of spatial information
systems  for  geographic  applications  has  been  facilitated  by  developments  in  accurate
spatial  referencing  systems  including  ellipsoid  estimation,  geodetic  datums,  projections
and  coordinate  systems.  Spatially  accurate  feature  extraction  from  geographic  image
data  has  been  facilitated  by  substantial  development  in  geometric  correction  of  sensor
and  topographic  distortions.  There  has  been  less  development  to  ensure  the  integrity
of spatial information in non-geographic domains probably because of the potential
diversity  and  limited  generality  of  these  domains.  Without  a  sound  spatial  referencing
system, the calculation of spatial metrics is dubious. Most non-geographic applications
of  spatial  analysis  have  to  make  similar  assumptions  as  this  study  as  to  the  effect  of
geometric distortions on spatial calculations. 

The  lack  of  development  of  appropriate  spatial  referencing  systems  for  non-
geographic  environments  is  a  major  obstacle  for  the  extension  of  spatial  analysis  and

© Blackwell Publishing Ltd. 2003

502

B A Bryan and B P Stone

SIS  into  these  domains.  However,  the  mathematics  behind  the  establishment  of  spatial
referencing  systems  for  the  Earth  and  the  geometric  transformations  of  camera  distor-
tions are directly transferable to non-geographic domains. Although clearly not a trivial
exercise,  attention  needs  to  be  devoted  to  the  creation  of  a  generic  spatial  referencing
methodology and geometric transformations applicable to a wide range of non-geographic
domains to increase the beneﬁts of spatial analysis in these domains.

Another obstacle to the extension of spatial analysis to non-geographic domains is
the lack of appreciation of spatial issues amongst domain experts. A lack of appreciation
of the potential utility of spatial analysis within a particular domain impedes the take-
up of this analytical technology. Greater collaboration between the growing number of
spatial scientists and non-geographic domain experts may remedy this.

8 Conclusions

This study presents a very different application within spatial information science – the
loose coupling of digital infrared video with a SIS and spreadsheet to create a pupillo-
meter. Digital infrared video provided a useful spatio-temporal data capture medium for
pupillometry. De-interlacing the digital video was used to double the temporal sampling
resolution of the data with an acceptable and predictable loss in spatial integrity of the
data. The automatic pupil feature extraction technique employs interactive user-speciﬁed
analysis limits, and combines threshold analysis with spatial smoothing and an areal ﬁlter,
to successfully quantify pupil area and calculate the P/I area ratio. Image analysis was
also  able  to  identify  the  light  status  in  each  ﬁeld.  Post-processing  in  a  spreadsheet  was
used to quantify pupil metrics including mean dilation magnitude and constriction onset
latency  ﬁgures  for  analysis  in  the  broader  study  into  the  relationships  between  pupil
dynamics and cognitive ability under varying cognitive loads. The method of pupillometry
presented here illustrates and discusses some of the issues involved in the accurate and
rigorous use of spatial analysis and SIS in a non-geographic domain.

The  authors  greatly  appreciate  the  generosity  of  Mr.  Iain  Grierson  of  the  Department
of  Soil  and  Water,  The  University  of  Adelaide,  in  lending  the  digital  video  equipment
used in this study. The use of the computing resources at GISCA, the National Centre
for Social Applications of GIS, is also greatly appreciated. 

Acknowledgements

References

Ahern  S  and  Beatty  J  1979  Pupillary  responses  during  information  processing  varying  with

Beatty  J  1982  Task-evoked  pupillary  responses,  processing  load,  and  the  structure  of  processing

scholastic test scores. Science 205: 1289 –92

resources. Psychological Bulletin 91: 276 –92

Beatty J and Lucero-Wagoner B 2000 The pupillary system. In Cacioppo J T, Tassinary L G, and
Berntson G C (eds) Handbook of Psychophysiology (Second edition). Cambridge, Cambridge
University Press: 142– 62

Beatty J and Wagoner B L 1978 Pupillometric signs of brain activation vary with level of cognitive

processing. Science 199: 1216 – 8

© Blackwell Publishing Ltd. 2003

Pupillometry: A Non-geographical Application of SIS

503

Boersma  F,  Wilton  K,  Barham  R,  and  Muir  W  1970  Effects  of  arithmetic  problem  difﬁculty
on  pupillary  dilation  in  normals  and  educable  retardates.  Journal  of  Experimental  Child
Psychology 9: 142–55

Bradshaw J L 1968 Pupil size and problem solving. Quarterly Journal of Experimental Psychology

20: 116 –22

Brody N 1992 Intelligence. San Diego, CA, Academic Press
Dangermond J and Smith L K 1988 Geographic information systems and the revolution in carto-
graphy:  The  nature  of  the  role  played  by  a  commercial  organization.  The  American
Cartographer 15: 301–10

Deary  I  J  2000  Looking  Down  on  Human  Intelligence:  From  Psychometrics  to  the  Brain.  New

ESRI 2001 ArcDoc: ArcGIS 8.1 Documentation. Redlands, CA, Environmental Systems Research

York, Oxford University Press

Institute

Fotiou F, Fountoulakis K N, Goulas A, Alexopoulos L, and Palikaras A 2000 Automated stand-
ardized  pupillometry  with  optical  method  for  purposes  of  clinical  practice  and  research.
Clinical Physiology 20: 336– 47

Glasbey C A and Robinson C D 1999 Estimation of tissue proportions in X-ray CT images using

a new mixed pixel distribution. Task Quarterly 3: 409 –18

Glasbey C A, Abdalla I, and Simm G 1996 Towards automatic interpretation of sheep ultrasound

scans. Animal Science 62: 309 –15

Heinrich W 1896 Die Aufmerksamkeit und die Funktion der Sinnesorgane. Zeitschrift für  psychologie

und Physiologie der Sinnesorgane 9: 343– 88

Hess  E  H  1972  Pupillometrics:  A  method  of  studying  mental,  emotional,  and  sensory  processes.
In Greenﬁeld N S and Sternbach R A (eds) Handbook of Psychophysiology. New York, Holt,
Rinehart and Winston: 491–531

Hess  E  H  and  Polt  J  M  1964  Pupil  size  in  relation  to  mental  activity  during  simple  problem-

solving. Science 140: 1190 –2

Hyönä  J,  Tommola  J,  and  Alaja  A-M  1995  Pupil  dilation  as  a  measure  of  processing  load  in
simultaneous  interpretation  and  other  language  tasks.  Quarterly  Journal  of  Experimental
Psychology 48A: 598– 612

Kahneman D and Beatty J 1966 Pupil diameter and load on memory. Science 154: 1583 –5
Kimmel  J  D,  Pendergrass  V  E,  and  Kimmel  E  B  1967  Modifying  children’s  orienting  reactions

instrumentally. Conditional Reﬂex 2: 227– 35

Lanting  P,  Bos  J  E,  Aartsen  J,  Schuman  L,  Reichert-Thoen  J,  and  Heimans  J  J  1990  Assessment
of  pupillary  light  reﬂex  latency  and  darkness  adapted  pupil  size  in  control  subjects  and  in
diabetic patients with and without cardiovascular autonomic neuropathy. Journal of Neurology,
Neurosurgery, and Psychiatry 53: 912– 4

Mentz P 1895 Die Wirking akustischer Sinnesreize auf Puls und Athmung.  Philosophische Studien

Nguyen A H and Stark L W 1993 Model control of image processing: Pupillometry. Computerised

11: 61–124; 371–93; 562– 602

Medical Imaging and Graphics 17: 21–33

Old  L  J  2001  Utilizing  spatial  information  systems  for  non-spatial-data  analysis.  Scientometrics

Peavler W S 1974 Pupil size, information overload, and performance differences. Psychophysiology

51: 563 –71

11: 559 – 66

Reed T E and Jensen A R 1991 Arm nerve conduction velocity (NCV), brain NCV, reaction time,

and intelligence. Intelligence 15: 33– 47

Richer F, Silverman C, and Beatty J 1983 Response selection and initiation in speeded reactions:
A  pupillometric  analysis.  Journal  of  Experimental  Psychology:  Human  Perception  and
Performance 9: 360–70

Roubinovitch J 1900 Des variations du diamétre pupillaire en rapport aver l’effort intellectuel. In
Janet  P  (ed)  Quantriéme  Congrés  Internationale  de  Psychologie:  Compte  rendu  des  séances
et texts des mémoires, publiés par les soins du doctuer Pierre Janet. Paris: F Alcan

Sacks  B  and  Smith  S  1989  People  with  Down’s  syndrome  can  be  distinguished  on  the  basis  of
cholinergic dysfunction. Journal of Neurology, Neurosurgery, and Psychiatry 52: 1294 –5
Schaeffer T Jr, Ferguson J B, Klein J A, and Rawson E B 1968 Pupillary responses during mental

activities. Psychonomic Science 12: 137– 8

© Blackwell Publishing Ltd. 2003

504

B A Bryan and B P Stone

Schluroff  M  1982  Pupil  responses  to  grammatical  complexity  of  sentences.  Brain  and  Language

17: 133 – 45

Siddle D A T and Glenn S M 1974 Habituation of the orienting response to simple and complex

stimuli. American Journal of Mental Deﬁciency 78: 688 –93

Smyth  M,  Anderson  M,  and  Hammond  G  1999  The  modiﬁed  blink  reﬂex  and  individual  differ-

ences in speed of processing. Intelligence 27: 13 –35

Steinhauer  S  R,  Condray  R,  and  Kasparek  A  2000  Cognitive  modulation  of  midbrain  function:
task-induced reduction of the pupillary light reﬂex. International Journal of Psychophysiology
39: 21–30

© Blackwell Publishing Ltd. 2003

