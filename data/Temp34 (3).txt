G   E   O   M   A   T   I   C   A

                    AN EFFECTIVE APPROACH TO ESTIMATING 
                    COMPUTING TIME OF VECTOR DATA SPATIAL 
                    COMPUTATIONAL DOMAINS IN WEBGIS

                                                  Mingqiang Guoa,c*, Ying Huangb, Zhong Xiea  and Liang Wua
                                                                       a Faculty of Information and Engineering, China University of Geosciences (Wuhan), Wuhan, China
                                                                       b Development and Support Department, Wuhan Zondy Cyber Science and Technology Co. Ltd., 

                                                                 
                                                        c Key Laboratory of Geological Information Technology, Ministry of Land and Resources, Beijing, China

Wuhan, China

Computing time estimation is an arduous issue for scientists in computer science and GIScience. In order
to build a more effective estimation model for computing time of spatial computational domains (SCDs) in
WebGIS, decision tree machine learning method is leveraged to build a computing time decision tree (CTDT)
model. The CTDT modelling approach is focused on and elaborated in this paper. The node splitting method
is the key technology of this new approach. It can effectively address the issue of computing time estimation.
The computing time estimation framework of SCDs in WebGIS is developed by this study. Since the learning
samples of SCDs have been collected, the CTDT model of computing time of SCDs in WebGIS can be easily
trained. To demonstrate the effectiveness of the new approach, map visualization is chosen as a typical SCD
in  WebGIS  to  conduct  a  group  of  experiments.  The  test  results  indicate  that  the  performance  of  CTDT  is
obvi ously higher than area method (AM) and regression analysis method (RAM). It is capable of estimating
the computing time of SCDs. The effective computing time prompt on the client side can tremendously improve
the user’s interactive experience.

L’estimation du temps de calcul est un problème ardu pour les scientifiques des domaines de l’informatique
et  de  l’information  géographique.  Pour  être  en  mesure  de  créer  un  modèle  d’estimation  plus  efficace  du
temps de calcul des domaines de calcul de l’information géospatiale (DCIG) pour les SIG sur le Web, la
méthode  d’apprentissage  machine  de  l’arbre  décisionnel  est  exploitée  pour  créer  un  modèle  d’arbre
déci sionnel du temps de calcul (ADTC). Le présent article met l’accent sur l’approche de modélisation de
l’ADTC et l’expose plus en détail. La méthode de fractionnement des nœuds est la technologie clé de cette
nouvelle approche. Elle peut résoudre efficacement le problème de l’estimation du temps de calcul. Cette
étude développe le cadre d’estimation du temps de calcul des DCIG dans les SIG sur le Web. Grâce aux
exemples d’apprentissage des DCIG collectés, le modèle d’ADTC du temps de calcul des DCIG dans les SIG
sur le Web peut être facilement formé. Pour démontrer l’efficacité de la nouvelle approche, la visualisation
d’une carte est choisie comme DCIG représentatif d’un SIG sur le Web pour mener une série d’expériences.
Les résultats des tests indiquent que la performance de l’ADTC est, de toute évidence, supérieure à celles de
la  méthode  des  surfaces  (MS)  et  de  la  méthode  de  l’analyse  de  régression  (MAR).  Elle  est  en  mesure
d’es timer  le  temps  de  calcul  des  DCIG.  Le  temps  de  calcul  réel  affiché  du  côté  du  client  peut  améliorer
con sidérablement l’expérience interactive de l’utilisateur.

1. Introduction

In  the  field  of  computer  science,  the
effec tiveness  of  computing  time  estimating  is
important  for  resource  allocation,  which  impacts
final computing performance [Tang and Wang 2009;
Tang et al. 2011; Yang et al. 2005]. More importantly,
if the computing time can be effectively estimated,
the computing system can show the elapsed time and
remaining time to users. This information improves
the  user’s  interactive  experience  and  effi ciency,
especially  for  intensive  computational  tasks.  In

order  to  address  the  above  considerations  in
WebGIS  applications,  an  effective  approach  for
estimating computing time of spatial computational
domains (SCDs) should be further studied.

This paper consists of five sections. In Section 2,
related  literature  is  reviewed.  In  Section  3,  the
methodology  of  computing  time  decision  tree
(CTDT) modelling is articulated. Section 4 describes
the  development  of  the  computing  time  estimation
framework in WebGIS. In Section 5, a case study is

Mingqiang Guo
*gmqandjxs@163.com

Ying Huang

Zhong Xie

Liang Wu

                                                                                              dx.doi.org/10.5623/cig2017-102

GEOMATICA  Vol. 71, No. 1, 2017, pp. 21 to 26

Geomatica 2017.71:21-26.Downloaded from www.nrcresearchpress.com by Santa Barbara (UCSB) on 04/07/19. For personal use only.G   E   O   M   A   T   I   C   A

conducted to demon strate the effectiveness of the new approach
for vector map visualization SCDs in WebGIS. Finally, Section 6
summarizes with the con clusion and future works.

2. Background

Some  scholars  have  proposed  approaches  to  estimate  the
computing time of SCDs [Guo et al. 2015; Guo et al. 2014; Shook
et  al.  2013;  Tang 2013;  Wang  et  al. 2013;  Wang  et  al. 2006].
These approaches mainly fall into the following two categories:

(1)  Area  method (AM)  is  a  typical  approach  [Guo  et  al.
2014]. That is, the area of SCD is used to estimate its comput-
ing time. Aiming to estimate the computing time of SCDs, some
scientists  take  into  account  the  spatial  characteristic  of  SCDs
[Guo et al. 2015). Using the map visualization in WebGIS as an
example,  the  computing  time  of  a  SCD  can  be  estimated  by
Equation 1.

t =

(xmax (cid:2) xmin ) i (ymax (cid:2) ymin )
(Xmax (cid:2) Xmin ) i (Ymax (cid:2) Ymin )

i T

(1)

where t is the computing time of a SCD of map visualization; T
is  the  total  computing  time  of  the  full  map;  (xmin,  ymin),  (xmax,
ymax) are the geographical coordinates of the visualization bound
box; (Xmin, Ymin), (Xmax, Ymax) are the geographical coordinates of
the full map bound box. 

This method can estimate the computing time of SCDs to
some extent. However, it is only capable of estimating the com-
puting time for homogeneous geospatial data. It does not take
into account the spatial distribution of geospatial data. So, AM
cannot effectively estimate the computing time of SCDs.

(2)  Regression  Analysis  Method (RAM).  Some  scientists
have  proposed  new  approaches  to  build  a  function  model  of
computing  time  by  statistical  analysis  method.  Regression
analysis method (RAM) is one of the typical methods [Guo et
al. 2015]. Guo et al. put forward a novel computational inten-
sity modelling approach for SCDs of vector data visualization.
This  method  has  considered  the  complex  characteristics  of
SCDs. Some impact factors (such as number of vector features,
number of vertices, etc.) that will affect the computing time are
taken  into  account.  This  approach  considers  both  the  spatial
heterogeneity  and  complexity  of  SCDs.  It  can  estimate  the
computing time of SCDs to some extent. However, some less
significant factors are missed in the process of impact factors
correlation  analysis,  which  reduces  the  effectiveness  of  the
esti mation model. 

With the aim of addressing the above issues, the decision
tree model is leveraged to build the computing time estimation
model for SCDs. Decision tree is one of the machine learning
methods  that  is  widely  applied  in  classification  problems  and
big  data  mining  [Breiman 2001;  Fayyad  and  Irani 1992;  Ho
1998; Liaw and Wiener 2002; Pradhan 2013; Quinlan 1986].
This method can be used to train a decision tree model based on
a number of existing learning samples. 

22

3. Methodology of Computing
Time Decision Tree (CTDT)
Modelling

3.1 Learning Samples of SCDs

Like  the  classification  decision  tree,  learning  samples
should  be  collected  first.  Each  learning  sample  includes  the
values  of  computational  intensity  features  and  the  computing
time of SCD. Because the computational intensity features of
different  types  of  SCDs  vary,  the  learning  samples  should  be
collected separately for each type of SCD. And the computing
time  decision  tree  (CTDT)  model  should  be  trained  for  each
type of SCD separately. Assume that x0, x1, x2, … xi …xm are
the computational intensity features of one type of SCD; X is
the vector expression, X = (x0, x1, x2, … xi …xm); m is the total
number of computational intensity features. Taking map visu al-
ization as an example, computational intensity features include
a number of features in viewshed, including geographical coor-
dinates, geometry type of features, width of the viewshed, height
of  the  viewshed,  geographical  width  of  the  viewshed,
geo graphical height of the viewshed, etc. 

Defining R as the global sample space that includes all of
the learning samples of one type of SCD, the goal of CTDT is
to construct a binary decision tree based on these samples. Each
child node in the binary tree is split into two child nodes recur-
sively, beginning from the root node, until the computing time
deviation is smaller than a preset threshold (σ). Commonly, in
statistical  analysis  tools,  σ  is  set  to  be  equal  to  0.05  [Koehn
2004]. And σ also can be set to be a smaller value to improve
the precision of the model. A one-to-one correspondence exists
between a node and a sub sample space. For the root node, the
corresponding sample space is R.

3.2 Node Splitting Methodology of CTDT

The key  issue  of  CTDT  modelling  is  how  to  split  each
node  in  the  binary  decision  tree.  Because  computing  time  is  a
continuous  value,  the  estimation  of  computing  time  of  SCDs
belongs to the regression problem. So, the total residual sum of
squares (RSS) of two child nodes generated from node division
should be the minimum one. In other words, RSS can be used as
the criterion of node division. Defining R1, R2 as two sub sample
spaces split from one node, RSS1, RSS2 are the residual sum of
squares in two child nodes separately: RSS = RSS1 + RSS2. 

In  order  to  find  the  minimum  RSS,  all  values  of  all
com pu tational intensity features in the sub sample space cor-
responding  to  the  node  should  be  chosen  to  split  the  node.
Then, the RSS of each division can be calculated. After the RSS
cor re sponding to all values of all computational intensity fea-
tures  have  been  cal culated,  the  minimum  RSS can  be  found.
Then,  the  corresponding  computational  intensity  feature  (xj)
and the value of it (s) are chosen as the optimal division con-
dition: j is the index of computational intensity feature; n is the

Geomatica 2017.71:21-26.Downloaded from www.nrcresearchpress.com by Santa Barbara (UCSB) on 04/07/19. For personal use only.G   E   O   M   A   T   I   C   A

sep arately.  Then  leftChildNode and  rightChildNode are  split
recursively to let the CTDT grow until the deviation (E) of leaf
nodes  are  smaller  than  σ.  For  each  leaf  node  of  CTDT,
leftChildNode and  rightChildNode are  null.  After  all  of  the
nodes  grow  to  leaf  nodes,  then  the  final  CTDT  model  can  be
stored and represented by a corresponding CTDT_Node object. 
Using  the  CTDT_Node  object,  the  computing  time  of  a
new  sample  can  be  easily  estimated.  The  main  workflow  of
estimation is to recursively find the final leaf node beginning from
the root node of CTDT_Node object. In the target leaf node, the
average computing time values (t) of the samples are the estima-
tion result for the new sample (see Equation 4), where targetNode
is  the  final  leaf  node  object  found  in  the  CTDT_Node,  n is  the
number of samples in a node, i is index of sample and m is the
index of computing time in a learning sample.

t =

1

n

i

n(cid:2)

i=0

targetNode.samples[i][m]

(4)

3.4 Performance Evaluation of CTDT

After  the  CTDT  model  has  been  built,  its  performance
needs  evaluating.  The  computing  time  estimation  belongs  to
the regression problem, therefore the standard deviation (SD) is
used to evaluate the performance of CTDT, as in Equation 5. 

(3)

SD =

1

n

i

n(cid:3)

i=0

(t

i

(cid:2) t '

)2

i

(5)

where ti is the real computing time of one test sample of SCD,
and  t’i is  the  corresponding  estimation  result  in  the  CTDT
model;  n is  the  total  number  of  test  samples.  The  lower  the
standard  deviation,  the  higher  the  performance  of  the  CTDT
model. The performance of the CTDT model will be verified in
Section 5.

number of samples in a node; ti is the computing time of sample
i. RSS is calculated by Equation 2, where R1(j, s) = {(X, t) | xj≤s},
R2(j, s) = {(X, t) | xj > s}.

RSS =

(cid:2)

(cid:2)

(t

i

x
i

(cid:2)R1( j,s)

i

1

n

(cid:2) )2
t

i

+

(cid:2)

(cid:2)

(t

i

x
i

(cid:2)R1( j,s)

x
i

(cid:2)R2 ( j,s)

i

1

n

(cid:2) )2
t

i

x
i

(cid:2)R2 ( j,s)

(2)

In order to improve the performance of the CTDT model,
the binary decision tree should stop splitting when it can satisfy
the  preset  precision  requirement. Assume  that  σ  is  the  preset
deviation threshold. After one node has been split into two sub
child nodes, the deviation in each child node should be calcu-
lated and be compared with σ. If it is smaller than σ, the child
node is a leaf node that can not be split again. Conversely, the
child node will be split recursively. The deviation (E) in each
child  node  can  be  calculated  by  Equation  3.  When  all  of  the
nodes  in  the  binary  decision  tree  stop  splitting,  the  CTDT  is
finally  constructed:  j is  the  index  of  computational  intensity
feature; xi is the value of computational intensity feature j; n is
the  number  of  samples  in  a  node;  ti is  the  computing  time  of
sample i.

E =

i

1

n

(cid:3)

x
i

(cid:2)R( j,s )

(cid:2)

(t

i

i

1

n

(cid:3) )2
t

i

x
i

(cid:2)R( j,s )

t

i

3.3 CTDT Modelling and New Sample
Estimation

In Section 3.2, the modelling approach of CTDT has been
elaborated. After the CTDT has been trained based on a set of
learning samples of SCDs, the computing times of new SCDs
can  be  estimated  by  simply  finding  the  target  leaf  node  in
CTDT  recursively. The  root  node  and  its  two  child  nodes  are
shown in Figure 1. The data structure of CTDT_Node has been
designed to store and represent a CTDT model:

Class CTDT_Node{

Public CTDT_Node leftChildNode; 
Public CTDT_Node rightChildNode; 
Public int j; 
Public double s; 
Public double[ ][ ] samples;

}

For the root node of CTDT, all of the learning samples of
SCDs  are  included  in  variable  samples.  The  CTDT  begins  to
grow from the root node. Each node will be split into two child
nodes if its deviation (E) is bigger than σ, which is mentioned
in  Section  3.2.  The  splitting  method  is  also  articulated  in
Section  3.2. The  samples  set  in  the  current  node  will  be  split
into  two  sub  samples  set  by  xj and  its  value  s,  then  they  are
saved  to  the  samples of  leftChildNode and  rightChildNode

Figure 1: The root node and child nodes of CTDT.

23

Geomatica 2017.71:21-26.Downloaded from www.nrcresearchpress.com by Santa Barbara (UCSB) on 04/07/19. For personal use only.G   E   O   M   A   T   I   C   A

4. Computing Time Estimation
Framework of SCDs in WebGIS

As  mentioned  in  Section  1,  WebGIS  is  a  user  intensive
sys tem.  Large  numbers  of  clients  access  the  network  spatial
information service published on the server side. Each request
from the client will generate a SCD. All of the SCDs can be col-
lected and saved in the learning samples database. Based on the
database, a CTDT model can be trained to estimate the comput-
ing time of a new request. Once the the CTDT model estimates
the computing time of a new request, the computing time can be
sent to the client side immediately and prompt users on the client
side. If the computing time is long, users can continue to do other
operations  and  return  when  the  previous  request  is  completed.
Accurate estimates of time required for computing is useful for
users  to  realize  work  efficiencies  in WebGIS.  If  no  computing
time prompt is generated for any request, the user is left guessing
whether to wait or stop the current request operation. To address
the  above  problems  and  ameliorate  the  user  interactive  experi-
ence in WebGIS, the computing time estimation framework of
SCDs is designed in this paper, as shown in Figure 2.

On the client side, there are three types of interfaces. Take
map visualization for example: (1) client users operate the map
application  through  the  map  operation  interface  and  submit
map image requests to the GIS server; (2) the prompt interface
provides users with the estimated computing time of submitted
map  requests;  (3)  the  resulting  interface  represents  the  map
images. When the GIS server receives a map request, it imme-
diately  analyzes  the  parameters  of  the  map  request,  and  then
generates the SCD of the map request. After the SCD has been
generated, it will be executed on the server. At the same time,
the  CTDT  model  effectively  estimates  the  computing  time  of
the SCD. This is sent to the client side and the prompt interface
informs the user of the estimated wait time for the map images
to be generated on the GIS server. 

5. Experiment and Discussion

Since online map service is one kind of typical GIS serv ic e
that  is  widely  applied  in  WebGIS,  map  visualization  SCD  is
chosen as a typical SCD to demonstrate the performance of the
CTDT model. The computing time estimation framework was
implemented  using  the  C#  language,  and  compiled  using
Visual Studio 2010. The vector spatial data for test has 202 695
spatial  features  and  the  total  number  of  geographical  coordi-
nates  is  9 224 233.  The  total  volume  size  is  506.977  MB.  In
order  to  verify  the  performance  and  effectiveness  of  CTDT
proposed by this paper, two traditional approaches (i.e. AM and
RAM, mentioned in Section 2) are used to conduct a group of
tests and comparison analysis.

5.1 Learning Samples Collection of Map
Visualization SCD

In  order  to  build  a  CTDT  model  for  map  visualization
SCD, the learning samples must be collected first. For the map
visualization task, the following parameters can be regarded as
its computational intensity features: i.e. number of features in
viewshed (nf); number of geographical coordinates (ng); geom-
etry type of features (gt); width of the viewshed (w); height of
the  viewshed  (h);  geographical  width  of  the  viewshed  (gw);
geographical height of the viewshed (gh); The computing time
(t) of map visualization task is the dependent variable. So, one
leaning  sample  of  map  visualization  SCD  is  collected  as  [nf,
ng, gt, w, h, gw, gh, t]. 

Using the computing time estimation framework of SCD
in  WebGIS  described  in  Section  4,  4011  learning  samples  of
map visualization SCDs are collected. In order to compare the
performance  of  the  CTDT  model  with  AM  and  RAM
(described  in  Section  2),  4000  samples  are  used  to  build  the
CTDT  model  and  the  regression  model  of  RAM. Another  11

Figure 2: Computing time estimation framework of SCDs.

24

Geomatica 2017.71:21-26.Downloaded from www.nrcresearchpress.com by Santa Barbara (UCSB) on 04/07/19. For personal use only.G   E   O   M   A   T   I   C   A

0 

1  1 107 

827 

8 448.26 

6 315.82 

38 

can be drawn, as follows:

samples  are  used  to  check  the  performance  of  these  three
approaches,  as  shown  in  Table  1.  Sometimes  no  features  are
distributed in a map viewshed. Under this circumstance, nf and
ng are equal to 0. 

Table 1: Checking samples for performance analysis.

nf

ng

gt

w

h

gw

gh

t

0 

0 

0 

0 

0 

12 525 

839 878 

2  1 062  1 027 

62 303.56  60 273.58  2 059 

0 

1  1 084  1 259 

13 051.39  15 168.97 

34 

1 151 

85 455 

1  1 040  1 437 

3 728.54 

5 153.14 

195 

1 202 

69 784 

2  1 061  1 338 

29 615.29  37 356.69 

139 

8 015 

539 866 

2  1 098  1 202 

35 517.93  38 911.07 

788 

400 

19 870 

1  1 100 

776 

29 807.92  21 041.29 

55 

76 407  5 178 957 

2  1 039 

725 

51 115.10  35 678.94  9 677 

0 

0 

0 

1  1 029  1 510 

26 592.11  39 039.53 

1  1 084 

745 

17 269.26  11 879.81 

2  1 104 

755 

59 511.93  40 704.64 

42 

24 

39 

5.2 Performance Analysis

To  compare  the  performance  of  the  three  approaches
(CTDT, RAM and AM), the computing times of 11 test sam-
ples  estimated  by  these  approaches  are  recorded.  The  results
are  eas ily  compared  with  the  real  computing  time  in  a  line
curves chart, as shown in Figure 3.

From the line curves shown in Figure 3, two conclusions

(1) The overall trend of real computing time is nearly con sis-

tent with the computing time estimated by three approaches. 

(2)  The  performance  of  CTDT  and  RAM  is  obviously
higher and steadier than AM, and the performance of CTDT is
the highest one. 

In  order  to  compare  CTDT  with  RAM  more  clearly,  the
absolute deviations of the estimated computing times of the 11
test samples are calculated, as shown in Figure 4. The results
indicate that the absolute computing time deviations of CTDT
are far lower than RAM. The standard deviation (mentioned in
Section 3.4) of CTDT is 138, while it is 466 for RAM and 5263
for AM. This obviously shows that the overall performance of
CTDT is the highest of the three: it is 3.38 times higher than
RAM and 38.14 times higher than AM. 

Figure 3:
Computing
time of
different
approaches.

Figure 4:
Computing
time 
deviation 
of CTDT 
and RAM.

25

Geomatica 2017.71:21-26.Downloaded from www.nrcresearchpress.com by Santa Barbara (UCSB) on 04/07/19. For personal use only.G   E   O   M   A   T   I   C   A

6. Conclusion

The main contribution of this paper is to develop a novel
and effective modelling approach of computing time of SCDs
in WebGIS. The performance of the new approach is 3.38 times
higher  than  the  traditional  regression  analysis  method.
However, the training process of the CTDT model still needs to
be  optimized.  It  will  take  significant  time  to  train  a  CTDT
model  where  there  are  large  numbers  of  learning  samples  of
SCDs. In order to constantly improve the effectiveness of the
CTDT model, it should be retrained when the learning samples
are changed, so as to make the computing time prompt on the
client  side  in  WebGIS  more  effective.  The  parallel  training
approach  of  the  CTDT  model  will  be  further  studied  in  the
future, so as to ameliorate the performance of CTDT modelling.

Acknowledgements

This  project  is  funded  by  the  China  Postdoctoral  Science
Foundation (No. 2014M552115), and is supported the National
Key Research & Development Project (No. 2016YFB0502600);
National Natural Science Foundation of China (No. 41701446);
Hubei  Province  Natural  Science  Foundation  of  China
(No. 2017CFB277); Key Laboratory of Geological Information
Technology  Foundation,  Ministry  of  Land  and  Resources,
China (No:2017-324).

References
Breiman, L. 2001. Random Forests. Machine Learning. 45(1): 5–32.
Fayyad, U.M. and K.B. Irani. 1992. On the handling of continuous-valued
attributes in decision tree generation. Machine Learning. 8(1): 87–102.
Guo, M., Q. Guan, Z. Xie, L. Wu, X. Luo, Y. Huang. 2015. A spatially
adaptive decomposition approach for parallel vector data visuali-
zation  of  polylines  and  polygons.  International  Journal  of
Geographical Information Science. 29(8): 1419–1440.

Guo, M., Y. Huang, Z. Xie. 2014. Parallel scheduling strategy of web-
based  spatial  computing  tasks  in  multi-core  environment.  High
Technology Letters. 20(4): 395–400.

Guo, M., Y. Huang, Z. Xie. 2015. A balanced decomposition approach
to  real-time  visualization  of  large  vector  maps  in  CyberGIS.
Frontiers of Computer Science. 9(3): 442–455.

Ho, T.K. 1998. The Random Subspace method for constructing deci-
sion  forests.  Pattern  Analysis  and  Machine  Intelligence,  IEEE
Transactions on. 20(8): 832–844.

Koehn,  P.  2004.  Statistical  significance  tests  for  machine  translation
evaluation.  Paper  presented  at  the  Conference  on  Empirical
Methods in Natural Language Processing, EMNLP 2004, 25–26
July 2004, Barcelona, Spain.

Liaw,  A.  and  M.  Wiener.  2002.  Classification  and  regression  by

randomForest. R News. 2(3): 18–22.

Pradhan, B. 2013. A comparative study on the predictive ability of the
decision tree, support vector machine and neuro-fuzzy models in
landslide  susceptibility  mapping  using  GIS.  Computers  and
Geosciences. 51(2): 350–365.

Quinlan,  J.R.  1986.  Induction  of  decision  trees.  Machine  Learning.

1(1): 81–106.

Shook,  E.,  S. Wang, W. Tang.  2013. A  communication-aware  frame-
work  for  parallel  spatially  explicit  agent-based  models.

26

International  Journal  of  Geographical  Information  Science.
27(11): 2160–2181.

Tang, W. 2013. Parallel construction of large circular cartograms using
graphics processing units. International Journal of Geographical
Information Science. 27(11): 2182–2206.

Tang, W., D.A. Bennett, S. Wang. 2011. A parallel agent-based model
of land use opinions. Journal of Land Use Science. 6(2-3): 121–135.
Tang, W., S. Wang. 2009. HPABM: a hierarchical parallel simulation
framework 
agent-based  models.
spatially-explicit 
Transactions in GIS. 13(3): 315–333.

for 

Wang,  D.,  M.W.  Berry,  L.J.  Gross.  2006.  On  parallelization  of  a
spa tially-explicit  structured  ecological  model  for  integrated
ecosystem 
International  Journal  of  High
Performance Computing Applications. 20(4): 571–581.

simulation.

Wang, S., L. Anselin, B. Bhaduri, C. Crosby, M.F. Goodchild, Y. Liu,
et al. 2013. CyberGIS software: a synthetic review and integra-
tion 
International  Journal  of  Geographical
Information Science. 27(11): 2122–2145.

roadmap. 

Yang,  C.,  D.W.  Wong,  R.  Yang,  M.  Kafatos,  Q.  Li.  2005.
in  web-based  GIS.
techniques 
Performance-improving 
International  Journal  of  Geographical  Information  Science.
19(3): 319–342.

MS rec’d 16/12/14
Revised MS rec’d 17/05/18

Authors

Mingqiang  Guo  is  a post-doctor  in  China  University  of
Geosciences, born in 1984. He received his PhD degree from
China University of Geosciences in 2013. He also received his
BS degree from China University of Geosciences in 2007. His
research focuses on key techniques for CyberGIS performance
optimization,  parallel  spatial  computing,  computational
inten sity representation and load balancing algorithms.

Ying  Huang  is  a post-doctor,  born  in  1981.  She  received
her PhD degree from China University of Geosciences in 2008.
Her  research  focuses  on  key  techniques  for  CyberGIS
frame-work, concurrent processing performance optimization,
big spatial data, spatial cloud computing, web services, OGC
services and load balancing algorithms.

Zhong  Xie  is  a professor  at  China  University  of
Geosciences, born in 1968. He received his PhD degree from
China University of Geosciences in 2002. He also received his
BS degree from China University of Geosciences in 1990. His
research focuses on key techniques for geographical informa-
tion systems, parallel spatial computing, CyberGIS framework,
intensity
parallel 
rep re sen ta tion and load balancing algorithms.

computational 

computing, 

spatial 

Liang Wu is an associate professor in China University of
Geosciences, born in 1976. He received his PhD degree from
China University of Geosciences in 2005. He also received his
BS degree from China University of Geosciences in 1998. His
research focuses on key techniques for CyberGIS framework,
big  spatial  data,  spatial  cloud  computing  and  load  balancing
algorithms. q

Geomatica 2017.71:21-26.Downloaded from www.nrcresearchpress.com by Santa Barbara (UCSB) on 04/07/19. For personal use only.