GeoInformatica 2:4, 335–358 (1998)
# 1998 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.

Linking Objects of Different Spatial Data Sets by
Integration and Aggregation

MONIKA SESTER, KARL-HEINRICH ANDERS, AND VOLKER WALTER
Institute for Photogrammetry, Stuttgart University, 70174 Stuttgart, Germany
E-mail: {monika.sester, kh.anders, volker.walter}@ifp.uni-stuttgart.de

Received March 2, 1998; Revised June 30, 1998; Accepted August 12, 1998

Abstract

In order to solve spatial analysis problems, nowadays a huge amount of digital data sets can be accessed:
cadastral, topographic, geologic, and environmental data, in addition to all kinds of other types of thematic
information. In order to fully exploit and combine the advantages of each data set, they have to be integrated. This
integration has to be established at an object level leading to a multiple representation scheme. Depending on the
type of data sets involved, it can be achieved using different techniques.

Such a linking has many beneﬁts. First, it helps to limit redundancies and inconsistencies. Furthermore, it helps
to take advantage of the characteristics of more than one data set and therefore greatly supports complex analysis
processes. Also, it opens the way to integrated data and knowledge processing using whatever information and
processes are available in a comprehensive manner. This is an issue currently addressed under the heading of
‘interoperability’.

Linking has basically two aspects: on the one hand, the links characterize the correspondence between
individual objects in two representations. On the other hand, the links also can carry information about the
differences between the data sets and therefore have a procedural component, allowing the generation of a new
data set based on given information (i.e., database generalization).

In the paper three approaches for the linking of objects in different spatial data sets are described. The ﬁrst
deﬁnes the linking as a matching problem and aims at ﬁnding a correspondence between two data sets of similar
scale. The two other approaches focus on the derivation of one representation from the other one, leading to an
automatic generation of new digital data sets of lower resolution. All the approaches rely on methodologies and
techniques from artiﬁcial intelligence, namely knowledge representation and processing, search procedures, and
machine learning.

Keywords: multiple representations, aggregation, database generalization, matching, machine learning

1.

Introduction

With the availability of geoprocessing tools and automatic data acquisition techniques, a
steady and rapid growth in the amount of digital data can be observed. These data are
collected by different organizations, in different spatial resolutions, by different sensors,
and based on various data models. This results in a tremendous variety of data sets. Since
each of the data sets focuses on different aspects of the physical reality, each has its proper
right to exist. Another important aspect is that spatial phenomena occur at different levels
of detail. Views in different scales reveal various aspects of the data—all of them are
equally important. This has to be reﬂected by representations of the objects at different
scales—a fact that has traditionally been taken care of in the map series provided by the

336

SESTER, ANDERS, AND WALTER

mapping agencies. These maps exist as separate entities, linked only implicitly by the
common geometrical reference, or by common objects.

In order to make use of this rich variety of available information, the various data sets
have to be linked explicitly. Such a functionality goes far beyond the simple overlay of
separate data layers: it implies the direct linking of the individual objects in the data sets. It
can either be achieved by integrating data sets into one uniform data set, or by providing
interchangeability between the representations through links among homologous objects.
In an ideal scenario therefore these different data sets coexist, however they are connected
with each other (see ﬁgure 1). In this way, data of different spatial resolution, geometric
precision, and thematic focus can be combined and used in an integrated way and with
mutual beneﬁts. Linking exhibits two important aspects: on the one hand, it opens the way
to combine already existing data sets to form multi-scale databases. On the other hand—
which is particularly of interest in the context of database generalization—the links also
can carry information about the transitions from one data set to the other, thus allowing the
direct generation of a new, generalized data set. Therefore, once the scale transition
relationships [9] between the representations are known, they can be used to generate new
data through generalization.

A multiple representation scheme ideally also includes an analysis functionality
allowing the system to choose the appropriate representation for a given task or to perform
inferences across scales using hierarchical data analysis. The underlying assumption here
is that problems are less complex on a coarser level. Furthermore the results of the coarse
level can be used as approximate values for solutions on ﬁner levels. Such techniques are
commonly used in digital image processing (see e.g., [2]). In this way, hierarchical data
analysis allows querying on objects even if they are not deﬁned in the same representation.

Figure 1. Multiple representation scheme: linking data sets of different data models, thematic focus, types, and
scales (DLM: Digital Landscape Models at scales 1:25,000, 1:200,000, 1:1,000,000). The arrows indicate
possible links.

LINKING OBJECTS OF DIFFERENT SPATIAL DATA SETS

337

Besides this analysis functionality, such a system has the following beneﬁts:

* Information fusion: attributes of the data sets can be exchanged.
* Information generation and update: one data set can be generated from the other one,

thus supporting update and revision processes.

The key problems in the realization are the following:

* Provision of a multiple representation data scheme, allowing the same objects to have

different geometric and semantic properties.

* Establishing explicit links between the objects in different representations.
* Hierarchical data analysis procedures.

The paper focuses on the linking aspect. These links indicate the type of transitions an
object undergoes when moving from one representation to the next. These transformations
are manifold: objects may keep their representation, they may change their geometry, type
or attributes, merge with other objects, or can completely disappear. In order to establish
such links the various relations between objects in different representations have to be
revealed. Obviously, they are inﬂuenced by the objects themselves, their semantics, their
geometric properties, and the given application. Correspondences can be established at the
level of individual object instances, at object class level, or at the geometry level. The
easiest way of doing so is via a common object identiﬁcation, e.g., a street name or the
name of a building. In general, however, the objects are named individually in the different
data sets. Another realization is based on the same geometry—where objects are said to
correspond if they are in the same geometric location. Since data sets usually are captured
based on different data models and possibly by different organizations, there will be
geometric discrepancies in the resulting data. The third possibility is to link objects based
on general knowledge about them, e.g., that a city consists of many buildings and streets.
Basically, establishing links can be seen as a matching problem, involving information
given in similar representation schemes. This matching can be solved with various
approaches, depending on the type of data to be matched (e.g., feature based or relational
matching). Data sets of different scales, however, are too different to match directly. Thus,
before the matching itself, a generalization step has to transform the data into similar,
comparable structures. This can be achieved with database generalization approaches.

The paper gives examples for three different linking approaches. After a review of
related work, Section 3 focuses on linking data sets of similar scale based on geometric
and topologic properties of the objects using a relational matching approach. Linking data
sets of different scale can only be performed based on known semantic relations. To this
end, these relations between objects in different scales have to be described. They can be
established explicitly for each individual object by assigning each object its corresponding
partner in the other scale. More ﬂexibility is offered by using abstract knowledge and
applying it to the data. The provision of this knowledge, however, is not trivial—a fact
called the knowledge acquisition bottleneck. Typically, knowledge is acquired using text
documents, querying experts, etc.—processes, which require further formalization of the

338

SESTER, ANDERS, AND WALTER

knowledge. Section 4 presents an approach where the knowledge is set up based on written
documents, which are commonly used by human experts.

Making knowledge explicit involves the speciﬁcation of a lot of objects, relations and
parameters. Machine learning techniques can be applied in order to derive explicit
information from implicit data. Starting from an existing data set the procedure tries to
reveal the underlying structure inherent in the data. Section 5 presents an approach to
derive the aggregation rules with the help of supervised learning. A discussion of the
different methods concerning their applicability and a summary conclude the paper.

2. Related work

Research concerning the full integration of data sets from different sources is presently
done in the ﬁeld of multiple representation [8], [33]. The problem of linking different data
sets is tackled in many research contexts. One important branch is in the domain of
database generalization or model generalization.

Many issues in automatic generalization concentrate on speciﬁc features, mainly lines.
The problem, however, is that usually the generalization of one object also affects others,
e.g., the simpliﬁcation of a line inﬂuences the form of the polygon it borders. Thus, objects
should not be treated separately. In current generalization research there is a focus on
comprehensive models where the key issue is to integrate semantic and geometric context
[20], leading to network-like representation structures. Geometric context so far has been
mainly described either by regular rasters [14], [35], or by triangulation approaches [15].
The latter provide a rich data structure to describe topological and proximity relations
between spatial objects in a map: two objects are considered as neighbors if they are
connected via a common edge in the triangulation network.

Semantic context can be speciﬁed by a set of explicit rules (e.g., [3], [25], [38]). A way
to achieve a generalization on-the-ﬂy has been proposed by van Oosterom [37]: his aim is
the derivation of a temporary generalization, mainly for visualization purposes. The
approach is based on a single aggregation rule which takes the adjacency of the objects and
their importance—which has to be speciﬁed in advance—into account. The use of
machine learning for the acquisition of structural knowledge is addressed in several
approaches, e.g., FOIL [23] or CLARET [21]. These systems are, however, mainly
designed to acquire descriptions of single, isolated objects, and do not focus on an integral
context dependent description. In the context of generalization, Weibel et al. [45] use a
learning approach to acquire the knowledge a human cartographer intuitively uses when
faced with a speciﬁc generalization task. This is done by logging both her actions and the
situation when she did it. ID3, a popular learning algorithm ([22]; also brieﬂy explained in
Section 5) is used to extract the underlying relations, connections and dependencies.

Matching techniques are also known under the name conﬂation, which comes from the
Latin con ﬂare meaning ‘‘blow together’’ [19]. One of the ﬁrst approaches of matching
spatial data from different data models is the work of the Bureau of Census in Washington
DC [26], [28]. A system was developed to merge digital data sets provided by the Bureau

LINKING OBJECTS OF DIFFERENT SPATIAL DATA SETS

339

of Census and the United States Geological Survey (USGS). The aim of the project was to
improve the quality of the data, to eliminate errors and to exchange attributes and objects.
Different matching techniques have been developed for the attribute exchange of US
Census Bureau TIGER data with other data sets. The TIGER database contains a large
number of different attributes but it is spatially very often incorrect. Therefore, many users
want to merge the highly attributed TIGER data with their own captured data with more
correct geometry. Examples can be found in [7], [31] and [36].

Gabay and Doytsher [10] considered how maps can be matched which differ slightly
concerning the geometric properties but can differ considerably concerning the
topological properties. With the assumption that one data set is captured in a higher
quality, the geometry of the data set with the lower quality is improved [11]. In [7] the
importance of n : m matchings is discussed and examples for an automatic exchange of
attributes are given. Van Wijngaarden et al. [39] overlay building data acquired at different
scales and investigate the cardinality and type of correspondence between the objects.

Spaccapietra et al. [32] analyze discrepancies in spatial data representations. They
identify possible problems and propose concepts for solutions. They principally
distinguish between manual and semi-automatic approaches for
the integration.
Devogele et al. [9] present an integrated approach starting with semantic integration
followed by geometric matching.

3. Relational matching of spatial data

In this section the integration of two data sets of similar scale is deﬁned as a matching
problem which means that primitives of the data sets should be matched to each other. The
word primitives can represent a geometrical element as well as an object structure. After
matching the primitives of two data sets an integration can be performed. This could be for
example a combination and supplement of feature classes or attributes or an improvement
of the geometry.

The decision regarding which primitives should be matched is dependent on the
similarity of the data sets [42]. If data captured in the same data model have to be matched,
corresponding features can easily be found because of similar object structures and
attributes. Afterwards the corresponding geometric elements can be matched to each other.
This is a top down approach, also known as semantic data integration (ﬁgure 2).

In this work a matching strategy for GDF and ATKIS data is developed. GDF is a
European standard for the modeling, acquisition and exchange of road network data [13].
GDF data are captured for most areas in Western Europe and are available for the whole
area of Germany. ATKIS is the German topographic cartographic spatial database and
presently contains 60 different object classes for the whole area of Germany at the scale
1:25,000 (beside this scale there are further levels of data aggregation at the scales
1:200,000 and 1:1,000,000. GDF and ATKIS correspond the most at the level 1:25,000).
Object classes which are captured both in ATKIS and GDF form only a subset because of
the different applications. The aim of ATKIS is to provide the users with a basic set of

340

SESTER, ANDERS, AND WALTER

Figure 2. Top down vs. bottom up approach.

spatial topographic objects whereas GDF was especially developed for purposes of vehicle
navigation.

Due to the different object structures in GDF and ATKIS it is not possible to perform the
matching at the object level. The geometrical and topological representation of the data
has to be used (bottom up approach). Because the common data sets of ATKIS and GDF
extensively contain objects from the road environment it was decided to use the roads as
matching primitives.

3.1. Examples of ATKIS and GDF acquisition

In the following, some examples of the data sets which were used for this work are
presented to illustrate the different kinds of matching pairs. When comparing ATKIS and
GDF it can typically be seen that in some areas the data sets are very similar whereas
especially in intersection areas strong differences appear. GDF was developed for
purposes of vehicle navigation and therefore it is necessary to store not only information
about the topography but also about how a vehicle could pass an intersection. That means
that all ﬁlter lanes have to be captured which leads to a more complex acquisition. Figure 3
a) shows the different acquisition of an intersection in ATKIS and GDF. It can be seen that
in the object class trafﬁc the acquisition of GDF data is more detailed and that ATKIS data
form a subset of GDF data.

While at least a subset of the elements were captured similarly in ﬁgure 3 a) the example
of ﬁgure 3 b) shows an intersection which is captured completely differently in ATKIS and

LINKING OBJECTS OF DIFFERENT SPATIAL DATA SETS

341

Figure 3. Different acquisition in ATKIS and GDF.

GDF. There are so few common elements in the two data sets that correspondences can
hardly be seen.

A further difference between ATKIS and GDF data can be a different acquisition of the
number of lanes. Figure 3 c) shows an example in which a street is captured in ATKIS only
by the middle axis whereas it is represented by two lanes in GDF. The inverse situation that
a street is captured in ATKIS by two lanes and in GDF by the middle axis can also be found
in the data sets. Figure 3 d) shows an intersection that is captured in more detail in GDF but
one of the streets is captured in ATKIS by two lanes in contrast to the GDF data.

342

SESTER, ANDERS, AND WALTER

; bj2

; . . . ; bjn

Figure 4 shows the possible instances of matching. One element ai could be matched to
exactly one element bj. Furthermore one element ai could be matched to several elements
g could be matched to
g. On the contrary several elements fai1
; . . . ; ain
fbj1
exactly one element bj. Moreover several elements fai1
g could be matched to
; . . . ; ain
g or one element could not be matched at all. This is
several elements fbj1
represented with a wildcard (*). The matching n : m1 (cid:135) m2 describes a special case of
n : m matching. It means that one or more elements of one data set are matched to several
elements of the other data set which are not topologically connected. This is the situation
that in one data set a street is captured by the middle axis and in the other data set by two
lanes (cf. ﬁgure 3 c) and 3 d)).

; . . . ; bjm

; ai2
; ai2

; bj2

3.2. Matching approach

The approach of this work is based on the principles of relational matching which were
introduced by [29]. This approach was veriﬁed by [40] and was used for the ﬁrst time in
photogrammetric computer vision. In order to evaluate the search space a support function
is derived from information theory. This approach is theoretically founded and is based
only on statistical investigations between the data sets. That means that no weight factors,
thresholds or starting parameters (tuning factors) are needed. The statistical investigations
are calculated from training matchings.

The matching problem is mapped onto a communication system to calculate the support
function. Figure 5 shows this approach. For the sake of brevity, we restrict the description
of the approach to the absolute minimum. A comprehensive treatment can be found in
[44]. A communication system transfers messages through a channel from a transmitter to
a receiver. Depending on the channel there will be differences between the transmitted and
the received message. If the channel is an ideal channel the transmitted and the received
message are exactly the same. If the channel is disturbed, which means there is noise in the
channel, then the transmitted and the received message differ. The best channel is the one
in which the smallest difference between transmitted and received messages appear.

The problem of searching for the best channel can be seen as equivalent to the matching
problem of two data sets [5], [6], [40]. In order to ﬁnd the best channel between a

Figure 4. Cardinality of the matching pairs.

LINKING OBJECTS OF DIFFERENT SPATIAL DATA SETS

343

Figure 5. Mapping of the matching problem onto a communication system.

transmitter and a receiver, a mapping function is sought which transfers the transmitted
message to a received message which is the most similar. The matching problem can be
seen similarly as a communication system. A transmitter sends as a message the data set
D1 which is received by the receiver as the data set D2. The differences between D1 and
D2 appear because of noise in the channel.

Information theory offers a comprehensive repertoire of measures for the optimization
of communication systems. The measure which was used in this work is the mutual
information I(cid:133)ai; bj(cid:134) which is an important measure for the design and performance of
communication systems and is deﬁned as:

I(cid:133)ai; bj(cid:134) (cid:136) log2

[bit].

P(cid:133)aijbj(cid:134)
P(cid:133)ai(cid:134)

(cid:133)1(cid:134)

P(cid:133)ai(cid:134) is the probability that a symbol ai is sent from the transmitter and P(cid:133)aijbj(cid:134) is the
conditional probability that the symbol bj is received when the symbol ai was sent. The
mutual information measures the amount of information which one symbol ai gives about
another symbol bj.

In order to calculate the mutual information I(cid:133)D1; D2(cid:134) of a matching h : D1?D2 the two
spatial data sets D1 and D2 are seen as messages which consist of symbols represented by
the matching primitives (in our approach the centerlines of streets) [41], [43], [44]. The
primitives have to be described by features and relations to map them onto an alphabet
D (cid:136) fd1; d2; (cid:1) (cid:1) (cid:1) ; dng.

For the matching of ATKIS and GDF data the features’ length, shape and position of
start and end point are considered. The relational part is described by the topological
relation connected. The mutual information of two data sets D1 and D2 (cid:136) h(cid:133)D1(cid:134) is deﬁned

344

SESTER, ANDERS, AND WALTER

by the sum of the mutual information of all matching pairs p which take part in the
matching h:

Ih(cid:133)D1; D2(cid:134) (cid:136)

I(cid:133)length(cid:133)p(cid:134); length(cid:133)h(cid:133)p(cid:134)(cid:134)(cid:134)

X

p[h

X

p[h
X

(cid:135)

(cid:135)

(cid:135)

p[h
X

X

ri[h

rj[h

I(cid:133)form(cid:133)p(cid:134); form(cid:133)h(cid:133)p(cid:134)(cid:134)(cid:134)

I(cid:133)position(cid:133)p(cid:134); position(cid:133)h(cid:133)p(cid:134)(cid:134)(cid:134)

I(cid:133)connected(cid:133)ri; rj(cid:134); connected(cid:133)h(cid:133)ri(cid:134); h(cid:133)rj(cid:134)(cid:134)(cid:134)

(cid:133)2(cid:134)

The best matching of two data sets is a combination of matching pairs where the sum of
the support function leads to a maximum. This is a problem with exponentially increasing
search space. But when taking a closer look at the data it can be seen that there is a strong
locality of the matchings. Therefore, it is not necessary to evaluate the whole search space
which stands for all possible combinations of matchings but it is sufﬁcient to evaluate only
a subset. A method was developed which splits the search space heuristically into smaller
parts which can be evaluated independently [41], [43], [44]. The following optimization of
these parts was done with an A* algorithm (see for example [12]). The A* algorithm ﬁnds
solutions to problems (which have their search space represented in a tree) in a shorter
time than blind search methods.

3.3. Results

The approach was tested on four test areas with a size of 2 (cid:3) 2 km2 and of different street
density. The ATKIS and GDF data were kindly made available by the State Surveying
Ofﬁce of Baden-Wu¨rttemberg and the company Bosch/Teleatlas, respectively. The results
of the automatic approach were compared with manually produced matchings. Table 1
shows the results of the different test areas. On average 96.26% of the elements were
matched by the automatic procedure in the same way as manually. It can be seen that test
area 1 contains signiﬁcantly fewer successful matchings than the other test areas. The
reason is that the ATKIS and GDF data in this test area were not captured at the same time.
A lot of intersection areas have been strongly changed due to a reduction in trafﬁc. The
ATKIS data were acquired after the changes, whereas the GDF data were acquired before

Table 1. Results of automatic matching.

Test Area

1

2

3

4

number of matching pairs
number of ATKIS elements in test area
number successfully matched ATKIS elements
in percent

208
363
328
90.35

349
530
523
98.67

332
530
515
97.16

469
640
620
96.87

Total

1358
2063
1986
96.26

LINKING OBJECTS OF DIFFERENT SPATIAL DATA SETS

345

the changes. In some local areas this led to completely different data sets and increased the
number of incorrectly matching pairs.

With this matching procedure different kinds of applications are possible (see ﬁgure 6).
The geometry of two data sets can be compared automatically in order to identify
incorrectly captured elements or updates in the data sets and to improve the geometric
quality. A further application is the transfer of attributes or object classes which are
captured in one data set but not in the other. For example, street names are captured
in GDF but not in ATKIS. This is an application with a high level of automation
potential.

4. Medium scale objects from large scale data through aggregation

The previous section has shown how to establish links between data models of similar
scale. This method is not directly usable for two data sets of different scales. First of all, we
have to transform both data sets to a similar scale—which is a data aggregation problem.
In the following, an approach will be demonstrated showing the derivation of built-up
areas for a medium scale data model from a large scale data model based on predeﬁned
rules.

Figure 6.

Integration of ATKIS and GDF.

346

SESTER, ANDERS, AND WALTER

4.1. The German ALK—digital cadastral map

In this approach we create ATKIS DLM25 (see previous section) built-up areas from ALK
data. ALK data are acquired in the scale 1:500 and include information about parcels and
their usage, political borders, buildings, topographic objects and text (street names, type of
a building, . . .). Geometric features are points, lines and areas (cf. ﬁgure 8). The ALK is
provided by the local survey administrations and is available in four different exchange
formats (BGRUND, SICAD-GDB, EDBS and DXF).

4.2. Aggregation rules

First of all the links between the data sets have to be established. A so-called object-
catalog of ATKIS speciﬁes how the objects have to be created and captured. The following
rule describes how built-up areas (object id. 2111) have to be acquired [1].

Built-up areas are areas that are exclusively or mainly used for living. Besides
buildings, there are also objects serving for the provision of needs of the whole area
like small workshops, organizations of clerical, cultural, social, or sanitary purpose.
The boundaries between a built-up area and neighboring areas are given by the
boundaries of the parcels of land the buildings are standing on. [Translated from the
German original.]

These rules are made for humans—in order to transfer them to an automatic system they
have to be formalized. The speciﬁcation above reveals a link between the data sets, namely
the fact that built-up areas consist of adjoining residential areas. Residential areas are
parcels of land comprising building objects like houses, garages, etc. This, however, is
information which is stored (explicitly and implicitly) in ALK. As the rule implies
aggregation of neighboring building-objects to a settlement area, the question is how to
deﬁne a neighborhood in this application—in this case by adjacency. The transition from
ALK to ATKIS therefore has to rely on a detailed examination of the underlying data
models, making implicit information explicit and thus usable. This will be revealed in the
following semantic modeling process.

In order to describe spatial objects in a digital map, we use semantic modeling [18] as a
conceptual method to analyze how a human operator detects such kinds of objects. Figure
7 shows the semantic model in the OMT notation [27] which we use to describe parcels of
land and built-up areas.

4.3.

Implementation and results

Our approach contains the following three steps:

Find area features which represent parcels

This ﬁrst step is optional and only necessary when in the exchange format the parcels

LINKING OBJECTS OF DIFFERENT SPATIAL DATA SETS

347

Figure 7. Semantic model of parcels and built-up areas.

are not stored as area features but as so-called spaghetti data. Therefore the ﬁrst step is
to compute all possible areas based on the given list of lines. An area is represented by
a simple polygon which is a cycle of line features in the net of lines (cf. left part of
ﬁgure 7).

Classify the parcels

Based on their usage the parcels are grouped into the three classes: residential,
industrial and area of mixed use. Therefore, we take all text features which are
instances of Whs, Gar, Bpl (German abbreviation for residential house, garage,
building plot) as residential areas and instances of Fabr, Btrg, Lagg (German
abbreviation for factory, service building, warehouse) as industrial buildings. Areas of
mixed use have instances of both residential and industrial text features. Analogously
to the previous step we make a point-in-polygon test for all possible combinations
to ﬁnd the relations to the corresponding areas (cf. lower middle and right part of
ﬁgure 7).

Aggregate parcels

For all the three classes we aggregate all adjoining parcels of identical class to create
residential area, industrial area and area of mixed use objects. The semantic rule for
grouping of these areas is the adjacency principle (see right hand side of ﬁgure 7), i.e.,

348

SESTER, ANDERS, AND WALTER

all residential areas which are connected via a common border are merged. This can
easily be performed using the topological relations between the areas which is directly
derivable from our data model.

Figure 8 gives the result of the grouping and shows the built-up areas in that region. This
result is achieved only based on the assumption of a spatial aggregation of adjoining built-
up objects. Comparing these ATKIS-objects with original ATKIS-data reveals the
following (see ﬁgure 9):

* The main source of the differences are: different acquisition dates and different

interpretation of the acquisition rules by different human operators.

* The boundaries of the areas do not exactly correspond: this is due to the fact that in
ATKIS the roads are stored as line objects only by their middle axis. The adjacent
objects then meet at that axis. In our case as we take the road model from ALK (which
is area based), the built-up areas consequently border the ALK roads. An extension
would be to also generalize the roads (ﬁnd the middle axis from a road area) and then
generalize both data types in common.

4.4. Possible extensions of the approach

The result of the previous steps shows which aggregation level is achievable based on an
initial semantic modeling of the knowledge implicitly given in the data and explicitly

Figure 8. Built-up areas generated from ALK data (black lines): residential area (light gray), area of mixed use
(gray) and industrial area (dark gray).

LINKING OBJECTS OF DIFFERENT SPATIAL DATA SETS

349

Figure 9. Overlay of original ATKIS built-up areas (black lines) and automatically derived areas (shaded
areas).

given in terms of a—rather abstract—object description catalog. In order to compensate
for possible exceptions to this, different strategies have to be applied depending on the
type of relation to be modeled. One such obvious exception is the fact that some built-up
areas are aggregated, even if there is a road in between.

If the relations are mainly geometric, a triangulation structure can be used to determine
the neighborhood. This process can be followed by a spatial clustering operation, minimal
spanning trees [24]. In the same way, e.g., higher level structures of ATKIS can be derived
by application of further aggregation procedures. For example, the location of the
boundary of a city (ATKIS object id. 2101) is described in the object catalog as comprising
all the built-up and industrial areas, and also including the trafﬁc and vegetation areas. In
this case the aggregation cannot be based on the adjacency principle alone, but has also to
consider possible gaps in between. This can be solved with a constrained Delaunay
triangulation on the polygon points of the settlement objects, followed by a spatial
clustering. The hull around these clustered objects then represents the boundary of a city.
This hull can easily be derived by deleting all edges which are shared by two objects—thus
only the bordering edges remain.

If, however, the relations between the objects are not known explicitly, Machine

Learning techniques can be applied (see next section).

5. Learning aggregation rules

Machine learning techniques are preferably applied in cases where explicit knowledge is
not available or difﬁcult to acquire. Also, in situations where a system has to deal with
changing environments, such methods are very useful [34]. In the following, supervised

350

SESTER, ANDERS, AND WALTER

learning is used to derive aggregation rules from a data set. The idea is that ﬁrst the teacher
gives examples of objects to be aggregated and then the system derives the underlying,
object speciﬁc conditions.

The approach is realized in an interpretation and learning environment, where the
learning component is the classical program ID3 [22]. ID3 learns classiﬁcation rules based
on given attribute-value–lists using the entropy criterion from information theory. The
attributes in this list represent the set of attributes of which an object may consist. These
attributes can be seen as a kind of vocabulary with which an object (or a relation) may be
described. This vocabulary is given in advance and consists of object properties (e.g., the
size, form, elongation, . . . of a polygon) and object relations (e.g., the difference in size,
the distance, the containment, the connection, . . . of two polygons). From this set ID3
selects the relevant attributes for the concept to be learned.

In this approach,

the learning is embedded in a system, where complex object
descriptions can be acquired incrementally, based on a given general object structure,
which includes object relations and attributes. The general semantic relationships [16]
which are modeled in the structure are generalization and classiﬁcation (is-a-relation), as
well as aggregation (part-of-relation) and association (arbitrary relationship). Starting
from this structure, object classiﬁcation and aggregation can be carried out. The teacher
has to specify the type of semantic relation to be learned and to give representative
examples and counter-examples for it.

The task in this case is to acquire the rules for the aggregation of objects of a data set to a
more general representation. The main problem in aggregating is the deﬁnition of what to
group, why and also when [30]. Obviously it
their
characteristics and their relations. These conditions vary from object to object (e.g.,
aggregation based on direct adjacency, closeness, or semantic similarity). Hence, these
criteria have to be revealed in the learning process. In the following example, the detailed
data set
is digital cadastral data—real-estate-objects—given in an unstructured
representation, namely a set of polygons without semantic interpretation. The aim is to
derive descriptions of the objects in the scene and their semantic relationships. In this way
preconditions for object aggregation can be learned.

is dependent on the objects,

5.1. Learning objects and semantic relations

In a ﬁrst learning step new object types are derived, i.e., a classiﬁcation of the polygon
objects is learned. The teacher points at various polygon–objects and refers to them as ﬁeld
or trafﬁc. The system derives the classiﬁcation of these structures from the data set. The
teacher points at some polygons (here: poly16 and poly3) and names them ﬁeld, and at
others (here: poly1, poly12 and poly6) and classiﬁes them as trafﬁc.

LINKING OBJECTS OF DIFFERENT SPATIAL DATA SETS

351

% polygon_object contains contained object_elongation object_lq object_size polytyp num_points num_right_-
angles num_parallel num_same_length object_form junction_ell
junction_tee junction_frk junction_arw
junction_njn5%.

0.86 4748.38 rectangle 4 4 2 2 H 0 4
no no 1.28
[ﬁeld
0.41 3698.30 rectangle 7 3 2 1 H 2 6
[ﬁeld
no no 1.58
0.30 3438.53 quadrat
[trafﬁc no no 5.23
[trafﬁc no no 3.05
0.14 256.25
[trafﬁc no no 11.56 0.03 852.17

0 0 0 ]
0 0 0 ]
8 2 2 11 H 4 10 0 0 0 ]
0 0 0 ]
0 0 0 ]

rectangle 4 2 1 0 V 0 4
5 2 1 4 H 2 4
quadrat

;
;
;
;
;

;
;
;
;
;

; poly16
; poly3
; poly1
; poly12
; poly6

The system automatically creates two new object classes and ID3 derives the

classiﬁcation function of the two object classes ﬁeld and trafﬁc from these examples.

deﬁne polygon_object ( area ) ? class ;

vars class , area ;
if <= ( ( object_elongation (area) val) , 2.96 ) then

elseif > ( ( object_elongation (area) val) , 2.96 ) then

‘ﬁeld’ ? class;

‘trafﬁc’ ? class;

endif;
enddeﬁne;

This code was generated by the program and, since it is implemented in an interpreted
language called POP11 [4], it can immediately be executed and used by subsequent
processes. In POP11 syntax the simple arrow ? assigns an expression to a variable; the
double arrow is also an assignment, but duplicates the value on top of the stack, so that it is
available to be used again, here to be compared with the value 2.96. A function is always
embedded between deﬁne and enddeﬁne. The resulting function differentiates ﬁelds and
trafﬁc objects according to their elongation. The threshold value (2.96) in this function
was automatically derived based on a clustering of all the values into appropriate classes,
again selected based on the entropy principle.

In this way, the system’s knowledge has been extended: now the polygons have new
methods to apply, namely to differentiate between the two new object classes using the
new classiﬁcation rule. After that, in a second learning step, a further specialization of
object classes can be derived. The class trafﬁc can be specialized into street and cycle
track: by pointing at a trafﬁc object, the system immediately appends the newly acquired
knowledge to the object trafﬁc. Thus the two new object classes are sub classes of the
trafﬁc-class. These classes inherit all the attributes and methods of their super class but
have the additional speciﬁcations just learned.

In the same way also associations between objects can be learned, e.g., the relation
between a cycle track and a neighboring street. From a set of examples, the following
function (decision tree) for such a relation is automatically gained by ID3:

352

SESTER, ANDERS, AND WALTER

deﬁne street_cycle_track( area1, area2 ) ? class ;

vars class, area1, area2 ;
if ( are_parallel (area1, area2) val) == ‘‘yes’’ then
if ( connection (area1, area2) val) == ‘‘yes’’ then

elseif ( connection (area1, area2) val) == ‘‘no’’ then

‘positive’ ? class;

‘‘negative’’ ? class;

endif;

‘‘negative’’ ? class;

endif;
enddeﬁne;

elseif ( are_parallel (area1, area2) val) == ‘‘no’’ then

This function speciﬁes that in order to determine the neighborhood of streets and cycle
tracks a check has to be made as to whether they are parallel and connected—which might
be obvious after reading it. Constructing this rule by hand, one might easily have
considered parallelism alone and have forgotten to check for a connection. Figure 10 (left,
dotted lines) visualizes the objects sharing this association.

Also aggregations of objects can be interactively and iteratively gained. The ﬁeld-ﬁeld–
relation is an example of a reﬂexive relation, resulting in an aggregation of the
participating objects (see ﬁgure 10, left, solid lines). Fields sharing this relation can be
merged. The relation learned from the data speciﬁes that objects sharing two common
TEE-nodes can be aggregated, which reﬂects the hierarchical partitioning of the parcels. In
the interpretation phase, objects apply this function. In this way, e.g., ﬁelds ﬁeld2 and
ﬁeld3 are aggregated, resulting in a new ﬁeld object. This in turn shares the required
relation with the ﬁelds ﬁeld6 and ﬁeld8, and thus can be iteratively merged to them,
resulting in ﬁeld13. For the street-objects a similar relation has been learned: streets may
be merged—provided they share the relation learned from the data set. In this case, the

Figure 10. Left: Association street-cycle track (dotted line); relation ﬁeld-ﬁeld (solid line): observe that only
those ﬁelds are linked that share the learned relation, i.e., that have two TEE-nodes in common (for clariﬁcation,
the nodes shared by ﬁeld2 and ﬁeld3 are given). Right: Final interpretation of the scene.

LINKING OBJECTS OF DIFFERENT SPATIAL DATA SETS

353

criterion for merging is the connection of streets. Although the same functionality
(merging, aggregation) is achieved, the underlying function is different—it is object
dependent and derived from the data.

Thus, in the end a complete scene description evolves, together with a corresponding
model of all the objects in the scene. The knowledge acquired in the learning process is
visualized in ﬁgure 11.

5.2. Result

The approach relies on the fact that the teacher is responsible for the learning, by showing
‘interesting concepts’, which she thinks might be responsible for the structure to be
derived. Since she has an idea of which objects are important in the scene and which
relations might be relevant, she presents representative objects for such concepts and the
system derives the preconditions which are relevant to it. The resulting function is general
and can be applied to other data sets as well. The same technique can be applied to derive
relations among other objects, e.g., all the objects inside a city.

Figure 11. Structural description of the knowledge acquired in the learning process: objects and semantic
relations, given in OMT notation [27].

354

6. Discussion

SESTER, ANDERS, AND WALTER

The three methods presented in the paper are all essential to the problem of linking
different data sets. In our view, there is not a single solution to solve this complex problem,
but different techniques have to interact. As demonstrated in the examples, the different
approaches have their own application ﬁelds.

As long as the data sets exhibit a certain similarity (in structure and geometry), the ﬁrst
approach is very suitable and can be applied to arbitrary problem domains. The presented
approach for matching ATKIS and GDF is based on the comparison of the geometrical and
topological representation of the data.

Therefore, this approach is usable for matching data which are captured at a similar
scale. It is not necessary that the data sets are synchronized in time. In [41], [43], [44]
quality measures derived from information theory are presented. With these quality
measures it is possible to identify incorrectly matched elements in an automatic way.
Incorrectly matched elements occur in areas where the data have been captured very
differently in their respective sources which is a good indicator for updates in the data
sets.

When data sets captured at different scales have to be matched, ﬁrst the data sets have to
be preprocessed in order to get a similar representation—which is basically an aggregation
or generalization process. The question of how and when to aggregate objects is not trivial
at all. If a semantically structured data set is available, rules can be formulated which
describe relationships within the data. These rules can either be derived by interpretation
of manuals or existing rules made for human operators, or by visually inspecting existing
data sets and discovering regularities. Such techniques can successfully be applied in cases
where the necessary knowledge is available and can be formulated. The problem is to ﬁnd
and formulate all possible exceptions to the general rules.

The basic idea of the last approach is to use machine learning techniques for the
derivation of the underlying knowledge implicitly given in existing data sets. The
learning procedure does the same as a human operator is doing, namely trying to identify
regularities in the data and formulating a rule from that. The advantage of an automatic
system is its objectivity. Furthermore, in this approach the result is represented in a form
that can directly be applied by the system, as it is in the system’s language. However,
there is a caveat: the learning system depends on the given vocabulary and on the
selection of examples. The learning system guarantees ﬁnding an explanation for the
given facts—however it might be rather complex, due to an incorrect or inappropriate
vocabulary or due to atypical examples. Therefore, it is of greatest importance that the
result of the learning is veriﬁed by the teacher in order to assess its relevance. Only if the
rule that was learned makes sense to the teacher (or fulﬁlls given preconditions), can it
be considered reliable.

the
We consider our work as necessary pieces of a puzzle of methods for
generalization and integration of spatial data. Methods of the type described in the
paper are necessary: approaches to the formulation of knowledge in terms of rules,
methods to extract knowledge in case it is difﬁcult to acquire as well as ﬂexible methods
to match data sets.

LINKING OBJECTS OF DIFFERENT SPATIAL DATA SETS

355

7. Conclusions, summary and outlook

This paper has introduced some of the problems of multiple representation. As a major
research topic the establishment of links between different data sets has been identiﬁed.
Two main properties of the links have to be considered: they are either declarative and
specify that objects are tied together, or they can have a procedural component, expressing
the changes an object undergoes when going from one representation to another. Both
aspects are vital for a multiple representation system. In the paper techniques for both
issues have been addressed.

First, we described how two data sets of similar scales can be matched in order to proﬁt
in terms of exchanging attributes, updating, homogenization, etc. The second functionality
has been used for the derivation of a representation of lower resolution from a highly
detailed data set, i.e., to perform database generalization. This model generalization is
mainly based on semantic links between the data sets. A primary problem is the provision
of the necessary knowledge used for the semantic linking. Obviously all available
knowledge should be applied—machine learning techniques are very useful in situations
where no explicit knowledge is available. Their main feature is to reveal explicit
knowledge from implicit data. In this case, existing maps serve as a knowledge store,
which capture a lot of implicit information. All the issues rely on integrating different
techniques from artiﬁcial intelligence.

Further research has to focus on deﬁning a multiple representation database scheme and
also on the use of this structure for hierarchical data analysis: in order to gain an overview
of a given situation, small scales are consulted; only in regions of interest is a further
zooming performed where the details can be investigated leading to the natural coarse-to-
ﬁne–treatment of problems.

Parts of this work is embedded in the joint research project Semantic Modelling for the
Extraction of Spatial Objects from Images and Maps and is funded by the German
Research Organization (DFG). We want to thank our anonymous reviewers for their
valuable comments and also the editors for their encouragement and help.

Acknowledgments

References

1. Amtlich Topographisches-Kartographisches Informationssystem (ATKIS). Arbeitsgemeinschaft der La¨nder

der Vermessungsverwaltungen der Bundesrepublik Deutschland (AdV), Bonn, 1988.

2. F. Ackermann and M. Hahn. ‘‘Image pyramids for digital photogrammetry,’’ in H. Ebner, D. Fritsch, and C.
Heipke, editors, Digital Photogrammetric Systems, pages 43–58, Mu¨nchen, September 1991. Wichmann
Verlag.

3. K.-H. Anders and M. Sester. ‘‘Methods of data base interpretation—applied to model generalization from
large to medium scale,’’ in W. Fo¨rstner and L. Plu¨mer, editors, SMATI ’97: Semantic Modelling for the
Acquisition of Topographic Information from Images and Maps, pages 89–103. Birkha¨user, 1997.

356

SESTER, ANDERS, AND WALTER

4. R. Barrett, A. Ramsay, and A. Sloman. POP-11, A Practical Language for Artiﬁcial Intelligence. Ellis

Horwood Ltd., Chichester, West Sussex, England, 1985.

5. K.L. Boyer and A.C. Kak. Symbolic stereo from structural descriptions. Technical Report TR-EE 86-12,

School of Electrical Engineering, Purdue University, West Lafayette, Indiana, February 1986.

6. K.L. Boyer and A.C. Kak. ‘‘Structural stereopsis for 3-D vision,’’ IEEE Transactions on Pattern Analysis

and Machine Intelligence, Vol. 10(2):144–166, 1988.

7. J. Brown, A. Rao, and J. Baran. ‘‘Are you Conﬂated? Integrating TIGER and other data sets through

Automated Network Conﬂation,’’ in GIS-T 95, GIS/Trans Ltd, Cambridge, April 1995.

8. B. Buttenﬁeld and J.S. Delotto. Multiple representations: Initiative 3 specialist meeting report. Technical

Report 89-3, NCGIA, Santa Barbara, 1989.
9. T. Devogele, J. Trevisan, and L. Raynal.

relationships,’’ in Kraak and Molenaar [17], pages 6.19–6.33.

‘‘Building a multi-scale database with scale-transition

10. Y. Gabay and Y. Doytsher. ‘‘Adjustment of line maps,’’ in GIS/LIS ’94, Phoenix, Arizona, pages 191–199,

1994.

11. Y. Gabay and Y. Doytsher. ‘‘Automatic feature correction in merging line maps,’’ in 1995 ACSM/ASPRS
Annual Convention & Exposition Technical Papers—Charlotte, North Carolina, volume 2: pages 404–411,
1995.

12. P.E. Hart, N.J. Nilsson, and R. Raphael. ‘‘A formal basis for the heuristic determination of minimum cost

paths,’’ IEEE Transactions on Systems, Science and Cybernetics, SSC, Vol. 4(2):100–107, 1968.

13. L. Heres and other. GDF-Documentation Vol. 1—Vol. 8. Task Force EDRM, 1991.
14. E. Ja¨ger. Untersuchungen zur kartographischen Symbolisierung und Verdra¨ngung im Rasterdatenformat.

Ph.D. thesis, Fachrichtung Vermessungswesen, Universita¨t Hannover, 1990.

15. C.B. Jones, D.B. Kidner, L.Q. Luo, G.Ll. Bundy, and J.M. Ware. ‘‘Database design for a multi-scale spatial
information system,’’ International Journal of Geographical Information Systems, Vol. 10(8):901–920,
1996.

16. C. Jones. Geographical Information Systems and Computer Cartography. Addison Wesley Longman Ltd.,

17. M.J. Kraak and M. Molenaar. Advances in GIS research, Proc. of 7th Int. Symposium on Spatial Data

Handling (SDH), volume 1: Delft, The Netherlands, 1996. Faculty of Geod. Engineering.

18. F. Lehmann. Special Issue of the Journal Computers and Mathematics with Applications, volume 23:

Harlow, 1997.

Numbers 2–9, 1992.

19. M. Lynch and A. Saalfeld. ‘‘Conﬂation: automated map compilation—A video game approach,’’ in

American Society of Photogrammetry, editor, Auto-Carto 7, pages 343–352, 1985.

20. W.A. Mackaness, R. Weibel, and B.P. Buttenﬁeld. Report of the 1997 ICA workshop on map generalization,

19–21 June. Technical report, Ga¨vle, Sweden, 1997.

21. A.R. Pearce and T. Caelli. Interpreting schematics: Learning how to recognize spatio-temporal relational

structures. Technical report, ftp://ftp.cs.curtin.edu.au/pub/adrianp/docs/cviu_article.ps.gz, 1997.

22. J.R. Quinlan. ‘‘Induction of decision trees,’’ Machine Learning, Vol. 1(1):81–106, 1986.
23. J.R. Quinlan.

‘‘Learning logical deﬁnitions

from relations,’’ Machine Learning, 5(1):239–266,

24. N. Regnauld. ‘‘Recognition of building clusters for generalization,’’ in Kraak and Molenaar [17], pages

1990.

4B.1–4B.14.

pages 121–130, 1985.

Prentice Hall, Inc., 1991.

Vol. 2(3):217–228, 1988.

25. D. Richardson. ‘‘Automatic processes in database building and subsequent automatic abstractions,’’

Cartographica, Monograph 47, Vol. 33(1):41–54, 1996.

26. B. Rosen and A. Saalfeld. ‘‘Match criteria for automatic alignment,’’ in Auto-Carto 7, Washington D.C.,

27. J. Rumbaugh, M. Blaha, W. Premerlani, F. Eddy, and W. Lorensen. Object-Oriented Modeling and Design.

28. A. Saalfeld. ‘‘Automated map compilation,’’ International Journal of Geographical Information Systems,

29. L.G. Shapiro and R.M. Haralick. ‘‘Structural description and inexact matching,’’ IEEE Transactions on

Pattern Analysis and Machine Intelligence, Vol. 3:504–519, 1981.

LINKING OBJECTS OF DIFFERENT SPATIAL DATA SETS

357

30. K.S. Shea and R.B. McMaster. ‘‘Cartographic generalization in a digital environment—when and how to
generalize,’’ in B. Buttenﬁeld and R. McMaster, editors, Map Generalization: Making rules for knowledge
representation, pages 103–118. Longman, 1991.

31. S.M. Smith and V. Petermann. ‘‘Outside plant facilities location and data conversion techniques,’’ AM/FM

International, March 1996, 1996.

32. S. Spaccapietra, Ch. Parent, and Th. Devogele. ‘‘Analysis of discrepancies in spatial data representation,’’
in Proceedings of International Cooperative Database Systems for Advanced Applications, Kyoto, Japan,
1996.

33. S. Spaccapietra, Ch. Parent, and Y. Dupont. ‘‘Model independent assertions for integration of heterogeneous

schemas,’’ Very Large Data Bases Journal, Vol. 1(1):81–126, 1992.

34. T. Strat. ‘‘Advancing computer vision through advances in photogrammetry,’’ in H. Ebner, C. Heipke, and
K. Eder, editors, Spatial Information from Digital Photogrammetry and Computer Vision, volume 30/3:
pages 784–792, Munich, Germany, September 1994. ISPRS.

35. B. Su, Z. Li, G. Lodwick, and J.-C. Mu¨ller. ‘‘Algebraic models for the aggregation of area features based
Information Science, Vol.

International Journal of Geographical

upon morphological operators,’’
11(3):233–246, 1997.

36. L. Tomaselli. ‘‘Topological transfer: evolving linear GIS accuracy,’’ in URISA (Urban and Regional

Information Association), pages 245–259, 1994.

37. P. van Oosterom. ‘‘The GAP-tree, an approach to ‘‘on-the-ﬂy’’ map generalization of an area partitioning,’’
in J.-C. Mu¨ller, J.-P. Lagrange, and R. Weibel editors. GIS and Generalization—Methodology and Practice,
pages 120–132. Taylor & Francis, 1995.

38. J.W.N. van Smaalen.

‘‘Spatial abstraction based on hierarchical

re-classiﬁcation,’’ Cartographica,

Monograph 47, Vol. 33(1):65–74, 1996.

39. F. van Wijngaarden, J. van Putten, P. van Oosterom, and H. Uitermark. ‘‘Map integration—update
propagation in a multi-source environment,’’ In Proceedings of the 5th International Workshop on Advances
in Geographic Information Systems, Las Vegas, USA, 1997.

40. G. Vosselman. Relational Matching, Lecture Notes in Computer Science, Vol. 628. Springer Verlag, Berlin,

1992.

41. V. Walter. Zuordnung von raumbezogenen Daten—am Beispiel ATKIS und GDF. Dissertation, Deutsche

Geoda¨tische Kommission (DGK) Reihe C, Heft Nr. 480, 1997.

42. V. Walter and D. Fritsch. ‘‘Matching techniques for road network data in different data models,’’ in J.
Soliman and D. Roller, editors, 28th International Symposium on Automotive Technology and Automation,
pages 633–640. Automotive Automation Limited, Croydon, England, September 1995.

43. V. Walter and D. Fritsch. ‘‘Matching strategies for integration of spatial data from different sources,’’ in
Y.C. Lee and Zhi-Lin Li, editors, International Workshop on Dynamic and Multi-Dimensional GIS, 25–26.
August, Hong Kong, pages 215–228, 1997.

44. V. Walter and D. Fritsch. ‘‘Relational matching of spatial data,’’ Accepted for Publication in: International

Journal of Geographical Information Science, 1998.

45. R. Weibel, S. Keller, and T. Reichenbacher. ‘‘Overcoming the knowledge acquisition bottleneck in map
generalization: The role of interactive systems and computational intelligence,’’ in A.U. Frank and W.
Kuhn, editors, Spatial Information Theory, Lecture Notes in Computer Science Vol. 988, pages 139–156,
Springer Verlag, Berlin, 1995.

358

SESTER, ANDERS, AND WALTER

Monika Sester
studied Geodesy at the Technical University of Karlsruhe and obtained a Master’s degree
(Dipl.-Ing.) in 1986. At present she is a staff member of the Institute for Photogrammetry of the University of
Stuttgart, Germany, where she obtained her Ph.D. in 1995. Since 1994 Dr. Sester is the head of the GIS research
group of the Institute, consisting of six researchers. Her primary research interests lie in multi-scale approaches in
GIS and Image analysis.

Karl-Heinrich Anders Dipl.-Inform. Karl-Heinrich Anders studied Computer Science at the University of
Stuttgart and received his Master’s degree (Dipl.-Inform.) in 1993. Since 1993 he has been working as research
assistant at the Institute of Photogrammetry in Stuttgart, Germany. His research interests include spatial data
mining, computational geometry, as well as 3-D-building modeling.

Volker Walter
studied Computer Science at the University of Stuttgart and received his Master’s degree
(Dipl.-Inform.) in 1992. Afterwards Doctor Walter has been working at the Institute for Photogrammetry in
Stuttgart on his Ph.D., entitled Relational Matching of Data from Different Data Models, which he ﬁnished after
three years in 1996. Currently he is still working at the Institute for Photogrammetry on updating vector data using
high resolution remote sensing imagery.

