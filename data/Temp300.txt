This article was downloaded by: [Florida State University]
On: 20 October 2014, At: 20:50
Publisher: Taylor & Francis
Informa Ltd Registered in England and Wales Registered Number: 1072954 Registered
office: Mortimer House, 37-41 Mortimer Street, London W1T 3JH, UK

International Journal of Geographical
Information Science
Publication details, including instructions for authors and
subscription information:
http://www.tandfonline.com/loi/tgis20

Reconsidering the definition of a
spatial data infrastructure
Paul H.J. Hendriks a , Ezra Dessers b & Geert van Hootegem b
a Institute for Management Research, Radboud University ,
Nijmegen , the Netherlands
b Centre for Sociological Research, Katholieke Universiteit
Leuven , Leuven , Belgium
Published online: 27 Feb 2012.

To cite this article: Paul H.J. Hendriks , Ezra Dessers & Geert van Hootegem (2012) Reconsidering
the definition of a spatial data infrastructure, International Journal of Geographical Information
Science, 26:8, 1479-1494, DOI: 10.1080/13658816.2011.639301

To link to this article:  http://dx.doi.org/10.1080/13658816.2011.639301

PLEASE SCROLL DOWN FOR ARTICLE

Taylor & Francis makes every effort to ensure the accuracy of all the information (the
“Content”) contained in the publications on our platform. However, Taylor & Francis,
our agents, and our licensors make no representations or warranties whatsoever as to
the accuracy, completeness, or suitability for any purpose of the Content. Any opinions
and views expressed in this publication are the opinions and views of the authors,
and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content
should not be relied upon and should be independently verified with primary sources
of information. Taylor and Francis shall not be liable for any losses, actions, claims,
proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or
howsoever caused arising directly or indirectly in connection with, in relation to or arising
out of the use of the Content.

This article may be used for research, teaching, and private study purposes. Any
substantial or systematic reproduction, redistribution, reselling, loan, sub-licensing,
systematic supply, or distribution in any form to anyone is expressly forbidden. Terms &
Conditions of access and use can be found at http://www.tandfonline.com/page/terms-
and-conditions

International Journal of Geographical Information Science
Vol. 26, No. 8, August 2012, 1479–1494

Reconsidering the deﬁnition of a spatial data infrastructure

Paul H.J. Hendriksa*, Ezra Dessersb and Geert van Hootegemb

aInstitute for Management Research, Radboud University, Nijmegen, the Netherlands; bCentre for
Sociological Research, Katholieke Universiteit Leuven, Leuven, Belgium

(Received 9 February 2011; ﬁnal version received 1 November 2011)

The great interest in spatial data infrastructures (SDIs) has led to a wealth of SDI
deﬁnitions in SDI debates. The article aims to contribute to both theory-oriented
and practice-oriented SDI research by providing a critical re-examination of the SDI
literature. Ashby’s formal theory of regulation, which sees infrastructures as regulatory
devices, is used to identify the strengths and weaknesses of several SDI deﬁnitions.
This exercise shows how debates of the SDI objectives and the roles of users get caught
in mantraps and also opens the door for a way out of this confusion by distinguishing
between functional and adoption objectives. It also highlights the emphasis on techno-
logical components in the SDI deﬁnitions, which sidestep the importance of structural
and human resource components in SDI.

Keywords: spatial data infrastructures SDI; Ashby; spatially enabled societies

Introduction

1.
The concept of spatial data infrastructures (SDIs) refers to the infrastructure, or basic phys-
ical and organizational structures, needed to facilitate efﬁcient and effective use of spatial
data (Rajabifard et al. 2006, Hjelmager et al. 2008). The realization that spatial data or geo-
graphical information systems (GIS) storing these data should not be considered within the
boundaries of individual organizations or contexts has led to the development of ideas and
practices of SDI. Spatial data and GIS simply need to be embedded in a broader framework
if the usefulness of spatial data to multiple users – individuals, groups and organizations –
at national and global levels is to be addressed meaningfully (Williamson et al. 2003). SDI
requires the ability to envision the potential of working with spatial data produced by oth-
ers and to look beyond the conﬁnes of data models and technological dimensions when
addressing issues of data usage. In this way, SDI has proven to be a successful concept.
Many governments have launched SDI initiatives at local, national and international levels
(see Crompvoets et al. 2004, Masser 2005, Rajabifard et al. 2006). In addition to the dedi-
cated sessions at conferences and discussions in leading geographical journals, researchers
have also devoted to SDI special conferences, such as GSDI (global spatial data infrastruc-
ture), and journals (e.g. International Journal of Spatial Data Infrastructure Research).
In the research community, it is clear that the concept of SDI has passed its infancy from the

*Corresponding author. Email: p.hendriks@fm.ru.nl

ISSN 1365-8816 print/ISSN 1362-3087 online
© 2012 Taylor & Francis
http://dx.doi.org/10.1080/13658816.2011.639301
http://www.tandfonline.com

Downloaded by [Florida State University] at 20:50 20 October 2014 1480

P.H.J. Hendriks et al.

fact that after the initial stream of papers and articles, there are now several books address-
ing SDI-related concepts and practices (e.g. Groot and McLaughlin 2000, Williamson et al.
2003, Masser 2005, 2007, Onsrud 2007, Nedovic-Budic et al. 2011).

As many authors (e.g. Georgiadou et al. 2005, De Man 2006, Hjelmager et al. 2008)
have observed, SDI is a complex phenomenon. This complexity is due to several causes.
First, the question which objectives SDI should serve makes the concept complex. Possible
reasons for considering an SDI range from the more mundane concerns such as linking
current and future data sets via broad objectives of ‘spatially enabled societies’ (Rajabifard
2007, Rajabifard et al. 2010) or ‘spatially enabled governments’ (Masser et al. 2008) to
the more lofty goals of ‘democratizing the use of Geographical Information’ (Roche et al.
2003) or, more generally, the ‘triple bottom line’ (Williamson et al. 2003) involving eco-
nomic, social and environmental goals. The debate about SDI objectives is repeated in the
discussion whether SDIs should deliver products or support communication and cooper-
ation processes, leading to various generations of SDI (Masser 1999, Crompvoets et al.
2004, Georgiadou et al. 2005).

Second, the role of users is a source of complexity within SDI. To understand that role,
many different viewpoints need to be identiﬁed and combined, such as the enterprise, infor-
mation, computation, engineering and technology viewpoints (Hjelmager et al. 2008). The
enterprise viewpoint, or administrative perspective, involves many different stakeholders
from different jurisdictional levels in the spatial data community, including policy-makers,
data producers, brokers, resellers and end-users (Williamson et al. 2003, Rajabifard et al.
2006). Users are not just local and national government agencies, with often conﬂicting
interests and traditions of suboptimal cooperation (Harvey et al. 1999), but also compa-
nies or grassroots groups (Poore 2003, Elwood 2008). Part of the complexity problem of
SDI, as Williamson et al. (2003, p. xxvi) see it, is that ‘SDI is an evolving concept that
sustains various perspectives or views depending on the user’s interests and its role within
the broader SDI hierarchy.’

The third reason that SDI is complex is that it consists of many different components,
and in deﬁnitions they often appear as unordered lists of disparate elements. For instance,
Georgiadou et al. (2005. p. 1113) state that ‘SDI subsumes technology, systems, stan-
dards, networks, people, policies, organizational aspects, geo-referenced data, and delivery
mechanisms to end users.’ It is no easy task to assess whether such lists, of which the SDI
literature offers many, are either logical or complete.

A fourth reason that SDI is complex comprises a more general class of miscellaneous
complexity sources. For instance, SDIs owe part of their complexity to their inevitably
dynamic nature caused by rapid technological developments (Rajabifard et al. 2002). Also
adding to its complexity is the notion of an SDI hierarchy, because the identiﬁcation of
global, regional and national levels down to local and corporate levels at which SDIs are
to be addressed involves many intra-level and inter-level relationships (Williamson et al.
2003). Another source of complexity is the fact that many disciplines are interested in SDI,
including geography, sociology, informatics, organization studies, public administration,
economics and environmental studies.

Despite its success, SDI is still a fuzzy concept, as, for instance, Williamson et al.
(2003) note. The combined causes of complexity described above help explain why SDI
has been hard to deﬁne. The complexity of the SDI concept has caused distinctions to
be vague and sometimes confused, thereby either unduly simplifying the SDI notion or
increasing its apparent complexity even more. The objective of this article is to identify
the strengths, weaknesses and challenges of the current understanding of SDI by criti-
cally reviewing collective SDI deﬁnitions. A useful but insufﬁcient approach to achieve

Downloaded by [Florida State University] at 20:50 20 October 2014 International Journal of Geographical Information Science

1481

that objective would be to take existing understandings as its starting point (gathering def-
initions, identifying deﬁnition elements and sorting these), as the current literature does
not provide a sufﬁciently sharp and encompassing foothold. A purely inductive approach
analysing extant literature would inherit any embedded lack of rigour. This article argues
here that Ashby’s systemic theory of regulation provides a useful starting point for crit-
ically reviewing existing SDI deﬁnitions (Ashby 1956, 1960). This theory is appropriate
as SDI, as an infrastructure, is a concept of regulation; it has little meaning outside this
context or its speciﬁcations (e.g. management, policy, governance). It also highlights that
an SDI, as a regulatory concept, plays an intermediate role between objectives and ways
of achieving these. That intermediate role may be a partial explanation of why it is hard to
deﬁne the SDI phenomenon; an SDI is not there for its own sake but exists as a facilitating
device to connect objectives and the activities designed to meet them. Recognizing this
intermediate role in regulation leads to a functional deﬁnition of an SDI by focusing on
‘what it can or should do’ (Hendriks 1986).

The rest of this article is organized as follows. First, Section 2 identiﬁes the differences
and similarities of deﬁnitions of SDI offered in the literature. In Section 3, an assess-
ment template for SDI deﬁnitions is developed based on system-theoretical arguments.
In Section 4 that template is then used as a review tool to assess the completeness, consis-
tency and combinability of prevailing deﬁnitions. Section 5 discusses how the conceptual
exercises presented in this article may help to unravel the four sources of complexity
surrounding the SDI deﬁnitions that were identiﬁed above.

2. Charting the SDI landscape

SDI deﬁnitions in the literature take many different directions (De Man 2008). To come
to grips with this variety, different SDI deﬁnitions starting from existing reviews were
collected and analysed. Although an ever-growing list of deﬁnitions can be found in the
literature, only few publications actually discuss and compare deﬁnitions offered in SDI
literature. The overview by Chan et al. (2001) is often used. Other authors who have pub-
lished lists of SDI deﬁnitions, such as Rajabifard et al. (2003) and more recently Van
Loenen (2006) and Vandenbroucke et al. (2009), all refer to Chan et al. (2001) as the start-
ing point for their inventory. As the basis for this review, the deﬁnitions in these overviews
were stacked, and selected recent deﬁnitions were added from both scientiﬁc- and practice-
oriented publications (such as the SDI cookbook, GSDI (2004)). This resulted in a list of
28 SDI deﬁnitions. A comparative analysis showed two classes of elements used in the
deﬁnitions: (A) a description of SDI components (such as technology or human resources
(HRs)) and/or (B) a listing of SDI objectives (such as data access).

Some authors prefer to identify the components in a general way by using a collec-
tive term, such as ‘framework’, where others list speciﬁc components. This means the
(A) deﬁnitions can be divided up into (A0) deﬁnitions that do not refer to components,
(A1) deﬁnitions describing the components via general categories and (A2) those that
specify lists of components. It is not always easy to draw the dividing line between broadly
identifying and listing components because a component such as technology may qualify
as a speciﬁcation of the more general identiﬁcation of a ‘set-up of instruments’, yet it may
itself be a framework that covers many kinds of more speciﬁc types. Also, even if the
analysed set of deﬁnitions did not show this, it is possible to combine broad categories
with speciﬁc lists in one deﬁnition. Therefore, the distinction between the categories only
serves to show the variety of approaches, and it should not be seen as a rigid taxonomic
scheme that allows assigning individual deﬁnitions to their ultimate home base.

Downloaded by [Florida State University] at 20:50 20 October 2014 1482

P.H.J. Hendriks et al.

The historical overviews of SDI by Masser (2005) and Rajabifard et al. (2002, 2006)
were used to order the different types of SDI objectives speciﬁed in the deﬁnitions. These
authors make a distinction between ﬁrst-generation SDIs that have data as their key driver
and are based on a product model and second-generation SDIs in which user needs are
the key driver and are based on a process or development model. These and other authors,
including Roche et al. (2003) who refer to ‘social utility value’ and Williamson et al.
(2003) who mention the ‘triple bottom line’, recognize that SDI development is driven not
only by data and user needs but also by broader background objectives (Rajabifard et al.
also relate ﬁrst-generation SDI to, for instance, the promotion of economic development,
the stimulation of better government and encouraging environmental sustainability). This
means that the (B) deﬁnitions can be divided up into (B0) those that do not refer to objec-
tives, (B1) those that include data-related objectives (such as data sharing) and (B2) those
that add user-related objectives (such as supporting business processes) and objectives that
are broader than issues of direct SDI use (such as performance of organizations, sustaining
economic development or spatially enabling societies and governments).

Combining the two elements and their three categories leads to the scheme presented
in Table 1 listing eight possible groups of deﬁnitions.1 Each group represents a speciﬁc
combination of how the components and/or SDI objectives are speciﬁed in the deﬁnition.
For each group, one representative deﬁnition is given in Table 1.

The ﬁrst two classes of deﬁnitions deﬁne SDI via their components, excluding any

reference to objectives.

(1) The ﬁrst class of deﬁnitions uses a general concept to express what constitutes
an SDI by characterizing it as a social network of people and organizations, as
exempliﬁed by the deﬁnition given by Craglia and Campagna (2009, p. 10) listed
in Table 1.

(2) The second type of deﬁnition lists a set of components an SDI should or could
include, also without mentioning any objectives. McLaughlin and Nichols’ (1994)
deﬁnition is an example of this, as it includes a variety of constituents, ranging from
spatial databases to institutional arrangements. Even the end-users are viewed as
SDI components.

Deﬁnitions are also provided that make no mention of SDI components and describe
the SDI in terms of the objectives it should support. A distinction can be made here
between deﬁnitions that refer to data-related objectives (deﬁnition class 3) and those that
refer to a combination of data-related, user-related and/or broader objectives (deﬁnition
class 6).

(3) Crompvoets et al. (2004) identify an SDI entirely in terms of the data-related

objective of facilitating and coordinating spatial data exchange and sharing.

(6) Grus et al. (2010, p. 439) use a combination of data-related and user-related objec-
tives to deﬁne an SDI. Just like deﬁnitions in class 3, their deﬁnition does not
include a reference to the components of an SDI.

While the classes either specify components or objectives, most deﬁnitions do both; they
combine some speciﬁcation of essential components with critical objectives. Typically,
they refer to objectives of one type (data-related, user-related or broader).

(4) No examples of deﬁnitions linking one type of objectives to a general description

of the components were found.

Downloaded by [Florida State University] at 20:50 20 October 2014 International Journal of Geographical Information Science

1483

h
t
o
b
y
b

n
o
i
t
c
e
l
l
o
c

a
t
a
d

l
a
i
t
a
p
s

f
o

n
o
i
t
a
c
i
l
p
u
d

d
e
t
a
i
c
o
s
s
a

d
n
a

a
t
a
d
l
a
i
t
a
p
s

f
o

n
o
i
t
a
z
i
l
i
t
u

r
e
t
t
e
b

e
l
b
a
n
e

d
n
a

s
r
e
c
u
d
o
r
p

d
n
a

s
r
e
s
u

)
0
1
0
2

.
l
a

t
e

s
u
r
G

(

s
e
c
i
v
r
e
s

o
t

]
k
r
o
w
t
e
n
[

s
n
o
i
t
a
s
i
n
a
g
r
o

n
e
e
w
t
e
b
d
n
a

n
i
h
t
i

w

g
n
i
t
u
b
i
r
t
n
o
c

y
b
e
r
e
h
t

,
]
s
e
v
i
t
c
e
j
b
o
w
o
r
r
a
n
[

a
t
a
d

s
e
s
s
e
c
o
r
p

s
s
e
n
i
s
u
b
e
h
t

f
o

e
c
n
a
m
r
o
f
r
e
p

e
h
t
o
t

l
a
i
t
a
p
s

f
o
e
s
u
d
n
a

e
g
n
a
h
c
x
e

,
s
s
e
c
c
a

e
t
a
t
i
l
i
c
a
f

]
s
t
n
e
n
o
p
m
o
c
[

s
p
u
-
t
e
s

l
a
c
i
g
o
l
o
n
h
c
e
t
-
n
o
n

d
n
a

.
l
a
t
e

e
k
c
u
o
r
b
n
e
d
n
a
V

(

]
s
e
v
i
t
c
e
j
b
o

r
e
d
a
o
r
b
[

)
9
0
0
2

s
t
e
s

a
t
a
d

l
a
i
t
a
p
s

,
a
t
a
d
a
t
e
m

:
s
n
a
e
m
n
o
i
t
a
m
r
o
f
n
i

d
n
a

s
e
c
i
v
r
e
s
k
r
o
w
t
e
n
;
s
e
c
i
v
r
e
s

a
t
a
d
l
a
i
t
a
p
s
d
n
a

s
s
e
c
c
a

,

g
n
i
r
a
h
s

n
o

s
t
n
e
m
e
e
r
g
a

;
s
e
i
g
o
l
o
n
h
c
e
t

g
n
i
r
o
t
i
n
o
m
d
n
a

n
o
i
t
a
n
i
d
r
o
o
c
d
n
a

;
e
s
u

d
n
a

n
i

e
l
b
a
l
i
a
v
a

e
d
a
m

r
o

d
e
t
a
r
e
p
o

,

d
e
h
s
i
l
b
a
t
s
e

,
s
e
r
u
d
e
c
o
r
p

d
n
a

s
e
s
s
e
c
o
r
p

,
s
m

s
i
n
a
h
c
e
m

E
R
I
P
S
N

I

)
.

.

.
(

.
e
v
i
t
c
e
r
i

D
s
i
h
t
h
t
i

w
e
c
n
a
d
r
o
c
c
a

t
c
e
r
i
d

a

e
v
a
h

y
a
m

t
a
h
t

s
e
i
t
i
v
i
t
c
a

d
n
a

s
e
i
c
i
l
o
p

o
t
n
o
i
t
a
l
e
r

n
i

g
n
i
k
a
m
-
y
c
i
l
o
p
t
s
i
s
s
a
d
l
u
o
h
s

t
n
e
m
n
o
r
i
v
n
e

e
h
t

n
o
t
c
a
p
m

i

t
c
e
r
i
d
n
i

r
o

)
7
0
0
2
n
o
i
s
s
i
m
m
o
C
n
a
e
p
o
r
u
E
(

e
g
n
a
h
c
x
e

e
h
t

f
o

n
o
i
t
a
n
i
d
r
o
o
c

e
h
t
n
i

s
r
e
d
l
o
h
e
k
a
t
s

n
e
e
w
t
e
b

a
t
a
d

l
a
i
t
a
p
s

f
o
g
n
i
r
a
h
s
d
n
a

)
4
0
0
2
.
l
a

t
e

s
t
e
o
v
p
m
o
r
C

(

y
t
i
n
u
m
m
o
c

a
t
a
d

l
a
i
t
a
p
s

d
n
a

n
o
i
t
a
t
i
l
i
c
a
f

e
h
t

.
d
n
u
o
f

e
r
e
w

)
I

D
S
N

(

e
r
u
t
c
u
r
t
s
a
r
f
n
I

a
t
a
D

,
y
g
o
l
o
n
h
c
e
t

e
h
t

s
n
a
e
m

d
n
a

s
d
r
a
d
n
a
t
s

,
s
e
i
c
i
l
o
p

y
r
a
s
s
e
c
e
n

s
e
c
r
u
o
s
e
r
n
a
m
u
h

,
e
r
o
t
s

,
s
s
e
c
o
r
p

,
e
r
i
u
q
c
a
o
t

e
v
o
r
p
m

i
d
n
a

,
e
t
u
b
i
r
t
s
i
d

a
t
a
d

l
a
i
t
a
p
s
o
e
g

f
o
n
o
i
t
a
z
i
l
i
t
u

e
h
t

f
o
e
c
ﬁ
f
O
e
v
i
t
u
c
e
x
E
(

)
4
9
9
1

t
n
e
d
i
s
e
r
P

g
n
i
s
s
e
c
c
a

r
o
f

e
r
u
t
c
u
r
t
s
a
r
f
n
i

n
A

,
e
l
p
m
a
x
e

r
o
F
)
6
(

a
t
a
D

l
a
i
t
a
p
S

,
e
l
p
m
a
x
e

r
o
F
)
3
(

e
h
t

e
c
u
d
e
r
o
t

a
t
a
d
l
a
i
t
a
p
s
g
n
i
r
a
h
s

d
n
a

t
u
o
b
a

s
i

)
I

D
S
(

e
r
u
t
c
u
r
t
s
a
r
f
n
I

,
s
n
o
i
t
a
s
i
n
a
g
r
o
d
n
a

e
l
p
o
e
p

f
o

s
k
r
o
w
t
e
n

l
a
i
c
o
s

t
s
o
m
e
r
o
f

e
r
a

s
e
r
u
t
c
u
r
t
s
a
r
f
n
I

a

y
a
l
p
a
t
a
d

d
n
a

y
g
o
l
o
n
h
c
e
t

h
c
i
h
w
n
i

s
i

y
g
o
l
o
n
h
c
e
t

e
h
T

.
e
l
o
r

e
v
i
t
r
o
p
p
u
s

l
a
i
c
o
s

t
u
b

,
e
v
i
s
n
e
p
x
e

s
i

a
t
a
d

,
p
a
e
h
c

d
n
a

a
i
l
g
a
r
C

(

e
l
b
a
u
l
a
v
n
i

e
r
a

s
n
o
i
t
a
l
e
r

)
9
0
0
2

a
n
g
a
p
m
a
C

h
t
i

w
g
n
i
l
a
e
d
(

y
g
o
l
o
n
h
c
e
t

,
s
k
r
o
w
t
e
n

d
n
a

t
n
e
m
e
g
a
n
a
m

,
n
o
i
t
c
e
l
l
o
c

a
t
a
d

l
a
n
o
i
t
u
t
i
t
s
n
i

,
)
n
o
i
t
a
t
n
e
s
e
r
p
e
r

s
d
r
a
d
n
a
t
s
d
n
a

s
e
i
c
i
l
o
p

,
s
t
n
e
m
e
g
n
a
r
r
a

d
n
a
n
i
l
h
g
u
a
L
c
M

(

s
r
e
s
u
-
d
n
e

d
n
a

d
l
u
o
h
s

e
r
u
t
c
u
r
t
s
a
r
f
n
i

a
t
a
d

l
a
i
t
a
p
s

,
a
t
a
d

l
a
i
t
a
p
s

f
o

s
e
c
r
u
o
s

e
d
u
l
c
n
i

a
t
a
d

,
a
t
a
d
a
t
e
m
d
n
a

s
e
s
a
b
a
t
a
d

)
4
9
9
1

s
l
o
h
c
i
N

l
a
c
i
g
o
l
o
n
h
c
e
t

f
o
t
e
s

a

s
i

I

D
S
n
A

,
e
l
p
m
a
x
e

r
o
F
)
7
(

s
e
l
p
m
a
x
e
o
n
,
s
s
a
l
c

s
i
h
t

f

O

)
4
(

a
t
a
D

l
a
i
t
a
p
S

,
e
l
p
m
a
x
e

r
o
F
)
1
(

n
o
i
t
a
c
ﬁ
i
p
y
t

l
a
r
e
n
e
G

:
1
A

s
t
n
e
n
o
p
m
o
c

f
o

s
e
v
i
t
c
e
j
b
o

r
e
d
a
o
r
b

r
o

d
e
t
a
l
e
r
-
r
e
s
u
o
s
l
A

:
2
B

s
e
v
i
t
c
e
j
b
o

d
e
t
a
l
e
r
-
a
t
a
d
y
l
n
O

:
1
B

s
e
v
i
t
c
e
j
b
o

o
N

:
0
B

s
e
v
i
t
c
e
j
b
O

.
s
n
o
i
t
i
n
ﬁ
e
d

I

D
S
r
o
f

e
m
e
h
c
s
g
n
i
t
r
o
S

.
1
e
l
b
a
T

–

s
t
n
e
n
o
p
m
o
c

o
N

:
0
A

s
t
n
e
n
o
p
m
o
C

l
a
i
t
a
p
s

r
o
f

e
r
u
t
c
u
r
t
s
a
r
f
n
i

,
e
l
p
m
a
x
e

r
o
F
)
8
(

l
a
i
t
a
p
S
l
a
n
o
i
t
a
N

,
e
l
p
m
a
x
e

r
o
F
)
5
(

a

f
o

s
t
n
e
n
o
p
m
o
c

e
h
T

,
e
l
p
m
a
x
e

r
o
F
)
2
(

s
t
n
e
n
o
p
m
o
c

f
o
t
s
i
L

:
2
A

Downloaded by [Florida State University] at 20:50 20 October 2014 1484

P.H.J. Hendriks et al.

(5) The second most common class of deﬁnitions (containing 6 of the 28 deﬁnitions
analysed) combines a speciﬁed list of SDI components with data-related objectives.
An example of this type of deﬁnition is offered by the Executive Ofﬁce of the
President (1994) that is shown in Table 1.

(7) The components of an SDI are identiﬁed in some publications, but it is considered
unfeasible to make an exhaustive list. Therefore, the SDI components are described
in a very broad way, that is, as ‘a set-up’ (Vandenbroucke et al. 2009) or ‘a frame-
work’ (Van Loenen 2006), while the data-related, user-related or broader objectives
are more explicitly discussed.

(8) The most in-depth deﬁnitions combine a speciﬁcation of components, such as
the technology and standards, with combinations of data-related, user-related or
broader objectives (this is also the most popular class in our data set, containing
10 of the 28 deﬁnitions). For instance, the deﬁnition of the European Commission
(2007) that is shown in Table 1 lists a set of components and combines short-
term, data-related goals with long-term, broader objectives of supporting political,
economic, social and personal development.

While Table 1 shows the various deﬁnitions of SDI, it still also partly hides the differences
and inconsistencies between the various deﬁnitions. In the set of 28 deﬁnitions, no two
deﬁnitions were found that presented exactly the same list of components or the same
essential objectives. Also deﬁnitions classiﬁed in the same group in Table 1 can be very
different when examined more closely.

3. Conceiving SDI in systemic terms

3.1. The intermediate role of SDI in regulation
To understand the common foundation of the various deﬁnitions of SDI, the term infras-
tructure should ﬁrst be explained. An infrastructure is commonly deﬁned as the basic
features or structure of some larger whole, for example, a country, a community or an orga-
nization. For instance, the Merriam-Webster dictionary (2006) deﬁnes infrastructure as ‘the
underlying foundation or basic framework (as of a system or organization)’. Infrastructures
should be understood in the context of the larger system in which they are based; they are
not primarily stand-alone phenomena with a function of their own. An infrastructure is
apparent in the regulation of the system. For instance, the road infrastructure of a country
is present because of economic and social factors that make the road network important.
As an infrastructure, the road network is an intentional network. Regulation is used as a
‘neutral’ term indicating any activity aimed at deliberately regulating some object. It can
refer to management or policy or governance; these terms are used when regulation is
applied to different systems such as organizations, societies and networks. It can refer to
individuals or grassroots groups intentionally regulating their own behaviour, or govern-
ment or managers trying to facilitate or control the behaviour of others. A basic model
of system regulation is provided by Ashby (1956, 1960, Achterbergh and Vriens 2009,
Pickering 2010). Ashby’s approach to regulation is appealing because it offers a logic-
based, formal model of regulatory functions in goal-oriented systems, which ensures its
broad applicability. Ashby perceives regulation as the act of inﬂuencing the behaviour of
some entity. The focus is not on the subject being regulated but on the behaviour of the
regulated entity. Rather than one speciﬁc theory of regulation aimed at empirically identi-
fying different instances of regulation, Ashby offers a metalanguage of principles, concepts

Downloaded by [Florida State University] at 20:50 20 October 2014 International Journal of Geographical Information Science

1485

and models for transdisciplinarian use (Francois 1999). Ashby provides a functional deﬁni-
tion of a regulator, thus making his model particularly broadly applicable. For instance, his
approach can be applied to situations where an external regulator (e.g. government) aims to
inﬂuence a large system (e.g. a state), as well as to situations where an individual considers
the regulation of their own behaviour (e.g. a person regulating their health via holidays and
other means). Ashby’s approach has been highly inﬂuential, inspiring such scientists as
Herbert Simon, Norbert Wiener and Stafford Beer (see Pickering 2010). The main inﬂu-
ence of Ashby’s model is indirect via the theories of these and other authors, though many
authors continue to directly use Ashby’s approach, for example, for the measurement of
environmental performance of business organizations (Lewis and Stewart 2003), for diag-
nosing ‘healthy organizations’ (Tarride et al. 2008) or for analysing leadership of medical
practitioners (Thygeson et al. 2010).

Ashby constructs his functional concept of regulation from the three stages of control
(deﬁning objectives), design (preventing disturbances from thwarting the achievement of
the objectives) and operational supervision (using available means in individual situations;
see Figure 1). The infrastructure relates to the design stage; it refers to the collection of
resources designed to tackle disturbances in reaching objectives. This can be rephrased
more positively as resources that should provide the conditions to achieve the objectives.
In the case of the road infrastructure, the objectives involve people getting from A to B in a
timely, economical and comfortable fashion. The disturbances and implied conditions are
not only the terrain and other variables of absolute and relative location but also character-
istics of the current road network and its use, for example, leading to trafﬁc congestions.
The resources consist of the roads, the trafﬁc regulations, police patrol, and so on. It is
important to note that because resources in themselves are meaningless, an infrastructure
should be divorced neither from its objectives (cf. Ashby’s control stage) nor from its
use. An infrastructure is a policy-related or management-related concept, and as such it
is an intermediate between objectives and concrete situations. This intermediate character
means that an infrastructure should be deﬁned in functional terms (Hendriks 1986); while
the various resources of the infrastructure (i.e. its components) form its core, they alone
cannot deﬁne it. An SDI is not deﬁned by its objectives or its concrete use, yet without
either, trying to understand the whole would be futile.

Regulation

Regulation activity 2: Design
Providing the means to tackle
disturbances in light of  established
goals

Regulation activity 3: Operational
Supervision
Selection from available means and
their use in a concrete situation

Regulation activity 1: Control
The identification of  goals

Regulated
behaviour

Behaviour of  the regulated system
(e.g. transformation process of  an
organization)

Goals

Figure 1. Ashby’s model of regulation.

Downloaded by [Florida State University] at 20:50 20 October 2014 1486

P.H.J. Hendriks et al.

3.2. The objectives of SDI

The functions of an infrastructure and its use in concrete situations involve two different
classes of objectives, which can be labelled functional and adoption objectives, respec-
tively. Functional objectives refer to the function of the infrastructure; they deﬁne the
infrastructure’s reason for existence (in the case of the road infrastructure, the objective
of people getting from A to B). In an SDI, these functional objectives are spatial data
related: the raison d’être of SDIs is to improve spatial data handling and the underlying
functional objectives (e.g. connections to the triple bottom line and to spatially enabled
societies).

When considering the functionality of the infrastructure (i.e. the degree in which the
functional objectives are actually met), the adoption of the infrastructural resources is rel-
evant. The infrastructure can only be adopted in situations in which some feature of its
functional objectives is relevant. To a designer of an SDI, the adoption of the infrastructure
is also an objective, although it is separate from functional objectives. Adoption objectives
derive from the fact that the design stage in regulation, when the infrastructure is estab-
lished, involves preparing for actually tackling disturbances once they occur (cf. Ashby’s
third stage of regulation). An infrastructure not in use has potential only and gains meaning
through being used in concrete situations. The requisites for adoption of an infrastructure
are the recognition by potential users that it is available (their awareness of it) and that
it can help them achieve their (functional) objectives, as well as their ability and willing-
ness (motivation, trust and broader social context, etc.) to adopt the components offered in
an SDI. Theoretically, an infrastructure stands a better chance of serving its (functional)
purpose when it is designed with adoption by potential users in mind. Inherent to an SDI
is a model of adoption which, rephrased into regulation terms, involves an understanding
or making an educated guess of when the infrastructure will fulﬁl its function (lifting the
barriers, providing the appropriate conditions). It entails an understanding of what may or
may not work. Yet it would be inaccurate to say that the perspective of the end-user deﬁnes
the SDI (cf. Poore 2003), even if an SDI can only be enacted by its actual use. What deﬁnes
the SDI is the regulatory perspective, which means that it is associated with objectives of
adoption.

3.3. The components of SDI
The core elements of SDI are its components (referred to as resources) that should allow
tackling possible disturbances in reaching (spatially related) functional objectives (e.g.
Craglia and Campagna 2009, Vandenbroucke et al. 2009). Infrastructures are relatively
stable, in spite of the dynamics associated with their technological components. Resources
for a single use would not be considered part of an infrastructure. The components of an
SDI do not consist only of the much-debated databases, issues of interoperability and stan-
dards, legal issues and processing facilities. All these are technological components, not
only referring to computer technology but also interpreted in a broad sense (also including
conceptual data models and legal regulations). A more encompassing model, specifying
an integrated framework of infrastructural components and their connections, is offered
by Achterbergh and Vriens (2009), who discern three classes of such components. These
classes are (1) organizational structures, or the pattern of tasks and the coordination needed
to achieve the objectives; (2) skills and competencies of individuals and groups required;
and (3) all other resources, identiﬁed as technological components, employed by these
individuals and groups. The tendency in the SDI literature to put the third class – the

Downloaded by [Florida State University] at 20:50 20 October 2014 International Journal of Geographical Information Science

1487

technology – on a pedestal is in line with how infrastructures are perceived in everyday
language, where too easily an infrastructure is equated with the ‘technical infrastructure’.
An SDI’s technological components alone will not ensure success in achieving the objec-
tives. The second class of skills and competencies is required to achieve the functional
objectives of the system in which the SDI is part of the regulation. Therefore, technologi-
cal resources are not the core of the SDI to be used, however necessary, to achieve results,
but they are to be considered as integral to the resources required to achieve the functional
and adoption objectives. What the skills and competencies are depends on the system in
question. At the level of a country, effective and efﬁcient data handling requires appro-
priate education and research institutions addressing the development and dissemination
of knowledge concerning concepts, theories and tools of spatiality, as well as a smoothly
operating labour market. All such spatial skills-related institutions are therefore to be con-
sidered as crucial SDI components. At the level of an organization, the hiring policies,
the development and rewards systems, the training programmes and other practices of HR
management aimed at acquiring, developing and retaining skills and competencies within
the workforce needed for effective and efﬁcient handling of spatial data (in light of the
organization’s overall mission and objectives) are part of that organization’s SDI.

Aside from technological resource and HR, there is a third class of SDI components
that is consistently overlooked, and it concerns the crucially important class of ‘how work
is organized’ (the ﬁrst class in Achterbergh and Vriens’ typology). The objectives of SDIs
are typically complex, requiring a multitude of tasks to be performed. Therefore, achiev-
ing the objectives depends on how these tasks of working with spatial data are deﬁned
(divided) and how divided tasks are coordinated. At the level of a country, the division of
labour concerns how the tasks of, for instance, organizations or other groups are assigned
(by the government or by themselves), how these (spatial data) tasks are linked to the tasks
of others and how they are coordinated. A country’s government could be organized fully
along functional lines with different national departments for urban, environmental and
healthcare planning and so on or it could group these tasks regionally (most countries have
adopted some combination of these two options, however, mostly replicating the functional
division at local levels, thus not achieving full integration). The ﬁrst option would result
in highly specialized bodies, whereas the second option would produce more generalized
government agencies. The requirements for an SDI as facilitator for these individual gov-
ernment agencies to achieve effective, efﬁcient and coordinated data usage would be very
different for the two situations. Consider a national water policy that is fragmented across
many agencies responsible for the different areas of water management (e.g. groundwa-
ter, surface water or drinking water), for a speciﬁc thematic aspect (such as infrastructure,
environment, culture or public health) or for a certain administrative area (e.g. munici-
pality, polder, province, region or country). Such a highly specialized task division would
require extensive coordination structures and data exchange protocols. If the water manage-
ment system were a coherent and functional whole, comprising surface water, groundwater,
river and lake beds and banks, the need for coordination and data exchange could be very
different.

At the level of an organization, similar distinctions are important to the ground-
work of an SDI. For instance, consider a consultancy ﬁrm delivering land-use planning
services. The requirements for the technological and HR components of the organiza-
tion’s SDI will be different if that organization has a specialist department for all spatial
data handling compared with being organized into departments responsible for differ-
ent customer–market combinations, dividing the handling of spatial data across these
departments.

Downloaded by [Florida State University] at 20:50 20 October 2014 1488

P.H.J. Hendriks et al.

3.4. Summary

In summary, it can be established that an SDI deﬁnition that recognizes its regulatory nature
needs to encompass the two different classes of objectives, functional and adoption, as
well as three classes of components, organizational structures, HR systems and all other
components, summarized as technological resources. What sets an SDI apart from other
infrastructures is that these components are intentionally crafted to achieve the functional
objectives of geo-data-related processes. Looking at SDI from an Ashby-like perspective
shows its intermediate position as a connector of functional and adoption objectives and
activities to achieve these. What makes SDIs especially complex is that they aim at sup-
porting individuals and groups towards their speciﬁc goals. However, that which facilitates
achieving one objective can be counterproductive in achieving others. Another point is
that in one situation a speciﬁc resource may be used, whereas in another the same may
be rejected. Changing objectives can also have an effect on the effectiveness of processes.
Therefore, any taxonomic approach to deﬁning SDI, listing viewpoints, components, and
so on and combining these in conceptual schemata, however elaborate, systematic and
well-informed, is bound to fail. It follows that a deﬁnition of SDI would be incomplete
without a reference to both classes of objectives and to the processes and practices SDIs
are supposed to support (to enable, to facilitate, to control, etc.). However, this should
not be taken to mean that these objectives or the processes and practices they refer to are
part of the SDI. Even if they cannot be adequately understood (i.e. deﬁned) when isolated
from the behaviour of individuals and organizations, SDIs are to be distinguished from that
behaviour.

4. Reconsidering prevailing SDI deﬁnitions
The approach detailed above will be used here for reviewing existing SDI deﬁnitions. It can
contribute to the discussion of ‘What is an SDI?’, a question that can be answered in two
distinct ways, that is, referring to the deﬁnition of SDI and to the characterization of the
SDI phenomenon that is being deﬁned. Below, an assessment is given for either answer to
this question. First, assorted deﬁnitions will be proofread using an Ashby-like perspective
of infrastructures as a litmus test and a focus for discussion. Second, it will be assessed
how the literature approaches the SDI as the object of deﬁnition; in other words, the views
on what characterizes and constitutes SDIs are reconsidered.

4.1. Ad (1) What deﬁnes an SDI?
It is apparent that many authors struggle with the combination of components and objec-
tives. It can be argued that both are indispensable to understand the functional nature of
an SDI. Without objectives, SDIs lack their raison d’être and without components they
lack facilities for achieving these objectives. Consequently, deﬁnitions in classes (1), (2),
(3) and (6), which do not include both objectives and components, have to be considered
as incomplete.

Deﬁnitions have been sorted on the distinction between data-related, user-related and
broader objectives that were derived from discerning ﬁrst- and second-generation SDI
(Masser 2005, Rajabifard et al. 2006). This distinction is useful because it makes clear
that data-related objectives alone do not deﬁne an SDI. Users and their organizational
and social context are indispensable, yet underexposed (cf. Poore 2003). However, ade-
quately addressing the role of the user when deﬁning SDI is not an easy task. User-centred
deﬁnitions typically take the SDI as a point of reference. As an example, take the elaborate

Downloaded by [Florida State University] at 20:50 20 October 2014 International Journal of Geographical Information Science

1489

deﬁnition given by Onsrud (2008) presented in Section 2, which includes objectives of
all three types. That deﬁnition identiﬁes (1) ‘easy, consistent and effective access to geo-
graphic information and services’ (data-related objectives) and (2) the ‘support of political,
economic, social and personal development’ (user-related and broader objectives) as SDI
objectives. Onsrud speciﬁcally says that what deﬁnes an SDI is that it is conceived and
designed ‘to serve its goals’. Deﬁnitions like these take ‘SDI as a means’ as the perspec-
tive for considering situations in which it may be useful (compare the idea of a hammer
looking for a carpenter instead of a carpenter looking for a hammer). A more adequate
take on the role of SDI is arrived at if it is considered as a possible means not for achiev-
ing ‘its objectives’ but the objectives of the SDI users (user-related objectives) and their
organizational or social context (broader objectives), whether these users are individuals,
groups or organizations. Characteristic of any infrastructure is that it should offer generic
facilities for achieving classes of objectives. An SDI is much like a road infrastructure that
should help achieve objectives for all kinds of users, not only for transport companies but
also for visiting family. An infrastructure may serve many objectives that are not known to
its designers beforehand. Yet the objectives of these SDI users deﬁne the role of an infras-
tructure as a regulatory device, and not some abstract class of ‘objectives of the SDI’. The
objective of SDI is not the use of spatial data extended into user-related or broader goals
but to serve those purposes of individuals, groups and organizations for which spatial data
are or may become useful. These objectives and the possible role of an SDI in achieving
them deﬁne its potential functionality.

It is important to view the SDI not from the perspective of its own objectives, which are
essentially of a virtual nature, but from the reversed perspective of the users’ objectives.
Only through that reversal can it become visible that the triplet of data-related, user-related
and broader objectives alone cannot fully capture the nature of SDI. That triplet looks at
the functionality of an SDI from the SDI’s perspective and thus involves only a partial per-
spective on the role of individuals and organizations. There are other conditions for SDI
to support effectively the users’ objectives, which involve the capability and willingness
of potential users to access, accept and integrate SDI in their work (i.e. in the tasks they
perform to achieve their objectives). These conditions, though connected to the functional
conditions, are of a different nature; they do not refer to a means–ends connection. They
involve a broad spectrum of social phenomena, including power relations, culture and edu-
cational facilities, that affect SDI effectiveness (e.g. discussed by Harvey (2003), De Man
(2006)). All deﬁnitions that try to go beyond the restricted data-related nature of its objec-
tives struggle with the role of users and their broader organizational and social objectives.
This struggle can only be resolved by taking the organizations and other SDI users as the
point of reference for deﬁning the SDI and by distinguishing between their functional goals
and the goals associated with adopting SDI in their work.

In addition to the objectives, the role of the components in the various deﬁnitions needs
to be examined. As Ashby’s deﬁnition of regulation explains, SDI components are mean-
ingful only once objectives have been set and barriers to achieving these, identiﬁed by
Ashby as disturbances, have been speciﬁed. Only one deﬁnition that was analysed rec-
ognized this indispensable connecting role of disturbances, in this case referred to as
impediments, to give SDI components their raison d’être:

A spatial data infrastructure supports ready access to geographic information. [. . .] These
actions encompass the policies, organizational remits, data, technologies, standards, delivery
mechanisms, and ﬁnancial and human resources necessary to ensure that those working at
the (national) and regional scale are not impeded in meeting their objectives (GSDI, cited by
Masser (2005))

Downloaded by [Florida State University] at 20:50 20 October 2014 1490

P.H.J. Hendriks et al.

Particularly, older deﬁnitions focus on technological resources – especially those related
with computer use – or have lists that put technological features on a pedestal. This ﬁts
the previously mentioned tendency outside the SDI domain of associating infrastructure
ﬁrst and foremost with technological infrastructure. More extensive lists, such as the one
offered by GSDI mentioned above, include more diverse categories of components, such as
data, metadata, policies, standards and regulations, services and education. What such lists
appropriately signal – yet mostly implicitly – is that the individual components will not give
SDIs their functionality but some meaningful combination of them. However, there was no
deﬁnition based on an analysis of the interdependencies between (classes of) components;
all deﬁnitions appear as unordered lists where the components are concerned.

To conclude, most attention in SDI deﬁnitions has been paid to technological resources,
or the third class in Achterbergh and Vriens’ (2009) argument (see Section 3). These
authors argue that this class is not to be considered on a stand-alone basis; it derives its
relevance from the ﬁrst two classes. Hardly any attention is given to the ﬁrst class, that
of organizational structures. A different division, allocation and coordination of tasks is
bound to lead to a different need for the other resources, including the technological ones.
This is surely an important shortcoming in deﬁnitions of and approaches to SDI.

4.2. Ad (2) What constitutes an SDI?

When considering what an SDI is, one may address the deﬁnition of an SDI or the exis-
tence of one. Several approaches view SDI as a phenomenon or system of its own, with
a separate existence and relationship to its environment. These approaches seem to deﬁne
SDI but upon closer examination they sidestep the core nature of infrastructures as regu-
latory devices. The basic approach taken in these studies is visible in Hjelmager et al.’s
(2008) distinction of ﬁve perspectives of SDI labelled as the enterprise, information, com-
putation, engineering and technology perspectives. This article then elaborates the ﬁrst two
of these. The enterprise perspective grounds the other perspectives and ‘describes the pur-
pose, scope and policies for an SDI. The enterprise viewpoint describes the relationship
of an SDI to its environment, its role and the policies associated’ (Hjelmager et al. 2008,
p. 1299). An elaborated understanding of SDI considered from an enterprise perspective
may come from Grus et al.’s (2010) treatment of SDI as complex adaptive systems (CAS),
which highlights many informative traits of SDI, such as their openness in the sense of
interaction with their environment, their nonlinearity, their emergent nature resulting from
the interactions between components and not from characteristics inherent in the compo-
nents themselves, their adaptability, self-organization, unpredictability and sensitivity to
initial conditions. While these approaches have contributed to the understanding of SDI, it
is important to stress that in themselves they do not provide an appropriate basis for a total
understanding because they approach SDI as a stand-alone phenomenon maintaining rela-
tionships with its surroundings. A deﬁnition of SDI, which is the key focus in this article,
is then only implied. Presuming that an enterprise or CAS perspective fully captures the
nature of SDI easily leads to confusion. It opens the discussion on SDI not with the deﬁni-
tion of SDI but with an interpretation of the phenomenon, leaving the deﬁnition implicit in
the background. It seems more appropriate to address the system that the SDI should help
regulate as a CAS (e.g. a country that introduces a clearinghouse to support its national
SDI, an organization that delivers its data-related services via SDI, a grassroots group that
connects to an international SDI to support its social action). The CAS perspective on SDI
focuses on ‘what an SDI is’ and not on ‘what an SDI can or should do’.

Downloaded by [Florida State University] at 20:50 20 October 2014 International Journal of Geographical Information Science

1491

An increasingly popular debate in which the idea of SDI as ‘a phenomenon with a sep-
arate existence’ becomes more visible and elaborated is SDI performance (e.g. Steudler
2003, De Man 2006, Scholten et al. 2006, Giff and Crompvoets 2008). The argument lead-
ing to the SDI performance question entails using a management approach to SDI. The
argument links the outcomes associated with SDI usage to SDI objectives embedded in
a strategy. Performance assessment then involves weighing outcomes against objectives,
which presumes the identiﬁcation of performance indicators and standards to assess indi-
cator values. This approach may prove useful, but it should be stressed that it starts at
the ‘wrong’ level. First and foremost the concept of performance refers to that what is
being regulated via the infrastructure and not to the infrastructure itself. As stressed above,
it is not the data-related, user-related and broader objectives that deﬁne the SDI, but the
objectives of individuals, groups and organizations that may be better achieved through a
collectively built and maintained SDI. Therefore, the performance question concerns the
SDI’s proven functionality, given conditions of access, acceptance and integration, judged
by how well these objectives are met. Obviously, if one uses certain resources or tools, it
makes sense to ask questions about quality and functionality of these; the provider of the
resources would be particularly interested in such questions. However, to couch that debate
in performance terminology appears odd, to say the least. Assessing the infrastructure in
its own right involves a strange inversion based on a manifestation of the infrastructure.
In other words, the performance debate approaches the SDI as a physical entity, but the
actual character of an SDI can only be established within the context of its use.

Similar remarks can be made regarding the organization of the SDI, for instance,
through clearinghouse constructions, stafﬁng policies and geospatial one-stop shops (e.g.
Junker and Weber 2001, Dueker and Bender 2003, Crompvoets et al. 2004, Kohler and
Wachter 2006, Goodchild et al. 2007). Since these discussions, just like the debates con-
cerning the ﬁve perspectives mentioned in Section 4.2, CAS and performance, aim at
contributing to understanding SDIs, they may appear to build on a deﬁnition of SDI and
elaborate on it. Yet closer examination shows that they, willingly or not, overlook the inter-
mediate character of the SDI as a regulation phenomenon. These approaches take SDI as
‘something that is there’; therefore, they involve a manifestation of SDI.

5. Conclusions
The objective of this article was to critically review existing SDI deﬁnitions using a
system-theoretical understanding of infrastructures as the reviewing perspective. While
this approach in itself does not produce a new, sharper deﬁnition of SDI, it should still be
helpful in expanding our understanding of SDIs. To conclude this article, the conceptual
discussion of SDI is used to brieﬂy revisit the four classes of complexity involved in deﬁn-
ing SDI that were identiﬁed in the introduction. The ﬁrst two sources of complexity, the
roles played by objectives and users, are closely linked. The distinction between functional
and adoption objectives is key to these discussions. It is important to note that users (cf.
the second source of complexity) are connected to both functional and adoption objec-
tives. As De Man (2006, p. 338), quoting Carver, establishes: ‘SDIs should be focused on
real people using real systems to address real problems.’ The adoption objectives refer to
individual practices of ‘real people’ turning to the ‘real systems’ available in SDI when
tackling their ‘real problems’, while the functional objectives are dealing with these real
problems (e.g. understanding them, assessing their relevance, solving them). There is noth-
ing forcing SDI designers to have an explicit adoption model in mind when constructing
the SDI’s functionality, but it seems logical to assume that better knowledge of adoption

Downloaded by [Florida State University] at 20:50 20 October 2014 1492

P.H.J. Hendriks et al.

factors may lead to both better SDI design knowledge and a more effective contribution of
SDI to its intended users’ performance. The distinction between functional and adoption
goals shows that grouping together user-related objectives with data-related objectives and
broader objectives is insufﬁciently precise. The role of users in connection with SDI objec-
tives is different from the roles of the data-related and broader objectives. The concept of
adoption objectives may help in dealing with these differences in the practice of designing,
implementing and running ‘real’ SDIs.

The third source of complexity is the role of components. What a system-theoretical
approach to regulation makes clear is that, at a general level, these components come under
three classes of organization structures (tasks and their coordination), HR systems (skills,
competencies, etc. presumed necessary for task completion) and technology (all other
resources that are considered instrumental to achieving functional objectives). Applying
this distinction to SDI literature shows that the class of technological mechanisms appears
centre stage in SDI debates, while particularly the ﬁrst class of components (organizational
structures) gets systematically overlooked (the ‘Spatialist’ research programme is one of
the exceptions proving this rule, see Dessers et al. (2010)). Even if ‘the core of an SDI
is a set of networked, and potentially interlocked, geospatial databases’ (Hjelmager et al.
2008), without downplaying the importance of the necessary standards, laws and regu-
lations, interoperability issues, and so on, such components alone cannot make the SDI
‘work’. A meaningful connection to SDI objectives, both functional and adoption, pre-
sumes that technological components are linked to task division and HR facilities (e.g.
educational and training programmes). More insight is needed in the role of these two
classes of SDI components.

The fourth class of miscellaneous complexity sources such as the dynamic nature of
SDI and SDI hierarchies has not been explicitly addressed in this article. A better under-
standing of this fourth class should build on the perspective developed in this article and
also needs further conceptualization. For example, adequately dealing with the dynamics
of SDI requires a model of regulation (or intervention) as a process, whereas the focus in
this article is on identifying the structure of the SDI concept. This means a limitation of
this article and shows that further elaboration of the argument developed here is necessary.

Note
1. The combination of ‘no components’ and ‘no objectives’ does not lead to a feasible deﬁnition.

References
Achterbergh, J. and Vriens, D., 2009. Organizations: social systems conducting experiments.

New York: Springer.

Ashby, W.R., 1956. An introduction to cybernetics. London: Chapman and Hall.
Ashby, W.R., 1960. Design for a brain: the origin of adaptive behaviour. New York: John Wiley.
Chan, T.O., et al., 2001. The dynamic nature of spatial data infrastructures: a method of descriptive

classiﬁcation. Geomatica, 55 (1), 65–72.

Craglia, M. and Campagna, M., 2009. Advanced regional spatial data infrastructures in Europe.

Luxembourg: Ofﬁce for ofﬁcial publications of the European Communities.

Crompvoets, J., et al., 2004. Assessing the worldwide developments of national spatial data
clearinghouses. International Journal of Geographical Information Science, 18 (7), 665–689.
De Man, E., 2008. The multi-faceted nature of SDIs and their assessment – dealing with dilemmas.
In: J. Crompvoets, A. Rajabifard, B.V. Loenen, and T.D. Fernández, eds. A multi-view framework
to assess spatial data infrastructures. Melbourne: Melbourne University Press, 23–49.

De Man, W.H.E., 2006. Understanding SDI; complexity and institutionalization. International

Journal of Geographical Information Science, 20 (3), 329–343.

Downloaded by [Florida State University] at 20:50 20 October 2014 International Journal of Geographical Information Science

1493

Dessers, E., et al., 2010. Developing spatially-enabled business processes: the role of organisational
structures. In: A. Rajabifard, J. Crompvoets, M. Kalantari, and B. Kok, eds. Spatially enabling
society, research, emerging trends and critical assessment. Leuven: Leuven University Press,
41–54.

Dueker, K.J. and Bender, P., 2003. Building and maintaining a statewide transportation frame-
work. In: Annual meeting of the transportation research board. Washington, DC: Transportation
Research Board National Research Council, 93–101, 12–16 January 2003, Washington, DC.
Elwood, S., 2008. Grassroots groups as stakeholders in spatial data infrastructures: challenges and
opportunities for local data development and sharing. International Journal of Geographical
Information Science, 22 (1), 71–90.

European Commission, 2007, Establishing an Infrastructure for Spatial Information in the European
Community (INSPIRE). Directive 2007/2/EC of the European Parliament and of the Council of
14 March 2007.

Executive Ofﬁce of the President, 1994, Coordinating geographic data acquisition and access:
the National Spatial Data Infrastructure. Executive Order 12906. Federal Register, 59,
17671–17674.

Francois, C., 1999. Systemics and cybernetics in a historical perspective. Systems Research and

Behavioral Science, 16 (3), 203–219.

Georgiadou, Y., Puri, S.K., and Sahay, S., 2005. Towards a potential research agenda to guide the
implementation of spatial data infrastructures – a case study from India. International Journal
of Geographical Information Science, 19 (10), 1113–1130.

Giff, G.A. and Crompvoets, J., 2008. Performance indicators a tool

to support spatial data

infrastructure assessment. Computers Environment and Urban Systems, 32 (5), 365–376.
Goodchild, M.F., Fu, P.D., and Rich, P., 2007. Sharing geographic information: an assessment of the
geospatial one-stop. Annals of the Association of American Geographers, 97 (2), 250–266.
Groot, R. and McLaughlin, J., 2000. Geospatial data infrastructure: concepts, cases and good

practice. Oxford: Oxford University Press.

Grus, L., Crompvoets, J., and Bregt, A.K., 2010. Spatial data infrastructures as complex adaptive

systems. International Journal of Geographical Information Science, 24 (3), 439–463.

GSDI, 2004, The SDI cookbook [online]. Available from: http://www.gsdi.org/gsdicookbookindex,

Accessed on 13 November 2011.

Harvey, F., 2003. Developing geographic information infrastructures for local government: the role

of trust. Canadian Geographer-Geographe Canadien, 47 (1), 28–36.

Harvey, F.J., Buttenﬁeld, B.P., and Lambert, S.C., 1999. Integrating geodata infrastructures from the

ground up. Photogrammetric Engineering and Remote Sensing, 65 (11), 1287–1291.

Hendriks, P.H.J., 1986. De relationele deﬁnitie van begrippen: een relationeel realistische visie
op het operationaliseren en representeren van begrippen (Functionally deﬁning concepts; a
relationally-realistic perspective on the operationalisation and representation of concepts).
Amsterdam: Koninklijk Nederlands Aardrijkskundig Genootschap.

Hjelmager, J., et al., 2008. An initial formal model for spatial data infrastructures. International

Journal of Geographical Information Science, 22 (11–12), 1295–1309.

Junker, M. and Weber, G., 2001. Geodata management in a transborder region. Results of the INFO
2000 project Spatial Data Clearinghouse Saar-Lor-Lux CLEAR. Nfd Information-Wissenschaft
Und Praxis, 52 (8), 445–452.

Kohler, P. and Wachter, J., 2006. Towards an open information infrastructure for disaster research
and management: data management and information systems inside DFNK. Natural Hazards,
38 (1–2), 141–157.

Lewis, G.J. and Stewart, N., 2003. The measurement of environmental performance: an application

of Ashby’s law. Systems Research and Behavioral Science, 20 (1), 31–52.

Masser, I., 1999. All shapes and sizes: the ﬁrst generation of national spatial data infrastructures.

International Journal of Geographical Information Science, 13 (1), 67–84.

Masser, I., 2005. GIS worlds: creating spatial data infrastructures. Redlands, CA: ESRI.
Masser, I., 2007. Building European spatial data infrastructures. Redlands, CA: ESRI.
Masser, I., Rajabifard, A., and Williamson, I., 2008. Spatially enabling governments through SDI
implementation. International Journal of Geographical Information Science, 22 (1), 5–20.
McLaughlin, J. and Nichols, S., 1994. Developing a national spatial data infrastructure. Journal of

Surveying Engineering-ASCE, 120 (2), 62–76.

Merriam-Webster, 2006. Merriam Webster’s collegiate dictionary. Springﬁeld: Merriam-Webster.

Downloaded by [Florida State University] at 20:50 20 October 2014 1494

P.H.J. Hendriks et al.

Nedovic-Budic, Z., Crompvoets, J., and Georgiadou, Y., eds., 2011. Spatial data infrastructures in

context: north and south. London/New York: CRC Press.

Onsrud, H., 2007. Research and theory in advancing spatial data. Redlands, CA: ESRI.
Onsrud, H., 2008. Foreword. In: J. Crompvoets, A. Rajabifard, B.V. Loenen, and T.D. Fernández, eds.
A multi-view framework to assess spatial data infrastructures. Melbourne: Melbourne University
Press, xi–xii.

Pickering, A., 2010. The cybernetic brain: sketches of another future. Chicago, IL: University of

Chicago Press.

Poore, B.S., 2003. The open black box: the role of the end-user in GIS integration. Canadian

Geographer-Geographe Canadien, 47 (1), 62–74.

Rajabifard, A., ed., 2007. Towards a spatially enabled society. Melbourne: University of Melbourne.
Rajabifard, A., Feeney, M.-E.F., and Williamson, I.P., 2002. Future directions for SDI development.

International Journal of Applied Earth Observation and Geoinformation, 4 (1), 11–22.

Rajabifard, A., Feeney, M.-E.F., and Williamson, I.P., 2003. Spatial data infrastructures: con-
cept, nature and SDI hierarchy. In: Williamson, I.P., Rajabifard, A. and Feeney, M.-E.F., eds.
Developing spatial data infrastructures. From concept to reality. London/New York: Taylor &
Francis, 17–40.

Rajabifard, A., et al., 2006. The role of sub-national government and the private sector in future
spatial data infrastructures. International Journal of Geographical Information Science, 20 (7),
727–741.

Rajabifard, A., et al., eds., 2010. Spatially enabling society; research, emerging trends and critical

assessments. Leuven: Leuven University Press.

Roche, S., Sureau, K., and Caron, C., 2003. How to improve the social utility value of geographic
information systems for French local governments? A Delphi study. Environment and Planning
B-Planning & Design, 30 (3), 429–447.

Scholten, M., Klamma, R., and Kiehle, C., 2006. Evaluating performance in spatial data

infrastructures for geoprocessing. IEEE Internet Computing, 10 (5), 34–41.

Steudler, D., 2003. Developing evaluation and performance indicators for SDI’s. In: I. Williamson,
A. Rajabifard, and M.F. Feeney, eds. Developing spatial data infrastructures: from concept to
reality. London: Taylor and Francis, 235–246.

Tarride, M.I., et al., 2008. Healthy organizations: toward a diagnostic method. Kybernetes, 37 (8),

1120–1150.

Thygeson, M., Morrissey, L., and Ulstad, V., 2010. Adaptive leadership and the practice of medicine:
a complexity-based approach to reframing the doctor-patient relationship. Journal of Evaluation
in Clinical Practice, 16 (5), 1009–1015.

Vandenbroucke, D., et al., 2009. A network perspective on spatial data infrastructures: application to

the sub-national SDI of Flanders (Belgium). Transactions in GIS, 13 (1), 105–122.

Van Loenen, B., 2006. Developing geographic information infrastructures. The role of information

policies. Delft: Delft University of Technology.

Williamson, I., Rajabifard, A., and Feeney, M.F., eds., 2003. Developing spatial data infrastructures:

from concept to reality. London: Taylor and Francis.

Downloaded by [Florida State University] at 20:50 20 October 2014 