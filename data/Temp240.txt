International Journal of Geographical Information Science
Vol. 25, No. 12, December 2011, 1971–1999

Automatic revision of rules used to guide the generalisation process in
systems based on a trial and error strategy

Patrick Taillandiera,b,c*, Cécile Duchênec and Alexis Drogoula,b,d

aInstitut de la Francophonie pour l’Informatique (IFI), Modélisation Simulation Informatique
(MSI), Unité Mixte Internationale (UMI), Ha Noi, Vietnam; bIRD, Unité Mixte Internationale
(UMI) UMMISCO, Bondy, France; cInstitut Géographique National (IGN), Conception Objet et
Généralisation de l’Information Topographique (COGIT), Saint-Mandé, France; dUniversité Pierre
et Marie Currie (UPMC), Unité Mixte Internationale (UMI), Paris, France

(Received 12 May 2009; ﬁnal version received 19 February 2011)

Automating the generalisation process, a major issue for national mapping agencies, is
extremely complex. Several works have proposed to deal with this complexity using a
trial and error strategy. The performance of systems based on such a strategy is directly
dependent on the quality of the control knowledge (i.e. heuristics) used to guide the
trials. Unfortunately, most of the time, the deﬁnition and updation of knowledge is a
fastidious task. In this context, automatic knowledge revision can not only improve the
performance of the generalisation, but also allow it to automatically adapt to various
usages and evolve when new elements are introduced. In this article, an ofﬂine knowl-
edge revision approach is proposed, based on a logging of the system and on the analysis
of outcoming logs. This approach is dedicated to the revision of control knowledge
expressed by production rules. We have implemented and tested this approach for the
automated generalisation of groups of buildings within a generalisation model called
AGENT, from initial data that reference a scale of approximately 1:15,000 compared
with the target map’s scale of 1:50,000. The results show that our approach improves
the quality of the control knowledge and thus the performance of the system. Moreover,
the approach proposed is generic and can be applied to other systems based on a trial
and error strategy, dedicated to generalisation or not.

Keywords: automated generalisation; rule revision; trial and error strategy

1.

Introduction

Generalisation intends to decrease the level of detail of geographic data in order to answer
a given need. Cartographic generalisation is a particular type of generalisation in which the
goal is to produce a map at a given scale. The application of numerous operations such as
scaling, displacement or elimination of objects is needed in order to ensure the readability
of the target map while keeping the essential information of the initial data. The automation
of this process is complex and has been the subject of numerous researches over the last
20 years. Some of these works propose to solve this problem by using global deformation
techniques (Hojholt 2000, Sester 2000). Others propose to solve it by local, step by step,
approaches (e.g. Ruas 1998b, Ware and Jones 1998, Neun et al. 2009). There, the problem

*Corresponding author. Email: patrick.taillandier@gmail.com

ISSN 1365-8816 print/ISSN 1362-3087 online
© 2011 Taylor & Francis
http://dx.doi.org/10.1080/13658816.2011.566568
http://www.tandfonline.com

1972

P. Taillandier et al.

of automation consists in dynamically choosing the sequence of generalisation operations
to apply on the geographic objects in order to ﬁnd the state that maximises an evaluation
function. In this article, we are interested in these latter approaches that use explicit knowl-
edge to guide the choice of generalisation operations (Brassel and Weibel 1988, Beard
1991, McMaster and Shea 1992, Ruas 1998b, Mustiere 2005, Ruas and Duchêne 2007).
This knowledge is called control knowledge. The performances of the systems relying
on such approaches are directly linked to the quality of their control knowledge. Indeed,
the application of some generalisation actions can be time consuming and the geographic
objects to generalise are often numerous. Generalising an area with bad knowledge can
lead to unsatisfactory results or/and take too much time to be acceptable. This kind of
problem is particularly true in the case of generalisation of groups of objects, also known
as meso-objects (Ruas 2000), such as building groups, for which each action is usually
time consuming. Currently, in such systems, the control knowledge has to be manually
entered by experts. Then, it needs to be tuned, and this is an often long and tedious
task. Another problem concerns the evolution of the system when new elements (e.g. new
actions) are integrated into the model. In this case, the knowledge has to be updated to
account for these elements. Again, this is tedious and requires turning to an expert. To ease
the tuning and evolution of such systems, we claim it is necessary to be able to auto-
matically revise the knowledge provided to the system. Our work proposes a trial and
error approach to automatically revise the control knowledge of generalisation systems
expressed by production rules, which does not require the intervention of generalisation
experts, and which only uses the information retrieved from prior trials. We present our
approach as well as its implementation in the AGENT generalisation model (Ruas 1999,
Regnauld 2001). We also show results of tests carried out with this approach for the gen-
eralisation of building groups. In Section 2, we present the context of this work in deeper
details, in particular the AGENT model, as well as our objectives. Section 3is devoted to the
presentation of our approach. Section 4presents and discusses results obtained for the gen-
eralisation of building groups within the AGENT model. Section 5offers some conclusions
and perspectives.

2. Context and objective

Informed tree search strategy and AGENT generalisation model

2.1.
In this article, we are interested in generalisation systems based on a speciﬁc type of trial
and error approach: the informed tree search exploration. This approach consists in search-
ing the best solution to a problem by exploring a search tree. The transition from one state
of the search tree to another corresponds to the application of an elementary action (e.g. a
generalisation operation). The ‘informed’ aspect comes from the use of control knowledge
(e.g. which action to apply) to guide the exploration of the tree. This approach is com-
monly used in Artiﬁcial Intelligence (AI). As a matter of fact, the ﬁrst ever AI program,
‘Logic Theorist’ (Newell and Simon 1956), dedicated to proving theorems, was based on
this type of approach. In order to ﬁnd the proof of a logic problem, Logic Theorist was
exploring a state tree in which the root represented the initial hypothesis, and each branch
a deduction based on logic rules. This approach is however particularly efﬁcient in contexts
where expert knowledge can be used to guide the exploration process. Unlike optimisation
approaches such as simulated annealing (Kirkpatrick et al. 1983) or genetic algorithms
(Holland 1975) that allow to ﬁnd a good solution to a problem without prior knowledge,
the informed tree search approach requires the deﬁnition of domain speciﬁc knowledge to
guide the exploration process. When this knowledge is pertinent, the systems based on this
approach obtain excellent performances.

International Journal of Geographical Information Science

1973

In this article, we are especially interested in a generalisation model based on this
approach: the AGENT model. This model, used in the AGENT European Project (Lamy
et al. 1999, Barrault et al. 2001), originates in Ruas (1999). It has been further described
in Ruas and Duch¯ene (2007).

In this model, geographic objects are modelled as agents. An agent is a computational
entity provided with a goal that can act autonomously in order to reach this goal thanks
to capacities of perception, deliberation, action and possibly communication with other
agents (Weiss 1999). The geographic agents manage their own generalisation, choosing
and applying generalisation algorithms (actions) to themselves. An agent can represent a
single object like a building or a road segment (micro agent) or a group of objects that
should be considered together at a certain stage of the generalisation process, such as a
group of buildings (meso agent).

The generalisation of the agents is guided by a set of constraints that translate the spec-
iﬁcations of the desired cartographic product. An example of a constraint is, for a building
agent, to be sufﬁciently large to be readable. Each constraint relative to a geographical
agent is modelled as an object (in the computer science meaning of the term) linked to
this agent. Each constraint has a level of satisfaction that ranges from 1 (the constraint is
not satisﬁed) to 10 (it is totally satisﬁed). For each state, the agent computes its own sat-
isfaction, which corresponds to the mean of its constraint satisfaction levels weighted by
their respective importance. In addition, the constraints have the role of computing for their
associated agent, for each state, a list of actions to try. For example, if the constraint of the
size of a building ﬁnds that the agent is too small, it will propose a scaling action to the
agent.

To satisfy its constraints, a geographical agent carries out a cycle of actions during
which it tests the different actions proposed by its constraints in order to reach a perfect
state (where all of its constraints are satisﬁed) or at least the best possible state (the state
visited that maximises the agent satisfaction). The cycle of actions results in an informed
exploration of a state tree. Figure 1 presents the cycle used by the AGENT model. For
systems based on an informed tree search strategy, this action cycle is quite classic.

Figure 1. AGENT model action cycle.

1974

P. Taillandier et al.

It begins with the characterisation of the current state of the agent (or group of agents)
and its evaluation. Then, the agent tests if the current state is good enough or if it is neces-
sary to continue exploring other states. If the agent decides to continue the exploration, it
tests if the current state is valid or not. An invalid state is deﬁned as a state that is unlikely
to have a better state among its descendants. Thus, the agent has no interest in exploring
the descendants of invalid states. If the state is not valid, the agent backtracks to its pre-
vious state; otherwise, the agent constructs a list of actions to try. If this list is empty, the
agent backtracks to its previous state, otherwise, the agent chooses the best action (the one
with the highest priority) and applies it. In the AGENT model, the priority of application
of an action depends on the priority of the constraint that proposed this action (i.e. its
urgency to be satisﬁed). The higher the priority of a constraint, the sooner the actions it
proposes are evaluated. This value, which is dynamic (it is computed for each agent state),
is not necessarily correlated with the importance of the constraint. For example, concerning
the generalisation of building blocks, it is necessary to give a high priority to the density
constraint when its satisfaction is low, even if the satisfaction of the proximity constraint,
which is more important for the cartographic result, is low as well. Indeed, without pre-
viously solving density problems, it is not possible to have enough space for all buildings
and thus to solve proximity problems. When a constraint proposes several actions, the pri-
ority of application of an action depends on the weight the constraint associates to it. After
applying an action, the agent goes back to the ﬁrst step. The action cycle ends when the
stopping criterion is matched or when all actions have been applied for all valid states, that
is, when the agent backtracks to its initial state (ﬁrst state of the action cycle) and has no
more action to try.

Figure 2 gives an example of a state tree obtained on a building with the AGENT action
cycle. It shows all the states through which the building has gone during its trials and the
actions leading from one state to another one.

For the generalisation of one type of geographic objects, the implementation of the

AGENT model requires the deﬁnition of two kinds of control knowledge:

Enlarging while
simplifying to
rectangle

2

Scaling

3

Enlarging while
simplifying to
rectangle

1

4

Generalisation
1:15,000 → 1:50,000

Valid state

Invalid state

Best state

Simplification

5

6

7

Scaling

Squaring

Figure 2. Example of a state tree for the generalisation of a building.

International Journal of Geographical Information Science

1975

(cid:129) Constraint priority knowledge deﬁnes the priority of each constraint compared with
the others. In most of the works that rely on the AGENT system, the priority is
computed as a function of the constraint violation degree.

(cid:129) Action application knowledge deﬁnes the action application domain, that is, the
actions (and their weight) proposed by each constraint according to the state of the
geographic agent.

In the AGENT model, the control knowledge is expressed in the form of production rules.
This kind of representation is commonly used in domains where expert knowledge has to
be represented, which is the case of the generalisation domain. Its interest is that it can be
easily interpreted by domain experts and thus facilitates the validation and updation of the
experts’ knowledge.

A production rule has the following form:

If Condition then Conclusion

We assume that a set of measures, characterising the object states, is deﬁned for each piece
of knowledge. For example, a measure set is deﬁned for the action application knowledge
of each constraint. For each piece of knowledge, the conditions of the rules depend on
the set of measures linked to the piece of knowledge. Examples of measures concerning
building groups are given in Figure 3. An example of a production rule part of the action
application knowledge for building blocks is: If ‘density > 0.8’ then ‘weight for the global
building removal action = 1’.

In addition to these two kinds of control knowledge, which are speciﬁc to each geo-
graphic agent type, the AGENT model permits the deﬁnition of two other types of control
knowledge which are shared by all geographic agents:

(cid:129) Validity criterion: this determines, according to the previously visited states, if the
current state is valid or not, that is, if it is interesting or not to continue the explo-
ration from this state. The validity criterion allows avoiding the exploration of an
inﬁnite tree due to oscillations in the constraint satisfaction values. The validity crite-
rion that is the most commonly used in the AGENT model is based on two conditions
that the state must verify:
(1) the satisfaction of the constraint that proposed the action has been improved

above a certain threshold,

(2) there is a partial improvement compared with each of the already visited states.
A partial improvement means that at least one constraint had its satisfaction
improved. For example, let C1 and C2 be the two constraints of an agent. Let
Sn be a new state of this agent where C1 = 45 and C2 = 70. Let Sa and Sb
be two previously visited characterised, respectively, by C1 = 50, C2 = 70 and
C1 = 60, C2 = 60. In this example, Sn will not be valid. Indeed, though there
is a partial improvement from Sb to Sn (C1 has improved), none of the agent
constraints’ satisfaction has improved from Sa to Sn (C1 has decreased and C2
is equal).

This validity criterion allows for deteriorations of the state satisfaction. Indeed, as
shown by Ware et al. (2003) and Neun et al. (2009), it is sometimes necessary to
pass trough bad states in order to ﬁnd very good ones. Moreover, since the constraint
satisfaction is an integer (from 1 to 10), the second condition ensures the convergence
of the action cycle. Indeed, the number of constraint satisfaction conﬁgurations is

1976

P. Taillandier et al.

Measures:

Nb: Number of  buildings
NbBig: Number of  big buildings
MeanSize: Mean building size
MedianSize: Median building size
MinSize: Min building size: MinSize
MeanProx: Mean building proximity
MedianProx: Median building proximity
MinProx: Min building proximity
NbOverlap: Number of  building overlapping
Area: Area
Density: Density

Nb: 2
NbBid: 0
MeanSize: 430 m2
MedianSize: 420 m2
MinSize: 420 m2
MeanProx: 22.5 m
MedianProx: 22.5 m
MinProx: 22.5 m
NbOverlap: 0
Area: 4340 m2
Density: 0.08

Data set:

Nb: 8, NbBig: 0, MeanSize: 393 m2, MeadianSize: 430 m2, MinSize: 216 m2, MeanProx: 25.1 m,
MedianProx: 23.5 m, MinProx: 0 m, NbOverlap: 3, Area: 17121 m2, Density: 0.17

Nb: 2, NbBig: 0, MeanSize: 430 m2, MeadianSize: 420 m2, MinSize: 420 m2, MeanProx: 22.5 m,
MedianProx: 22.5 m, MinProx: 22.5 m, NbOverlap: 0, Area: 4340 m2, Density: 0.08

Nb: 9, NbBig: 1, MeanSize: 365 m2, MeadianSize: 295 m2, MinSize: 240 m2, MeanProx: 12.5 m,
MedianProx: 10.7 m, MinProx: 0 m, NbOverlap: 7, Area: 30253 m2, Density: 0.078

Figure 3. Example of a Characterised object set for groups of buildings.

ﬁnite (its value is 10constraint_number). So, the second condition will never be satisﬁed
after at most 10constraint_number tries.

(cid:129) Action cycle stopping criterion: this determines, according to the characteristics and
current state of the agent, if it is likely that a better state can be reached during the
action cycle, and therefore if it is worth to carry on the exploration or not. This crite-
rion allows lowering the expected quality of the generalisation process outcomes for
some speciﬁc agents, when it is dynamically identiﬁed as likely to be not reachable.
Contrary to the validity criterion, this criterion does not only stop the exploration of
a branch of the tree, but also the complete exploration process.

These two criteria improve the efﬁciency of the exploration process by limiting the num-
ber of uselessly visited states. Indeed, the validity criterion allows to skip uninteresting
branches of the tree (ones that do not possibly contain any better state), and the stopping
criterion allows to stop the exploration process when it is not possible to ﬁnd a better state
than the ones already found.

We call ‘knowledge set’ a knowledge base containing all the types of control knowledge

necessary for the generalisation system.

We call ‘piece of knowledge’ a knowledge based extracted from a knowledge set and
related to one of the identiﬁed types of control knowledge. For example, a knowledge set
contains n pieces of knowledge for the ‘constraint priority’ knowledge type, where n is the
number of constraints.

International Journal of Geographical Information Science

1977

2.2. Objective of the knowledge revision

As introduced in Section 1, our work proposes an approach to automatically revise the
control knowledge of generalisation systems based on an informed tree search strategy.

The performance of the system is measured using two criteria: its effectiveness (obtain-
ing good cartographic results) and its efﬁciency (obtaining these results quickly). In order
to be effective, the knowledge must ﬁnd the best possible state (the best state that can
be reached according to the available generalisation actions). In order to be efﬁcient, the
knowledge must guide the exploration as directly as possible towards this ‘very best state’
and avoid exploring useless states (states that are not on the path towards the best state).

Usually, systems based on informed tree search exploration use different kinds of
knowledge: some play a role in the order of application of actions (e.g. the constraint
priority knowledge), others for pruning the state trees (e.g. the validity criterion). Good
constraint priority knowledge contributes to have the best state placed on the left of the
state tree. Good validity criterion knowledge contributes to avoid useless states (and only
keep useful ones).

2.3. Related work

The automation of generalisation processes requires much knowledge. This knowledge
can be acquired thanks to domain experts – but this raises the problem of collecting and
formalising it (Rieger and Coulson 1993, Weibel et al. 1995, Kilpelinen 2000) – a problem
classically known as ‘the bottleneck of knowledge acquisition’ (Feigenbaum 1977). One
approach for solving this dilemma is the application of Machine Learning Techniques.
Several prior works have used machine learning in the context of generalisation (Weibel
et al. 1995, Ruas and Holzapfel 2003, Mustière 2005).

The use of such techniques requires solving two kinds of difﬁculties (Ruas et al. 2006).
The ﬁrst concerns the choice of the knowledge to learn and its formalisation. These choices
appear to be critical with respect to the quality of the results. The second difﬁculty is related
to the collection of examples (Ruas and Holzapfel 2003, Mustière 2005). It is often tedious
and problematic to build learning sets from examples labelled by experts. Indeed, it requires
using several systems that are not interrelated: for instance, a GIS to choose the examples,
a document with screen captures to collect the expert assessments and a machine learning
software to induce the predictive model. To overcome this difﬁculty, one possible approach
is to design an environment that aims at facilitating the collection of examples and their
analysis in the GIS (Duchêne et al. 2005). Another possible approach, for systems capable
of self-evaluating their own generalisation results, is to directly acquire the examples by
automatically analysing the successes and failures encountered, without the assistance of
the experts.

Burghardt and Neun (2006) used such an approach to build a case base: in order to
generalise a geographic object, the system applies a sequence of generalisation operations.
At each step, the choice of the operation to apply is guided by the results obtained by the
operations for ‘similar’ states in terms of violations of cartographic constraints. For a given
state, the more the application of an operation improved the satisfaction of constraints, the
more this operation had a chance of being proposed for a similar state. In this approach,
which allows online revision, case bases represent the control knowledge. Thus, there is
no explicit representation of this knowledge. By contrast, in our work, we aim at working
with explicit rule-based knowledge since an explicit representation allows the experts to
easily validate the knowledge acquired, but also allows to deduce high-level generalisation
knowledge from it. In Section 4.3, we propose a more detailed comparison between this
approach and ours.

1978

P. Taillandier et al.

Ruas et al. (2006) sought to acquire new knowledge in the from of rules based on the
analysis of the execution logs. We place our approach to controlling the automatic revision
of knowledge in the continuity of this work, but with the aim of revising the initial rules
rather than simply learning new rules to be added to the initial ones. Indeed, it is sometimes
interesting to take the initial knowledge into account, since it may contain information that
cannot be acquired by machine learning techniques, such as the time consumption of some
actions, the defects of the evaluation function and so on.

3. Proposed knowledge revision approach

3.1. General approach

We propose a knowledge revision approach that can be used to revise the control knowledge
of systems based on an informed tree search strategy. For example, it is possible to use our
approach in the context of the Logic Theorist program (presented in Section 2.1).

In the context of the AGENT model, the goal of our approach is to revise the knowledge
of a single type of geographic agent. This can be either a micro agent (e.g. a building) or a
meso agent (e.g. a group of buildings). In order to clarify the presentation of our approach,
we will use the term ‘object’ to designate what the geographic agent represents even if, in
practice, an agent can represent a group of such ‘objects’.

Our approach is based on the analysis of the execution logs, but we do not seek to
revise the knowledge online. Indeed, we are considering the situation of a production line,
where it is possible to stop the generalisation process during several hours (e.g. during the
night) to improve the performance of the system. Our approach requires stopping the ‘nor-
mal’ process of generalisation in order to activate the knowledge revision process with a
dedicated knowledge set. We call this dedicated knowledge set the ‘full-exploration knowl-
edge set’. It visits all possible states and thus acquires the most complete and accurate
pieces of information on the successes/failures met by each piece of knowledge. Once the
knowledge has been revised, the ‘normal’ generalisation process resumes with the revised
knowledge.

In order to determine when the ofﬂine revision process should be triggered, we propose
to integrate a diagnosis module capable of evaluating the quality of the knowledge online.
This article does not discuss this diagnosis module. It has been presented in several existent
papers (Taillandier 2008, Taillandier et al. 2009).

Our knowledge revision approach is composed of two stages:

(cid:129) Exploration stage consists in logging the process while the system generalises a

(cid:129) Analysis stage consists in analysing the logs obtained during the previous stage and

sample of objects.

using it to revise the knowledge.

The exploration stage is independent of the type of knowledge revised. On the contrary,
the analysis stage must be specialised for each type of knowledge. In this article, we
present a specialisation of this stage for knowledge expressed in the form of production
rules.

3.2. Exploration stage

The exploration stage is composed of two steps: the selection geographic object samples
that will be used for the revision process and the generalisation of these objects with a
full-exploration knowledge set. We present these two steps in Sections 3.2.1 and 3.2.2.

International Journal of Geographical Information Science

1979

3.2.1. Geographic object sample selection

In order to retrieve pertinent information from their generalisation, the objects belong-
ing to the selected sample must be various enough to be representative of all available
geographic objects of the considered class. However, their number must also be restricted
in order to limit the computing time of the revision process. As this process is carried out
ofﬂine, the time is not a hard constraint; but the generalisation of the objects with the full-
exploration knowledge set introduces a high computational complexity and can be very
time consuming. In this article, we assume that only a single data set of geographic objects
of the considered class is available. This assumption is consistent with the usual scenario
when our approach is employed by a user who wants to revise knowledge from a data set
composed of numerous objects of the considered class (too much to use all these objects
in the revision process).

To select a representative sample, we proceed as follows:

(1) Characterisation of all available geographic objects of the considered class
(2) Clustering of the geographic objects
(3) Selection of a sample of geographic objects in each cluster

These three steps are detailed below:

Step 1: characterisation of objects. This step consists in building a characterised object
set by describing in terms of features and measures all available objects of the considered
class. A key point of this step is to choose the relevant measure set in order to pertinently
characterise the geographical objects. Figure 3 gives an example of such a characterised
object set, on objects of the class ‘group of buildings’.
Step 2: clustering of the geographic objects. The goal of this step is to divided the objects
of the data set into groups composed of similar objects. Deﬁning such groups ensures that
all groups will be represented in the object sample. The geographical objects in the data set
are divided into groups by means of clustering techniques used on the characterised object
set. Clustering algorithms such as expectation-maximisation (EM) (Dempster et al. 1977)
can divide a set of objects described by a set of attributes into a set of disjointed clusters. An
important point in this step concerns the parameters used for the clustering: Speciﬁcally,
the choice of the number of groups and of the distance between objects. Concerning the
ﬁrst point, in the literature, several methods have been proposed to automatically infer the
best number of groups (Xu et al. 1993, Kassab and Lamirel 2008). Domain knowledge may
be used to deﬁne the distance choice. In the case where no domain knowledge is available,
it is possible to use ‘classical distances’ such as the Euclidian or Manhattan distances.
Most clustering algorithms allow computing the probability for each object to belong to
each group. These probabilities will be used in the next step.
Step 3: object selection. This last step consists in selecting a sample of objects in each of
the previously formed groups. The selected objects are those most representative of their
group, that is, those having the highest probability of belonging to their group.

The number nbi of objects selected from a group i depends on the expected size of the
sample and on the relative size of the group in terms of the number of objects compared
with the number of objects in the whole map. The objective is to keep a proportional
representation of the groups while concurrently ensuring that even the smallest groups are
still represented in the sample. The number nbi is computed as follows:
(cid:5)

(cid:4)

(cid:3)

(cid:2)

nbi = Max

ﬂoor

(nbwanted × nbtotal
nbtotal

l

)

+ 0.5

, 1

1980

P. Taillandier et al.

where nbwanted is the number of wanted objects, nbi
i and nbtotal the total number of available objects.

total the number of objects in the group

For example, let us consider 100 objects ‘building’. Twenty buildings are needed for
the revision process. The clustering algorithm divided the objects into two groups: the
ﬁrst group composed of 25 objects and the second one of 75 objects. The representa-
tive sample will be composed of 5 objects from the ﬁrst group and 15 objects from the
second.

3.2.2. Generalisation with a full-exploration knowledge set and logging
Once a sample of objects has been selected, a generalisation process is run on these objects
and logged. In order to produce as much information as possible for the analysis stage of
the knowledge revision process, the control knowledge set used for this generalisation is a
full-exploration knowledge set.

We deﬁne the notion of full-exploration knowledge set as a knowledge set that allows
the system to construct all possible states that can be visited by all possible knowledge sets
for each generalised object. Typically, a full-exploration knowledge set is a knowledge set
for which all possible actions are tested for each valid state and for which the ending cycle
criterion and the validity criterion are as weak as possible to ensure the convergence of
the exploration. The full-exploration knowledge set has two beneﬁts. Firstly, it reveals the
optimal obtainable states (in terms of agent satisfaction) according to the action set and
then demonstrates which action sequences must be applied to reach those states. Secondly,
once an object has been generalised with this knowledge set, this object can simulate any
possible knowledge set by rearranging the states without having to build new states, that is,
without running the generalisation again. Thus, once the object sample selected during the
ﬁrst step has been generalised with the full-exploration knowledge, it becomes possible to
test any knowledge set on this sample with very few computation resources.

The log obtained at the end of the exploration stage contains all the state trees built dur-
ing the exploration stage. A state tree is characterised by the set of visited states (described
by the values of the measure sets used) and by the set of transitions (described by the action
applied).

3.3. Analysis stage

3.3.1. General revision approach by log analysis
Following the exploration stage, we have a set of objects generalised with a full-exploration
knowledge set and the associated state trees that make up the log (see above). We are now
interested in using these state trees to revise the knowledge.

We propose to formulate the revision problem as a search problem: we will search the
knowledge set that maximises an evaluation function measuring the generalisation system
performance. This is discussed in Section 3.3.2. For this search problem, the search space
corresponds to the set of values that can take the different pieces of knowledge. In order to
reduce the search space, we propose not to revise all pieces of knowledge at the same time,
but to revise them by kind of knowledge. For example, to revise the pieces of knowledge
that deﬁne the constraint priority in a ﬁrst step, then, in a second step, the pieces of knowl-
edge that deﬁne the application domain of the actions and so on. The search approach used
to revise each piece of knowledge depends on the nature of the piece. In Section 3.3.3, we
propose a search approach dedicated to rule revision.

International Journal of Geographical Information Science

1981

3.3.2. System performance function evaluation

As stated in Section 3.3.1, our revision approach consists in searching the knowledge set
that maximises an evaluation function. This evaluation function characterises the user’s
needs towards the generalisation system. In particular, this function deﬁnes the balance
between the efﬁciency and the effectiveness of the system. Indeed, for some applications,
the efﬁciency will be important (e.g. for online generalisation) while for others the effec-
tiveness will be more important (e.g. for a map production line). The deﬁnition of this
function is a key point of our approach. Thus, it is essential that this one be adequate for
the user’s needs. There is no generic evaluation function. The evaluation function must be
speciﬁcally deﬁned for each application. As an example, in Section 4.1.3, we describe the
evaluation function that we, used for our experiments. The deﬁnition of this function can be
difﬁcult. In this articles perspective (Section 5), we come back to this deﬁnition problem.
We call Perf (SK, Obj) the function for evaluating the performance of a system S while
using a knowledge set K for the generalisation of all geographic objects of the class Obj.
The computation of the function requires generalising all geographic objects obj belonging
to Obj. In practice, most of the time, it is impossible to compute Perf (SK, Obj). Indeed, it is
rarely possible to generalise each obj belonging to Obj. Thus, for our revision approach, we
will just estimate Perf (SK, Obj) on the sample of objects selected and generalised during
the exploration stage. In fact, the value of Perf (SK, OS), OS being the sample selected
during the exploration stage, will be used to evaluate the quality of knowledge sets.

3.3.3. Search approach for rule revision

Keep in mind that each piece of knowledge is represented by a set of production rules and
is linked to a measure set. All predicates of the rules describing a piece of knowledge are
expressed (only) according to the measures linked to this piece of knowledge. Thus, the
search space associated to a piece of knowledge is the set of the combinations of values
that can be assumed by the measures. This search space becomes inﬁnite as soon as at least
one measure returns continuous values.

In order to reduce the search space, we propose to partition the measure set space into
areas admitting a priori the same behaviour, an area corresponding to the condition of a
rule, and the behaviour associated to this area to the conclusion of the rule. Currently, we
state the hypothesis that the ideal behaviour of the generalisation system is not chaotic,
so that continuous subspaces of the measure set space exist where this ideal behaviour is
constant. The revision problem then consists in assigning the best possible conclusion to
each area of each piece of knowledge.

Our search approach is ﬁnally composed of four steps (Figure 4). The ﬁrst one consists
in building, from the logs (i.e. from the state trees associated with the generalised sample
objects), example sets that represent the ideal behaviour of each piece of knowledge. The
second step consists in partitioning the measured set of each piece of knowledge in areas
that admit a priori a homogenous decision to apply (conclusion of the rule). The third step
consists in searching, by mean of a local search, the best conclusion to assign to each area.
The last step consists in simplifying the rule sets by rule aggregation. These four steps are
detailed below.

3.3.3.1. Constructing the example sets. The ﬁrst step of the search approach consists in
building an example set that characterises the ideal behaviour of each piece of knowledge
from experience.

1982

P. Taillandier et al.

Step 1

Construction of  example sets by
state tree analysis

State1, Act
2
State2, Act
1
......

Step 2

Partitioning of  the measure set
space into areas

Assigning conclusions to areas

Step 3

Step 4

Simplification of  the rule bases by
rule aggregation

0

3

1 M

1

Act

Act
Act

2

1

Act

Act
Act

2

2

M
2
 +
Act
5
3

2
Act

Act

1

1

M
2
 +
Act
5

2
Act

3

Act

2

1

M

2

3

0

0

3

1 M

1

Act

Act

2

1

M

1

M

1

M

2

5

0

Act

Act

2

1

M

1

Initial rules

Analysis
stage

Figure 4. Search approach for rule revision.

The construction of the example sets is achieved by analysing the state trees obtained
during the exploration stage (each state tree resulting from the generalisation of one sam-
ple object). One example set is built per piece of knowledge. An example corresponds to
one state of a state tree. It is composed of n predictors and a label. The predictors are the
measures associated to the piece of knowledge, and the label is the decision assessed as the
good one for this experienced state. A state is described by the measure set linked to the
piece of knowledge. The ‘decision’ describes the ideal behaviour of the piece of knowl-
edge. For example, in the case of the piece of knowledge concerning the action application
domain, the decision can be ‘apply this action’ or ‘do not apply any action’.

The method used for the construction of the example sets is that proposed by Taillandier
(2007). It ﬁrst consists in extracting the best paths from each state tree. A best path is a
sequence of at least two states, which has the root of a tree (or of a sub-tree) for initial
state and the best state (in terms of agent satisfaction) of this tree (or sub-tree) for ﬁnal
state. Then, an example is built from each state of each best path that contains the relevant
information, depending on the piece of knowledge under revision. For example, concerning
the action application knowledge, if a state belongs to a best path and if the application of an
action leads to another state of the same best path, the ideal decision is ‘apply this action’.
Figure 5 gives a simpliﬁed example of the example set built from the generalisation of an
object with two actions A1 and A2.

3.3.3.2. Partitioning the measure set space. The second step of our search approach con-
sists in partitioning the measures set into disjointed areas that admit a homogenous ideal
behaviour of the system (i.e. homogeneous conclusions of the rules), based on an analysis

International Journal of Geographical Information Science

1983

M
M

1(state 1) = 3
2(state 1) = 7

1

Action A1

Action A2

M
M

1(state 2) = 8
2(state 2) = 7

2

5

M
M

1(state 5) = 3
2(state 5) = 7

Action A1

Action A2

M
M

1(state 3) = 8
2(state 3) = 7

3

4

M
M

1(state 4) = 8
2(state 4) = 10

Valid state

Invalid state

Best state

Best path: state 1 → state 2 → state 4

Example set:

{
 (M
 (M
}

1 = 3, M
1 = 8, M

1 = 7, conclusion = Apply Action A1),
1 = 7, conclusion = Apply Action A2),

Figure 5. Example of a built example set.

of the successes and failures encountered when generalising the sample of objects. Each
area corresponds to the condition of a production rule. For example, consider a system that
can propose only an action A that depends on a measure set composed of just one mea-
sure M. One example of partitioning can be decomposing the domain of M (and thus the
measure set space of A) into two areas: (M < 0) and (M ≥ 0).

One constraint of this partitioning is to take into account the initial rules. The initial
rules already form a partitioning of the measure space where each area admits one conclu-
sion. In order to take the initial rules into account, we impose that each area obtained after
this partitioning step be a sub-area of an initial area; that is, that a rule deﬁning a ﬁnal area
be either one of the initial rules or a specialisation of one of the initial rules. The interest
of this constraint is to keep the possibility to obtain rules similar to the initial rules after
the revision process. The partitioning approach that we propose consists in learning a new
partitioning from the example set employing supervised machine learning techniques. This
learned partitioning is independent of the initial rules and is based on the experience (the
example set). The areas obtained by it are thus homogenous according to the experience.
Different algorithms such as C4.5 (Quinlan 1993) or RIPPER (Cohen 1995) can be used
for this supervised learning. We then specialise the partitioning formed by the initial rules
by combining it to this new partitioning (Figure 6).

Once the partitioning has been carried out, the next step of the revision process consists

in assigning the best possible conclusion for each area of each piece of knowledge.

3.3.3.3. Conclusion assignments by local search. The third step of our search approach
consists in assigning a conclusion for each area obtained at the end of the previous step.
We call ‘solution’ a complete assignment of conclusions for each area of the measured set
of the pieces of knowledge considered.

1984

P. Taillandier et al.

Act
2

Act
1

Act

2

M

2

5

0

M
2

3
Act

2

0

Act
1

4

M

1

Learnt rules

M

1

M

2

Initial rules

5
3
Act

1

Act
2
Act
1
Act
1

M

4

0
Partioned initial rules

1

Example set:
1 = 4, M
1 = 5, M
1 = 2, M
1 = 2, M
1 = 1, M
1 = 1, M

2 = 2, Act
1
2 = 2, Act
1
2 = 4, Act
2
2 = 2, Act
2
2 = 5, Act
2
2 = 4, Act
2

M

M
M
M
M
M

Figure 6. Partitioning approach.

We deﬁned our revision problem as an optimisation problem in which we search, for
a given system S, the solution sol among the possible solution set Sol that maximises
the performance of the system (presented in Section 3.3.2). According to the fact that for
each area, we have to choose a conclusion among a set of conclusions Concl, the size of
the solution space (size of Sol) is equal to Conclnumber of areas. Recall that the revision can
concern several pieces of knowledge, and thus several area sets at the same time (e.g. the
constraint priority knowledge). Therefore, the number of areas can be very high.

To help this search, we dispose of an initial solution (the initial rule sets) that is often
good. There are numerous methods to solve a search problem of this kind. Due to the size
of the solution space, it is impossible to use a complete approach. In consequence, we
use an incomplete approach. Indeed, in order to solve this problem, we propose to use a
local search algorithm. The principle of this kind of algorithm is to start with an initial
solution and to attempt to improve it by exploring its neighbourhood. Most of the time,
these algorithms are very effective for this kind of exploration problem. There are numer-
ous local search algorithms such as hill-climbing, tabu search (Glover 1989) or simulated
annealing (Kirkpatrick et al. 1983) that can be used to solve this problem. In the context
of our ofﬂine revision process, the efﬁciency of the search method is not a major issue.
Hence, it is preferable to use methods which avoid getting stuck at a local optimum, like
the tabu search or the simulated annealing rather than a simple hill-climbing. As to the
choice between these two methods, the experiments we carried out showed similar results.
Local search approaches require deﬁning the notion of a neighbourhood of a solution.
For our problem, we deﬁne it as the set of solutions for which only one of the areas will
have its conclusion value changed.

3.3.3.4. Rule set simpliﬁcation. The previous step permits assigning a good conclusion
to each area. The last step of our search approach consists in simplifying the obtained
(revised) rule sets by aggregating the areas. The goal of this step is to improve the
readability of the rule sets as well as their generalisation capacity.

International Journal of Geographical Information Science

1985

M

5

2
b
Act
1
3

Act
1
a

0

3

Act
2

Act
1

Act
1
c

d

M

1

M
2

5

Act
1
3

ab

0

3

Act
2

Act

1

Act
c

1

d

M

1

Rule aggregation

Rule aggregation

M

2

5

Act
1
3

ab

Act

2

Act

1
cd

0

3

M

1

Figure 7. Example of rule set simpliﬁcation.

At each iteration, two areas are aggregated in order to form a bigger area. It can be
noted that the choice of the two areas that are aggregated together at each iteration can
have an impact on the ﬁnal rules. However, all the tests carried out tended to show that
this impact is not signiﬁcant in terms of ﬁnal rule set quality. Figure 7 gives an example of
simpliﬁcation: at a ﬁrst iteration, the area a deﬁned by the rule ‘if M 1 ≤ 3 and M 2 ≤ 3 then
apply action Act1’ is merged with the area b deﬁned by the rule ‘If M 1 ≤ 3 and M 2 ≤ 3
then apply action Act1’. The resulting area ab is deﬁned by the rule ‘if M 1 ≤ 3 then apply
action Act1’.

At a second iteration, the area c deﬁned by the rule ‘if M 1 > 3 and M 2 ≤ 3 then apply
action Act1’ is merged with the area d deﬁned by the rule ‘if M 1 > 3 and M 2 > 3 and M 2
≤ 5 then apply action Act1’. The resulting area cd is deﬁned by the rule ‘if M 1 > 3 and M 2
≤ 5 then apply action Act1’.

Once these four steps of the revision process are carried out, we obtain revised knowl-
edge (in the form of rule sets), ready to be used in place of the initial knowledge in the
generalisation system.

Implementing our knowledge revision approach for the generalisation of

4.
building groups with the AGENT model

The knowledge revision method described in Section 3has been implemented in a research
platform based on Clarity (1 Spatial), resulting in a prototype for knowledge revision
associated to the AGENT generalisation model. In this section, we report on one of the
experiments carried out in order to assess this knowledge revision method. This test case
focuses on the generalisation of urban space.

Generalising the urban space is a complex problem. It requires managing a high density
of data. Using different levels of analysis has proven to be a good solution for dealing with
this complexity. Several works were dealing with the deﬁnition of these levels of analysis
(Ruas 1999, Boffet 2000, Chaudhry and Mackaness 2008, Steiniger et al. 2008).

In this test case, we concentrate on the analysis level of the building groups deﬁned by
Regnauld (1998), Bard (2004) and Gaffuri and Trévisan (2004): a building group is a space
composed of a set of ‘close’ buildings belonging to the same building block (space sur-
rounded by a minimum cycle of roads). The choice of this class of agents and of this target
scale is due to the difﬁculty to deﬁne good knowledge for their generalisation. Actually, the
generalisation of building groups poses efﬁciency and effectiveness problems. The gener-
alisation algorithms used to generalise them are often time consuming. Thus, it is important
ot ﬁnd a good state while exploring few states.

The initial data stem from BD TOPO, the 1 m resolution database of the French
National Mapping Agency (NMA) (reference scale approximately 1:15, 000). The target
scale is 1:50,000.

1986

P. Taillandier et al.

4.1. Settings of our test case

4.1.1. Deﬁned generalisation constraints and available generalisation algorithms
In this section, we present the constraints and the actions used for our experiments. We
deﬁned six constraints for the building group agents. These constraints are the following:

(cid:129) Proximity constraint: this constraint states that the buildings should be neither too
close to each other nor too close to the roads. It is assessed by computing distances
between neighbouring buildings and roads, following Ruas (1998a).

(cid:129) Building satisfaction constraint: this constraint states that the buildings composing
the building group should individually satisfy their internal constraints. It is assessed
by analysing the individual satisfaction of the buildings.

(cid:129) Density constraint: this constraint states that the building density is not too high
in comparison to the initial building density. It is assessed by comparing the
black/white ratios at current state and at initial state.

(cid:129) Spatial distribution constraint: this constraint states that the current building spatial
distribution should be close to the initial building spatial distribution. It is assessed
by checking that no empty spaces appeared where there were initially buildings.
(cid:129) Big buildings preservation constraint: this constraint states that the buildings whose
area is bigger than a threshould should not be removed. It is assessed by comparing
the number of big buildings at current state and at initial state.

(cid:129) Corner buildings preservation constraint: this constraint states that the buildings
located at the corner of roads should not be removed. It is assessed by comparing
the number of corners, where there are buildings, at current state and at initial state.
These last two constraints represent a partial expression of the expectation that the
most important buildings of the group should be preserved.

In order to satisfy its constraints, we authorise the building group agent to apply ﬁve

actions, which are presented in Figure 8. Each action is linked to a constraint.

(1) Building satisfaction constraint:

(cid:129) Building generalisation action: this action triggers the individual generalisation

of the building agents composing the building group.

(2) Proximity constraint:

(cid:129) Building displacement action: this action displaces buildings that have proximity
problems. This action is based on the displacement algorithm proposed by Ruas
(1998a).

(cid:129) Local building removal action: this action removes buildings according to a
local context. It removes in priority the buildings that have the most serious
overlapping problems.

(cid:129) Building removal/displacement action: this action selects the building that has
the most serious proximity problems and removes it. If another building is close
to the removed building, this one is displaced in order to be closer to the removed
building. This action is based on the displacement algorithm proposed by Ruas
(1998a).

(3) Density constraint:

(cid:129) Global building removal action: this action removes buildings according to the
global context. It removes in priority the buildings that have the less space to
move. This action is based on the algorithm proposed by Ruas (1999).

International Journal of Geographical Information Science

1987

Figure 8. Building group actions.

Note that no action is associated to the spatial distribution, big building preserva-
tion and corner buildings preservation constraints. These constraints are only used by the
system to reject states where their violation degree would be too high.

4.1.2.

Initial knowledge sets

For our experiment, we deﬁned three different initial knowledge sets, among which two are
deﬁned by experts.

The experts deﬁned their knowledge sets with the help of tools allowing them to
manually test the actions, display the measures values for a given agent state, generalise
geographical agents with the AGENT system including different pieces of knowledge and
visualise the resulting state trees. In order to tune the control knowledge, they carried out
their experiments with a building group located in the town of Orthez in the south-west of
France. This town is composed of 280 building groups.
The three knowledge sets are described as follows:

(cid:129) Most effective knowledge set: knowledge set derived from the full-exploration knowl-
edge set. For each generalised building group, this knowledge set ﬁnds the best
possible state considering the constraints and available actions proposed by those
constraints. Nevertheless, it requires exploring many states per generalisation and is
thus not efﬁcient at all. This lack of efﬁciency leads to the impossibility of using this
knowledge set for real world application.

(cid:129) Cartographic expert knowledge set: knowledge set deﬁned by a cartography expert
who is not an AGENT model expert. The heuristic used by the expert while deﬁn-
ing this knowledge set was to search in priority to deﬁne an effective knowledge

1988

P. Taillandier et al.

set. Then, the expert tried to improve the efﬁciency of its knowledge set by adding
knowledge related to the pruning of the state trees.

(cid:129) AGENT model expert knowledge set: knowledge set deﬁned by a cartography expert
who is also an AGENT model expert. The heuristic used by the expert while deﬁn-
ing this knowledge set is the same as the one used by the previous expert: the expert
searched in priority to deﬁne an effective knowledge set. Then, the expert tried
to improve the efﬁciency of its knowledge set by adding knowledge related to the
pruning of the state trees.

4.1.3. Revision parameters and test protocol
The implementation of our approach requires to choose three algorithms and to deﬁne a
performance function.

Our general algorithm choice approach was to choose well-established and well-known
algorithms. As a result, we used the EM algorithm (Dempster et al. 1977) for the objects
selection part (cf. Section 3.2.1) to divide the objects into clusters. We used the C4.5 algo-
rithm (Quinlan 1993) to learn rules for our partitioning method (cf. Section 3.3.4), and
the tabu search (Glover 1989) for our conclusion assignment approach (Section 3.3.5).
For the implementation of the EM and C4.5 algorithms, we used the OpenSource learning
framework WEKA (Witten and Frank 1998).

The function Perf (SK, OS) was deﬁned empirically by means of experiments with
different knowledge sets and different building groups (but not the ones used for this test
case, in order to avoid risks of over-ﬁtting – i.e. to prevent the system from learning by
heart). We are considering the situation of a production line, where the most important
goal is obtaining good cartographic results and where it is possible to manually retouch (by
technicians) some generalised building groups.

We used the following Perf (SK, OS) function:

Perf (SK, OS) = 4 × Effectiveness(SK, OS) + Efﬁciency(SK, OS)

5

This function favours the effectiveness of the system over its efﬁciency thanks to factor 4
(deﬁned empirically).

The effectiveness evaluation function used is based on the satisfaction of each

geographic agent (see Section 2.1). It is deﬁned as follows:

Effectiveness(SK, OS) =

(cid:3)

FirstQuartile(SK, OS) + Mean(SK, OS)
20

(cid:4)
2

with

(cid:129) First Quartile (SK, OS): ﬁrst quartile satisfaction value obtained with the system S,
while using the knowledge set K, for the generalisation of all objects of the sample
OS.

(cid:129) Mean (SK, OS): mean satisfaction obtained with the system S, while using the

knowledge set K, for the generalisation of all objects of the sample OS.

This function allows the mean satisfaction of the generalised object to be taken into
account while balancing this result by the ﬁrst quartile satisfaction value. The interest of

International Journal of Geographical Information Science

1989

this weighting comes from the reality that it is preferable for the mapping agencies to work
with objects that are three quarters well-generalised and one quarter poorly generalised
(which can be retouched by technicians) than to use averaged homogeneous results (which
require much more retouching). The factor 1/20 is used to normalise the value of this
function. Importantly, we reiterate here that the satisfaction of a geographic agent is ranged
between 1 and 10. We add a power of 2 in order to accentuate the difference between values.
In terms of satisfaction, a good result for our application scenario (building group which
does not need to be retouched) corresponds to a value higher than 9. Values lower than 8
correspond to a non-acceptable generalisation result.

Concerning the efﬁciency function, we used the following:

Efﬁciency(SK, OS) = NbStates(SK, OS)

NbStates (SK, OS) − 1

(cid:6)

(cid:7)

1
3 ×

−5

(cid:8)

with

(cid:129) NbStates (SK, OS): mean number of states obtained with the system S, while using

the knowledge set K, for the generalisation of all objects of the sample OS.

The choice of this this efﬁciency function, of which the proﬁle is presented in Figure 9,
can be explained by a desire for the effectiveness function to cover a large range of values
(on the interval [0,1]) for values of the mean number of states ranged between 10 and ∞.
For our application scenario, we have empirically deﬁned that a mean number of visited
states of 10 can be considered as a very good result in terms of efﬁciency. A number of

Figure 9. Proﬁle of the efﬁciency function: f (x) = x

√

1
3 × (−5

x − 1).

1990

P. Taillandier et al.

states ranging between 10 and 15 can be considered a good result in terms of efﬁciency; a
number of states ranges between 15 and 25, an average result and a number of states higher
than 30, a bad result.

Concerning the test protocol, we used 50 building groups to revise the three initial
knowledge sets. These 50 building groups were selected by our object sample selection
approach in the same area as that used by the experts to tune their knowledge sets (the town
of Orthez). We then assessed the initial sets and their revised versions on the 200 building
groups contained in another town in the south-west of France, Salies-de-Béarn. It means
that for each knowledge set, we run the generalisation system on these 200 building groups
twice: ﬁrst with the initial version of the knowledge set and then with the revised version
of the knowledge set. We then compared the performance obtained with the generalisation
system while running with the initial and revised versions of the same knowledge set,
by analysing the evolution of three indicators. The ﬁrst indicator reﬂects the compromise
effectiveness/efﬁciency of a knowledge set: it is the perfomance function deﬁned above.
The second indicator reﬂects the effectiveness of a knowledge set: it is the distribution of
the ﬁnal satisfactions (reached generalisation quality) within our sample of 200 building
groups. The third indicator reﬂects the efﬁciency of a knowledge set: it is the distribution of
the number of states visited to reach the best solution during the trial/error generalisation
process, within our sample of 200 building groups.

4.2. Results
One of the major differences between the initial knowledge sets and the revised ones con-
cerns the use of the Building removal/displacement action. In the three initial knowledge
sets, this action was proposed for all states whereas it was never used by the revised ones.
This is due to the fact that this action is theoretically expected to be very useful (therefore
the experts advise to use it), but the implementation we used is bugged. Concerning the
knowledge set deﬁned by the cartographic expert, the application domain of the Building
generalisation action was extended after revision.

Figure 10 shows the results obtained with the initial and revised knowledge sets in terms
of effectiveness and efﬁciency. One point on the point cloud represents a generalised build-
ing group. The y-coordinate corresponds to the generalised building group satisfaction (the
system effectiveness) and the x-coordinate to the number of states visited to generalise the
building group (the system efﬁciency). Ideally, all points (i.e. generalised building groups)
should be located in the top left corner. Figure 11 shows diagrams representing the dis-
tribution of the ﬁnal satisfactions. In these diagrams, the satisfaction of all generalised
building groups is represented, ordered by satisfaction value. Table 1 gives the values of
the Perf (SK, OS) function for all knowledge sets. Finally, Figure 12 gives an example of
cartographic results.

Firstly, we can notice the difﬁculties of deﬁning a knowledge set that will ensure both
the effectiveness and the efﬁciency of the generalisation system. Indeed, even with a good
command of the AGENT model, it is not easy to deﬁne a knowledge set that is both effec-
tive and efﬁcient for all geographic objects. This is shown by the presence of a high number
of light grey squares on the bottom right parts of the diagram on Figure 10c (satisfaction
lower than 8 and number of visited states higher than 30). The AGENT model expert
deﬁned a good knowledge set (better than the one deﬁned by the cartographic expert in
terms of effectiveness) but not a perfect one. Whereas this knowledge set permits the
acquisition of good cartographic results (most squares and most agent satisfaction above
the threshold of 9 on Figures 10c and 11, few errors in Figure 12c), it is not efﬁcient (many

International Journal of Geographical Information Science

1991

Figure 10. System effectiveness and efﬁciency: comparison results between the initial knowledge
sets and the revised ones. (a) Most effective knowledge set; (b) Knowledge set deﬁned by the
cartographic expert; and (c) Knowledge set deﬁne by the AGENT model expert.

1992

P. Taillandier et al.

Figure 11. Repartition of the generalised building group satisfaction.

Table 1. System performance: comparison results between the initial knowledge sets and
the revised ones. The bold indicates the best performance.

Knowledge set

Initial or revised

Perf (SK, OS)

Most effective knowledge set

Knowledge deﬁned by the cartographic expert

Knowledge deﬁned by the AGENT model expert

Initial
Revised
Initial
Revised
Initial
Revised

0.761
0.799
0.784
0.801
0.799
0.807

International Journal of Geographical Information Science

1993

Figure 12. Example of cartographic results. (a) Most effective knowledge set; (b) Knowledge set
deﬁned by the cartographic expert; and (c) Knowledge set deﬁned by the AGENT model expert.

light grey squares above the threshold of 30 on Figure 10c). The difference of mean sat-
isfaction values between the two knowledge sets can seem low (lower than 0.2), but is
nevertheless signiﬁcant considering the satisfaction function used (that could be greatly
improved). Indeed, tests carried out showed that such a mean satisfaction value difference
represents a real difference of the cartographic quality.

The cartographic expert whose obtained good efﬁciency came up short in terms of
effectiveness (light grey diamonds to low in Figure 10b, many agents with satisfaction
under the threshold of 9 on Figure 11). Actually, the corresponding cartographic results
(Figure 12b) suffer from several problems: several buildings were not generalised while
density and proximity problems are evident. This result, which is rather surprising, may
be due to two reasons. The ﬁrst one is that the cartographic expert did not manage to get
the best of the generalisation system in terms of effectiveness as did the AGENT expert. A
second possible explanation is that the cartographic expert tested his knowledge set only
on a small sample of objects. Deﬁning good knowledge (in terms of effectiveness and
efﬁciency) to generalise 10 objects is easy; deﬁning knowledge that is as good for a whole

1994

P. Taillandier et al.

data set is much more complex. Thus, the cartographic expert may have concentrated his
effort only on some particular cases and this did not prove suitable for the general. The
AGENT expert has maybe tested more intensively his knowledge set. It could be interesting
to carry out more experiments with other experts in order to check if this pattern is a
common one.

Concerning the values obtained for the performance function for the two expert knowl-
edge sets, it conﬁrms that the knowledge set deﬁned by the AGENT expert is better than
the one deﬁned by the cartographic expert (Table 1).

To conclude on the subject of knowledge sets deﬁned by the human experts, this test
case shows that the deﬁnition of knowledge sets which are both efﬁcient and effective is a
complex task for human experts. Actually, the two experts succeeded in deﬁning an initial
knowledge set that permits the acquisition of good cartographic results, but they did not
succeed in adding pieces of knowledge that improve its efﬁciency without deteriorating its
effectiveness. Last, we can notice that the experts are inﬂuenced by the knowledge they
have of the theoretical behaviour of a generalisation action, whereas our model bases on
actual results obtained with this action. Therefore, an expert can advise to make intensive
use of an action that theoretically provides good results but of which the implementation is
bugged so that in many cases its actual results are not satisfactory – which leads to useless
tries of this action and decreases the efﬁciency of the system. In such cases, our system
detects that the results are not satisfactory and does not advise to use it. Indeed, in the
case of the Building removal/displacement action mentioned above, comparing the expert
knowledge with the revised knowledge leads us to identify the need to re-implement this
action.

As to the results obtained with the most effective knowledge set (Figures 10a, 11 and
12a), we remark that the results are very good in terms of effectiveness but quite poor in
terms of efﬁciency. Actually, the mean number of visited states is close to 150 per gener-
alisation. This number is far too high to consider using this knowledge set for a real world
application. This knowledge set is the one that has the lowest performance value (Table 1).
With regard to the result obtained after revision, we see that in all cases they are good –
both in terms of effectiveness and efﬁciency. As shown in Table 1, these three knowledge
sets are better than their respective initial knowledge sets. Essentially, for the most effec-
tive knowledge set, if the results are slightly less good in terms of effectiveness, they are
far better in terms of efﬁciency. Remember, for each generalised building group, the most
effective knowledge set ensures ﬁnding the best possible state considering the constraints
and the available actions proposed. Therefore, after revision, it was not possible to obtain
better results in terms of effectiveness. Recall also that before the revision, the most effec-
tive knowledge set was not usable for real applications due to its efﬁciency problems. The
revision allowed dividing the mean number of visited states per generalisation by a fac-
tor of 10 and thus rendering it usable. For the knowledge set deﬁned by the cartographic
expert, the results are better in terms of both efﬁciency and effectiveness (Figures 10b
and 11). The effectiveness is the most improved, notably, after revision; no more build-
ings remain ungeneralised (Figure 12b). For the knowledge set deﬁned by the AGENT
expert, we observe that the quality in terms of effectiveness is very close for both initial and
revised knowledge sets. Nevertheless, the revision process allowed for great improvement
in the system’s efﬁciency: actually, the mean number of visited states per generalisation
was divided by a factor 2 (Figure 10c).

Comparing the results attained with the three revised knowledge sets, we notice that
they all achieved results that were very close in terms of efﬁciency. Their mean number
of visited states was lower than 13, and thus lower than the threshold value of 15 – which
marks the limit between a good result and an average result in terms of efﬁciency. The

International Journal of Geographical Information Science

1995

best cartographic results, as well as the highest performance value, were achieved while
using the revised version of the knowledge set deﬁned by the AGENT expert, which was
the best of the three initial knowledge sets. This experiment shows that if it is possible to
obtain good knowledge sets when revising bad knowledge sets, it is possible to get even
better results when revising good knowledge sets. Indeed, this experiment seems to prove
that our approach takes the speciﬁcities of the initial knowledge into account. Actually, the
revision from the knowledge set deﬁned by the AGENT expert (which is the best initial
knowledge set of the three) attained the best knowledge set after revision. An explanation
is that the revision process preserved some pertinent elements deﬁned by the AGENT
expert that could not be directly acquired by the experience (i.e. from the logs generated
during the exploration stage). In other words, it appears particularly interesting to revise
existing knowledge rather than just trying to acquire new knowledge from scratch. This
result conﬁrms our initial hypothesis (cf. Section 2.3), even if it would be worth to conﬁrm
it by means of more intensive tests.

4.3. Discussion: comparison with the approach proposed by Burghardt and Neun
As introduced in Section 2.3, the main difference between our approach and the one pro-
posed by Burghardt and Neun (2006) concerns the use of explicit control knowledge.
Indeed, in our work, we are interested in the revision of rules that can be easily inter-
preted by generalisation expert. On the contrary, the approach proposed by Burghardt and
Neun (2006) works with a case base that does not provide an explicit representation of the
knowledge.

The main advantage of the Burghardt and Neun (2006) approach is its capacity
to revise continuously the knowledge. Such online revision is not possible with our
approach. Indeed, our approach requires analysing complete state trees (generalised with
full-exploration knowledge set). It is not possible to use our approach with partial state trees
as the ones obtained during real utilisations of the generalisation system. Moreover, to give
relevant results, our approach requires analysing a set of generalised objects at the same
time and not only one object. If only one object is considered during the revision, there is
a risk to deteriorate the quality of the knowledge if the knowledge required to generalise
this one is very different than the one used to generalise the majority of the objects.

Another difference lies in the fact that their approach allows to learn knowledge from
scratch whereas our approach requires to have a set of initial knowledge. However, as
showed in the experiment, the use of good initial knowledge can allow to obtain even
better revised knowledge.

To conclude, we can say that these two approaches are not linked to the same initial
conditions: the use of the approach proposed by Burghardt and Neun (2006) is particularly
interesting when a continuous improvement of the knowledge is needed. On the contrary,
when the key issue concerns the analysis of knowledge content and when it is possible to
stop the generalisation process to revise the knowledge, our approach becomes particularly
well ﬁtted. An interesting study would consist in comparing the effectiveness of these two
approaches when using the same set of actions, constraints and measures.

5. Conclusion
In this article, we highlighted the advantages of integrating an automatic module of
knowledge revision within a generalisation system based on an informed tree search
strategy.

1996

P. Taillandier et al.

We proposed an approach for revising the control knowledge based on introspection
and logs analysis. We developed a method allowing knowledge revision expressed in the
form of production rules. We assessed this method by implementing it within the AGENT
generalisation model and by carrying out an experiment for the generalisation of building
groups at the 1:50,000 scale. This experiment showed that our revision approach could
allow the system to improve the initial control knowledge in terms of efﬁciency or/and
effectiveness. It also conﬁrms our initial hypothesis that it is interesting to take the initial
knowledge into account and to revise it, rather than just acquiring new knowledge.

Our approach can be applied to other kinds of geographic objects and for other scales.
Carrying out experiments for other geographic objects would allow us to test our approach
in a more intensive way and to study its possible limits. In this context, implementing
our approach for the problem of road generalisation could be particularly interesting.
Undeniably, deﬁning control knowledge for road generalisation is complex. Moreover, their
generalisation brings into play a new type of control knowledge: the activation order of the
subagents. In fact, the general process of road generalisation using the AGENT model is
similar to the process carried out for the building generalisation or for the building group
generalisation. A road segment is modelled as a geographic agent that has constraints and
that can apply generalisation action upon itself. In order to ﬁnd the best possible state, the
road agent uses, as the other types of geographic agents, an informed tree search strategy.
However, a road agent has the ability to apply a splitting action, that is, to divide itself into
several road subagents that are then activated (Duchêne et al. 2001). A road subagent can
also be divided into several subagents. Most of the time, the activation order of the sub-
agents has a big impact on the cartographic results. Thus, we propose to use our approach
to revise this new type of knowledge by modelling the subagent activation order problem
as a tree search problem, in which each branch of the tree corresponds to the activation of
a subagent.

In the same way, our approach can be applied to any system based on an informed tree
search strategy. All that it would require is that its implementation be adapted to knowledge
description formalisms different from the production rules we have been using so far.

To be able to select a representative sample of geographic objects is a key point of our
revision approach. In this context, we proposed a sampling method based on clustering
techniques. The choice of the clustering algorithm as well as its parameterisation can have
a deep impact on the selected sample quality. As a future work, it is important to study in
more detail this impact.

Another key point of our approach is the performance function Perf (SK, OS) used to
evaluate the performance of the system. Designing such a function in order to characterise
the needs of the user can be tricky, especially when these needs are not well formalised
(which is often the case). Thus, one of our perspectives consists in developing methods to
assist users in designing this function themselves. A ﬁrst approach that could be used to
face this problem could consist in directly using machine learning techniques. Indeed, it
is possible to use an approach similar to the one proposed by Ruas and Holzapfel (2003)
for the building alignment characterisation. Thus, a sample of results would be proposed
to an expert. This one would give an effectiveness mark, an efﬁciency mark and a global
performance mark to each of the results. These marks would then be used to learn an
effectiveness function, an efﬁciency function and a performance function depending on
the two previous marks. A second approach, more complex, could consist in designing the
performance function using active learning. Thus, it could be interesting to use the works
of Hubert and Ruas (2003) and Christophe (2008) as a base. The system would present
several samples of results (generalised with different knowledge sets) to the expert. This

International Journal of Geographical Information Science

1997

system could deﬁne which one contains the best results and add commentaries about them
through a dedicated interface. The system would then use these commentaries to reﬁne the
effectiveness, efﬁciency and performance functions and to choose new result samples to
present to the expert. In that case the learning would be the result of a form of participatory
design emerging from a dialogue between the expert and the system.

Acknowledgement
The authors thank Julien Gaffuri and Laurence Jolivet for their participation in the
experiments.

References
Bard, S., 2004. Méthode d’évaluation de la qualité de données géographiques généralisées.
Application aux données urbaines. Thesis (PhD). Université Paris VI, Laboratoire COGIT.
Barrault, M., et al., 2001. Integrating multi-agent, object-oriented, and algorithmic techniques for
improved automated map generalization. In: 20th international conference of cartography, 6–10
August 2001, Beijing, China. Vol. 3, Beijing, China 2110–2116.

Beard, K., 1991. Constraints on rule formation. In: B. Buttenﬁeld and R. McMaster, eds. Map gen-
eralisation: making rules for knowledge representation. Harlow, Essex UK: Longman Scientiﬁc
and Technical, 121–135.

Boffet, A., 2000. Creating urban information for cartographic generalization. In: International
symposium on spatial data handling (SDH) 10–12 August 2000, Beijing, China, 3b4–3b16.
Brassel, K. and Weibel, R., 1988. A review and conceptual framework of automated map generalisa-

tion. International Journal of Geographical Information Systems, 2 (3), 229–244.

Burghardt, D. and Neun, M., 2006. Automated sequencing of generalisation services based on col-
laborative ﬁltering. In: 4th international conference GIScience, 20–23 September 2006, Munster,
Germany.

Chaudhry, O.Z. and Mackaness, W., 2008. Automatic identiﬁcation of urban settlement boundaries
for multiple representation databases. Computer Environment and Urban Systems, 32, 95–109.
Christophe, S., 2008. Creative cartography based on dialogue. In: In proceedings of AutoCarto, 8–10

September 2008, Shepherdstown, USA.

Cohen, W., 1995. Fast effective rule induction. In: International conference on machine learning,

9–12 July 1995. Tahoe City, CA: Morgan Kaufmann, 115–123.

Dempster, A.P., Laird, N.M., and Rubin, D.B., 1977. Maximum likelihood from incomplete data via

the em algorithm (with discussion). Journal of the Royal Statistical Society, 39, 1–38.

Duchêne, C., Barrault, M., and Haire, K., 2001. Road network generalization: A multi AGENT sys-
tem approach. In: Proceedings of the 20th international cartographic conference, 6–10 August
2001, Beijing, China.

Duchêne, C., Dadou, D., and Ruas, A., 2005. Helping the capture of expert knowledge to support
generalisation. In: ICA Workshop on generalization and multiple representation, 7–8 July 2005,
La Coruña, Spain.

Feigenbaum, E., 1977. The art of artiﬁcial intelligence 1: Themes and case studies of knowledge
engineering. Technical report. Department of Computer Science stanford University, Stanford,
CA.

Gaffuri, J. and Trévisan, J., 2004. Role of urban patterns for building generalisation: an application
of AGENT. In: Workshop on generalisation and multiple representation, 20–21 August 2004,
Leicester, UK.

Glover, F., 1989. Tabu search. Journal on Computing, 1, 190–206.
Hojholt, P., 2000. Solving space conﬂicts in map generalisation: using a ﬁnite element method.

Cartography and Geographic Information Sciences, 27 (1), 65–74.

Holland, J., 1975. Adaptation in natural and artiﬁcial systems. Amm Arbor, MI: University of

Michigan Press.

Hubert, F. and Ruas, A., 2003. A method based on samples to capture user needs for generalisa-
tion. In: Fifth workshop on progress in automated map generalisation, 28–30 April 2003. Paris,
France.

1998

P. Taillandier et al.

Kassab, R. and Lamirel, J., 2008. A feature based cluster validation for high dimensional data. In:
artiﬁcial intelligence and applications, 13–16 February 2006, Innsbruck, Austria. ACTA Press,
232–239.

Kilpelinen, T., 2000. Knowledge acquisition for generalization rules. Cartography and Geographic

Kirkpatrick, S., Gellatt, Jr. C.D., and Vecchi M.P., 1983. Optimization by simulated annealing.

Information Science, 27 (1), 41–50.

Science, 220, 671–680.

Lamy, S., et al., 1999. AGENT project: automated generalisation new technology. In: 5th EC-GIS

Workshop, 28–30 June 1999, Stresa, Italy.

McMaster, R.B. and Shea, K.S., 1992. Generalization in digital cartography. USA: Association of

American Geographers.

Mustière, S., 2005. Cartographic generalization of roads in a local and adaptative approach: a knowl-
edge acquisition problem. International Journal of Geographical Information Science, 19 (8–9),
937–955.

Neun, M., Burghardt, D., and Weibel, R., 2009. Automated processing for map generalization using

web services. GeoInformation, 13 (4), 425–452.

Newell, A. and Simon, H., 1956. The logic theory machine. IRE Transactions on Information Theory,

Quinlan, J., 1993. C4. 5: programs for machine learning. San Francisco, CA: Morgan Kaufmann

2 (3), 61–79.

Publishers Inc.

Regnauld, N., 1998. Généralisation du bti: structure spatiale de type graphe et représentation

cartographique. Thesis (PhD). Université de Provence-Aix-Marseille I.

Regnauld, N., 2001. Constraint based mechanism to achieve automatic generalisation using an agent

modelling. In: 9th GISRUK conference, 18–20 April 2001, Glamorgan, Wales, 329–332.

Rieger, M.K. and Coulson, M.R., 1993. Consensus or confusion: cartographers’ knowledge of

generalisation. Cartographica, 30 (2&3), 69–80.

Ruas, A., 1998a. A method for building displacement in automated map generalisation. International

Journal of Geographical Information Sciences, 12 (8), 789–803.

Ruas, A., 1998b. OO-Constraint modelling to automate urban generalisation process.

In:
Proceedings of the 8th international symposium on spatial data handling, 11–15 July 1998,
Vancouver, BC, Canada, 225–235.

Ruas, A., 1999. Modèle de généralisation de données géographiques a base de contraintes et

d’autonomie. Thesis (PhD). Université de Marne la Vallée, Laboratoire COGIT.

Ruas, A., 2000. The roles of meso objects for generalisation. 9th international symposium on spatial

data handling, 10–12 August 2000, Beijing, China, 3b, 50–63.

Ruas, A. and Duchêne, C., 2007. A prototype generalisation system based on the multiagent sys-
tem paradigm. In: W. Mackaness, A. Ruas and L. Sarjakoski, eds. generalisation of geographic
information: cartographic modelling and applications. Elsevier, chap. 14, 269–284.

Ruas, A., et al., 2006. Methods for improving and updating the knowledge of a generalization system.

In: Autocarto, June 2006, Vancouver, WA.

Ruas, A. and Holzapfel, F., 2003. Automatic characterisation of building alignments by means of
expert knowledge. In: International cartographic conference, Durban, Afrique du Sud, 1604–
1615.

Sester, M., 2000. Generalization based on least square adjustment. International Archives of

Photogrammetry and Remote Sensing, 23, (part B4), 931–938.

Steiniger, S., et al., 2008. An approach for the classiﬁcation of urban building structures based on

discriminant analysis techniques. Transactions in GIS, 12 (1), 31–59.

Taillandier, P., 2007. Automatic knowledge revision of a generalisation system. In: Workshop on

generalisation and multiple representation, 2–3 August 2007. Moscow, Russia.

Taillandier, P., 2008. Knowledge diagnosis in systems based on an informed tree search strategy:
application to cartographic generalisation. In: CSTST student workshop, 27–31 October 2008,
Cery-Pointoise, Paris, France, 589–594.

Taillandier, P., Duchêne, C., and Drogoul, A., 2009. Using belief theory to diagnose control knowl-
edge quality. Application to cartographic generalisation. In: ´Risk, Ínnovation and vision for the
future, 13–17 July 2009, Da Nang City, Vietnam, 49–56.

Ware, J.M. and Jones, C.B., 1998. Conﬂict reduction in map using iterative improvement.

GeoInformatica, 2 (4), 383–407.

International Journal of Geographical Information Science

1999

Ware, J.M., Jones, C.B., and Thomas, N., 2003. Automated map generalization with multiple
operators: a simulated annealing approach. International Journal of Geographical Information
Sciences, 17 (8), 743–769.

Weibel, R., Keller, S., and Reichenbacher, T., 1995. Overcoming the knowledge acquisition bottle-
neck in map generalization: the role of interactive systems and computational intelligence. In:
2nd COSIT conference, 14–18 September 1995, Ellicottville, USA, 139–156.

Weiss, G., 1999. Multiagent systems. A modern approach to distributed artiﬁcial intelligence.

Cambridge, MA: The MIT Press.

Witten, I. and Frank, E., 1998. Data mining: practical machine learning tools and techniques. San

Francisco, CA: Morgan Kaufmann Publishers Inc.

Xu, L., Krzyzak, A., and Oja, E., 1993. Competitive learning for clustering analysis, RBF net and

curve detection. IEEE Transactions Natural Networks, 4, 636–649.

Copyright of International Journal of Geographical Information Science is the property of Taylor & Francis Ltd

and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright

holder's express written permission. However, users may print, download, or email articles for individual use.

