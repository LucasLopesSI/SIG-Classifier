International Journal of Geographical Information Science
Vol. 19, No. 3, March 2005, 267–292

Research Article

Sparse Grids: a new predictive modelling method for the analysis of
geographic data

S. W. LAFFAN*{{, O. M. NIELSEN{, H. SILCOCK{ and M. HEGLAND{
{Centre for Remote Sensing and GIS, School of Biological, Earth and Environmental
Sciences, University of New South Wales, Sydney, Australia, 2052
{Mathematical Sciences Institute, Australian National University, Canberra, Australia,
0200

(Received 11 November 2003; in final form 13 May 2004 )

We introduce in this paper a new predictive modelling method to analyse
geographic data known as sparse grids. The sparse grids method has been
developed for data-mining applications. It is a machine-learning approach to
data analysis and has great applicability to the analysis and understanding of
geographic data and processes. Sparse grids are a subset of grid-based predictive
modelling approaches. The advantages they have over other grid-based methods
are that they use fewer parameters and are less susceptible to the curse of
dimensionality. These mean that they can be applied to many geographic
problems and are readily adapted to the analysis of geographically local samples.
We demonstrate the utility of the sparse grids system using a large and spatially
extensive data set of regolith samples from Weipa, Australia. We apply both
global and local analyses to find relationships between the regolith data and a set
of geomorphometric, hydrologic and spectral variables. The results of the global
analyses are much better than those generated using an artificial neural network,
and the local analysis results are better than those generated using moving
window regression for the same analysis window size. The sparse grids system
provides a potentially powerful tool for the analysis and understanding of
geographic processes and relationships.

Keywords: Spatial analysis; Geographic data; Predictive modelling; Sparse
Grids; bauxite

1.

Introduction

We introduce in this paper a new predictive modelling method to analyse geographic
data known as sparse grids. The sparse grids method has been developed for data-
mining applications and has great applicability to the analysis and understanding of
geographic data and processes.

Sparse grids operate in attribute space, using a series of additive functions to
represent relationships between a response variable and a set of predictor variables.
In this sense, they perform the same role as many other analytical methods. The
advantages of sparse grids are that they use fewer parameters, and thus degrees of
freedom, than other grid-based methods and are less susceptible to the curse of

*Corresponding author. Email: shawn.laffan@unsw.edu.au

International Journal of Geographical Information Science
ISSN 1365-8816 print/ISSN 1362-3087 online # 2005 Taylor & Francis Ltd
http://www.tandf.co.uk/journals
DOI: 10.1080/13658810512331319118

268

S. Laffan et al.

dimensionality. These are both important considerations when analysing geographic
data.

The paper is structured into four main sections. We first review the different
approaches used to analyse geographic data. This is followed by a description of the
sparse grids analysis system in the context of predictive modelling,
including
adapting the method to be spatially explicit using geographically local weights. We
then demonstrate the utility of the approach using a spatially extensive data set of
regolith samples. We conclude with a consideration of the further potential of sparse
grids for geographic analysis.

2. Analysing geographic data

There are many applications of numerical analysis to geographic data. These are
normally used to find correlations or associations between some geographically
distributed response variable and a set of related predictor variables. The models
generated by these analyses are then used for classification, for predictive mapping,
or to achieve some understanding of the relationships among the system of
variables. In data mining, the discovery of such functions is referred to as predictive
modelling and includes both classification and regression.

Predictive modelling approaches are able to characterize a large class of
behaviours and involve training or fitting a model to a data set. For example, one
may wish to predict the vegetation cover of a particular region based on spatially
distributed measurements of spectral response, elevation, slope, and lithology. Non-
geographic examples include predicting the likelihood of a car insurance customer
making a claim, a business customer purchasing a product, or a resident committing
taxation fraud.

Different types of models are obtained from different functional classes. Classical
least-squares methods use linear and nonlinear functions with relatively few
parameters but make key assumptions about the distribution of the data. Modern
nonparametric methods are characterized by large numbers of parameters and can
flexibly approximate general function sets. Example predictive modelling systems
include regressions and correlations (Moore et al. 1995, Crisp et al. 2001), expert
systems (Cook et al. 1996), Artificial Neural Networks (ANNs) (Paola and
Schowengerdt 1995, Lees 1996), classification and regression trees (CART)
(Breiman et al. 1984, Lees and Ritman 1991), Bayesian networks (Kiiveri 2002),
Generalized Linear Models (GLMs) (Pereira and Itami 1991, Zimmerman and
Kienast 1999), Generalized Additive Models (GAMs) (Zaniewski et al. 2002),
Multivariate Adaptive Regression Splines (MARS) (Friedman 1991), ANOVA
splines (Luo et al. 1998), and Support Vector Machines (Gilardi and Bengio 2000).
Reviews of some of these approaches and their applications are given in Franklin
(1995), Gahegan (2000) and Guisan and Zimmerman (2000), and the mathematical
principles are described in Hastie et al. (2001).

One key aspect of all of these predictive models is that they attempt to find, or
enforce, order on a system represented by a set of data axes, or data spaces (Aspinall
and Lees 1994). In this sense, they are no different from when they are applied to
problems from other fields. However, there is one factor that all of the data used in
geographic modelling have in common, and that is their co-occurrence in geographic
space. All of the system drivers and response variables have an expression in, and
these predictive models should be
interact
constructed so they are spatially explicit, in recognition of Tobler’s First Law of

in, geographic space. Therefore,

Sparse grids

269

Geography—‘that everything is related to everything else; but that near things are
more related than those far apart’ (Tobler 1970). Doing this should improve model
performance. However, many of the modelling systems used for geographic analysis
do not directly incorporate this knowledge, and so they are spatially implicit.
Results are mapped back into geographic space to create a surface of predictions,
but knowledge of geographic neighbours is not incorporated into the analysis
(Mackey and Laffan 2002).

We now describe some of the considerations important to predictive modelling

with geographic data, beginning with geographically global and local models.

2.1 Geographically global and local models

One means of conceptualizing predictive models applied to geographic data
is to consider them as geographically global or geographically local. In the
geographically global case, the data are analysed under the assumption that
processes or relationships apply equally across the study area. It is possible to make
these global models spatially explicit by including location as an additional model
variable, but this does not necessarily improve model accuracy and is invalid where
the density of sample locations is too low to represent the spatial variation of the
phenomena studied.

Geographically global approaches make a number of assumptions, including
equilibrium between the driving processes and the subject of interest across the study
area. This is an expression of spatial non-stationarity and can result in decreased
model accuracies caused by the complexity of the geographically varying relation-
ships. It is possible to use an analysis method that can incorporate the many
different states of the system being analysed, although one should expect that this
will result in an extremely complex and difficult to interpret model that may still
have a low accuracy (Laffan and Lees 2004). This is a major limitation of
geographically global analysis methods.

Geographically local methods weight the contribution of each data-set location in
the analysis using their proximity in geographic space, in recognition of Tobler’s
First Law. They commonly use the same analysis methods as geographically global
approaches (Getis and Ord 1992, Anselin 1995, Ord and Getis 1995, Fotheringham
et al. 2002). The weighting systems are often implemented so that the contribution of
a sample location decreases smoothly with distance and can use sample windows of
any shape (Laffan 2002). These local models are repeatedly applied across the study
area using a moving window approach, resulting in a geographic surface of models.
A consequence of this approach is that the modelling system for each location is
much simpler than in the global case because the effects of spatial non-stationarity
are reduced, and possibly even eliminated. The main limitation of this approach is
the need for a high density of observations from which to calibrate the local
models.

2.2 Other considerations

There are many other important considerations for any of the predictive modelling
approaches applied to geographic data, regardless of whether they are geographi-
cally local or global. We consider four here: the effect of geographic correlations, the
complexity of parameterization, the comprehension of model results, and the
dimensionality of the data.

270

S. Laffan et al.

A consequence of Tobler’s First Law is that geographic data are highly correlated,
which causes problems with statistical models that assume that the data errors are
significance testing, not
uncorrelated (Gould 1970). This problem affects
parameterization, and progress has been made to deal with this issue since 1970
(Brunsdon 2001). An alternative approach is to use machine learning algorithms,
which do not make such assumptions about the errors (Gahegan 2003), and then use
error assessments instead of significance tests to assess model performance.

The utility of a model

is often judged by the difficulty of setting up, or
parameterizing, the model. Theoretically this should only affect the implementation
of a model, as the primary goal is to achieve the best result, but in reality it does
limit the uptake of models beyond the research community. An additional, and
possibly more important, problem of model parameterization is its effect on
geographically local
implementations. Manually parameterizing a feed forward
ANN for 200 000 different local samples is clearly an intractable task, unless one is
willing to assume some common settings are robust enough to apply across the
entire study area (which leads back to the problem of applying global models
discussed above). Some efforts have been made towards automatically parameteriz-
ing models (Gahegan et al. 1999), but each class of model has specific requirements,
and some require visual interpretation (e.g. variograms and generalized additive
models).

Understanding how model results are derived is the most important step in the
analysis process when the aim is to understand the relationships in a system. This is
conceptually simple in the case of rule-based systems like Decision Trees and Expert
Systems, as the set of rules may be readily interpreted (although a large rule set will
present challenges). However, systems that use continuous weighting functions of
the input variables are more difficult to interpret where there are many parameters.
For example, ANNs are often described as black boxes (Gahegan 2003), as the
combination of weights is very complex. An approach to understanding these
systems is to use visualization techniques. The geographic dimension of the data can
be used to good effect by presenting the sub-components of the system as a set of
geographic maps. This is equally applicable to rule-based systems as to those using
continuous weighting systems and has been demonstrated for a feed-forward ANN
by Laffan (1998), and extended to time-series analyses by Wilby et al. (2003). Such a
visualization approach may not enable a complete understanding of the system, but
it can be used to make the models less opaque.

Finally, geographic data sets tend to be of a high dimensionality. This is because
there are a myriad of different possible cause-and-effect processes acting on any
location in geographic space, and there are numerous data layers that can be used to
represent this (e.g. geomorphometric indices derived from DEMs and hyperspectral
remote-sensing data). To be truly effective, numerical analysis systems need to be
able to cope with this effect either by including all of the data or by reducing the
dimensionality of the data by using an appropriate subset of the data dimensions.
The field of Data Mining provides an approach to dealing with this issue.

3. Sparse grids

Sparse grids have been developed to approximate general smooth functions of many
variables, providing a method for reducing dimensionality problems where
approximations of high dimensional functions are sought. The functions are

Sparse grids

271

represented with a manageable number of parameters, and the determination of
function values from the parameters is computationally feasible.

The sparse grids approach was first described by Smolyak (1963) and adapted for
partial differential equations by Zenger (1991). Subsequently, Griebel et al. (1992)
developed an algorithm known as the combination technique, prescribing how the
collection of simple grids can be combined to approximate high dimensional
functions. More recently, Garcke et al. (2001) and Garcke and Griebel (2002)
demonstrated the feasibility of sparse grids in data mining by using the combination
technique in predictive modelling.

An introduction to the theory of sparse grids is given by Zenger (1991), and
research software implementing sparse grids for predictive modelling has been
developed by the authors. It is used for this study and the source code is freely
available at http://datamining.anu.edu.au/software.

In terms of models, the sparse grids are additive, containing components which
correspond to trends, curvatures and fluctuations as a function of single variables,
and interactions where the trends, curvature and fluctuations themselves vary, and
these variations have trends, curvatures and fluctuations. The additive nature of the
sparse grids turns out to be computationally advantageous as it leads to linear
systems of equations for the parameters. These additive models generalize linear
models commonly used in statistics, for example Multivariate Adaptive Regression
Splines (MARS) (Friedman 1991) and the Additive Models of Hastie and Tibshirani
(1986, 1990).

We now describe the sparse grid method. First, we review regular grid function
spaces, then we introduce sparse grid functions as sums of regular grids, and in
a third section, we discuss fitting sparse grid functions to data. This is followed by a
discussion of the interpretation of sparse grids and their extension to use a
geographically local weighting system.

3.1 Functions on regular grids

In this section,
functions defined on regular grids to model smooth multi-
dimensional real functions are introduced. We will first review the case of one
dimension and then consider higher-dimensional functions.

In the case of one variable, we consider equidistant grids with nk grid points where
n051 and nk51+2k21 for k51, 2, … Thus, the sequence of grid sizes is nk51, 2, 3, 5,
9, 17, … We will consider functions which are defined by their values on the grid
points and are interpolated linearly in between (figure 1). We denote the set of
piecewise linear functions defined on a regular grid with nk grid points by V(k).

The sets (or spaces) V(k) form an ascending sequence V(0),V(1),V(2),… where
V(0) is the set of constant functions with only one grid point at the left boundary of
the interval, V(1) is the set of linear functions with two grid points (the interval
boundaries), V(2) is the the set of functions with three grid points (the boundaries
plus a midpoint), and so on for an increasing sequence.

These spaces allow us to model important features of more general functions with
increasing degrees of complexity, as is done with many modelling systems such as
GLMs and GAMs. For a one-dimensional case, one can only model an average
height of a function using V(0) because it is a constant model. The next space, V(1),
can provide information about a linear trend or slope of the function, while the
space V(2) has some crude form of curvature. The spaces V(3), V(4) and greater allow
us to model increasingly fine variations of the function (figure 2).

272

S. Laffan et al.

Figure 1. Piecewise linear function in V(4).

Figure 2. Using increasingly complex piecewise linear functions (solid lines with 1, 2, 3 and 5
grid points representing spaces V(0), V(1), V(2) and V(3)) to model a possible relationship
(dotted lines).

We can interpret piecewise linear functions in terms of the function features which
they model. In particular, we express the function as a sum of components which
model the height, slope, curvature and possibly other function features (figure 3).
This decomposition is similar to a Fourier or wavelet decomposition. Each term in
this decomposition corresponds to a scale of the correlate, where the relative sizes of
the different components provide information about the smoothness of the function.
Such decompositions are well known for functions of time or space. Note, however,
that here we have a functional relationship between the response variable and a
correlate. The scale of a fluctuation is thus not a temporal or spatial scale but a scale
of change in the correlate.

In the case of two variables, we consider regular grids with nk6nl grid points,
where k and l range over 0, 1, 2, 3, … and nk stands for 1+2k as before. The
corresponding function space, which we denote by Va with a5(k,
l), contains
functions that are piecewise linear on each of the grid lines. In fact, they are
piecewise linear on any line parallel to an axis. This leads to piecewise bilinear
functions which, in each rectangle defined by four neighbouring grid points, takes
the form c0+c1x1+c2x2+c3x1x2. The set of spaces Va defined in this way provide a
very flexible tool to model large classes of functions used for two dimensional
problems in engineering and science (Braess 2001, Ciarlet 2002).

Sparse grids

273

Figure 3. Decomposition of a piecewise linear function into its components.

features of

the underlying function. This

From the set of two-dimensional grids, we again have a collection of function
includes
spaces which represent
V(0,0),which models an average height, V(1,0), which models slopes or trends in the
first variable, and V(0,1), which models trends in the second variable. Curvature, the
rate of change of the slope, in the first variable is modelled by V(2,0). Similarly, V(0,2)
models the change in slope in the second variable. An interesting space is V(1,1),
which models the change in the slope of the first variable in terms of the second, or
vice versa. Thus, this space contains terms modelling the interactions between the
two predictors in addition to purely additive effects of the individual variables.

However, high-dimensional regular grid function spaces use many degrees of
freedom. In the simplest non-trivial case with two grid points per variable, the total
number of grid points is 2d. Thus, regular grids have been used in the case of one to
four dimensions, but they are not computationally feasible for higher dimensions.

3.2 Sparse grid functions

There are two basic ways to understand sparse grids—either as subsets of very fine
regular grids or as arbitrary combinations of smaller regular grids. We consider the
second viewpoint here. Sparse grids are obtained by overlaying regular grids all
having the same number of dimensions, but possibly having different resolutions
along each dimension. For example, we can have spaces like V(1,8) where there are
higher-order fluctuations in the second variable, and a linear relationship in the first
variable. Thus, one can model arbitrary combinations of
fluctuations and
interactions. This is the strength of models using grid-based functions.

Formally, the sparse grid function space V is spanned by some regular grids

Va1 , . . . , Vak :

An element fgV of the sparse grid is a linear combination of functions fai [Vai :

V ~Va1

z (cid:1) (cid:1) (cid:1) zVak :

f xð Þ~fa1 xð Þz (cid:1) (cid:1) (cid:1) zfak xð Þ:

ð1Þ

ð2Þ

274

S. Laffan et al.

Such additive models generalize linear models. Additive models have been
in non-parametric

considered in different contexts, and they are a core tool
regression (Hastie and Tibshirani 1986, Tibshirani 1990, Friedman 1991).

Note that the components Vaj are not necessarily linearly independent, and so
some degrees of freedom are wasted on duplication, and the components are not
uniquely determined. However, the representation of a sparse grid function as a
composition (as in equation (2)) does have other major computational advantages,
which we will discuss later.

In the simplest case of one predictor variable, the sparse grids are identical
to regular grids, and in this case, nothing new is obtained. One does get new
grids in two or more dimensions. An example of a sparse grid space using linear
functions of three variables to model any position in a cube is given in figure 4.
Note that the regular grid which contains the same linear functions contains
several additional interaction terms and uses eight degrees of freedom instead of
four.

From figure 4,

it is clear that regular grid spaces are wasteful. They use
more parameters, or degrees of freedom, than is necessary for a good approxima-
tion. This can be seen if one tries to model the spaces of linear functions
with function spaces V(k,l). The smallest space which contains the linear functions
of two variables is V(1,1) for which the sparse grid space would be V(1,0)+V(0,1).
This space contains linear trends in both variables but,
in addition, contains
functions which can change the linear trend in one variable as a function of the other.
In this case one parameter has thus been ‘wasted’. However, for more than
two dimensions, the number of wasted parameters grows exponentially with the
dimension. In the case of d variables, the smallest space based on full grids
which contains linear functions is V(1,1,…,1) which uses 2d parameters, much more
than the d+1 required to represent a linear function in d variables. If one uses the
additive representation of the sparse grid, then one has d spaces of linear functions
with two degrees of freedom each. Thus, one requires a total of 2d degrees of
freedom, less than twice the optimal d+1. For example, with d58 variables, one has
d+159 grid points, and the representation in the form of equation 2 will
require 2d516 grid points. For comparison, the full grid uses 2d5512 grid
points to describe the same problem—a substantial difference because grid points are
not reused between the component grids.

An estimate of

model where all

the number of parameters required by the sparse grids
interaction grids of some order are used, and where these

Figure 4.
smallest regular grid containing linear functions.

(a) Sparse grid points defining a linear function in three variables and (b) the

are of equal order, is

Sparse grids

n
X

(cid:1) (cid:2)
d

i~0

i

2 k{1
Þi
ð

275

ð3Þ

where i is the order of the combinations used (e.g. first order, second order), and d is
the number of variable axes used. Other variables are as described above. A constant
model will use one parameter.

More generally, for smooth functions it can be seen that most of the parameters
can be removed from the model without losing too much detail. This is the strength
of sparse grids—they use fewer parameters to achieve a similar functional
representation to regular grids of piecewise linear functions. This greatly reduces
the problems caused by the curse of dimensionality.

We have discussed sparse grids based on piecewise linear models. However, it is
also possible to base sparse grid function classes on other one-dimensional function
classes. These could include polynomials, where the polynomials model height,
slope, curvature and higher moments, trigonometric spaces which model fluctua-
tions, or wavelets which model local fluctuations, and one gets the corresponding
interpretations in higher dimensions. The challenge is to separate the various effects
using a data set of correlated variables, as is common for analyses of geographic
data.

3.3 Fitting sparse grids

Fitting the sparse grids system to a data set is done as follows. For a given response
variable y and predictor variables x1, …, xd, a predictive model is described by a
function

y~f x1, . . . , xd

ð

Þ:

ð4Þ

Typically, the partial functions of the sparse grids only depend on a subset of the
variables, or the dependence has a coarser scale, as discussed below. Each Va is
typically chosen such that it can represent functions with a high resolution in some,
but not all, dimensions (figure 5). This leads to significant reductions in the

Figure 5.
(a) Planimetric and (b) isometric views of the decomposition of the sparse grid
functions f(1,3)+f(3,1)2f(1,1), where f(1,1) is an intersection function to account for duplicated
grid points. Note the combination of linear and nonlinear components between the grid
points for f(1,3) and f(3,1) in (b).

276

S. Laffan et al.

computational complexity, and there is evidence that the approximation errors are
small (Zenger 1991, Bungartz 1992).

For observed data points x1, …, xn and function values y1, …, yn, we determine a
function f from some finite dimensional function space V to be the solution of a
penalized least-squares problem of the form

J fð Þ~ 1
n

n
X

i~1

(cid:3)

f xi(cid:3) (cid:4){yi

(cid:4)2zb Lfk

k2

ð5Þ

for some (differential) operator L. The solution of this problem can be viewed as a
projection of a generalized thin plate spline function (Hegland 2002). In the sparse
grids technique, the partial functions fa are computed independently as minima of J
for appropriate sets of spaces Va.

In other words, we construct the approximating functions we seek by choosing a
sparse grid, constructed from a set of regular grids as described, then choosing each
fai independently to be the ‘best fit’ function (in the least-squares sense) among the
functions in the appropriate Vai . However, an adjustment is now necessary to avoid
‘over-representation’ by functions when two or more of the regular grids have points
in common. We do this by subtracting the approximating function derived from the
intersection grid (figure 5). Because the same grid points may appear more than once
in different intersection grids, the general form for an approximating function
chosen this way is

f ~ca1fa1

z (cid:1) (cid:1) (cid:1) zcak fak

ð6Þ

where the cai are integers that must be calculated using combinatorial techniques
(yielding a so-called combination formula), and the fai come not only from the spaces
associated with the original set of regular grids but also from spaces associated with
intersections of grids in this set.

3.4

Interpreting the sparse grid model

As noted in section 2 models are often used to gain some understanding of the
relationships among a system of variables, and the ease by which such relationships
can be understood is one of the criteria by which models are compared (section 2.2).
Clearly, sparse grids predictions of geographic phenomena can be mapped as
surfaces of predictions, and this is the primary output from most modelling systems
applied to geographic data. In addition, one can derive estimates of model
performance for which most of the standard measures of model accuracy for
continuous data (interval or ratio data types) are applicable. The most common
example of this is the r2.

Alternately, one can describe the error according to some changing error
tolerance (Laffan and Lees 2004). In this case, one considers predictions within some
pre-specified tolerance of the known value as correct, and calculates accuracy as
usual, i.e. the percentage of samples correctly predicted. Further understanding of
the error is gained by graphing how the model performance changes with increasing
error tolerances. The advantage of this approach is that it does not make
distributional assumptions about the data and so can deal appropriately with any
continuous data, including those with multi-modal distributions.

A modification of the error tolerance approach takes into account the fact that
the model may not provide any predictive power, or there is no modelled

Sparse grids

277

relationship, and so the mean of the sample may be as good a predictor as the
model. An example of this is when a regression model has a slope of zero, and the
mean, represented by the intercept, is therefore the best predictor. To allow for this,
one calculates the percentage of samples for which the model is closer to the correct
answer than the mean. Again, this can be calculated for a series of tolerances and
graphed.

However, geographically global measures of error can conceal some of the
characteristics of prediction accuracy. To approach this, one can use other ways of
understanding the relationships modelled by the sparse grids system. These are the
visualization of
the geographic surfaces predicted by individual sparse grids
(analogous to that used for ANNs by Laffan 1998) and plots of the error
distributions of each individual grid. These take advantage of the additive nature of
the sparse grids, are merely extensions of the measures described above, and are
equally applicable to other additive models.

3.5 Geographically local sparse grids

We have already discussed the concept of geographically local models (section 2.1).
As stated, any model can be modified to use such local weights, and it is essentially a
geographical implementation of a kernel weighting system (Hastie et al. 2001,
Fotheringham et al. 2002). The sparse grids software has been adapted to do this by
weighting the errors during calibration. The smaller number of parameters used by
sparse grids means that the required data density is lower compared with other non-
parametric models, and therefore allows a greater geographical coverage of the
study area when using a geographically local sample than would be the case using
regular grids.

The main challenge of using a local weighting system is in the interpretation of
model results, as one now has hundreds to millions of models to interpret. Future
computer power will enable the use of the methods described in section 3.4,
dynamically linked to a cursor position. However, one is currently limited to
aggregate measures for each model component at each location, and aggregations of
those measures, mapped as geographic surfaces. Despite these limitations, mapping
the model components and results is an extremely useful visualization method
(Laffan 1998).

4. An application

Having described the sparse grids analysis system, we now demonstrate its utility
using a data set from the Weipa bauxite deposit, an aluminous lateritic ore body in
far north Queensland, Australia (figure 6).

The objective of the test application is to find correlations between sub-surface
regolith properties and some set of features that are easily measured from the
surface. The purpose of this is to better understand the applicability of mapping
surfaces of regolith properties as continuous fields, as opposed to spatially discrete
choropleths of regolith classes. Previous work using this data set is presented in
Laffan (2001, 2002) and Laffan and Lees (2004).

4.1 Data set

The data set consists of 57 642 drill cores collected between 1955 and 1980, of which
54 757 intersect bauxite (figure 7). These are sampled on a magnetic north aligned

278

S. Laffan et al.

Figure 6. Weipa bauxite deposit, Queensland, Australia (after Laffan and Lees 2004).

Figure 7. Distribution of sample points with 5 m elevation contours (light grey). The box
denotes the area plotted in figure 12.

grid at spacings from 38 m to 308 m (1000, 500, 250 and 125 feet) using an infilling
sample design. There is also a set of eight surface measurable features (figure 8): a
DEM and
(fD8
algorithm)(Freeman 1991); Landsat Thematic Mapper bands two, four and seven,
captured 16 June 1988; and the Euclidean distances from swamps and from drainage
lines (defined as cells with flow accumulation greater than 200 000 m2).

flow accumulation

attributes

derived

slope

and

of

For each drill core sample containing bauxite, there are measurements of
percentage abundance of oxides of aluminium, iron, silica and titanium. There are
also estimates of the depth to the base of the bauxite layer, and the depth of the
overburden (topsoil or A-horizon). The oxide variables were measured using atomic
absorption spectrometry, for which the stated precision is 1% (Dunster 1983). The

Sparse grids

279

Figure 8. Distribution of surface measurable features used (after Laffan and Lees 2004).

280

S. Laffan et al.

depth variables are measured to a 30 cm precision, controlled by the length of the
auger bit.

The cell size used for the surface measurable features is 30 m for consistency with
the Landsat data. The drill core data set was therefore resampled to this cell size for
analysis purposes. Locations identified in the Landsat image as having been mined
(vegetation regrowth or mine floor), or as cleared for mining, were excluded from
the analyses. Resampling and exclusions reduced the number of samples used in the
analyses to 14 833. A block of the titanium samples in the Weipa Peninsula was also
excluded because it had been given a constant value, reducing the data set for
titanium to 11 851 samples.

4.2 Landscape

Like many geographic phenomena, the test application is complex. The ground
surface has a very low gradient, and the landscape at Weipa has been subjected to
numerous landscape evolution processes during its estimated more than 40 million
years of development (Eggleton and Taylor 1999). Like many such processes, these
all operate over different spatial and temporal scales, and all are superimposed to
varying extents (Burrough 1993). These processes include lateritic evolution and
associated landscape lowering (estimated at 12 m by Eggleton and Taylor 1999),
fluvial reworking, sea-level fluctuations and storm surges (Foster 1996), aeolian
processes (Lees et al. 1990, 1993, Lees 1992), and mechanical disturbance through
tree throw events during cyclones. There is also extensive soil piping in the clay zone
beneath the bauxite and an iron-enriched zone (referred to as ironstone). Permanent
and seasonal swamps are caused by drainage impedance through collapsed pipes
and control much of the surface and sub-surface hydrology (Laffan 2001).

In addition to the above processes, the oxide variables all have differing solutional
mobilities, and so have different responses to landscape evolution processes. The
depth of the bauxite layer is also controlled by water table fluctuations, as its base is
defined as the top of the ironstone. The boundary between the two zones may be
abrupt or gradational, as can lateral variations. These variations are of the order of
2 m depth over a 100 m lateral distance, caused by groundwater fluctuations, or 2 m
depth over a 1 m lateral distance, caused by tree roots.

All of the above landscape evolution processes have made the application of
geographically global analyses subject to large errors due to the complexity of the
overall analysis task. There is a high degree of local hydrological control over the
components of the bauxite (Laffan 2002), and geographically local analysis methods
find better relationships than global ones (Laffan and Lees 2004). Even so, Laffan
and Lees found good local relationships for only 22% of sample locations using
moving window regression, an implementation of GWR using a binary spatial
weights matrix. This may be for several reasons, including geographically local
scales of equilibrium and limitations of the ordinary least-squares regression used.
The sparse grids analysis system has the potential to overcome some of these
numerical limitations.

4.3 Methods

Geographically global and local sparse grid models were generated using each of the
variables used by Laffan (2001) and Laffan and Lees (2004). The correlate variables
were the percentage abundance of oxides of aluminium, iron, silica and titanium,

Sparse grids

281

and the depth to the base of the bauxite layer. The predictor variables are listed in
section 4.1 and are shown in figure 8. All variables were scaled linearly between zero
and one during the analysis, and the final predictions were rescaled back into the
original range.

Combinations of sparse grids can be very complex systems. For a case study such
as this, there may be several thousand regular grids generated to describe a complete
solution, so we used a subset of sparse grids to make the analysis tractable.

For the geographically global analyses, we used all single variable grids and all
two variable combination grids, requiring eight and 28 grids, respectively. All sparse
grids used dimension five, V(5), for the non-constant axes, giving 17 grid mesh points
along those axes. When one accounts for the constant grid, this combination of grids
uses 7297 parameters (equation (3)). Two-thirds of the sample data were used to
calibrate the models (9887 points), and one third were withheld for model testing
(4982 points).

For the geographically local case, we used the same set of grid functions as in the
global case, but applied to each local sample. However, because there were fewer
data points in each sample, we used dimension V(2) to give three grid points along
each non-constant axis. This is slightly better than a linear model along the entire
range of the data, and uses 129 parameters (equation (3)). Using the entire range of
the data means that in those local samples with a limited subset of the data range,
for example with low slopes and elevations, the fitted sparse grid is effectively linear
along those axes. This is because there are no values to calibrate the model between
the second and third grid points.

The local samples were defined using binary weights from a circular window with
radius 600 m. Samples beyond this radius from the window centre were excluded
from analysis. The data were not separated into training and testing sets for the local
analyses, as the number of data points available would otherwise be too few to
generate reliable model results. Models were not fitted where there were insufficient
data in the local sample set, giving 20 994 models when they were applied to each
30 m cell in the study area.

The quality of the predictions were assessed using the error measures described in
section 3.4, the r2 and the frequency with which the prediction was within the
tolerance and closer than the relevant global or local mean. For the geographically
global case, geographic surfaces and error distributions were also generated for each
individual sparse grid in addition to the overall prediction. The tolerance approach
differs from that used by Laffan and Lees (2004), in that they used the difference of
the two predictions after aggregating to the tolerance intervals

We also used the results of Laffan and Lees (2004) as a comparison. These were
feedforward ANNs, using one hidden layer, and moving window regression (MWR)
using a 300 m sample window with binary weights. For a more direct comparison,
we also generated a set of MWR results using a 600 m sample radius.

4.4 Results

The errors (r2) for the sparse grids predictions are given in table 1, with the results of
Laffan and Lees (2004) for comparison. These use the sample locations from the
global testing set for which geographically local models have been fitted, so the
results are directly comparable (1232 points for aluminium, iron, silica and Depth to
Ironstone, and 1033 points for titanium). The residual errors are plotted as density
surfaces in figures 9 and 10, with the error tolerance graphs in figure 11. A subset of

282

S. Laffan et al.

Table 1. r2 values for testing subset locations for which geographically local models have been
fitted (1232 points for aluminium, iron, silica and Depth to Ironstone, and 1033 points for
titaniuma).

Variable

Global SG Local SG

ANN

Aluminium
Iron
Silica
Titanium
Depth to
Ironstone

0.52
0.82
0.32
0.48
0.14

0.80
0.91
0.65
0.74
0.50

0.40
0.82
0.02
0.22
0.05

600 m
MWR

300 m
MWR

0.78
0.89
0.60
0.69
0.42

0.85
0.93
0.74
0.79
0.62

600 m
Mean

0.70
0.87
0.45
0.62
0.27

aErrors for the same samples using the results of Laffan and Lees (2004) are provided for
comparison. Note that the iron results are biased because of a bimodal distribution.

the geographic surfaces are shown for silica in figure 12, again with the results of
Laffan and Lees (2004) for comparison. A sample of residual error plots for the
silica component grids is given in figures 13 and 14.

4.5

Implications

The results for the global sparse grids are better than those using ANNs (table 1,
figures 11 and 12). There is a much better fit to the data and a greater spatial
variation of the model predictions. The exception to this is iron, which has a
bimodal distribution, and so the r2 and the comparison with the mean (figure 11) is
not ideal. From these results, it appears that the geographically global analyses are
strongly affected by spatial non-stationarity of the relationships between the regolith
properties and the surface measurable features, as concluded by Laffan and Lees
(2004).

The r2 values for the ANN analysis results (table 1) are also lower than those
presented in Laffan and Lees (2004). When one considers that this is for a sub-
sample of the results, this is a clear indication that single-valued error statistics can
conceal important aspects of model performance.

The geographically local predictions, although they are fitted to a sample with a
much smaller geographic extent, show a similar degree of spatial variation to that of
the global sparse grids (figure 12). However, the residual error plots (figures 9 and
10) and r2 values (table 1) indicate that the local sparse grid models are better than
the global models, with the exception of titanium and iron. Iron has been explained
above, but titanium is different. It has a very low solutional mobility, and so there
may be very few locations where there is any local-scale control over its distribution.
The global model may therefore provide the greatest explanatory power.

It should also be noted that the 300 m MWR results are better than both the local
sparse grids and MWR results for the 600 m windows (figure 11). This last point
may in part be the result of the different sample sizes used, as the 210 m MWR
results of Laffan and Lees (2004) were better than the 300 m MWR results. This
indicates that the scale of the relationships between the regolith properties and the
surface measurable features often has a very short range.

The residual errors for the global silica component grids (figures 13 and 14) also
indicate that there is little direct relationship between silica and the individual
predictor variables. Much of the modelled relationship is actually represented by the
two variable interaction grids. A similar relationship exists for the other variables

Sparse grids

283

Figure 9. Density plots of residual errors for global sparse grid predictions (all test sample
locations).

284

S. Laffan et al.

Figure 10. Density plots of residual errors for local sparse grid predictions (all sample
locations for which a model was fitted).

Sparse grids

285

Figure 11. Error tolerance graphs for sparse grid global (SG Global), local (SG Local),
ANN and MWR predictions, calculated as the percentage of sample locations where the
predictions are within the tolerance and better than the associated mean value (SG Global and
ANN5global mean, SG Local and 600 m MWR5local mean of 600 m sample radius, 300 m
MWR5local mean of 300 m sample radius). Values are calculated from the sample sets used
in table 1.

286

S. Laffan et al.

Figure 12. Spatial distribution of a subset of local and global silica results, with ANN,
MWR and local mean surfaces for comparison.

Sparse grids

287

Figure 13. Residual error plots for all single variable grids used in the global silica analysis.
Symbols as in figure 9.

288

S. Laffan et al.

Figure 14. Residual error plots for a sample of the two variable interaction grids used in the
global silica analysis. Symbols as in figure 9.

Sparse grids

289

analysed. This indicates the complexity of the relationship between the system
drivers and the response variables in the Weipa study area.

5. Further application of sparse grids

Sparse grids represent a very flexible predictive modelling and analysis system. They
reduce many of the challenges faced when analysing geographic data (section 2). We
now describe some of the potential avenues for a further understanding of
geographic phenomena using sparse grids.

The analyses described here are likely to be more detailed than necessary, both in
terms of the grid resolution and in terms of the number of the grids used (see, for
example, figures 13 and 14). Even though they use fewer parameters than other
regular grid models, they can still require a large number of parameters and
therefore data samples. This will cause some statistical challenges where the ratio of
paramaters to samples is close to one. In this study, for example, we have used very
large numbers of grid parameters in relation to the number of samples (7297
parameters compared with 9887 samples for the global case). We did this because we
pursue more of a data-mining type of approach, where we ‘transform’ our data
using distributed models and then try to find a pattern in the result. The distributed
models may have a large amount of noise, but the hope is that one might able to
extract some signal, even if the models are overfitted and thus noisy.

There is a need to use adaptive sparse grids models with less parameter
redundancy. To this end, further research is being done into better selection of grid
mesh sizes and the choice of variables. Fitting sparse grids to a subset of the range of
values is one approach that may prove fruitful.

Conversely, the analysis of a complete sparse grids system, without model
selection, could be a useful approach to understanding the nature of
the
relationships in attribute space (section 3.1). This could be done by an analysis of
the collective accuracies of the various grid mesh sizes. If one variable has low errors
only for coarse grids, e.g. V(2), then the relationships are likely to be broad. If,
however, a variable has low errors for grids with more mesh points, e.g. V(8), then
the relationships are likely to be of a finer variation. This would be even more
interesting if there were more than one peak resolution, as there may be multi-scale
effects. When applied in the local case, one could then map the outcomes to
understand how the system varies through geographic space. Of course, one must
define what constitutes a low error to use this approach, and this is likely to be a
subjective process.

One obvious extension to the method would be to allow the geographically local
weights to decay smoothly with distance, rather than the binary weights used here.
The analysis code is capable of doing this, and future research would investigate the
optimization of these weights using cross-validation. Approaches such as cross-
validation and bootstrapping also allow one to obtain accuracy measures without
withholding a test subset, thus allowing more data for the calibration of models.

A final comment relates to the time required to conduct an analysis. The code is
written in Python and C, and so it is possible to run it on any operating system.
However, it currently needs the power of a super computer to be tractable for very
large data sets. The code is written to take advantage of parallel processors where
available, and there is the potential to use Grid Computing architectures (Foster
et al. 2001) via a web service to allow wider access to this power.

290

6. Summary

S. Laffan et al.

Sparse grids represent a promising approach to the analysis of geographic data, with
evident scope for further application and interpretation. Our analyses using the
Weipa data set indicate that they perform better than an artificial neural network in
the global case, and slightly better than moving window regression in the local case.
There remain issues to be addressed before they can be readily applied to other
geographic data sets, but these are all tractable. Indeed, they are no different than
those experienced when the analysis tools discussed in section 2 were first developed.
We can only benefit from having more analysis tools available that can cope with
the complexities of geographic data.

References
ANSELIN, L., 1995, Local indicators of spatial association—LISA. Geographical Analysis, 27,

pp. 93–115.

ASPINALL, R.J. and LEES, B.G., 1994, Sampling and analysis of spatial environmental data. In
the 6th International Symposium on Spatial Data Handling,

Proceedings of
Edinburgh, T.C. Waugh and R.G. Healey (Eds.), pp. 1086–1098.

BRAESS, D., 2001, Finite Elements, 2nd edn (Cambridge: Cambridge University Press).
BREIMAN, L., FRIEDMAN, J.H., OLSHEN, R.A. and STONE, C.J., 1984, Classification and

Regression Trees (Belmont, CA: Wadsworth).

BRUNSDON, C., 2001, Is ‘Statistix inferens’ still the geographical name for a wild goose?

Transactions in GIS, 5, pp. 1–3.

BUNGARTZ, H.-J., 1992, Du¨ nne Gitter und deren Anwendung bei der adaptiven Lo¨ sung
fu¨ r Informatik,

der dreidimensionalen Poisson-Gleichung. Dissertation, Institut
Technische Universita¨ t Mu¨ nchen.

BURROUGH, P.A., 1993, Soil variability: A late 20th century view. Soils and Fertilizers, 56,

pp. 529–562.

CIARLET, P.G., 2002, The Finite Element Method for Elliptic Problems, Vol. 40 of Classics in
Applied Mathematics
Industrial and Applied
Mathematics (SIAM)) Reprint of the 1978 original (North-Holland, Amsterdam;
MR 58 #25001).

(Philadelphia, PA: Society for

COOK, S.E., CORNER, R.J., GREALISH, G., GESSLER, P.E. and CHARTRES, C.J., 1996, A rule
based system to map soil properties. Soil Science Society of America Journal, 60,
pp. 1893–1900.

CRISP, M.D., LAFFAN, S.W., LINDER, H.P. and MONRO, A., 2001, Endemism in the

Australian flora. Journal of Biogeography, 28, pp. 183–198.

DUNSTER, J.N., 1983, Interim Report on Reserves of Redsoil for Grade H Calcined Bauxite in

Andoom, Technical report, Comalco Internal Report.

EGGLETON, R.A. and TAYLOR, G., 1999, Selected thoughts on ‘laterite’. In New Approaches to
an Old Continent, Regolith ’98 Proceedings, G. Taylor and C. Pain (Eds.),
pp. 209–226.

FOSTER, I., KESSELMAN, C. and TUECKE, S., 2001, The anatomy of the grid: Enabling scalable
virtual organizations. International Journal of Supercomputer Applications, 15,
pp. 200–222.

FOSTER, L.D., 1996, Sedimentary reworking across the Weipa bauxite deposit. Unpublished

thesis, Australian National University.

FOTHERINGHAM, A.S., BRUNSDON, C. and CHARLTON, M., 2002, Geographically Weighted
Regression, the Analysis of Spatially Varying Relationships (New York: Wiley).
FRANKLIN, J., 1995, Predictive vegetation mapping: geographic modelling of biospatial
patterns in relation to environmental gradients. Progress in Physical Geography, 19,
pp. 474–449.

Sparse grids

291

FREEMAN, T.G., 1991, Calculating catchment area with divergent flow based on a regular

grid. Computers and Geosciences, 17, pp. 413–422.

FRIEDMAN, J.H., 1991, Multivariate adaptive regression splines. Annals of Statistics, 19,

pp. 1–141.

GAHEGAN, M.N., 2000, On the application of inductive machine learning learning tools to

geographical analysis. Geographical Analysis, 32, pp. 113–139.

GAHEGAN, M.N., 2003, Is inductive machine learning just another wild goose chase (or might
it lay the golden egg)? International Journal of Geographical Information Science, 17,
pp. 69–92.

GAHEGAN, M.N., GERMAN, G. and WEST, G., 1999, Improving neural network performance
on the classification of complex geographic datasets. Journal of Geographical Systems,
1, pp. 3–22.

GARCKE, J. and GRIEBEL, M., 2002, Classification with sparse grids using simplicial basis

functions. Intelligent Data Analysis, 6, pp. 483–502.

GARCKE, J., GRIEBEL, M. and THESS, M., 2001, Data mining with sparse grids. Computing,

67, pp. 225–253.

GETIS, A. and ORD, J.K., 1992, The analysis of spatial association by use of distance statistics.

Geographical Analysis, 24, pp. 189–206.

GILARDI, N. and BENGIO, S., 2000, Local machine learning models for spatial data analysis.

Journal of Geographic Information and Decision Analysis, 4, pp. 11–28.

GOULD, P., 1970, Is Statistix inferens the geographical name for a wild goose? Economic

Geography, 46, pp. 439–448.

GRIEBEL, M., SCHNEIDER, M. and ZENGER, C., 1992, A combination technique for the
solution of sparse grid problems. In Iterative Methods in Linear Algebra, IMACS,
P. de Groen and R. Beauwens (Eds.), pp. 263–281 (New York: Elsevier).

GUISAN, A. and ZIMMERMAN, N.E., 2000, Predictive habitat distribution models in ecology.

Ecological Modelling, 135, pp. 147–186.

HASTIE, T. and TIBSHIRANI, R., 1986, Generalized additive models. Statistical Science, 1,

pp. 297–318.

HASTIE, T., TIBSHIRANI, R. and FRIEDMAN, J., 2001, The Elements of Statistical Learning:

Data Mining, Inference and Prediction (Berlin: Springer).

HASTIE, T.J. and TIBSHIRANI, R.J., 1990, Generalized Additive Models, Vol. 43 of Monographs

on Statistics and Applied Probability (London: Chapman & Hall).

HEGLAND, M., 2002, Additive sparse grid fitting. In Proceedings of the Fifth International

Conference on Curves and Surfaces, 2002 Saint-Malo, France.

KIIVERI, H.T., 2002, Mapping and monitoring dryland salinity using a time series of satellite
images and other spatial data sets. In Accuracy 2002, Proceedings of the 5th
International Conference on Spatial Accuracy Assessment in Natural Resources and
Environmental Sciences, G. Hunter and K. Lowell (Eds.), pp. 471–485.

LAFFAN, S.W., 1998, Visualising neural network training in geographic space. In Proceedings
of the Third International Conference on GeoCompuation, CD-ROM. http://www.
geocomputation.org/1998/index.html.

LAFFAN, S.W., 2001, Inferring the spatial distribution of regolith properties using surface

measurable features. PhD thesis, Australian National University.

LAFFAN, S.W., 2002, Using process models to improve spatial analysis. International Journal

of Geographical Information Science, 16, pp. 245–257.

LAFFAN, S.W. and LEES, B.G., 2004, Predicting regolith properties using environmental
correlation: a comparison of spatially global and spatially local approaches.
Geoderma, 120, pp. 241–258.

LEES, B.G., 1992, Geomorphological evidence for late Holocene climate change in northern

Australia. Australian Geographer, 23, pp. 1–11.

LEES, B.G., 1996, Neural network applications in the geosciences: an introduction. Computers

and Geosciences, 22, pp. 955–957.

292

Sparse grids

LEES, B.G., HAYNE, M. and PRICE, D., 1993, Marine transgression and dune initiation on

western Cape York, northern Australia. Marine Geology, 114, pp. 81–89.

LEES, B.G., HEAD, J. and YANCHOW, L., 1990, Reconnaissance thermoluminescence dating of

northern Australian coastal dune systems. Quaternary Research, 34, pp. 169–185.

LEES, B.G. and RITMAN, K., 1991, A decision tree and rule induction approach to the
integration of remotely sensed and GIS data in the mapping of vegetation in disturbed
or hilly environments. Environmental Management, 15, pp. 823–883.

LUO, Z., WAHBA, G. and JOHNSON, D.R., 1998, Spatial-temporal analysis of temperature

using smoothing spline ANOVA. Journal of Climate, 11, pp. 18–28.

MACKEY, B.G. and LAFFAN, S.W., 2002, Case studies in GIS. In Geographic Information
Systems and Environmental Modeling, K.C. Clarke, B.O. Parks and M.P. Crane
(Eds.), pp. 223–251 (Englewood Cliffs, NJ: Prentice-Hall).

MOORE, I.D., GESSLER, P.E., NIELSEN, G.A. and PETERSON, G.A., 1995, Soil attribute
prediction using terrain analysis. Soil Science Society of America Journal, 57,
pp. 443–452.

ORD, J.K. and GETIS, A., 1995, Local spatial autocorrelation statistics: Distributional issues

and an application. Geographical Analysis, 27, pp. 286–306.

PAOLA, J.D. and SCHOWENGERDT, R.A., 1995, A review and analysis of backpropagation
imagery.

remotely sensed multispectral

neural networks
for classification of
International Journal of Remote Sensing, 16, pp. 3033–3058.

PEREIRA, J. and ITAMI, R., 1991, GIS-based habitat modelling using logistic multiple
regression: a study of the Mt. Graham Red Squirrel. Photogrammetric Engineering
and Remote Sensing, 57, pp. 1475–1486.

SMOLYAK, S.A., 1963, Quadrature and interpolation formulas for tensor products of certain
in Russian (English translation: Soviet

classes of functions. 148, pp. 1042–1043,
Mathematics Doklady, Doklady Akademic Nauk SSR, 4, 240–243, 1963).

TOBLER, W.R., 1970, A computer movie simulating urban growth in the Detroit region.

Economic Geography, 46, (supplement):pp. 234–240.

WILBY, R.L., ABRAHART, R.J. and DAWSON, C.W., 2003, Detection of conceptual model
rainfall-runoff processes inside an artificial neural network. Hydrological Sciences, 48,
pp. 163–181.

ZANIEWSKI, A., LEHMANN, A. and OVERTON, J., 2002, Predicting species spatial distributions
using presence-only data: a case study of native New Zealand ferns. Ecological
Modelling, 157, pp. 261–280.

ZENGER, C., 1991, Sparse grids. In Parallel Algorithms for Partial Differential Equations,
Proceedings of the Sixth GAMM-Seminar, Kiel, 1990, Vol. 31 of Notes on Num. Fluid
Mech., Vieweg, pp. 241–251.

ZIMMERMAN, N. and KIENAST, F., 1999, Predictive mapping of alpine grasslands in
Switzerland: Species versus community approach. Journal of Vegetation Science, 10,
pp. 469–482.

