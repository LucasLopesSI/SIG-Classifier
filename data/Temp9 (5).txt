This article was downloaded by: [UTSA Libraries]
On: 04 October 2014, At: 17:52
Publisher: Taylor & Francis
Informa Ltd Registered in England and Wales Registered Number: 1072954 Registered
office: Mortimer House, 37-41 Mortimer Street, London W1T 3JH, UK

International Journal of Geographical
Information Science
Publication details, including instructions for authors and
subscription information:
http://www.tandfonline.com/loi/tgis20

Evaluating the usability of visualization
methods in an exploratory
geovisualization environment
E. L. Koua a , A. Maceachren b & M. ‐J. Kraak a
a International Institute for Geo‐Information Science and Earth
Observation (ITC) , PO Box 6, 7500 AA Enschede, The Netherlands
b GeoVISTA Center , Department of Geography , Penn State
University , 302 Walker , University Park , PA 16802, USA
Published online: 20 Feb 2007.

To cite this article: E. L. Koua , A. Maceachren & M. ‐J. Kraak (2006) Evaluating the usability of
visualization methods in an exploratory geovisualization environment, International Journal of
Geographical Information Science, 20:4, 425-448, DOI: 10.1080/13658810600607550

To link to this article:  http://dx.doi.org/10.1080/13658810600607550

PLEASE SCROLL DOWN FOR ARTICLE

Taylor & Francis makes every effort to ensure the accuracy of all the information (the
“Content”) contained in the publications on our platform. However, Taylor & Francis,
our agents, and our licensors make no representations or warranties whatsoever as to
the accuracy, completeness, or suitability for any purpose of the Content. Any opinions
and views expressed in this publication are the opinions and views of the authors,
and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content
should not be relied upon and should be independently verified with primary sources
of information. Taylor and Francis shall not be liable for any losses, actions, claims,
proceedings, demands, costs, expenses, damages, and other liabilities whatsoever
or howsoever caused arising directly or indirectly in connection with, in relation to or
arising out of the use of the Content.

This article may be used for research, teaching, and private study purposes. Any
substantial or systematic reproduction, redistribution, reselling, loan, sub-licensing,
systematic supply, or distribution in any form to anyone is expressly forbidden. Terms &

Conditions of access and use can be found at http://www.tandfonline.com/page/terms-
and-conditions

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 International Journal of Geographical Information Science
Vol. 20, No. 4, April 2006, 425–448

Research Article

Evaluating the usability of visualization methods in an exploratory
geovisualization environment

E. L. KOUA*{, A. MACEACHREN{ and M.-J. KRAAK{
{International Institute for Geo-Information Science and Earth Observation (ITC),
PO Box 6, 7500 AA Enschede, The Netherlands
{GeoVISTA Center, Department of Geography, Penn State University, 302 Walker,
University Park, PA 16802, USA

(Received December 2004; in final form October 2005 )

The use of new representation forms and interactive means to visualize geospatial
data requires an understanding of the impact of the visual tools used for data
exploration and knowledge construction. Use and usability assessment of
implemented methods and tools is an important part of our efforts to build
this understanding. Based on an approach to combine visual and computational
methods for knowledge discovery in large geospatial data, an integrated
visualization-geocomputation environment has been developed based on the
Self-Organizing Map (SOM), the map and the parallel coordinate plot. This
environment allows patterns and attribute relationships to be explored. A use
and usability assessment is conducted to evaluate the ability of each of these
visual representations to meet user performance and satisfaction goals. In the
test, different representations are compared while exploring a socio-demographic
dataset.

Keywords: Usability; Geovisualization; Self-organizing map; Visual exploration

1.

Introduction

The need to assess the usefulness and usability of geovisualization tools is increasing
interactions emerge (Muntz et al. 2003). The use of new
as new types of
representation forms and interactive means to visualize geospatial data requires
an understanding of the impact of the visual tools used for data exploration and
knowledge construction. Use and usability assessment of implemented methods and
tools are an important part of our efforts to build this understanding. Such
assessments focus on the effectiveness, usefulness and performance of a tool. In
geovisualization, this is needed because use and usability testing can provide insight
into how a visual interface can support data-exploration tasks.

Increasing research interest in the usability of geoinformation systems has recently
linked the Human–Computer Intercation (HCI)
field, cognitive science, and
information science in a few applications of approaches that integrate across these
fields (MacEachren and Kraak 2001, Haklay and Tobon 2003, Koua and Kraak
2004b, Fuhrmann et al. 2005). The traditional map-use studies (MacEachren 1995)
conducted in the field of cartography are not necessarily fully applicable in new

*Corresponding author. Email: koua@itc.nl

International Journal of Geographical Information Science
ISSN 1365-8816 print/ISSN 1362-3087 online # 2006 Taylor & Francis
http://www.tandf.co.uk/journals
DOI: 10.1080/13658810600607550

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 426

E. L. Koua et al.

interactive visualizations that involve new representational spaces and advanced
user interfaces. The lack of appropriate evaluation methodology in the geovisualiza-
for user-based testing in
tion domain and particularly task specifications
exploratory geovisualization tools (Slocum et al. 2001) has limited the number of
user studies directed at formally assessing geovisualization tools. Since the design of
effective visualization tools will depend upon understanding the way users interact
with and make interpretations of the information spaces used to represent patterns
and relationships in data, the choice of a representation and interaction method is
crucial to the success of a visualization environment. Empirical testing of the
visualization tools can provide insights into the potential of particular visual
displays and interaction paradigms (Fuhrmann et al. 2005).

One of the dominant approaches in geovisualization is the integration of several
representation methods that provide different perspectives of the data in multiple
linked views. Such an integration of views can be more effective if focused on the
potential of the individual representations for specific conceptual visualization goals
that can better support the exploration, evaluation, and interpretation of patterns,
and ultimately support knowledge construction (Roberts 2005). Based on an
approach to combine visual and computational methods for knowledge discovery in
large geospatial data, an integrated visualization-geocomputation environment has
been developed. This incorporates a self-organizing map (SOM) neural network
algorithm for the extraction of patterns and integrates this computational method
with graphical representations used to portray extracted patterns to support the
understanding of the structures and the geographic processes. This integration of
visual representations of the SOM (e.g. views on non-geographic information spaces
or attribute space; Koua and Kraak 2004a) with maps and the parallel coordinate
plot allow (geographic) patterns and attribute relationships to be explored. The tool
is designed to facilitate knowledge construction, using a number of steps provided in
a data mining and knowledge-discovery methodology.

In order to investigate the effectiveness of the design concept, a use and usability
assessment is conducted to evaluate the tool’s ability to meet user performance and
satisfaction goals (Fuhrmann 2005, Tobon 2005). The methodology of the test is
based on an understanding of several knowledge-discovery activities, visualization
operations, and a number of steps in computational analysis used to visualize
patterns in the data. In the test, different representation methods are used to explore
a socio-demographic dataset; these include maps, a parallel coordinate plot, and
interactive visualizations of the SOM output. The study emphasizes the knowledge-
discovery process based on exploratory tasks and a taxonomy of visualization
operations.

The results are organized according to the visual tasks derived from the taxonomy
of conceptual visualization goals and operations, and are compared for the different
visual representations (maps, parallel coordinate plots, and the SOM-based
representations). The taxonomy was used to structure the study. This paper
concentrates on the usability evaluation methodology, the test procedures, and the
results.

2. Exploration and knowledge-discovery tasks in the visualization environment

Judging whether a geovisualization (or other) exploratory environment is effective
requires answering the question: effective for what? We begin, therefore, with a
discussion of exploration and knowledge-discovery tasks to which a geovisualization

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 Integration of object-based and field-based models

427

environment can be applied. The model presented in figure 1 emphasizes the
exploratory nature of a visualization environment designed to provide support for
knowledge construction, from hypothesis formulation to the interpretation of
results. This figure focuses on the exploration steps undertaken by users. Some of
these steps may be repeated.

2.1 Defining user tasks for usability evaluation

The main goal of geospatial data analysis is to find patterns and relationships in the
data that can help answer questions about a geographic phenomenon or process.
The geographic analysis process can be viewed as a set of tasks and operations
needed to meet the goals of the data exploration (Fotheringham et al. 2000,
Andrienko and Andrienko 2005). The primary tasks in this process include:
checking the spatial positioning of elements of interest in order to verify spatial
proximity among different elements; verifying their spatial density; and obtaining an
overview of how a target value measured at one particular spatial location, or at
various neighbouring locations, varies for different attributes. These tasks involve a
number of more specific activities and operations that users will perform (Weldon
1996):

elements (within clusters and between different clusters);

N identification of the different clusters in the data, and relationships between
N comparison of values at different spatial locations, distinguishing the range of
N relation of the value, position, and shape of object identified;
N analysis of the relevance of the information extracted.

value;

The above activities are often facilitated by functions that allow selection, scaling,
rotation panning, brushing, browsing, filtering, and querying the database.

The exploration steps described in figure 1 are supported by basic visualization
tasks and operators, as users manipulate the graphical representations and initiate
actions during the different steps. These visualization operations are the basis for the
success of the exploration process.

2.2 Exploration tasks and visualization operators

To complete the tasks described above, the user will have to execute a number of
visualization operations during the exploration process described in figure 1. Several
authors have suggested taxonomies for visualization operations (Keller and Keller
1992, Qian et al. 1997, Zhou and Feiner 1998, Ogao and Kraak 2002). The most
comprehensive list (Keller and Keller 1992, Wehrend and Lewis 2000) includes
rank, compare,
identify,
associate, and correlate:

locate, distinguish, categorize, cluster, distribution,

distinctly recognizable.

N Identify: to establish the collective characteristics by which an object is
N Locate: to determine the absolute or relative position.
N Distinguish: to recognize as different or distinct.
N Categorize: to place in specifically defined divisions in a classification; this can
N Cluster: to join into groups of the same, similar or related type.

be done by colour, position, or type of object (shape).

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 428

E. L. Koua et al.

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 Integration of object-based and field-based models
429
N Distribution: to describe the overall pattern. This is closely related to cluster in
the same way that locate and identify are related. The cluster operation asks
that the groups be detected, whereas the distribution operation requires a
description of the overall clustering.
N Rank: to give an order or position with respect to other objects of like type.
N Compare: to examine so as to notice similarities, differences, order.
N Associate: to link or join in a relationship.
N Correlate: to establish a direct connection (correlation).

A set of representative tasks derived from the steps described in figure 1 and key
visualization operations described above are identified in visualization task
scenarios for the evaluation study. This results from a decomposition of the basic
visualization tasks and is presented in the next section. The rationale behind the use
of scenarios is that they can represent how the system is intended to be used by end
users. Task scenarios provide a task-oriented perspective on the interface and
represent a structure and flow of goals and actions that participants are supposed to
evaluate. Such scenarios ensure that certain interface features are evaluated (Caroll
and Rosson 1992, 2003, Caroll et al. 1998).

2.3 Evaluation tasks model

The conceptual goals and the different steps of the exploration and knowledge-
discovery process described earlier are used as the basis for defining low-level
(operational) tasks that users need to perform to meet the conceptual goals.

Examples of the visual representations used are shown in figure 2. Next to the
map (figure 2(a)) and the Parallel Coordinate Plot (PCP) (figure 2(b)) several SOM
based visualization have been used. These include unified distance matrix
representation (figure 2(c)), 2D/3D surface (figure 2(d )), component plane displays
(figure 2(e)) as well as 2D/3D projection (figure 2(f )). The map was selected because
it provides a visual representation of the real world that participants are used to. The
PCP was selected because it is becoming a prominent tool used in geovisualization.
The background of each of the SOM visualization has been described in Koua and
Kraak (2004a).

The visualizations are based on a dataset that represents the relationship between
geography and macroeconomic growth (Gallup et al. 1999). The dataset contains 48
variables on economy, physical geography, population, and health for 150 countries.
This dataset was separately explored by the test designer as an experiment, and the
conclusions of the exploration were used to validate the test participant’s results.

The test is based on a low-level taxonomy of tasks derived by decomposition of
basic visualization operators that users might perform in a visual environment
(table 1). This decomposition of the basic visualization operators was obtained by
analysing task structures of real-world visualization problems, representing the

Figure 1. Data mining, exploratory visualization, and knowledge discovery processes. The
first part of this process consists of the general data mining and knowledge-discovery steps
(computational analysis). Each of the steps of the computational analysis can allow
visualization. Patterns extracted as a result of the computational process can be explored
using graphical representations (geographic and non-geographic information spaces). This
exploration is guided by a number of steps to support knowledge construction. The steps
presented in this figure correspond to the classification of Gvis and KDD operations
presented by MacEachren (1999).

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 430

E. L. Koua et al.

Figure 2. Visual representation used in the test: (a) map; (b) parallel coordinate plot;
(c) SOM distance matrix representation; (d ) SOM 2D/3D surface; (e) SOM component plans;
(f ) SOM projection.

collection of subtasks, developing related taxonomy or classification as well as a set
of semantic relationships among the concepts, and other entities necessary to
perform the task.

The defined taxonomy mapped on the different representation methods used to
represent each task contains too many tasks. Since each task is executed with three,

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 Integration of object-based and field-based models

431

Table 1. List of operational tasks derived from the taxonomy, and specific example tasks for
the evaluation.

Conceptual goals/
visualization
operators

Locate

Identify

Distinguish

Categorize

Operational visualization task

Indicate data items of a certain
range of value

Identify relationships between
attributes

Distinguish how a target value
measured at one particular
spatial location, or at various
neighbouring locations, varies
for different attributes (e.g.
different values of the same
attribute at different spatial
locations, and the value of
different attributes at a
specific spatial location)
Define all the regions on the
display, and draw boundaries.
Indicate spatial positioning of
elements of interest and spatial
proximity among the
different elements

Cluster

Distribution

Find gaps in the data on the
display
Describe the overall pattern
(overview)

Rank

Compare

Associate

Correlate

Indicate the best and
worst cases in the display for an
attribute
Compare values at different
spatial locations and the order
of importance of objects (data
items) accordingly

Form relationships between data
items in the display. Identify
relationships between data items
(within clusters and between
different clusters)
Discern which data items share
similar attributes

Specific task explored
in the study

Task
number

Indicate the poorest countries
(reference to the 1995 GDP
lower than 750)
Identify possible relationships
between the following
attributes: population density
in the coastal region and in the
interior, and GDP per capita 95
How does income (GDP 1995)
of the countries vary across
space? Define differences and
similarities between the
countries

Define all the regions on the
display, and draw boundaries.
Define categories of countries
such as rich, and poor countries
on the display, and indicate to
which category South Africa
belongs. Are there any African
countries in this category? List
the countries
Find gaps in the data and
indicate the different clusters
What are the common
characteristics of low-income
countries (GDP lower than
750)?
Indicate the five lowest GDP
countries and the five highest
GDP
Compare population density on
coastal regions (within 100 km
of the coastline) and inland
regions (beyond 100 km from
the coastline)
Form relationships between
economic development (GDP
1995) of countries in the
geographic tropics as compared
with other countries
Examine economic
development (GDP 95) across
the countries: landlocked
countries and countries that
have access to the sea

1

2

3

4

5

6

7

8

9

10

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 432

E. L. Koua et al.

four, five, or six different representations, much time is needed to complete the test.
In order to create a test that could be handled by the authors as well as the test
person (a maximum duration of 1 h and a half for each test person), it was necessary
to review the task structure. This was realized based on a visual tasks taxonomy by
Zhou and Feiner (1998) that includes a set of dimensions by which the tasks can be
grouped. The major dimensions of this taxonomy include visual accomplishments
and visual implications. Visual accomplishments refers to the type of presentation
intents that a visual representation might help to achieve while visual implications
specify a particular type of visual action that a visual task may carry out. The
following experimental tasks are derived for the test (tables 1 and 2).

The operational tasks described in table 1 are tested against all three usability
indicators and corresponding measures discussed in the next section. Specific
domain exploration tasks related to the dataset explored are used to illustrate each
operational task as defined in table 2.

3. User-based and task-based usability evaluation of exploratory geovisualization

There are several objectives for the proposed usability evaluation. The evaluation
intends to assess the visualization tool’s ability to meet goals for user performance
task of exploring patterns and
and satisfaction with regard to the general
relationships in data. Examples would be the percentage of users that will be able
to complete representative tasks within a certain time or without requiring
assistance, or the percentage of users that will be satisfied with the usability of the
tool. It is realized that evaluations will not lead to absolute answers, and that
exploratory tasks are rather open, but still we are convinced that the evaluation can
result in clear indications.

3.1 Test measures

The proposed assessment methodology includes three criteria (table 3): effectiveness/
user performance, usefulness, and user reactions (attitude):

1. Effectiveness focuses on the tool functionality and examines the user’s
performance of the tasks, and how to manipulate any parameters or controls
available to complete the tasks. Effectiveness can be measured by the time
spent on completing tasks, the percentage of completed tasks (Sweeney et al.
1993, Rubin 1994, Fabricant 2001), the correctness of outcome of task
performance and response, the success and accuracy (error rate and error
types), the amount of time spent for help and questions, the range of functions
used and the level of success in using each, the ease of use or level of difficulty,
and the time spent to access the documentation or for help.

2. Usefulness refers to the appropriateness of the tool’s functionality and relates
to whether the tool meets the needs and requirements of users when carrying
out tasks, the extent to which users view the tools as supportive for their goals
and tasks, and the individual user’s level of understanding and interpretation
of the tool’s results and processes. It includes flexibility and compatibility in
relation to the user’s expectations (finding patterns in data, relating different
attributes, and comparing values of attributes for different spatial locations).
This is gathered through task performance, verbal protocols, post-hoc
comments, and responses on a questionnaire.

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 Integration of object-based and field-based models

433

Table 2. Specification of user tasks and visual representation method used to represent task.

Task
no.

Method used in the
prototype to represent
task

Representation
number

Conceptual
goals/
visualization
operators

Locate

Operational
visualization task

Indicate data items of a
certain range of value

Identify

Identify relationships
between attributes

Distinguish

Distinguish how a target
value measured at one
particular spatial location,
or at various neighbouring
locations, varies for
different attributes (e.g.
different values of the same
attribute at different
spatial locations, and the
value of different attributes
at a specific spatial
location)
Define all the regions on
the display, and draw
boundaries. Indicate
spatial positioning of
elements of interest and
spatial proximity among
the different elements
Find gaps in the data on
the display

Categorize

Cluster

Distribution Describe the overall

pattern (overview)

Rank

Compare

Indicate the best and worst
cases in the display for an
attribute

Compare values at
different spatial locations,
and the order of
importance of objects (data
items) accordingly

1

2

3

4

5

6

7

8

Maps
Parallel coordinate
plot
Component planes
Maps
Parallel coordinate
plot
Component planes
Maps
Parallel coordinate
plot
Component planes

Unified distance
matrix
2D/3D projection
2D/3D surface

Unified distance
matrix
2D/3D projection
2D/3D surface
Parallel coordinate
plot
Map
Parallel coordinate
plot
Component planes
Unified distance
matrix
2D/3D projection
2D/3D surface
Map
Parallel coordinate
plot
Component planes
Maps
Parallel coordinate
plot
Component planes

1
2

3
1
2

3
1
2

3

4

5
6

4

5
6
2

1
2

3
4

5
6
1
2

3
1
2

3

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 434

Conceptual
goals/
visualization
operators

Associate

E. L. Koua et al.

Table 2. Continued.

Task
no.

9

Operational
visualization task

Form relationships
between data items in the
display; identify
relationships between data
items (within clusters and
between different clusters)

Correlate

10

Discern which data
items share similar
attributes

Method used in the
prototype to represent
task

Representation
number

Maps
Parallel coordinate
plot
Component planes
Unified distance
matrix
2D/3D projection
2D/3D surface
Maps
Parallel coordinate
plot
Component planes

1
2

3
4

5
6
1
2

3

3. User reactions refer to the user’s attitude, opinions, subjective views, and
preferences about the flexibility, compatibility (between the way the tool looks
and works compared with the user’s conventions and expectations). It can be
measured using questionnaires and survey responses, and comments from
interviews and ratings.

Table 3. Usability indicators used in the assessment.

Specific
usability
measures

Usability indicators used

Effectiveness/user
performance
N Correctness of outcome
of task performance and
response (success,
percentage of
completed tasks,
accuracy or error rate)

Usefulness

N Compatibility and
appropriateness in
relation to user’s
expectations and
goals

User reactions (attitude)
N Opinions, subjective

views on the
flexibility,
compatibility
(between the way the
tool looks and works
and the user’s
expectations),
functionality, and
appropriateness of the
tool for the tasks
N User preferences

N Time to complete tasks
N Time spent for help,
documents access,
guidance and support

N User’s level of

understanding and
interpretation of the
tool’s results and
processes

Measuring
method

N Examines tool

N Task performance

N Questionnaires,

interviews and survey
responses

N Ratings

functionality and the
user’s performance of
the tasks and response
to specific questions

N Verbal protocols
N Post-hoc comments
N Responses on
questionnaire
N Answers to com
prehension
questions

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 Integration of object-based and field-based models

435

The specific usability measures and measuring methods used for the different tasks
are described in table 3 below.

3.2 Test environment and procedure

The operational tasks described in table 2 were used in the experiment with sample
cases from the dataset explored in the test. This dataset was separately explored by
the test designer as an experiment, and the conclusions of the exploration were used
to validate the test participant’s results.

The test environment consisted of a computer installed with ArcGIS, Matlab
software, and the prototype visualization tool. The test environment has been
selected so that noise levels are at a minimum, in order to avoid disrupting the test.
The test sessions were individual sessions in which the participant worked in the
presence of only the test administrator on the tasks using each of the different
representations. Two first candidate users were used as pilot test subjects to
ascertain any deficiencies in the test procedures, such as tasks descriptions, timing of
each test session, the rating system, and instructions for test tasks. A revision was
made based on the problems detected during pilot testing, particularly of the task
description and timing. Twenty participants, including geographers, cartographers,
and environmental scientists, with experience in data analysis and the use of GIS,
were invited to take part in the test. The dataset used is related to a general
geographic problem, for which all the participants have the knowledge to conduct
the analyses.

The individual SOM-based graphical representations were programmed to be
used separately in a window with interactive features provided in the Matlab
interface (zooming, panning, rotation, and 3D view). ArcGIS was used for tasks
involving maps, and a free and fully functional Java-based interactive parallel
coordinate plot was used, with the basic features needed for the test (brushing,
automatic display of names of countries and values of variables as the mouse moves
over the data records, and adding and removing attributes from the display).
Participants were encouraged to interact with the interface. While completing the
tasks, they were asked to report their preferences and viewpoints about the
representation forms.

To ensure that participants were at ease, were fully informed of any steps, and
inquiries were answered, an introduction to each session was given. The
introduction explained the purpose of the test, and introduced the test environment
and the tools to be used. Participants were informed that the test consists of testing
the design and tools, not their abilities. At the end of the introduction, participants’
questions were answered. The tasks were written on separate sheets and were given
one at a time according to the random numbers assigned. Individual test sessions
were conducted using random numbers for the order of task presentation of the
graphical representations for the 10 tasks, and for the order of the graphical
representations used for each task. The rationale behind the use of random numbers
for the order of task presentation and the graphical representations for each of the
10 tasks (three to four graphical representations were used for each task) was to
reduce the learning effect for the sample size. In the introduction, the participants
were informed about the total number of tasks, but the tasks were given one at a
time according to the random numbers assigned. Participants were assured that they
have the option to abandon any tasks that they were unable to complete. They were
left to work quietly, without any interruption unless necessary. Participants were

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 436

E. L. Koua et al.

asked to report, as they work, any problems they find or things they do not
understand and were allowed to ask questions during the test.

The introduction and all the steps of the test were contained in a script so that all
the participants were treated in the same way during the session and received the
same information. The script describes the steps of the test in detail, and was read to
each participant at the beginning of the session in order to ensure that all
participants receive the same information. To allow the participants to refer back to
the list of tasks as they attempt a task, a written description of the task was handed
to each participant.

A logging sheet for each participant (at each session) was used to record timing,
events, participant actions, concerns, and comments. At the end of the session, a
brief questionnaire was given to the participants to collect other comments they
need to communicate.

Two forms were used to record user task performance and the different ratings.
Task performance was reported by the test administrator. User ratings on usefulness
(compatibility, ease of use, understanding) and user reactions (satisfaction and
preferences) were reported by the participants on the second form for the different
tasks and representations used.

The average time required to complete all the tasks was 90 min. On a logging
sheet, the time for user task performance for each representation was recorded, as
well as participants’ opinions and comments. Participants were allowed to ask
questions during the test.

3.3 Participants

The profile of test participants was a target population that included geographers,
demographers, environmental scientists, and epidemiologists—likely users of such a
geovisualization environment. The selected participants were GIScience domain
specialists, with knowledge of the application domain (of economic development)
and of similar datasets. Twenty participants from an initial list of 25 who met the
profile set for the test agreed to make time for the test. They included geographers,
cartographers, geologists, and environmental scientists, and all had had experience
in data analysis and the use of GIS. They also had both the motivation and the
qualifications to carry out the kinds of analysis being studied. Most of the
participants are pursuing PhD research. The selection of the sample size (20
participants) was based on recommendations from usability engineering literature
(Nielsen 1994) regarding final testing that involves actual use.

The first two candidate users were used as pilot test subjects to ascertain any
deficiencies in the test procedures, such as task descriptions, timing of each test
session, the rating system, and instructions for test tasks. A revision was made based
on the problems detected during pilot testing, particularly of the task description
and timing.

4. Results

The analysis of the test data is organized according to the usability measures
described above: effectiveness/performance, usefulness, and user reactions. A
detailed analysis of the test data was conducted using a pairwise t-test with the
different representations to compare the mean scores for the different measures. The

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 Integration of object-based and field-based models

437

results are also presented by experimental tasks and corresponding conceptual
visualization goals. The tasks are grouped into clustering (cluster and categorize)
and exploration (locate, identify, distinguish, compare, rank, distribution, associate,
correlate).

4.1 Analysis of effectiveness

4.1.1 Correctness of response. Correctness of response was used as a measure of
performance. A task completed with the correct response is given 1, and a task not
completed or completed with the wrong response is assigned 0. The analysis of the
correctness of response shows that the parallel coordinate plot performed poorly
compared with maps and SOM component planes. The SOM component plane
display performed well for all tasks. The map performed well generally, except for
task 6 (distribution), task 2 (identify), and task 8 (compare).

The component plane display performed better than maps, and the parallel
coordinate plot for visualization tasks such as ‘identify’, ‘distribution’, ‘correlate’,
‘compare’, and ‘associate’. The maps were as good as component planes for tasks
such as ‘locate’, ‘distinguish’, and ‘rank’. For these tasks (rank, associate, and
distinguish), the parallel coordinate plot performed poorly.

For the tasks ‘cluster’ and ‘categorize’, the SOM-based representations (unified
distance matrix, 2D/3D surface and 2D/3D projection) performed equally well and
far better than the parallel coordinate plot. For revealing the categories, the unified
distance matrix was found to be less effective than the 2D/3D projection and 2D/3D
surface. The 2D/3D projection was found to be more effective for finding the
categories.

Further analysis of the correctness of response measure was conducted using a
pairwise comparison of the mean scores for the different representations for each
conceptual visualization goal examined. Statistics of the paired sample tests are
presented in table 4. The paired sample tests show significant differences (p,0.05) in
the mean scores for the different tasks. For the task ‘locate’, the map and the
component plane display performed equally well (with 100% successful task
completion by users), compared with the parallel coordinate plot (75% successful
task completion by users). For this task, a significant difference was found between
the map and the parallel coordinate plot (p50.021), and between the component
plane display and the parallel coordinate plot (p50.021).

For the task ‘identify’, the map and parallel coordinate plot performed relatively
poorly (60% and 55% successful task completion by users, respectively), compared
with the component plane display (90%). The component plane display shows a
significant difference in performance in comparison with the map (p50.030) as well
as to the parallel coordinate plot (p50.005).

4.1.2 Time to complete tasks. The time to complete the tasks was used as a second
variable for the performance measure. The analysis of the time taken to complete
the tasks reveals some important differences between the different representations
used (figure 3). In general, the component plane display required less time than the
maps and the parallel coordinate plot for the different tasks. The map was faster for
‘distinguish’ but a far slower medium for comparison tasks (figure 3).

For the task ‘locate’, the parallel coordinate plot required double the time needed
by the map and the component plane display for the same task. Thus, a significant
difference was found between the parallel coordinate plot and the map (p 5 0.005)

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 Conceptual
visualization goal

Representation
method

Table 4. Paired samples test for correctness of responsea.

Paired differences

95% confidence interval of the
difference

Map–Pcp
Pcp–Comp
Map–Pcp
Map–Comp
Pcp–Comp
Map–Pcp
Map–Comp
Pcp–Comp
Udm–Proj
Udm–Surf
Proj–Surf
Udm–Pcp
Proj–Pcp
Surf–Pcp
Map–Pcp
Map–Comp
Pcp–Comp
Map–Pcp
Pcp–Comp
Map–Pcp
Map–Comp
Pcp–Comp
Map–Pcp
Map–Comp
Pcp–Comp

M

0.25
20.25
0.05
20.3
20.35
0.65
0.05
20.6
20.15
20.1
0.05
0.45
0.45
0.45
20.05
20.65
20.6
0.1
20.1
0.15
20.3
20.45
0.25
20.2
20.45

SD

0.444
0.444
0.510
0.571
0.489
0.489
0.224
0.598
0.489
0.308
0.394
0.510
0.510
0.510
0.759
0.489
0.503
0.308
0.308
0.671
0.470
0.510
0.716
0.410
0.510

SEM

0.099
0.099
0.114
0.128
0.109
0.109
0.050
0.134
0.109
0.069
0.088
0.114
0.114
0.114
0.170
0.109
0.112
0.069
0.069
0.150
0.105
0.114
0.160
0.092
0.114

Lower

0.042
20.458
20.189
20.567
20.579
0.421
20.055
20.880
20.379
20.244
20.134
0.211
0.211
0.211
20.405
20.879
20.835
20.044
20.244
20.164
20.520
20.689
20.085
20.392
20.689

Upper

0.458
20.042
0.289
20.033
20.121
0.879
0.155
20.320
0.079
0.044
0.234
0.689
0.689
0.689
0.305
20.421
20.365
0.244
0.044
0.464
20.080
20.211
0.585
20.008
20.211

t

2.517
22.517
0.438
22.349
23.199
5.940
1.000
24.485
21.371
21.453
0.567
3.943
3.943
3.943
20.295
25.940
25.339
1.453
21.453
1.000
22.854
23.943
1.561
22.179
23.943

4
3
8

E

.

L

.

K
o
u
a

e
t

a
l
.

p-value
significance
(two-tailed)

0.021*
0.021*
0.666
0.030*
0.005*
0.000*
0.330
0.000*
0.186
0.163
0.577
0.001*
0.001*
0.001*
0.772
0.000*
0.000*
0.163
0.163
0.330
0.010*
0.001*
0.135
0.042*
0.001*

df

19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19
19

Locate

Identify

Distinguish

Categorize

Cluster

Distribution

Rank

Compare

Associate

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 Table 4. Continued.

Paired differences

95% confidence interval of the
difference

Conceptual
visualization goal

Representation
method

Correlate

Map–Pcp
Map–Comp
Pcp–Comp

M

0.35
20.15
20.5

SD

0.671
0.366
0.513

SEM

0.150
0.082
0.115

Lower

0.036
20.321
20.740

Upper

0.664
0.021
20.260

t

2.333
21.831
24.359

df

19
19
19

p-value
significance
(two-tailed)

0.031*
0.083
0.000*

*Difference is significant (p,0.05).
aUdm: unified distance matrix; Pcp: parallel coordinate plot; Comp: SOM component plane display; Proj: 2D/3D projection; Surf: 2D/3D surface plot.

I
n
t
e
g
r
a
t
i
o
n

o
f

o
b
j
e
c
t
-
b
a
s
e
d

a
n
d

f
i
e
l
d
-
b
a
s
e
d
m
o
d
e
l
s

4
3
9

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 440

E. L. Koua et al.

Figure 3. Time to complete tasks for three exploratory tools: map, parallel coordinate plot
(PCP), and component plane display.

and the component plane display (p 5 0.002). Table 5 provides detailed statistics on
the comparison of time spent on the tasks using the different representations.

For the task ‘identify’, the difference is significant between the component plane
display and the parallel coordinate plot (p50.020). The map required much more
time (245 s) than the component plane display (103 s) and the parallel coordinate
plot (129 s) for the task ‘compare’. A significant difference was found between the
map and the component plane display (p50.012).

4.2 Usefulness and user reactions

Usefulness and user reactions were reported using a five-point scale (55very good,
45good, 35fairly good, 25poor, 15very poor). Usefulness includes compatibility,
ease of use/flexibility, and perceived user understanding. User reactions include user
the different measures of
satisfaction and preferences. A combined view of
usefulness and user reactions is presented in figure 4 for the tasks.

4.2.1 Compatibility with the user’s expectations for the different
tasks. For
compatibility with the user’s expectations of the tool for the tasks, the map was
found to be more suitable (mean54.85 and median55 on the five-point scale) for
the tasks ‘locate’, ‘’distinguish’, and ‘rank’. The component plane display was found
to be more appropriate for the tasks ‘identify’, ‘distribution’, ‘compare’, ‘associate’,
and ‘correlate’. The parallel coordinate plot was rated generally poor (2 on the five-
point scale) or fairly good (3 on the five-point scale) for all the tasks. The best
ratings of the parallel coordinate plot were for the tasks ‘rank’ and ‘locate’, where
the mean score53.75 and the median54 (same result for both tasks). These results
for compatibility confirm the performance analysis presented in section 4.1. for
correctness of response and time taken.

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 Table 5. Paired samples test for the time taken to complete the tasksa.

Paired differences

95% confidence interval of the
difference

Task
Locate

Identify

Distinguish

Categorize

Cluster

Distribution

Rank

Compare

Map–Pcp
Map–Comp
Pcp–Comp
Map–Pcp
Map–Comp
Pcp–Comp
Map–Pcp
Map–Comp
Pcp–Comp
Udm–Proj
Udm–Surf
Proj–Surf
Udm–Proj
Udm–Surf
Udm–Pcp
Proj–Surf
Proj–Pcp
Surf–Pcp
Map–Pcp
Map–Comp
Pcp–Comp
Map–Pcp
Map–Comp
Pcp–Comp
Map–Pcp
Map–Comp
Pcp–Comp

M
246.267
0.300
50.200
22.000
83.167
75.273
290.000
237.200
3.143
21.133
25.313
2.882
21.350
12.100
11.273
13.450
25.273
26.636
13.000
21.571
67.667
214.889
30.450
55.944
126.333
132.077
30.444

SD
53.526
52.374
52.757
132.990
140.597
90.459
82.595
118.804
151.201
58.481
83.028
82.722
74.025
43.086
42.626
64.779
106.432
35.870
107.480
142.078
193.987
84.948
75.701
67.753
245.452
160.423
110.263

SEM
13.820
11.711
13.622
42.055
40.587
27.274
31.218
26.565
57.149
15.100
20.757
20.063
16.553
9.634
12.852
14.485
32.091
10.815
76.000
53.701
64.662
20.023
16.927
15.969
100.205
44.493
36.754

275.909
224.212
20.984
273.136
26.164
14.502
2166.388
292.802
2136.695
233.519
249.555
239.649
235.995
28.065
217.364
216.868
246.229
230.734
2952.672
2132.972
281.445
257.133
24.979
22.252
2131.253
35.134
254.312

216.625
24.812
79.416
117.136
172.498
136.044
213.612
18.402
142.981
31.252
38.930
45.414
33.295
32.265
39.910
43.768
96.775
17.461
978.672
129.829
216.778
27.355
65.879
89.637
383.919
229.020
115.200

t
23.348
0.026
3.685
0.523
2.049
2.760
22.883
21.400
0.055
20.075
20.256
0.144
20.082
1.256
0.877
0.929
0.788
20.614
0.171
20.029
1.046
20.744
1.799
3.503
1.261
2.968
0.828

df
14
19
14
9
11
10
6
19
6
14
15
16
19
19
10
19
10
10
1
6
8
17
19
17
5
12
8

p-value
significance
(two-tailed)
0.005*
0.980
0.002*
0.614
0.065
0.020*
0.028*
0.178
0.958
0.941
0.801
0.888
0.936
0.224
0.401
0.365
0.449
0.553
0.892
0.978
0.326
0.467
0.088
0.003*
0.263
0.012*
0.432

I
n
t
e
g
r
a
t
i
o
n

o
f

o
b
j
e
c
t
-
b
a
s
e
d

a
n
d

f
i
e
l
d
-
b
a
s
e
d
m
o
d
e
l
s

4
4
1

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 Task
Associate

Correlate

Map–Pcp
Map–Comp
Pcp–Comp
Map–Pcp
Map–Comp
Pcp–Comp

M
40.444
66.250
32.833
25.222
54.500
54.000

SD
83.539
101.841
83.512
98.776
86.186
48.360

Table 5. Continued.

Paired differences

SEM
27.846
25.460
24.108
32.925
20.314
15.293

95% confidence interval of the
difference

223.769
11.983
220.228
250.704
11.641
19.406

104.658
120.517
85.895
101.148
97.359
88.594

t
1.452
2.602
1.362
0.766
2.683
3.531

df
8
15
11
8
17
9

p-value
significance
(two-tailed)
0.184
0.020*
0.200
0.466
0.016*
0.006*

*Difference is significant (p,0.05).
aUdm: unified distance matrix; Pcp: parallel coordinate plot; Comp: SOM component plane display; Proj: 2D/3D projection; Surf: 2D/3D surface plot.

4
4
2

E

.

L

.

K
o
u
a

e
t

a
l
.

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 Integration of object-based and field-based models

443

Figure 4. Overall ratings of the representations for all the different tasks combined: (a) all
representations for all the tasks; (b) tools used for detailed exploration tasks; and (c) tools
used for visual grouping (clustering) tasks. The vertical axis represents the rating scale
(55very good; 45good; 35fairly good; 25poor; 15very poor).

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 444

E. L. Koua et al.

4.2.2 Flexibility/ease of use. As with compatibility, the map was found to be easier
for the tasks ‘locate’, ‘distinguish’, and ‘rank’. The component plane display was
found to be easier to use for the tasks ‘identify’ and ‘distribution’. The parallel
coordinate plot was generally found to be difficult to use, especially for the tasks
‘distinguish’, ‘associate’, and ‘compare’, but less difficult to use for the tasks ‘rank’
and ‘locate’.

4.2.3 Perceived user understanding of the representations used. The map and the
component plane display were generally well understood for all the tasks The
parallel coordinate plot was not well understood for some of tasks such as
‘compare’, ‘associate’, ‘distinguish’, ‘distribution’, and ‘correlate’, but relatively well
understood for the task ‘rank’.

4.2.4 User satisfaction. In general, users were satisfied with the component plane
display and the map. The parallel coordinate plot was not satisfactory for the tasks
‘distinguish’, ‘associate’, ‘correlate’, and ‘distribution’.

tasks revealed that

4.2.5 User preference rating. The overall preference rating of the tools for the
different
the map was preferred for the tasks ‘locate’,
‘distinguish’ and ‘rank’. The component plane display was preferred for the tasks
‘identify’, ‘distribution’, ‘compare’ and ‘correlate’. The map and the component
plane display were generally equally rated with regard to preference for the task
‘associate’. The parallel coordinate plot was not preferred for any of the tasks in the
test.

5. Discussion

The analysis of the test results presented in the previous section reveal some
important differences between the SOM-based representations, the map, and the
parallel coordinate plot as they are applied to the taxonomy of visualization tasks
used for the evaluation. As proposed by Wehrend and Lewis (2000) for visual
representations generally, each of the representation methods by its inherent
structure seems to emphasize particular attributes and support a particular set of
visual tasks or inferences.

Maps were more effective for certain visual tasks such as locate and distinguish,
but less effective for the tasks of comparison and correlation, and for relating many
attributes (figure 3). Although easy to use in general for all the test participants,
since they are used to such visual representation of the world, a major problem was
that the map can show only a limited number of attributes, which is not appropriate
for investigating many attributes for the dataset in a reasonable time. This would
require many maps to complete some of the tasks. For visual comparison, the map
was not as effective as the component plane display. It required more time for tasks
that involve viewing relationships, since differences between classes geographically
are not noticeable despite the colour scheme used for classification.

Component plane displays were more effective for visual perception and were also
found easier to use for finding relationships and understanding the patterns. This
representation was especially effective and suitable for tasks involving visual
composition (Zhou and Feiner 1998), such as associate, correlate, identify, and
compare. Participants reported that the component plane display did not require
much effort to view the patterns and to relate different attributes in a single view.
Relationships between the attributes were found to be very apparent in component

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 Integration of object-based and field-based models

445

planes. This ability to permit immediate information extraction at a single glance
with less effort is one of the measures of the quality of a visualization (Bertin 1983).
The component plane display was less effective for the task of ranking among
similar data items because of the clustering. Participants needed some guidance in
using the component planes, but generally found the tool easier to use after a short
introduction.

Parallel coordinate plots required the participants to keep track of a large amount
of information before they could summarize answers for the tasks. This is an
important issue in visual encoding and perception (Cleveland and McGill 1984,
1986, MacEachren 1995), key elements in knowledge construction using visual
representations. This difficulty in keeping track of the information perceived makes
the parallel coordinate plot difficult for the test participants to understand. Some
participants reported that they found the parallel coordinate plots confusing: too
many lines were used, and thus the picture provided was not clear, despite the
brushing feature used. Considerable effort was needed, patterns were difficult to see,
and it required more time to examine a particular variable. This aspect was critical
in the user rating (compatibility, ease of use, understanding, satisfaction, and
preference rating) for the effectiveness of the tool and may explain the poor results.
The visual processing of graphical displays by users (visual recognition and visual
grouping) is an important factor in graphical perception (Cleveland 1993). The
display of the parallel coordinate plot was found to be difficult to understand, but
good for relating multiple variables, with its dynamic, interactive features. It was
particularly inappropriate for tasks such as cluster, distinguish, and locate for
patterns found at different locations, tasks that are related to visual attention (Zhou
and Feiner 1998).

Among the clustering tools,

the 2D/3D surface was found to be more
comprehensible for visual grouping (proximity, similarity) and helpful for finding
small differences within clusters, although it was reported that the use of a fuzzy
boundary made it slightly difficult to see cluster borders. The 2D/3D surface is
generally preferred above the unified distance matrix. The 2D/3D projection was
more used for representing proximity among data items. The unified distance matrix
was found to be clear and helpful with the use of the hexagonal grid. These SOM-
based tools for visual clustering were found to be better than the parallel coordinate
plot.

6. Conclusion

In this paper, we have presented an approach for assessing the usability and
usefulness of
the visual-computational analysis environment. The evaluation
method emphasizes exploratory tasks and knowledge-discovery support. It is based
on the examination of a taxonomy of conceptual visualization goal and tasks. These
tasks were decomposed into operational visualization tasks and experimental tasks
related to the particular dataset used in the evaluation. New representation forms
used to visualize geospatial data such as the SOM use new techniques to represent
the attribute spaces. An important step in the design of such visualization tools is to
understand the way users make interpretations of the information spaces. The
choice of a proper representation metaphor is crucial to the successful use of the
tools. To investigate the usability of the different representations, it was necessary to
examine the subject’s ability to perform visual tasks such as identifying clusters and
relating the visual features to problems in the data-exploration domain. This was

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 446

E. L. Koua et al.

realized by applying the visual taxonomy-based evaluation methodology in order to
compare the use of SOM-based representations with that of maps and parallel
coordinate plots.

The results of the usability testing provided some insight into the performance,
and usefulness of the SOM-based representations (unified distance matrix, 2D/3D
projection, 2D/3D surface, and component plane display) compared with the map
and the parallel coordinate plot for specific visual tasks. For visual grouping and
clustering, the SOM-based representations performed better than the parallel
coordinate plot. For detailed exploration of attributes of the dataset, correlations,
and relationships, the SOM component plane display was found to be more effective
than the map for visual analysis of the patterns in the data and for revealing
relationships. The map was generally a better representation for tasks that involve
visual attention and sequencing (locate, distinguish, rank).

The results of this test can serve as a guideline for designing geovisualization tools
that integrate different representations such as maps, parallel coordinate plots, and
other information-visualization techniques. The integration of visual tools can for
example use tools such as the SOM component plane display for visual processing of
relationships and correlations in the data. The results of users’ exploration with such
exploratory tools can be presented in maps as the final output of the exploration
process.
It

for each task, a particular visual
that
representation, i.e. SOM visualizations, maps, or even parallel coordinate plots,
performs best. The availability of the combination of the visualization result is the
best possible environment to support exploratory activities.

is also obvious from the test

Acknowledgements
This research was supported, in part, by the US NSF (grant # EIA-9983451) and by
the US National Cancer Institute (grant CA95949).

References
ANDRIENKO, N. and ANDRIENKO, G., 2005, Exploratory Analysis of Spatial and Temporal

Data: A Systematic Approach (Berlin: Springer).

BERTIN, J., 1983, Semiology of graphics: diagrams, networks, maps (Madison, WI: University

of Wisconsin Press).

CARROLL, J.M. and ROSSON, M.B., 1992, Getting around the task-artifact cycle: how to make
claims and design scenario. ACM Transactions on Information Systems, 10, pp.
181–212.
J.M.

In
Toward a Multidisciplinary Science of Human–Computer Interaction, J.M. Carroll
(Ed.), pp. 431–461 (San Francisco, CA: Morgan-Kaufmann).

and ROSSON, M.B.,

2003, Design

CARROLL,

rationale

theory.

as

CARROLL, J.M., ROSSON, M.B., CHIN, M.B. and KOENEMANN, J., 1998, Requirements
development in scenario-based design. IEEE Transactions on Software Engineering,
24, pp. 1156–1170.

CLEVELAND, W.S., 1993, A Model for Studying Display Methods of Statistical Graphics.

Journal of Computational and Graphical Statistics, 2, pp. 323–364.

CLEVELAND, W.S. and MCGILL, R., 1984, Graphical perception: Theory, experimentation
and application to the development of graphical methods. Journal of the American
Statistical Association, 79, pp. 531–554.

CLEVELAND, W.S. and MCGILL, R., 1986, An experiment

in graphical perception.

International Journal of Man–Machine Studies, 25, pp. 491–500.

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 Integration of object-based and field-based models

447

FABRICANT, S.I., 2001, Evaluating the usability of the scale metaphor for querying semantic
information spaces. In Spatial Information Theory: Foundations of Geographic
Information Science, D.R. Montello (Ed.), pp. 156–171 (Berlin: Springer).

FOTHERINGHAM, A.S., BRUNSDON, C. and CHARLTON, M., 2000, Quantitative Geography:

Perspectives on Spatial Data Analysis (London: Sage).

FUHRMANN, S., AHONEN-RAINIO, P., EDSALL, R.M., FABRIKANT, S.I., KOUA, E.L.,
TOBON, C., WARE, C. and WILSON, S., 2005, Making useful and useable
Geovisualization: design and evaluation issues. In Exploring Geovisualization, J.
Dykes, A.M. MacEachren and M.J. Kraak (Eds), pp. 553–566 (Amsterdam: Elsevier).
FUHRMANN, S.P., 2005, User-centred design of collaborative geovisualization tools. In
Exploring Geovisualization, J. Dykes, A.M. MacEachren and M.J. Kraak (Eds), pp.
553–576 (Amsterdam: Elsevier).

GALLUP, L.J., SACHS, J.D. and MELLINGER, A.D., 1999, Geography and Economic
Development. Pleskovic, B., Stiglitz, J.E., eds. World Bank Annual Conference on
Development Economics 1998, 127–178 (Washington DC: World Bank).

HAKLAY, M. and TOBON, C., 2003, Usability evaluation and PPGIS: toward a user-centered
design approach. International Journal of Geographical Information Science, 17, pp.
577–592.

KELLER, P. and KELLER, M., 1992, Visual Clues: Practical Data Visualization (Los Alamitos,

KOUA, E.L. and KRAAK, M.J., 2004a, Alternative visualization of large geospatial datasets.

CA: IEEE Computer Society Press).

Cartographic Journal, 41, pp. 217–228.

KOUA, E.L. and KRAAK, M.J., 2004b, Evaluating self-organizing maps for geovisualization.
In Exploring Geovisualization, J. Dykes, A.M. MacEachren and M.J. Kraak (Eds)
(Amsterdam: Elsevier).

MACEACHREN, A.M., 1995, How Maps Work: Representation, Visualization, and Design (New

York: The Guilford Press).

MACHEACHREN A.M., WACHOWICZ, M., EDSALL, R., HAUG, D. and MASTERS, R., 1999,
Constructing knowledge from multivariate spatiotemporal data:
integrating geo-
visualization (GVis) with knowledge discovery in databases. International Journal of
Geographical Information Science, 13, pp. 311–334.

MACEACHREN, A.M. and KRAAK, M.J., 2001, Research challenges in geovisualization.

Cartography and Geoinformation Science, 28, pp. 3–12.

MUNTZ, R.R., BARCLAY, T., DOZIER, J., FALOUTSOS, C., MACEACHREN A.M., MARTIN, J.L.,
PANCAKE, C.M. and SATYANARAYANAN, M., 2003, IT Road Map to a Geospatial
Future, Report of the Committee on Intersections Between Geospatial Information and
Information Technology (Washington, DC: National Academics Press).

NIELSEN, J., 1994, Usability Engineering (San Francisco, CA: Morgan Kaufmann).
OGAO, P.J. and KRAAK, M.J., 2002, Defining visualization operations for temporal
cartographic animation design. International Journal of Applied Earth Observation
and Geoinformation, 4, pp. 11–22.

QIAN, L., WACHOWICZ, M., PEUQUET, D.J. and MACEACHREN A.M., 1997, Delineating
Operations for Visualization and Analysis of Space–Time Data in GIS (Cincinnati, OH:
GIS/LIS).

ROBERTS, J.C., 2005, Exploratory visualization with multiple linked views. In Exploring

Geovisualization, M.J. Kraak (Ed.), pp. 159–180 (Amsterdam: Elsevier).

RUBIN, J., 1994, Handbook of Usability Testing: How to Plan, Design, and Conduct Effective

Tests (New York: Wiley).

SLOCUM, T.A., BLOK, C., JIANG, B., KOUSSOULAKOU, A., MONTELLO, D.R., FUHRMANN, S.
and HEDLEY, N.R., 2001, Cognitive and usability issues in geovisualization: a research
agenda. Cartography and Geographic Information Science, 28, pp. 61–76.

SWEENEY, M., MAGUIRE, M. and SHACKEL, B., 1993, Evaluating user–computer interaction: a
framework. International Journal of Man–Machine Studies, 38, pp. 689–711.

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 448

Integration of object-based and field-based models

TOBON, C., 2005, Evaluating geographic visualization tools and methods: an approach and
experiment based upon user tasks. In Exploring Geovisualization, J. Dykes, A.M.
MacEachren and M.J. Kraak (Eds), pp. 645–666 (Amsterdam: Elsevier).

WEHREND, S. and LEWIS, C., 2000, A Problem-Oriented Classification of Visualization
Techniques. Proceedings of the 1st IEEE Conference on Visualization, 1990, pp. 139–
143, San Francisco, California.

WELDON, J.L., 1996, Data mining and visualization. Database Programming and Design, 9,

pp. 21–24.

ZHOU, M.X. and FEINER, S.K., 1998, Visual Task Characterization for Automated Visual
Discourse Synthesis. Proceedings of ACM Computer Human Interaction 1998, April
18–23, Los Angeles, California.

Downloaded by [UTSA Libraries] at 17:52 04 October 2014 