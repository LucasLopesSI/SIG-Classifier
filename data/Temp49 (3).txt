1

ARTICLE

Revue des descripteurs tridimensionnels (3D) pour la
catégorisation des nuages de points acquis avec un système
LiDAR de télémétrie mobile
Sylvie Daniel

Résumé : La compréhension de nuage de points LiDAR consiste à reconnaitre les objets qui sont présents dans la
scène et à associer des interprétations aux nuages d’objets qui le composent. Les données LiDAR acquises en milieu
urbain dans des environnements à grande échelle avec des systèmes terrestres de télémétrie mobile présentent
plusieurs difficultés propres à ce contexte : chevauchement entre les nuages de points, occlusions entre les objets
qui ne sont vus que partiellement, variations de la densité des points. Compte tenu de ces difficultés, beaucoup de
descripteurs tridimensionnels (3D) proposés dans la littérature pour la classification et la reconnaissance d’objets
voient leurs performances se dégrader dans ce contexte applicatif, car ils ont souvent été introduits et évalués avec
des jeux de données portant sur de petits objets. De plus, il y a un manque de comparaison approfondie entre les
descripteurs 3D mis en œuvre dans des environnements à grande échelle ce qui a pour conséquence un manque de
connaissance au moment de sélectionner le descripteur 3D le plus adapté à un nuage de points LiDAR acquis dans
de tels environnements. Le présent article propose une revue approfondie des travaux portant sur l’application
des descripteurs 3D à des données LiDAR acquises en milieu urbain dans des environnements à grande échelle
avec des systèmes terrestres de télémétrie mobile. Les principaux descripteurs 3D appliqués dans de tels contextes
sont ainsi recensés. Une synthèse de leurs performances et limites est ensuite effectuée de manière comparative
sur la base des travaux disponibles dans la littérature. Enfin, une discussion abordant les éléments impactant le
plus les performances des descripteurs et des pistes d’amélioration vient compléter cette revue.

Mots-clés : LiDAR, descripteurs 3D, reconnaissance d’objets, classification, nuage de points, système de télémétrie
mobile, comparaison de performances.

Abstract: Understanding a LiDAR point cloud entails recognizing the objects present in the scene and associating
interpretations to the object clouds that make it up. LiDAR data acquired in a large-scale urban setting with land-
based mobile telemetry systems present several challenges specific to this context: overlapping point clouds,
occlusion between objects that are seen only partially, variations in point density. Given these challenges, many
of the 3D descriptors proposed in literature for classifying and recognizing objects see their performance degrade
in this application context, because they were often introduced and assessed with datasets dealing with small
objects. In addition, there is a lack of thorough comparison between the 3D descriptors implemented in large-scale
environments, which induces a lack of knowledge when the time comes to select the 3D descriptor best adapted to
a LiDAR point cloud acquired in such an environment. This article proposes an in-depth review of works on the
application of 3D descriptors to LiDAR data acquired in a large-scale urban setting through land-based mobile
telemetry systems. The key 3D descriptors applied in such a context are thus inventoried. A comparative synthesis
of their performance and limits is then performed on the basis of the works available in literature. Finally, a dis-
cussion on the elements having the biggest impact on the descriptors’ performances and on improvement leads
completes this review.

Key words: LiDAR, 3D descriptors, object recognition, classification, point cloud, mobile telemetry system,
performance comparison.

Received 14 April 2018. Accepted 23 April 2018.

S. Daniel. Département des sciences géomatiques, Université Laval, 1055, avenue du Séminaire, Québec (Québec) G1V 0A6, Canada.

Email pour la correspondance : Sylvie.daniel@scg.ulaval.ca.

Copyright remains with the author(s) or their institution(s). Permission for reuse (free in most cases) can be obtained from RightsLink.

Geomat. 72: 1–15 (2018) dx.doi.org/10.1139/geomat-2018-0001

Published at www.nrcresearchpress.com/geomat on 30 July 2018.

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.2

Introduction

Les dernières années ont vu un développement remar-
quable des systèmes de télémétrie mobile (STM),
installés sur des véhicules terrestres (ex. voiture,
camion), afin de répondre aux besoins croissants de
données tridimensionelles (3D) de grands territoires à
très haute résolution. Une telle information tridimen-
sionnelle peut être utilisée, par exemple, pour
l’élaboration de maquette 3D urbaine (Toth 2009), la pla-
nification et maintenance des routes et des rues (Hervieu
et Soheilian 2013), la fourniture de services basés sur la
localisation (Kaartinen et al. 2012), les applications de
réalité virtuelle (Hyyppä et al. 2013) pour n’en citer que
quelques-uns. Dans le domaine du transport, la collecte
de ces données 3D précises et conformes à la réalité va
bénéficier aux futurs systèmes de navigation autonome
et d’assistance aux conducteurs dans le cadre des
véhicules sans chauffeur (Williams et al. 2013). Elles dev-
raient permettre également l’élaboration de solution
semi-automatique pour l’inventaire des infrastructures
routières (Williams et al. 2013) telles que les panneaux
de signalisation ou bien encore des arbres en milieu
urbain (Tanhuanpää 2016). Des bénéfices sont aussi
anticipés en aménagement urbain, et dans la mise à jour
et la détection de changement des bases de données
urbaines (Daniel et Doran 2013).

La compréhension de nuage de points LiDAR, visant
notamment l’élaboration de cartographie 3D à haute
résolution, consiste à reconnaitre les objets qui sont
présents dans la scène et à associer des interprétations
aux nuages d’objets qui le composent. Les données
LiDAR acquises en milieu urbain à cette fin présentent
plusieurs difficultés. En effet, la multiplicité et la
proximité des objets dans les scènes urbaines entrainent
un chevauchement entre les nuages de points qui leur
sont associés, des occlusions entre les objets qui ne sont
vus que partiellement, des variations de la densité des
points suivant la proximité ou l’éloignement des objets
vis-à-vis du LiDAR au moment de l’acquisition des
données, et beaucoup de symétrie et de répétitivité de
motifs créant une ambiguïté dans l’identification d’ob-
jets. De plus, en variant l’échelle d’analyse du nuage de
points, de nombreux paramètres peuvent se dissiper et
deviennent difficiles à détecter. Compte tenu de ces
difficultés, le processus de reconnaissance d’objets à par-
tir de nuages de points acquis avec des STM en milieu
urbain reste un problème de recherche difficile.

Différentes approches ont été investiguées pour effect-
uer une reconnaissance d’objets d’intérêt au sein d’un
nuage de points acquis avec un STM dans des environne-
ments urbains à grande échelle (ex. 200 millions de
points couvrant 10 km de rues au sein d’un kilomètre
carré). Plusieurs de ces approches ont exploité les primi-
tives géométriques représentatives des objets dans la
scène urbaine tels que les formes cylindriques des
poteaux ou lampadaires (Lam et al. 2010), les lignes et

Geomat. Vol. 72, 2018

segments de droites associés aux contours des façades
et des fenêtres (Liu et Stamos 2007). Plus récemment, de
nouvelles approches visant à exploiter des descripteurs
3D ont été proposées (Kim et Hilton 2013; Lehtomäki
et al. 2016). De nombreux descripteurs 3D ont été
introduits dans la littérature scientifique pour alimenter
les méthodes de reconnaissance d’objets. Les articles
passant en revue les performances d’un nombre
important de descripteurs 3D s’inscrivent le plus sou-
vent dans le cadre de travaux de recherche visant le gui-
dage de robots autonomes (Golovinskiy et al. 2009;
Himmelsbach et al. 2009) ou bien la reconnaissance d’ob-
jets individuels ou domestiques (Chen et al. 2016). Ces
travaux impliquent en général des données issues
de système de télémétrie statique ou de caméra de pro-
fondeur (c.-à-d., données rouge-vert-bleu profondeur,
RGB-D) (Hänsch et al. 2014; Chen et al. 2016). Ces con-
textes ne présentent pas les mêmes difficultés que celles
inhérentes aux scènes urbaines (cf. paragraphe
précédent). D’autre part, les travaux de recherche por-
tant sur l’exploitation des descripteurs 3D et s’inscrivant
dans le domaine des scènes urbaines à grande échelle ne
proposent et comparent les performances que d’un sous-
groupe de descripteurs 3D, en général trois à cinq (Chen
et al. 2016; Lehtomäki et al. 2016). Il y a donc un manque
de connaissance au moment de sélectionner de manière
éclairée les meilleurs descripteurs 3D qui soient adaptés
aux données STM issues d’environnements urbains à
grande échelle, notamment dans le cadre d’applications
de génie civil et d’arpentage. Une comparaison appro-
fondie des descripteurs adaptés à ce contexte fait
également défaut dans la littérature.

Compte tenu de ce constat, le présent article a pour
objectif de proposer une revue élargie des descripteurs
3D exploitables à des fins de reconnaissance d’objets à
partir de nuages de points acquis avec des STM en milieu
urbain et dans des environnements à grande échelle.
Ceci constitue le contexte applicatif spécifique de cet
article, qui se distingue des domaines de la robotique,
de la vision par ordinateur, des couloirs ferroviaires et
des tunnels miniers du point de vue principalement du
volume de données à traiter et des difficultés à sur-
monter. Les principes de base de ces descripteurs 3D
seront présentés en premier lieu. Par la suite, les princi-
paux descripteurs 3D appliqués dans le contexte ciblé
par cet article seront recensés et détaillés. Puis une
synthèse de leurs performances et limites sera effectuée
de manière comparative sur la base des travaux disponi-
bles dans la littérature. Une discussion abordant les
éléments impactant le plus les performances et les pistes
d’amélioration sera proposée avant de conclure.

Principes de base des descripteurs 3D
Types et approches d’utilisation des descripteurs 3D

La construction des descripteurs 3D peut être vue
comme une composition de transformations visant à
extraire un ensemble de propriétés géométriques

Published by NRC Research Press

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.Daniel

3

Fig. 1. Liens entre descripteurs locaux et globaux visant à structurer le nuage de points en différents niveaux d’abstraction.
[Couleur en ligne.]

décrivant un nuage de points 3D. Les transformations
permettent de représenter les données sous une autre
forme que leurs formes initiales, et de mettre en relief
des propriétés géométriques de sorte qu’il sera facile de
les extraire. Ces propriétés peuvent éventuellement être
retransformées pour en extraire de nouvelles propriétés.
La représentation d’un descripteur par une succession
de transformations est équivalente à dire qu’à chaque
étape, on part d’un nuage de vecteurs à N-dimensions vers
un nuage de vecteurs à M-dimensions. À la première
étape, N est égal, au minimum, à 3 (c.-à-d., coordonnées
XYZ associés à chaque point). À la dernière transforma-
tion, M est égal à la dimensionnalité du descripteur.

Les descripteurs 3D peuvent être globaux ou locaux.
Lorsqu’un point et son voisinage immédiat sont consi-
dérés par un descripteur, celui-ci est local. Lorsque le
descripteur caractérise le nuage de points associé à un
objet (c.-à-d., un segment de points), il est considéré
comme global. On définit aussi un descripteur comme
global lorsqu’il exploite la totalité du nuage de points
pour extraire une propriété. Les descripteurs globaux
peuvent être déduits des descripteurs locaux associés à
des primitives ponctuelles. Le regroupement progressif
des primitives ponctuelles et descripteurs 3D associés
permet de globaliser la caractérisation du nuage de
points. La figure 1 ci-dessous synthétise les liens entre les
descripteurs locaux et globaux au travers du regroupe-
ment successif des primitives permettant de structurer
le nuage de points en différents niveaux d’abstraction.

Les approches d’utilisation de descripteurs 3D pour la
caractérisation des nuages de points 3D diffèrent selon
le type du descripteur (local ou global) et le niveau d’ab-
straction (objet ou primitive point). Celles-ci visent
divers objectifs pour une compréhension et analyse de
scènes urbaines. Ainsi, on peut chercher à effectuer une
interprétation sémantique du nuage de points consis-
tant à attribuer un label à chaque point. On parle alors
de classification du nuage de points. On peut également
effectuer une analyse du nuage de points selon les objets
qui le constituent. On va alors chercher soit à localiser
des objets, soit à les catégoriser soit à les reconnaitre.
La localisation d’objet vise à circonscrire et isoler des

groupes de points associés à un même élément dans la
scène. Elle exploite souvent des connaissances a priori
sur la forme ou le contexte associé aux objets à localiser
(ex. dans une scène urbaine, la localisation d’objets
bâtis exploitent le fait que les points sont fréquemment
répartis sur une surface plane et que ces surfaces ont
tendance à avoir une orientation verticale). Une fois les
objets isolés, il est possible de les catégoriser en regrou-
pant ceux qui présentent des caractéristiques similaires.
La reconnaissance d’objets quant à elle s’effectue en
comparant les caractéristiques associées à chaque
catégorie d’objets à des caractéristiques connues
stockées dans une base de données. On attribue alors
une interprétation sémantique à chaque catégorie. La
démarche de catégorisation s’apparente à celle de recon-
naissance. En effet, dans le cas de la catégorisation, on
compare les caractéristiques d’un objet isolé spatiale-
ment dans le nuage de points aux caractéristiques
d’autres objets dans le nuage de points. Les objets
sont
caractéristiques
présentant des
regroupés dans une même catégorie (ex. catégorisation
des objets dans le groupe « végétation » si leurs normales
locales présentent une forte variabilité). Dans le cas de la
reconnaissance, la comparaison se fait avec des objets
prédéfinis stockés dans une base de données. La
catégorisation a pour avantage de catégoriser le nuage
de points sans nécessiter de connaître la signification
de chaque catégorie (cf. fig. 2).

similaires

La classification du nuage de points, la catégorisation
et la reconnaissance des objets font appel au calcul de
descripteurs 3D associés aux points ou aux segments
extraits. La classification et la reconnaissance impli-
quent le plus souvent des méthodes d’apprentissage
machine (c.-à-d., « machine learning »). Dans ce contexte,
des échantillons de points ou de segments sont utilisés
pour apprendre des descripteurs 3D représentatifs des
classes ou objets à reconnaitre. Les approches de recon-
naissance d’objets exploitent également des fonctions
de coût d’appariement pour déterminer l’objet de
référence qui s’apparente le plus au segment étudié.
Quant à la catégorisation d’objets, ce sont les distances
entre descripteurs 3D ou les mesures de similarité qui

Published by NRC Research Press

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.4

Geomat. Vol. 72, 2018

Fig. 2. Extraction d’objets de la catégorie quatre roues [jeu de données « IQmulus & TerraMobilita Contest » (Vallet et al. 2015)].
[Couleur en ligne.]

conditionnent le regroupement de segments de points
au sein d’une même catégorie.

Dans le cadre de la catégorisation et la reconnaissance
d’objets, il est possible d’effectuer la comparaison
directement sur le nuage de points du segment extrait.
On effectuera alors un recalage entre le nuage de points
associé à l’objet de référence (issue de la scène ou d’une
base de référence) et le nuage de points associé au seg-
ment à catégoriser ou à reconnaitre dans la scène. A cet
effet, des algorithmes tels que « random sample consen-
sus », RANSAC (Tarsha-Kurdi et al. 2008), « iterative clos-
est point », ICP (Pomerleau et al. 2013), « four congruent
point set » (4CPS) (Theiler et al. 2013) ont souvent été
utilisés dans la littérature. Le « random sample consen-
sus » (RANSAC) est une méthode itérative permettant
d’estimer les paramètres d’un modèle mathématique
prédéfini (ex. un plan, une droite 3D) à partir d’un jeu
de données pouvant contenir des données aberrantes.
Pour ce faire, il sous-échantillonne aléatoirement le
jeu de données. Ce sous-échantillon permet de calculer
les paramètres du modèle. Ensuite, ce modèle est
confronté à tous les éléments du jeu de données et le
nombre de données en désaccord avec ce modèle est
recensé. Ces deux étapes sont itérées jusqu’à ce qu’il y
ait un nombre suffisant d’éléments en accord (c.-à-d.,
consensus) avec le modèle estimé. Le « random sample
consensus » (RANSAC) permet en général d’estimer de
manière robuste les paramètres d’un modèle, même s’il
y a un nombre important de données aberrantes.
Lorsque le nombre de paramètres à estimer devient
grand, l’algorithme devient exigeant en terme de temps
de calcul. L’algorithme « iterative closest point » (ICP) vise
à minimiser itérativement la distance entre deux nuages
de points. Plus spécifiquement, il consiste à réviser
itérativement les transformations (translation, rotation)
nécessaires pour minimiser la distance entre les deux
nuages de points. Cette approche est en général stable
et robuste. Cependant, elle requiert une position initiale
des nuages de points relativement proche pour assurer
une convergence vers un résultat valide. L’algorithme

« four congruent point set » (4CPS) vise à déterminer la
transformation rigide qui amène le plus grand nombre
de points du premier nuage de points à une distance
inférieure à un seuil prédéfini du deuxième nuage de
points. Pour ce faire, il extrait du second nuage de points
tous les ensembles de quatre points coplanaires qui sont
congruents avec un groupe donné de quatre points
coplanaires issu du premier nuage de points. En se basant
sur ces ensembles mis en correspondance, il est alors pos-
sible de calculer la meilleure transformation rigide qui
permet de les aligner au mieux. Cette approche est
itérée avec tous les groupes de quatre points coplanaires
extraits du premier nuage de points jusqu’à trouver la
meilleure transformation. L’algorithme « four congruent
point set » (4CPS) ne requiert pas que les deux nuages de
points soient initialement proches ni qu’ils aient
une large zone commune de chevauchement. C’est une
approche qui est moins performante ou moins pratique
si les nuages de points sont très grands (l’hypothèse
de transformation rigide n’est alors plus adaptée) ou si
les nuages de points ne sont pas bruités (d’autres appro-
ches plus simples peuvent alors s’appliquer). La figure 3
propose une synthèse des différentes approches d’utilisa-
tion de descripteurs 3D pour la caractérisation des nuages
de points 3D à des fins de classification, de catégorisation
ou bien encore de reconnaissance.

Points d’intérêt

Le calcul des descripteurs 3D est souvent exigeant en
termes de temps de calcul, surtout s’il s’effectue sur la
scène complète plutôt que sur des segments de points.
Dans ce cas, il n’est pas raisonnable de l’envisager pour
tous les points du nuage étant donné le nombre très
important de ceux-ci. Par conséquent, les points d’intérêt
sont utilisés pour sélectionner des points intéressants
dans le nuage. En général, le but des détecteurs de
points d’intérêt est de déterminer les points qui sont
différents afin de permettre une description efficace des
objets et une mise en correspondance de ceux-ci lors de
variations de point de vue. Souvent ces points d’intérêt

Published by NRC Research Press

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.Daniel

5

Fig. 3. Synthèse des approches de classification de nuages de points et de catégorisation et reconnaissance d’objets à l’aide de
descripteurs tridimensionnels (3D). [Couleur en ligne.]

ne sont pas dissociés du descripteur auquel ils se rappor-
tent et portent alors le même nom. Plusieurs méthodes
sont recensées dans la littérature concernant l’extrac-
tion de points d’intérêt. Les prochains paragraphes en
présentent une synthèse.

Les détecteurs de points d’intérêt fréquemment utilisés
correspondent à une adaptation en 3D de détecteurs de
points élaborés initialement pour des images bidimension-
nelles (2D). Ainsi, le détecteur de points d’intérêt Harris 3D
est une extension en 3D du détecteur de coins de Harris
(Harris et Stephens 1988) pour les images 2D. Le calcul des
gradients d’intensité relatif à l’image est remplacé par le
calcul des normales à la surface locale en chaque point.
Un point d’intérêt est détecté là où il y a présence de
changements locaux (c.-à-d., variation significative des nor-
males dans un petit voisinage). Le détecteur de points
d’intérêt « scale invariant feature transform », SIFT 3D
(Flint et al. 2007) est une extension en 3D du détecteur
« scale invariant feature transform » (SIFT) proposé par
Lowe (Lowe 2004). Cette approche implique une démarche
identique à celle appliquée aux images. Elle utilise une
version 3D de la matrice Hessienne afin de sélectionner
les points d’intérêt. Une fonction de densité de points
f(x, y, z) est alors approximée par échantillonnage spatial
régulier des données. Puis un espace d’échelles est élaboré
à partir de la fonction de densité par application successive
de filtres gaussiens de taille variable. Les maxima
du déterminant Hessien sont alors détectés en tant que
points d’intérêt. Le détecteur « smallest univalue segment
assimilating nucleus » (SUSAN) 3D est une extension
du détecteur « smallest univalue segment assimilating
nucleus », SUSAN (Smith et Brady 1997) dédié à la

détection de coins dans les images. Sa démarche est
différente de celle du détecteur Harris. Au lieu d’évaluer
des gradients locaux, sensibles au bruit, une approche
morphologique est appliquée. L’opérateur de détection uti-
lise l’intensité des points. Un voisinage circulaire de rayon
prédéterminé est défini pour chaque point. Les points
inclus dans ce voisinage sont répartis en deux groupes :
ceux qui ont une intensité similaire au point central du
voisinage, et ceux qui ont une intensité différente.
Dans les régions plus ou moins homogènes du nuage
de points, la surface locale d’intensité similaire couvre
presqu’entièrement le voisinage. Par conséquent, les
coins présents dans le nuage peuvent être détectés
comme les endroits où le nombre de points avec des
intensités similaires dans un voisinage local atteint un
minimum local et est inférieur à un seuil prédéfini.

La littérature propose plusieurs détecteurs de points
d’intérêt qui ont été élaborés spécifiquement pour
les nuages de points 3D. Ainsi, le détecteur de points
d’intérêt « intrinsic shape signature », ISS (Zhong 2009)
est une technique basée sur des mesures de qualité rela-
tives à des régions. Elle utilise l’amplitude de la plus petite
valeur propre, calculée sur un voisinage local (afin d’in-
clure uniquement les points de ce voisinage présentant
de grandes variations le long de chaque direction princi-
pale) et le rapport entre deux valeurs propres successives
(afin d’exclure les points de ce voisinage ayant des
étendues similaires le long des directions principales).
La figure 4 ci-dessous propose un exemple d’utilisation de
points d’intérêt afin de recaler deux segments de points.
L’extraction de points d’intérêt peut se faire également
selon une approche de filtrage multiéchelle. Elle consiste

Published by NRC Research Press

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.6

Geomat. Vol. 72, 2018

Fig. 4. Appariement de points d’intérêt [extrait de la docu-
mentation de la bibliothèque PCL (Rusu et Cousins 2011)].
[Couleur en ligne.]

- Descripteurs à base de points de vue (Rusu et al.

2010; Steder et al. 2010);

- Descripteurs à base d’histogrammes (Körtgen

et al. 2003; Rusu et al. 2009).

Les descripteurs à base de graphe sont utilisés pour
caractériser des objets déformables et pouvant se
présenter sous différentes postures. On cite par exemple,
les nuages de points 3D de piétons et de mobilier urbain.
Ces descripteurs ont été très peu utilisés dans le cas des
nuages de points LiDAR acquis dans des environnements
à grande échelle.

Les descripteurs à base de transformations sont
obtenus en analysant le nuage de points 3D dans un
espace transformé. Ils sont basés sur l’extension en
3D de transformées mathématiques telles que la
transformation de Fourier 3D et la transformation en
ondelettes. Ces transformations ont la capacité
de compacter le signal 3D, d’être invariantes à un
ensemble d’opérations géométriques (translation,
rotation, : : : ) et de permettre d’analyser progressive-
ment le nuage de points, d’un niveau grossier vers un
niveau fin. Cependant, le calcul de ces transforma-
tions est complexe pour les moments ou degrés
supérieurs. De plus, ces derniers ne sont pas
nécessairement associés à des interprétations de la
géométrie du nuage de points et calculer des moments
ou degrés supérieurs n’augmente pas nécessairement
la précision et la distinction du descripteur. Ces
descripteurs ont été utilisés surtout pour la recherche
par le contenu dans des bases de données de nuages
de points, peu pour le traitement des nuages de points
issus de STM.

Les descripteurs à base de points de vue sont des
descripteurs prenant en compte une information selon
un ou plusieurs points de vue. En reconnaissance de for-
mes, les modèles et nuages de points 3D sont projetés
selon plusieurs points de vue. Les vues sont ensuite
ordonnées et comparées à des vues de référence
stockées dans une base de données. Ces descripteurs
fonctionnent mieux avec des nuages de points de fai-
bles dimensions, correspondant à des objets isolés, et
avec une pose peu éloignée (relativement à la taille du
nuage de points) de l’objet décrit. La complexité de la
scène urbaine dans le contexte de la télémétrie ter-
restre mobile ne permet pas de satisfaire l’ensemble
de ces critères. Ainsi, les objets peuvent se chevaucher,
comme c’est le cas entre le mobilier urbain et les arbres
ou les lampadaires. De plus, les structures peuvent être
de grande échelle et étendues, telles que les bâtiments.
Leur projection sera donc complexe.

Les descripteurs à base d’histogrammes se divisent en

trois groupes :

à appliquer un opérateur ou un filtre au nuage de points
3D. La déformation provoquée par l’opérateur doit
mettre en évidence la présence des points saillants lors
de la variation de l’un de ses paramètres (ou échelle).
Parmi les méthodes existantes, on peut citer :

- L’opérateur différence de normales (Ioannou et al.
2012) : il consiste à calculer la normale en un
point à deux échelles différentes (c.-à-d., deux
tailles de voisinage différent). L’opérateur calcule
la différence entre ces deux normales afin de
caractériser la géométrie locale du nuage de
points.

- L’opérateur Laplace Beltrami (Unnikrishnan
et Hebert 2008) : celui-ci correspond au calcul de
la divergence du gradient.

Un des avantages du traitement multiéchelle est qu’il
est parallélisable. Un second avantage est qu’à la fin du
traitement, les points d’intérêt se voient associés à des
échelles caractéristiques.

Certains détecteurs de points d’intérêt s’appliquent
davantage aux nuages de points 2D ou issus de caméra
de profondeur qu’aux nuages de points issus de STM
étant donné qu’ils impliquent la transformation du
nuage de points en une image de profondeur. Le
détecteur « normal aligned radial feature », NARF
(Steder et al. 2010) en est un exemple.

Revue des descripteurs 3D adaptés aux données
issues de systèmes de télémétrie mobile (STM)
dans des environnements urbains à grande échelle
Qu’ils soient calculés de manière locale ou globale, les
descripteurs 3D peuvent être classés selon les principales
catégories suivantes :

- Descripteurs à base de graphe (Shah et al. 2013);
- Descripteurs à base de transformations (Urban

and Weinmann 2015);

- Sacs de mots visuels;
- Histogrammes d’occupation;
- Histogrammes d’attributs géométriques.

Published by NRC Research Press

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.Daniel

7

Fig. 5. Système de coordonnées cylindriques et subdivision du descripteur « global Fourier histogram », GFH : (a) subdivision
de la région support selon r (e = 2 cellules), z (e = 2 cellules) et θ; (b) illustration du partitionnement du plan support selon
r (I = 6 cellules) et θ (J = 16 cellules). [Couleur en ligne.]

Les sacs de mots visuels (« bags of words/bags of
features ») mesurent l’occurrence des objets géo-
métriques associés à des interprétations appelées mots
visuels. Les mots visuels peuvent correspondre à des prim-
itives géométriques (coins, plans, arêtes), à des objets
entiers, à des centres de regroupement de points ou de
descripteurs. Dans le contexte des nuages de points d’en-
vironnements urbains à grande échelle, l’application de
ces descripteurs peut être déclinée selon deux cas de fig-
ure. Dans le premier cas, la description vise à caractériser
le nuage de points par les classes de caractéristiques/
primitives qui le composent, et leurs occurrences. La
caractérisation des primitives élémentaires est obtenue
par des descripteurs locaux. Dans le second cas, la
compréhension globale de la scène est ciblée en identifi-
ant les objets qui la composent et en représentant leurs
occurrences.

Les histogrammes d’occupation décrivent la réparti-
tion des points 3D du nuage de points local dans
l’espace autour d’un point d’intérêt. Ce dernier est
représenté par un système local de coordonnées (« local
reference frame », LRF) et son estimation doit être invar-
iante par transformations affines (combinaisons de
rotation, translation et changement d’échelle). La plu-
part des estimateurs du système local de coordonnées
se basent sur les normales locales ou sur l’analyse en
composantes principales du nuage de points local. Le
descripteur « spin image » (Guo et al. 2015) figure parmi
les descripteurs d’occupation. Celui-ci correspond à un
histogramme 2D formé en faisant tourner un plan
autour d’un vecteur normal à la surface de l’objet et
en comptant le nombre de points 3D qui tombent dans
chaque cellule de résolution définie au niveau du plan.
Initialement, la taille des cellules de résolution est
élevée limitant le nombre de points. Ensuite, les points
associés à des descripteurs saillants sont extraits. Ces
descripteurs sont recalculés et filtrés itérativement en
diminuant la taille de cellules jusqu’à atteindre une taille
minimale. Le principe du descripteur spin image est

développé davantage par le descripteur « signature of his-
tograms of orientations », SHOT (Tombari et al. 2010a) qui
construit un histogramme 2D des normales locales
calculées dans le voisinage du point d’intérêt. Plus
spécifiquement, ce sont les orientations des normales
locales par rapport à la normale du point d’intérêt qui
sont recensées dans l’histogramme. L’introduction du
descripteur « global Fourier histogram », GFH (Chen
et al. 2014) a été motivée par les inconvénients du descrip-
teur spin image et le fait que des objets situés au niveau
du sol dans un environnement urbain admettent
rarement un axe de rotation autre que l’axe verticale.
En effet, au moment de faire tourner le plan autour
du vecteur normal, le descripteur spin image omet
la coordonnée angulaire dans le système local de
coordonnées cylindriques. Pour sa part, le descripteur
GFH exploite cette coordonnée angulaire et présente
une invariance en rotation le long de l’axe vertical. Le
descripteur GFH est créé pour un point orienté qui
définit alors un système de coordonnées cylindriques
centré sur l’objet (c.-à-d. segment de points). Le point
central de l’objet est souvent choisi comme point
orienté et l’orientation est donnée par la direction du
vecteur normal en ce point. Le calcul des coordonnées
cylindriques r et z est identique à celui intervenant dans
le descripteur spin image. La région support du calcul
du descripteur, dont l’axe est perpendiculaire au sol
(z = [0 0 1]T), est partitionnée en cellules I, J, K également
distribuées dans l’espace des coordonnées cylindriques
(r, θ, z) comme l’illustre la figure 5. Comme pour les
précédents descripteurs d’occupation, le descripteur
GFH se présente sous la forme d’un histogramme 3D et
est calculé en comptabilisant le nombre de points qui
tombent dans chaque cellule de résolution définie au
niveau du support. Afin d’obtenir une invariance en
rotation selon l’axe vertical, un système global de
coordonnées est introduit en utilisant l’axe z et le vec-
teur normal n au point orienté. L’histogramme 3D est
alors analysé à l’aide de la transformée de Fourier rapide

Published by NRC Research Press

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.8

Geomat. Vol. 72, 2018

Fig. 6. Repère local de référence et caractéristiques associés
à la paire de points : point source – point cible (PsPt).
[Couleur en ligne.]

unidimensionelle, 1D (FFT) selon la dimension J de la
coordonnée angulaire θ. En effet, une rotation selon
cette dimension se traduit par un décalage de phase
dans le domaine fréquentiel et les amplitudes de la
transformation sont invariantes en rotation selon
cette dimension.

Les descripteurs d’occupation 3D « shape context »
(Körtgen et al. 2003) et « unique shape context », USC
(Tombari et al. 2010b) s’apparentent aux descripteurs
SHOT et spin image mais ils s’appuient sur une autre
technique. Dans leur cas, un système local de
coordonnées sphériques est construit autour du point
d’intérêt à la suite d’une triangulation du nuage de
points local. Le nombre de points 3D qui tombent dans
chaque cellule de résolution définie selon un espace-
ment logarithmique est alors décompté. Le descripteur
« pairwise 3D shape context » (Yu et al. 2014) est une
adaptation du descripteur 3D shape context impliquant
une analyse des points deux à deux au lieu d’une analyse
de chaque point individuellement vis-à-vis de son voisin-
age. Cette estimation d’un système local de coordonnées
propre à ces trois descripteurs (c.-à-d., 3D shape context,
USC, pairwise 3D shape context) apporte une stabilité
comparativement au descripteur SHOT qui s’appuie sur
l’estimation des normales locales ce qui crée des
ambiguïtés et un manque de robustesse. Cependant, la
détermination du système local de coordonnées rend
les calculs plus complexes du point de vue de l’estima-
tion des descripteurs. De plus, ces descripteurs basés
sur une estimation améliorée du système local
de coordonnées ne sont pas assez robustes aux effets de
troncatures, d’occlusion et aux variations de point de
vue, même pour des nuages de points de faible dimen-
sion. Or, pour les nuages de points LiDAR de scènes
urbaines, une même forme géométrique peut avoir plu-
sieurs instances dans différents emplacements de la
scène. Les points 3D sur ces formes peuvent donc avoir
des répartitions différentes. En conséquence, les descrip-
teurs d’occupation associés risquent d’être non simi-
laires et donc non efficaces à des fins de reconnaissance
d’objets. Le descripteur « principal axes descriptor »,
PAD (Chen et al. 2017) est un descripteur d’occupation
qui a été spécifiquement conçu pour la catégorisa-
tion et la reconnaissance d’équipements de construc-
tion. C’est un descripteur 3D global qui tire profit de la
structure rectangulaire et de la symétrie de droites
présentées par ces équipements. Une analyse en com-
posantes principales est effectuée afin de déterminer
les directions principales. Une grille d’occupation est
formée le long de ces directions principales et les
points du segment sont distribués dans les cellules de
la grille 3D. Des caractéristiques géométriques glob-
ales sont calculées à partir de cette grille telles que :
la distribution de l’occupation des cellules; les varia-
tions dimensionnelles (c.-à-d., longueur, largeur, hau-
teur de l’objet); le profil de la forme (c.-à-d., hauteur
maximum des cellules occupées de la grille selon la

longueur de l’objet); le nombre de plans constitutifs
de l’objet.

Les descripteurs d’attributs géométriques permettent
de décrire le nuage de points localement en analysant
les relations locales entre des attributs géométriques
estimés en chaque point 3D. Face aux problèmes d’occlu-
sion et de points cachés, ces descripteurs sont plus
robustes que les descripteurs d’occupation. Le problème
de manque de robustesse du système local de
coordonnées ne se pose pas, car les points 3D sont
étudiés les uns relativement aux autres et non relative-
ment au système local de coordonnées. Cependant, le
problème causé par ces descripteurs réside dans leur
sensibilité aux changements géométriques au voisinage
des structures d’intérêt. Ceci s’explique par le fait que
de nombreuses relations locales sont redondantes et
atténuent l’information contenue dans les attributs des
points saillants. Tel est le cas des descripteurs basés sur
un histogramme de caractéristiques ponctuelles « point
feature histogram », PFH (Rusu et al. 2008), et « fast point
feature histogram » FPFH (Rusu et al. 2009). Le descrip-
teurs PFH implique le calcul des normales en chaque
point du nuage. Pour un point Pi du nuage, l’ensemble
des k voisins de Pi (Pik) dans un rayon r est déterminé.
Pour chaque paire de points P1 et P2 de l’ensemble (Pik),
le point dont la normale fait le plus petit angle avec le
vecteur !
P1P2 est défini comme le point source Ps, l’autre
est alors défini comme le point cible Pt. Un repère de
référence local UVW est alors établi pour la paire de
points PsPt (cf. figure 6). Quatre valeurs sont alors
calculées comme caractéristiques de la paire de points :
trois valeurs d’angles (α, θ, φ) associés à la différence entre
les normales aux points Ps et Pt et une valeur de distance
→
d associée à la norme du vecteur
e . Pour finaliser le calcul
du descripteur PFH, les quadruplets (α, θ, φ, d) calculés
pour chaque paire de points P1 et P2 de l’ensemble (Pik)
sont répartis dans les intervalles d’un histogramme. Les
valeurs associées à chacun de ces intervalles constituent
les valeurs du descripteur.

Le descripteur PFH étant exigeant en matière de cal-
culs, des améliorations y ont été apportées donnant ainsi
naissance au descripteur FPFH. Celui-ci mesure les
mêmes angles que PFH mais il estime l’ensemble des
valeurs seulement entre tous les points et leurs k
plus proches voisins, suivi d’une repondération de

Published by NRC Research Press

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.Daniel

9

l’histogramme du point par les histogrammes des points
voisins. Le descripteur « viewpoint feature histogram »,
VFH (Rusu et al. 2010) est une extension de FPFH
pour une analyse globale d’un nuage de points. Il est
constitué de deux composants : l’un relatif au point de
vue, l’autre relatif à une extension du FPFH. Le descrip-
teur « ensemble of shape function », ESF (Chen et al.
2017). Parmi les descripteurs d’attributs géométriques
figure aussi le descripteur « histogram of local point
level » (Lalonde et al. 2006). Appliqué à un objet (c.-à-d.,
segment de points), il permet d’établir des statistiques
sur les caractéristiques locales de l’objet. Ainsi, pour
chaque point p du segment, la matrice de covariance du
point et de son voisinage est calculée puis elle est
décomposée selon ses valeurs propres λ0, λ1, λ2
(λ0 ≥ λ1 ≥ λ2) et ses vecteurs propres. Cela revient à
effectuer une analyse en composantes principales du
point p et de son voisinage. Trois mesures, L1, L2 et L3,
sont calculées à partir des valeurs propres : L1 = λ0;
L2 = λ0 − λ1; e3 = λ1 − λ2. Elles sont représentatives de
la tendance de la surface au point p à être assimilée à
une surface respectivement ponctuelle, courbe ou sur-
facique. Trois histogrammes sont alors établis à partir
des valeurs L1, L2, L3 prises par tous les points du seg-
ment. Trois mesures L, P, S, similaires à L1, L2, L3 ont
été proposées par Weinmann et al. (2015). L, P et S, peu-
vent être assimilées à la probabilité d’un segment de
points d’être catégorisé respectivement comme une
structure linéaire (c.-à-d., 1D), surfacique (c.-à-d., 2D)
ou volumétrique (c.-à-d., 3D). L’expression de chaque
mesure est donnée dans l’éq. 1 ci-dessous, avec λi corre-
spondant à la valeur propre i.
− λ
− λ
λ
λ

ð1Þ

P =

L =

S =

λ
λ

ðλ

ðλ

Þ

Þ

0

2

2

1

1

0

0

0

Plusieurs descripteurs 3D globaux élaborés à partir
d’un ensemble de caractéristiques et mesures
géométriques associées à un segment de points ont été
proposés dans la littérature. Par exemple, on retrouve
des descripteurs 3D constitués des trois dimensions de
la boite englobante orientée d’un segment (Chen et al.
2014). Dans (Golovinskiy et al. 2009), un descripteur est
calculé pour un segment de points en rassemblant
les mesures suivantes au sein d’un vecteur de
caractéristiques : nombre de points du segment, volume
estimé, hauteur moyenne (c.-à-d., coordonnée z),
écart-type des coordonnées en z, écart-type dans les deux
principales directions planaires. Lehtomäki et al. (2016)
propose un calcul de descripteur similaire incluant
17 caractéristiques, les quatre premières décrivant la
taille et forme globale du segment, et le reste décrivant
la distribution des points dans différentes directions.

Plutôt que d’appliquer un seul et même descripteur 3D
pour la catégorisation ou la reconnaissance de tous les
objets présents dans un nuage de points, il est possible
de sélectionner le descripteur le plus adapté à chaque

type d’objet à partir d’un ensemble prédéfinis de descrip-
teurs. C’est l’approche proposée par Taati et Greenspan
(2011). Leur descripteur VD-LSD (variable dimensional
local shape descriptor) incorpore une large classe de
descripteurs 3D (i.e. spin image, pairwise geometric
histogram, : : : ). La sélection du descripteur se fait de
manière systématique sur la base d’un ensemble de
propriétés géométriques (similaires à celles recensées
dans le précédent paragraphe) et une méthode d’optim-
isation (c.-à-d., algorithme génétique, recuit simulé, : : : ).
Dans d’autres travaux, on a essayé de combiner plusieurs
descripteurs 3D. Ainsi, Kim et Hilton (2013) ont combiné
les descripteurs géométriques FPFH, 3D shape context
(SC), SHOT et USC en incorporant une information sur
les points d’intérêt voisins et leurs descripteurs, et ce,
afin de réduire le problème de symétrie rencontré dans
les scènes urbaines extérieures.

Performances des descripteurs 3D appliqués aux
données issues de STM dans des environnements
urbains à grande échelle

La présente section recense les principaux travaux de
classification, catégorisation ou reconnaissance de nuages
de points acquis avec des STM dans des environnements
urbains à grande échelle. Elle dresse le portrait des perfor-
mances individuelles obtenues par les descripteurs 3D
dans ce contexte et des performances comparatives.

Dans Yu et al. (2015), une nouvelle méthode est
proposée pour la reconnaissance de mobilier urbain
(c-à-d., panneau de signalisation, lampadaire, arrêt de
bus) dans des nuages de points acquis avec des STM. La
démarche implique le descripteur FPFH ainsi qu’une
fonction de coût d’appariement entre les segments de
points extraits du nuage et des objets de référence.
Cette méthode a été testée avec quatre jeux de données
STM différents. Les performances moyennes obtenues
pour les trois classes d’objet d’intérêt sont 0,949 pour
la complétude (cf. éq. 2), de 0,971 pour l’exactitude
(cf. éq. 3), de 0,922 pour la qualité (cf. éq. 4) et de 0,960
pour la mesure F1 (cf. éq. 5). Ces résultats sont grande-
ment affectés par les performances de la segmentation
préalable. Ainsi, s’il y a des panneaux attachés aux lamp-
adaires et aux panneaux de signalisation, s’il y a des
arbres à proximité, les segments sont mal circonscrits
et la reconnaissance en est impactée.

ð2Þ

Compl ´etude =

TP
TP + FN

ð3Þ

Exactitude = TP

ð4Þ

Qualit ´e =

TP + FP
TP
TP + FP + FN

ð5Þ

mesure F1 = 2 compl ´etude exactitude
compl ´etude + exactitude

Published by NRC Research Press

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.10

Geomat. Vol. 72, 2018

Avec TP signifiant vrai positif; FN signifiant faux négatif;
FP signifiant faux positif.

Une analyse comparative a également été menée avec
un jeu de données constitué de 160 millions de points
acquis sur une portion de route de 948 m. Les descrip-
teurs 3D comparés étaient : 3D shape context; bilateral
map (van Kaick et al. 2013), analyse de courbe (Tabia et al.
2011), descripteur spectral (Litman et Bronstein 2014). La
méthode proposée par Yu et al. (2015) a surpassé ces
descripteurs en présentant un taux moyen d’erreur de
recalage de 0,76 %.

Weinmann et al. (2015) se sont intéressés à la classifica-
tion de nuages de points acquis dans des environne-
ments urbains à grande échelle. Les principales classes
à identifier étaient : façade, sol, voitures, moto, pan-
neaux de signalisation, piétons. En terme de descripteur,
ils ont utilisé les trois mesures L, P et S, pouvant être
assimilées à la probabilité d’un segment de points
d’être catégorisé respectivement comme une structure
linéaire (c.-à-d., 1D), surfacique (c.-à-d., 2D) ou
volumétrique (c.-à-d., 3D). En plus de ces trois mesures,
le descripteur comptait d’autres caractéristiques
géométriques telles les valeurs propres normalisées,
la densité de points locale, etc. Au moment de calculer
ce descripteur, l’approche proposée effectue une
détermination de la taille optimale du voisinage à
considérer. Afin de faciliter la comparaison objective de
leur méthode avec d’autres approches, ils ont utilisé
deux jeux de données publiques : Paris-rue-Madame
(Serna et al. 2014) et Paris-rue-Cassette (Paparoditis et al.
2014) En matière de précision globale, l’approche
proposée a obtenu un taux moyen de 89 %. Le taux
moyen de complétude s’est échelonné entre 0,64 %
(voitures) et 0,95 % (façade). La mesure e1 s’est
échelonnée entre 0,03 % (piétons) et 0,096 % (façade). Ces
résultats surpassent ceux obtenus par d’autres méthodes
recensées dans la littérature (Weinmann et al. 2014).
Les moins bons résultats obtenus pour les plus petites
classes sont en raison de leur manque de représentation
dans la base d’apprentissage. L’approche proposée reste
sensible à la présence de bruit dans les données et à une
sélection adéquate de la taille du voisinage. Une telle
sélection représente un coût de calcul plus important
comparativement à d’autres descripteurs. Cependant, elle
rend la méthode adaptable à différents jeux de données et
évite l’implication d’heuristiques empiriques.

Dans Awan et al. (2013), les auteurs présentent une
nouvelle méthode pour classifier automatiquement les
objets à proximité des routes dans un nuage points
acquis en environnement urbain. L’approche proposée
réalise en premier lieu une segmentation du nuage de
points pour isoler les objets. Elle calcule ensuite pour
ces segments de points un descripteur global inspiré du
descripteur variable dimensional local shape descriptor
(VD-LSD) de Taati et Greenspan (2011). Celui-ci implique
tous les points du segment (au lieu d’un voisinage
restreint) et un système de référence situé au centre du

segment. Les caractéristiques géométriques calculées
pour établir les histogrammes sont transposées du
niveau local au niveau global à l’échelle du segment. La
méthode a été testée avec un jeu de données acquis dans
le centre de New-York avec un STM. Il consiste en
710 million de points couvrant une superficie de
78 000 m2. Le taux de bonne classification obtenu
s’élève à 94,5 %. Comme pour l’approche de Weinmann
et al. (2015), les faux positifs sont en raison d’un manque
de représentation de certaines instances d’objet dans la
base de référence.

Lehtomäki et al. (2016) proposent une méthode par
apprentissage machine pour la classification nuage de
points acquis avec des STM afin de produire des cartogra-
phies des infrastructures routières. Les classes d’intérêt
sont : arbres, lampadaires, panneaux de signalisation,
voitures, piétons, palissade. L’approche inclut des
étapes d’élimination des points sur le sol et les façades
puis de segmentation des points restants. Pour chacun
de ces segments un descripteur global constitué de la
concaténation de trois descripteurs est calculé. Le pre-
mier descripteur consiste en 17 caractéristiques
générales (les quatre premières décrivant la taille et
forme globale du segment, et le reste décrivant la distri-
bution des points dans différentes directions), le
deuxième descripteur est le descripteur spin image et le
troisième descripteur est le descripteur FPFH. Un jeu de
données de 9 million de points (100 points/m2) compor-
tant plus de 400 objets a été utilisé pour établir les per-
formances de cette approche. Des tests comparatifs ont
été effectués impliquant différentes combinaisons des
trois descripteurs formant le descripteur global. Les
meilleurs résultats ont été obtenus pour ce dernier avec
un taux de bonne classification de 88,1 %. Mais il
dépasse de peu (0,2 %) la combinaison du premier
descripteur avec le descripteur FPFH. Lors de l’analyse
individuelle des descripteurs, c’est FPFH qui a obtenu
un taux moyen de bonne reconnaissance de 6 %
supérieur aux deux autres descripteurs. Au niveau de la
reconnaissance des classes individuelles, les classes
arbres, panneaux de signalisation et piétons sont celles
qui présentent le plus de confusion entre elles et avec
des segments indéfinis. Ces erreurs sont causées en par-
tie par une grande similarité entre des portions de ces
objets. Les performances de la méthode proposée par
Lehtomäki et al. (2016) ont été confrontées aux résultats
proposés par des études similaires dans la littérature,
bien que ne portant pas sur des jeux de données identi-
ques. Les travaux retenus ne comportent que des études
visant la reconnaissance d’objets à proximité de route,
impliquant des bases de référence ayant plus de
30 exemples par classe. Il ressort de cette comparaison
une influence avérée de la méthode de segmentation et
de la qualité des résultats produits. Aussi, les perfor-
mances supérieures du descripteur FPFH ont été
démenties par d’autres méthodes. Les raisons possibles
peuvent être une différence dans les caractéristiques

Published by NRC Research Press

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.Daniel

11

des nuages de points et dans la valeur des paramètres
intervenant dans le calcul des descripteurs.

Les performances du descripteur pairwise shape con-
text (Yu et al. 2014) ont été évaluées dans le contexte
des nuages de points acquis avec des STM en milieu
urbain. Après élimination des points de sol, une segmen-
tation est appliquée afin de regrouper sous forme de seg-
ments les points associés à des objets d’intérêt. Les tests
réalisés avec trois jeux de données différents ont visé la
reconnaissance des lampadaires et des arbres. Des taux
moyens de reconnaissance de 97,6 % pour les lampad-
aires (286 instances à reconnaitre, la moitié n’ayant
aucun élément attaché au lampadaire) et de 98,6 % pour
les arbres (659 instances à reconnaitre) ont été obtenus.
Le descripteur pairwise 3D shape context a conduit à
des appariements de segments corrects même pour des
objets présentant certaines parties manquantes ou des
topologies légèrement différentes. Par contre, son calcul
est plus complexe et plus lent compte tenu de l’implica-
tion de paires de points plus que de points individuels.

Dans Golovinskiy et al. (2009), les auteurs présentent
une approche de reconnaissance de segments de points
à partir de jeux de données MLS acquis dans des environ-
nements urbains. Les auteurs visent spécifiquement à
proposer une méthode capable de reconnaitre de petits
objets à l’échelle d’une ville. Les descripteurs associés
aux segments extraits se composent de caractéristiques
géométriques et contextuelles. Les premières incluent :
le nombre de points, le volume estimé, la hauteur
moyenne, l’écart-type des hauteurs, les écart-types dans
les deux directions principales planaires, et le descrip-
teur spin image. Plusieurs segmentations sont réalisées
induisant chacune le calcul de l’ensemble de ces
caractéristiques qui sont ensuite concaténées. Les
caractéristiques contextuelles sont relatives à la position
relative des objets dans l’environnement urbain (ex. les
voitures doivent être sur la route; les lampadaires sont
sur le trottoir). L’approche a été testée avec un jeu de
données constitué de 954 millions de points acquis à
Ottawa (Canada) couvrant une superficie de 6 km2.
16 classes d’objets, incluant plusieurs petits objets
(ex. poubelle, bouche d’incendie, parcomètre, : : : ), ont
été définies pour la classification des segments de points.
Les résultats démontrent que de meilleures perfor-
mances ont été obtenues en impliquant l’ensemble
des caractéristiques géométriques et contextuelles
plutôt qu’une partie d’entre elles, le meilleur taux de
reconnaissance étant de 65 %. Au niveau des classes indi-
viduelles, les performances sont variables, certaines
classes n’ayant été reconnues pour aucune de leurs
instances. Les meilleurs résultats ont été obtenus pour
les objets ayant le plus d’exemples dans la base
de données d’apprentissage. Les auteurs soulignent
la nécessité d’améliorer la phase de classification
de leur approche, suggérant l’ajout de nouvelles
caractéristiques géométriques et contextuelles.

Chen et al. (2014) proposent une étude comparative de
cinq descripteurs globaux (boite englobante, « histogram
of local point level », « hierarchy », spin image, GFH)
réalisée avec le jeu de données publique « Sydney urban
objects » (De Deuge et al. 2013). Celui-ci a été acquis dans
le quartier d’affaires du centre de Sydney avec un LiDAR
Velodyne HDL-64E. Il comporte 631 objets individuels
répartis en 15 catégories (véhicule traction avant,
bâtiment, autobus, voiture, piéton, pilier, poteau, feu
de circulation, panneau de signalisation, arbre, camion,
tronc, fourgonnette, véhicule utilitaire, et autres) dans
le cadre de l’étude de Chen et al. (2014). Du point de vue
du temps de calcul, le descripteur histogram of local
point level a été le plus lent (0,0052 ms en moyenne par
objet), et le descripteur boite englobante a été le plus
rapide (0,0006 ms). Pour le descripteur GFH, le temps de
calcul moyen par objet a été de 0,018 ms par objet, le
double du temps du descripteur spin image. Du point
de vue de la précision de la reconnaissance, le descrip-
teur GFH a obtenu globalement les meilleurs résultats
avec une précision de 0,7358, suivi du descripteur spin
image avec une précision de 0,7278. Le descripteur histo-
gram of local point level est celui qui a le moins bien
performé (0,5158). Cette étude comparative a mis de l’av-
ant une variabilité dans le classement des performances
des descripteurs en fonction des classes considérées.
Ainsi, le descripteur spin image a obtenu les meilleurs
résultats pour les classes autobus, piéton, pilier, feu de
circulation, et autres alors que le descripteur boite englo-
bante a le mieux performé pour la reconnaissance de la
classe camion. Les classes pilier, poteau, feu de circula-
tion, panneau de signalisation, et tronc sont celles qui
ont entraîné le plus de confusion parmi tous les descrip-
teurs 3D. Des classes présentant des formes similaires
(ex. voiture, véhicule traction avant) ont également
posé des difficultés à ces descripteurs globaux.

Une étude comparative a été également proposée par
Behley et al. (2012) portant sur des descripteurs locaux
(« histogram of normal orientations », spin images, « dis-
tribution histogram », SHOT, histogramme spectral
(« spectral histogram »)) appliqués à trois jeux de
données acquis avec un LiDAR Velodyne HDL-64E sur
trois campus universitaires présentant différentes
densités de points par m2 (respectivement 60, 2500 et
580 environ à une distance de 5–10 m du capteur). Les
principales conclusions tirées de cette étude sont une
variabilité des descripteurs les plus performants en fonc-
tion de l’algorithme de classification utilisée et une influ-
ence du système de coordonnées de référence pour le
calcul des descripteurs locaux. Un choix approprié d’un
tel système de référence peut améliorer de manière sig-
nificative les résultats. La dimension du voisinage local
est également un facteur d’impact. Il agit de manière plus
prépondérante que le nombre d’intervalles choisi pour
les histogrammes constitutifs des descripteurs.

Chen et al. (2018) présentent une étude comparative
de descripteurs 3D dans le domaine spécifique de la

Published by NRC Research Press

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.12

Geomat. Vol. 72, 2018

construction. Cinq descripteurs locaux et globaux ont
été évalués et calculés à partir de segments de points :
spin image (local), SHOT (local), USC (local), ESF (global),
PAD (global). Le descripteur PAD est celui qui a obtenu
le meilleur taux de bonne reconnaissance (80 %) alors
que le descripteur USC est celui qui a le moins bien
performé (60 %). Il est à noter que le descripteur PAD
prend en compte les caractéristiques géométriques
propres aux équipements de construction. Aussi, le nom-
bre d’échantillons d’entrainement et de tests étant
limités, les auteurs soulignent que de tels résultats ne
pourraient pas se confirmer dans un contexte plus
général. Pour tous les descripteurs,
les résultats
s’améliorent lorsque le niveau de détail présent dans le
segment de points augmente. Le descripteur SHOT est
celui qui présente la moins grande sensibilité à cette
variation du niveau de détail, le descripteur ESF étant le
plus affecté. Le pourcentage d’occlusion présent au sein
des segments influence l’ensemble des descripteurs.
Cependant, même en cas d’occlusion partielle, l’ensem-
ble des descripteurs parvient à reconnaitre les objets de
manière satisfaisante.

Discussion

Les différentes études qui ont été menées afin
d’évaluer les performances des descripteurs 3D avec des
données acquises par des STM en environnement urbain
à grandes échelles démontrent la variabilité des résultats
en fonction de plusieurs facteurs : la densité de points
caractérisant les objets à reconnaitre, et donc le niveau
de détail dans les segments; le niveau de bruit dans les
données; le pourcentage de données manquantes dans
le segment; la taille du voisinage local; le choix
du système local de coordonnées. Certains de ces
facteurs affectent tous les descripteurs de manière simi-
laire tandis que d’autres changent le classement des
descripteurs par ordre de meilleures performances. Il
n’y a donc pas actuellement de descripteur 3D surpas-
sant systématiquement tous les autres pour la reconnais-
sance de toutes les classes objets en milieu urbain.
Plusieurs études soulignent même que certains descrip-
teurs fournissent les meilleurs résultats pour un sous-
groupe de classes et d’autres descripteurs fournissent
les meilleurs résultats pour un autre sous-groupe. Une
approche visant à sélectionner de manière ad hoc dans
un ensemble prédéfini de descripteurs le meilleur en
fonction de l’objet à reconnaitre semble pertinent. C’est
ce qui a été en partie expérimenté dans les travaux de
Taati et Greenspan (2011). Plusieurs des études
présentées dans la précédente section intitulée
« Performances des descripteurs 3D appliqués aux
données issues de STM dans des environnements
urbains à grande échelle » impliquant un descripteur
formé de la concaténation de caractéristiques
géométriques et contextuelles ont suggéré d’utiliser le
plus de caractéristiques possibles dans le descripteur.
Cependant certaines ajoutent un coût substantiel en

terme de calcul et de la complexité sans contribuer de
manière significative au processus de classification. Des
techniques de sélection des caractéristiques permettant
de favoriser la qualité à la quantité sont à investiguer.

Parmi les approches recensées, beaucoup procèdent
par segmentation préalable du nuage de points. Il ressort
des comparaisons entre ces approches une influence
avérée de la méthode de segmentation et de la qualité
des résultats produits. Ceci est d’autant plus vrai lorsque
qu’il y a de la végétation à proximité des objets à recon-
naitre ou des éléments ajoutés à ceux-ci (ex. panneaux
attachés aux lampadaires). Dans ce contexte, les descrip-
teurs locaux pourraient être priorisés par rapport aux
descripteurs globaux. Une segmentation basée sur des
super-voxels pourrait s’avérer également efficace. C’est
ce qui est exploité dans Wang et al. (2015). L’approche
consiste à regrouper les points ayant des FPFH similaires
et à représenter chaque groupe, appelé super-voxel,
par un seul descripteur FPFH. Dans cette étude, les
performances obtenues pour l’identification d’objet en
utilisant le descripteur FPFH calculé à partir de super-
voxels dépassent celles d’autres descripteurs.

Plusieurs classes associées notamment à de petits
objets de l’environnement urbain ont obtenu de moins
bons résultats de manière récurrente dans les travaux
recensés. La principale source identifiée pour cette
déficience est le manque de représentation de ces classes
dans la base d’apprentissage. La disponibilité de jeux de
données publiques contenant un grand nombre de
classes et d’instances pour chacune de ces classes perme-
ttrait de surmonter ce problème. De tels jeux de données
offriraient aussi des moyens de comparaison objectifs
entre les différentes méthodes proposées pour la recon-
naissance d’objets. La préparation de ces jeux de
données représente plusieurs difficultés compte tenu
de la grande superficie à couvrir et donc de la quantité
massive de points contenus dans les fichiers, du nombre
important d’instances de classes à inclure dans les
échantillons d’apprentissage et de tests, de la nécessité
de labelliser et de segmenter les points souvent effectué
de manière manuelle. Malgré ces difficultés, plusieurs
initiatives ont déjà été lancées en ce sens (Paparoditis
et al. 2014; Serna et al. 2014; Hackel et al. 2017).

Si des temps de calcul prohibitif ont été engendrés par
certains des descripteurs mis en œuvre dans les études
recensées, plusieurs des auteurs soulignent que les
procédés de calcul de ces descripteurs sont parallélis-
ables et donc adaptables au volume massif de données
à traiter dans le contexte des environnements urbains
à grande échelle. Un partitionnement des jeux de
données sous forme de tuiles de dimension limitée est
aussi envisageable.

Conclusion

Cet article a proposé une revue exhaustive des princi-
paux descripteurs 3D adaptés à la catégorisation des
nuages de points acquis avec des STM en environnement

Published by NRC Research Press

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.Daniel

13

urbain à grande échelle. Les descripteurs, locaux et glo-
baux, ont été recensés et leurs principes de calcul
détaillés. Un ensemble de travaux et d’études compara-
tives mettant en œuvre ces descripteurs dans le contexte
applicatif de cet article ont été présentés, tout en soulig-
nant leurs performances, problèmes et limites. À la
lumière de cette revue, nous avons constaté que les
descripteurs 3D actuels nécessitent encore des
améliorations afin de pouvoir les utiliser dans la
caractérisation du nuage de points LiDAR acquis avec
des systèmes de télémétrie terrestre mobile dans des
environnements urbains à grande échelle. Les études
comparatives existantes montrent que les descripteurs
d’attributs géométriques et les descripteurs d’occupa-
tion dominent les autres catégories de descripteurs au
niveau de la caractérisation des nuages de points com-
plets et de faible échelle. Cependant, ces performances
chutent notablement dès qu’il s’agit de caractériser des
nuages de points LiDAR présentant des occlusions et
une variabilité du point de vue de la densité de points.
Des approches opérant une sélection ad hoc de descrip-
teurs ou de caractéristiques parmi un ensemble
prédéfini ou bien un regroupement des points sous
forme de super-voxel apparaissent comme des voies
d’amélioration d’intérêt.

On note aussi que le calcul de descripteurs fait souvent
intervenir le calcul de normales, de courbures, et l’explo-
ration d’un voisinage. Opérer ces calculs à l’avance et
rendre ces informations disponibles avec le fichier de
points permettrait d’accélérer grandement les traite-
ments du nuage de points. Mais cela nécessiterait d’in-
troduire une structure de données multi-résolution
adaptée et performante pour la caractérisation du voisin-
age. Une telle structure de données offrirait aussi des
opportunités de visualisation et d’interaction avec le
nuage de points. En effet, le rendu direct de modèle 3D
basé sur des points émerge graduellement comme une
solution viable alternative aux méthodes plus tradition-
nelles basées sur des maillages polygonaux. Nos futurs
travaux s’aligneront sur cette direction de recherche.

Remerciements

Ce travail est financé par le programme Découverte du
Conseil de Recherches en Sciences Naturelles et en Génie
(CRSNG) du Canada. L’auteur reconnait l’appui des mem-
bres de son équipe, étudiants et professionnels de
recherche, dans les différents projets en lien avec cet
article.

Bibliographie

Awan, S., Muhamad, M., Kusevic, K., Mrstik, P., and Greenspan,
M. 2013. Object class recognition in mobile urban LiDAR data
using global
shape descriptors. 2013 International
Conference on 3D Vision — 3DV 2013, University of
Washington, Seattle, WA, USA, 29–30 June. IEEE. pp. 350–357.
Behley, J., Steinhage, V., and Cremers, A.B. 2012. Performance of
histogram descriptors for the classification of 3D laser range
data in urban environments. 2012 IEEE International

Conference on Robotics and Automation (ICRA), St. Paul,
MN, USA, 14–18 May. IEEE. pp. 4391–4398.

Chen, J., Fang, Y., Cho, Y.K., and Kim, C. 2017. Principal axes
descriptor for automated construction-equipment classifica-
tion from point clouds. J. Comput. Civ. Eng. 31(2): 04016058.
doi:10.1061/(ASCE)CP.1943-5487.0000628.

Chen, J., Fang, Y., and Cho, Y.K. 2018. Performance evaluation of
3D descriptors for object recognition in construction applica-
tions. Autom. Constr. 86: 44–52. doi:10.1016/j.autcon.
2017.10.033.

Chen, T., Dai, B., Liu, D., and Song, J. 2014. Performance of global
descriptors for velodyne-based urban object recognition. 2014
IEEE Intelligent Vehicles Symposium Proceedings, Dearborn,
MI, USA, 8–11 June. IEEE. pp. 667–673.

Chen, Z., Czarnuch, S., Smith, A., and Shehata, M. 2016.
Performance evaluation of 3D keypoints and descriptors.
Symposium on Visual Computing.
International
Proceedings, Part II, Lecture Notes in Computer Science, Las
Vegas, NV, USA, 12–14 Dec. Springer, Cham. pp. 410–420.
doi:10.1007/978-3-319-50832-0.

Daniel, S., and Doran, M.A. 2013. geoSmartCity: geomatics con-
tribution to the smart city. Proc. 14th Annual International
Conference on Digital Government Research, Quebec City,
QC, Canada, 17–20 June. ACM Digital Library, New York, NY,
USA. pp. 65–71.

De Deuge, M., Quadros, A., Hung, C., and Douillard, B. 2013.
Unsupervised feature learning for classification of outdoor
3D scans. Proc. Australasian Conference on Robitics and
Automation (ACRA), Sydney, Australia, 2–4 Dec. Vol. 2, pp. 1–9.
Flint, A., Dick, A., and Van Den Hengel, A. 2007. Thrift: local 3D
structure recognition. 9th Biennial Conference of the
Australian Pattern Recognition Society on Digital Image
Computing Techniques and Applications, Glenelg, SA,
Australia, 3–5 Dec. IEEE. pp. 182–188. doi:10.1109/DICTA.
2007.4426764.

Golovinskiy, A., Kim, V.G., and Funkhouser, T. 2009. Shape-
based recognition of 3D point clouds in urban environments.
2009 IEEE 12th International Conference on Computer
Vision, Kyoto, Japan, 27 Sept.–4 Oct. IEEE. pp. 2154–2161.
Guo, Y., Sohel, F., Bennamoun, M., Wan, J., and Lu, M. 2015.
A novel local surface feature for 3D object recognition under
clutter and occlusion. Inf. Sci. 293: 196–213. doi:10.1016/j.
ins.2014.09.015.

Hackel, T., Savinov, N., Ladicky, L., Wegner, J.D., Schindler, K.,
and Pollefeys, M. 2017. Semantic3D.net: a new large-scale
point cloud classification benchmark. arXiv preprint
arXiv:1704.03847.

Hänsch, R., Weber, T., and Hellwich, O. 2014. Comparison of 3D
interest point detectors and descriptors for point cloud
fusion. ISPRS Ann. Photogramm. Remote Sens. Spat. Inf. Sci.
II-3: 57–64. doi:10.5194/isprsannals-II-3-57-2014.

Harris, C., and Stephens, M. 1988. A combined corner and edge
detector. Proc. Alvey Vision Conference, Manchester, UK, 31
Aug.–2 Sept. Organising Committee AVC 88. Vol. 15, No. 50,
pp. 147–151.

Hervieu, A., and Soheilian, B. 2013. Semi-automatic road/
pavement modeling using mobile laser scanning. ISPRS
Ann. Photogramm. Remote Sens. Spat. Inf. Sci. II-3/W3:
31–36. doi:10.5194/isprsannals-II-3-W3-31-2013.

Himmelsbach, M., Luettel, T., and Wuensche, H.J. 2009. Real-
time object classification in 3D point clouds using point
feature histograms. 2009 IEEE/RSJ International Conference
on Intelligent Robots and Systems (IROS 2009), St. Louis,
MO, USA, 11–15 Oct. IEEE. pp. 994–1000.

Hyyppä, J., Jaakkola, A., Chen, Y., and Kukko, A. 2013.
Unconventional LIDAR mapping from air, terrestrial and
mobile. Proc. Photogrammetric Week, Stuttgart, Germany,

Published by NRC Research Press

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.14

Geomat. Vol. 72, 2018

9–13 Sept. pp. 205–214. [Online]. Available from http://www.
ifp.uni-stuttgart.de/publications/phowo13/.

Ioannou, Y., Taati, B., Harrap, R., and Greenspan, M. 2012.
Difference of normals as a multi-scale operator in unorgan-
ized point clouds. 2012 Second International Conference on
3D Imaging, Modeling, Processing, Visualization and
Transmission (3DIMPVT), Zurich, Switzerland, 13–15 Oct.
IEEE. pp. 501–508.

Kaartinen, H., Hyyppä, J., Kukko, A., Jaakkola, A., and Hyyppä,
H. 2012. Benchmarking the performance of mobile laser
scanning systems using a permanent test field. Sensors,
12(9): 12814–12835. doi:10.3390/s120912814.

Kim, H., and Hilton, A. 2013. Evaluation of 3D feature descrip-
tors for multi-modal data registration. 2013 International
Conference on 3D Vision — 3DV 2013, Seattle, WA, USA, 29
June–1 July. IEEE. pp. 119–126.

Körtgen, M., Park, G.J., Novotni, M., and Klein, R. 2003. 3D shape
matching with 3D shape contexts. The 7th Central European
Seminar on Computer Graphics, Budmerice, Slovakia, 26–27
May. Vol. 3, pp. 5–17.

Lalonde, J.F., Vandapel, N., Huber, D.F., and Hebert, M. 2006.
Natural terrain classification using three-dimensional
ladar data for ground robot mobility. J. Field Robot. 23(10):
839–861. doi:10.1002/rob.20134.

Lam, J., Kusevic, K., Mrstik, P., Harrap, R., and Greenspan, M.
2010. Urban scene extraction from mobile ground based
LiDAR data. 5th International Symposium on 3D Data
Processing, Visualization and Transmission 3DPVT 2010,
Paris, France, 17–20 May. pp. 1–8.

Lehtomäki, M., Jaakkola, A., Hyyppä, J., Lampinen, J., Kaartinen,
H., Kukko, A., and Hyyppä, H. 2016. Object classification and
recognition from mobile laser scanning point clouds in a
road environment. IEEE Trans. Geosci. Remote Sens. 54(2):
1226–1239. doi:10.1109/TGRS.2015.2476502.

Litman, R., and Bronstein, A.M. 2014. Learning spectral descrip-
tors for deformable shape correspondence. IEEE Trans.
Pattern Anal. Mach. Intell. 36(1): 171–180. doi:10.1109/
TPAMI.2013.148. PMID:24231874.

Liu, L., and Stamos, I. 2007. A systematic approach for 2D-image
to 3D-range registration in urban environments. IEEE 11th
International Conference on Computer Vision, 2007 (ICCV
2007), Rio de Janeiro, Brazil, 14–20 Oct. IEEE. pp. 1–8.

Lowe, D.G. 2004. Distinctive image features from scale-
invariant keypoints. Int. J. Comput. Vis. 60(2): 91–110.
doi:10.1023/B:VISI.0000029664.99615.94.

Paparoditis, N., Vallet, B., Marcotegui, B., and Serna, A. 2014.
IQmulus & TerraMobilita contest — analysis of mobile laser
scans (MLS)
in dense urban environments. MATIS
Laboratory, French National Mapping Agency (IGN) and
Center for Mathematical Morphology (CMM), MINES
ParisTech.
[Online]. Available from http://data.ign.fr/
benchmarks/UrbanAnalysis/.

Pomerleau, F., Colas, F., and Siegwart, R. 2013. A review of point
cloud registration algorithms for mobile robotics. Found.
Trends Robot. 4(1): 1–104. doi:10.1561/2300000035.

Rusu, R.B., and Cousins, S. 2011. 3D is here: point cloud library
(PCL). 2011 IEEE International Conference on Robotics and
Automation (ICRA), Shanghai, China, 9–13 May. IEEE.
pp. 1–4. [Online]. Available from http://www.pointclouds.org.
Rusu, R.B., Marton, Z.C., Blodow, N., and Beetz, M. 2008.
Persistent point feature histograms for 3D point clouds.
Proc. 10th International Conference on Intelligent
Autonomous Systems (IAS-10), Baden-Baden, Germany, July.
IOS Press. pp. 119–128.

Rusu, R.B., Blodow, N., and Beetz, M. 2009. Fast point feature
histograms (FPFH) for 3D registration. IEEE International
Conference on Robotics and Automation, 2009 (ICRA’09),
Kobe, Japan, 12–17 May. IEEE. pp. 3212–3217.

Rusu, R.B., Bradski, G., Thibaux, R., and Hsu, J. 2010. Fast 3D rec-
ognition and pose using the viewpoint feature histogram.
2010 IEEE/RSJ International Conference on Intelligent
Robots and Systems (IROS), Taipei, Taiwan, 18–22 Oct. IEEE.
pp. 2155–2162.

Serna, A., Marcotegui, B., Goulette, F., and Deschaud, J.E. 2014.
Paris-rue-Madame database: a 3D mobile laser scanner data-
set for benchmarking urban detection, segmentation and
classification methods. 4th International Conference on
Pattern Recognition, Applications and Methods (ICPRAM)
2014, Angers, France, 6–8 Mar. Lecture Notes in Computer
Science (LNCS) — Springer.

Shah, S.A.A., Bennamoun, M., Boussaid, F., and El-Sallam, A.A.
2013. 3D-Div: a novel
local surface descriptor for
feature matching and pairwise range image registration.
2013 20th IEEE International Conference on Image
Processing (ICIP), Melbourne, VIC, Australia, 15–18 Sept.
IEEE. pp. 2934–2938.

Smith, S.M., and Brady, J.M. 1997. SUSAN — a new approach to
low level image processing. Int. J. Comput. Vis. 23(1): 45–78.
doi:10.1023/A:1007963824710.

Steder, B., Rusu, R.B., Konolige, K., and Burgard, W. 2010. NARF:
3D range image features for object recognition. Workshop
on Defining and Solving Realistic Perception Problems in
Personal Robotics at the IEEE/RSJ International Conference
on Intelligent Robots and Systems (IROS), Taipei, Taiwan,
18–22 Oct. Vol. 44.

Taati, B., and Greenspan, M. 2011. Local shape descriptor
selection for object recognition in range data. Comput.
Vis. Image Underst. 115(5): 681–694. doi:10.1016/j.cviu.
2010.11.021.

Tabia, H., Daoudi, M., Vandeborre, J.P., and Colot, O. 2011. A new
3D-matching method of nonrigid and partially similar
models using curve analysis. IEEE Trans. Pattern Anal.
Mach. Intell. 33(4): 852–858. doi:10.1109/TPAMI.2010.202.
PMID:21079272.

Tanhuanpää, T. 2016. Developing laser scanning applications
for mapping and monitoring single tree characteristics for
the needs of urban forestry. Doctoral dissertation,
Department of Forest Sciences, Faculty of Agriculture and
Forestry, University of Helsinki, Helsinki, Finland.
doi:10.14214/df.230.

Tarsha-Kurdi, F., Landes, T., and Grussenmeyer, P. 2008.
Extended RANSAC algorithm for automatic detection of
building roof planes from LiDAR data. Photogramm. J. Finl.
21(1): 97–109.

Theiler, P.W., Wegner, J.D., and Schindler, K. 2013. Markerless
point cloud registration with keypoint-based 4-points con-
gruent sets. ISPRS Ann. Photogramm. Remote Sens. Spat.
II-5/W2: 283–288. doi:10.5194/isprsannals-II-
Inf. Sci.
5-W2-283-2013.

Tombari, F., Salti, S., and Di Stefano, L. 2010a. Unique signatures
of histograms for local surface description. 11th European
Conference on Computer Vision, Heraklion, Crete, Greece,
5–11 Sept. Proceedings, Part II, Lecture Notes in Computer
Science. Springer, Berlin, Heidelberg. pp. 356–369.

Tombari, F., Salti, S., and Di Stefano, L. 2010b. Unique shape con-
text for 3D data description. Proc. ACM Workshop on 3D
Object Retrieval. ACM. pp. 57–62.

Toth, C.K. 2009. R&D of mobile LiDAR mapping and future
trends. Proc. ASPRS 2009 Annual Conference, Baltimore,
MD, USA, 9–13 Mar. American Society for Photogrammetry
and Remote Sensing (ASPRS). pp. 1–7.

Unnikrishnan, R., and Hebert, M. 2008. Multi-scale interest
regions from unorganized point clouds. IEEE Computer
Society Conference on Computer Vision and Pattern
Recognition Workshops, 2008 (CVPRW’08), Anchorage, AK,
USA, 23–28 June. IEEE. pp. 1–8.

Published by NRC Research Press

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.Daniel

15

Urban, S., and Weinmann, M. 2015. Finding a good feature
detector-descriptor combination for the 2D keypoint-based
registration of TLS point clouds. ISPRS Ann. Photogramm.
Remote Sens. Spat. Inf. Sci. II-3/W5: 121–128. doi:10.5194/
isprsannals-II-3-W5-121-2015.

Vallet, B., Brédif, M., Serna, A., Marcotegui, B., and Paparoditis,
N. 2015. TerraMobilita/iQmulus urban point cloud analysis
benchmark. Comput. Graph. 49: 126–133. doi:10.1016/j.
cag.2015.03.004.

van Kaick, O., Zhang, H., and Hamarneh, G. 2013. Bilateral maps
for partial matching. Computer Graphics Forum. Vol. 32,
No. 6, pp. 189–200.

Wang, H., Wang, C., Luo, H., Li, P., Chen, Y., and Li, J. 2015. 3-D
point cloud object detection based on supervoxel neighbor-
hood with Hough forest framework. IEEE J. Sel. Top. Appl.
Earth Obs. Remote Sens. 8(4): 1570–1581. doi:10.1109/
JSTARS.2015.2394803.

Weinmann, M., Jutzi, B., and Mallet, C. 2014. Semantic 3D scene
interpretation: a framework combining optimal neighbor-
hood size selection with relevant features. ISPRS Ann.
Photogramm. Remote Sens. Spat. Inf. Sci. II-3: 181–188.
doi:10.5194/isprsannals-II-3-181-2014.

Weinmann, M., Urban, S., Hinz, S., Jutzi, B., and Mallet, C. 2015.
Distinctive 2D and 3D features for automated large-scale
scene analysis in urban areas. Comput. Graph. 49: 47–57.
doi:10.1016/j.cag.2015.01.006.

Williams, K., Olsen, M.J., Roe, G.V., and Glennie, C. 2013.
Synthesis of transportation applications of mobile LiDAR.
Remote Sens. 5(9): 4652–4692. doi:10.3390/rs5094652.

Yu, Y., Li, J., Yu, J., Guan, H., and Wang, C. 2014. Pairwise three-
dimensional shape context for partial object matching and
retrieval on mobile laser scanning data. IEEE Geosci.
Remote Sens. Lett. 11(5): 1019–1023. doi:10.1109/LGRS.
2013.2285237.

Yu, Y., Li, J., Guan, H., and Wang, C. 2015. Automated extraction
of urban road facilities using mobile laser scanning data.
IEEE Trans. Intell. Transp. Syst. 16(4): 2167–2181. doi:10.1109/
TITS.2015.2399492.

Zhong, Y. 2009. Intrinsic shape signatures: a shape des-
criptor for 3D object recognition. 2009 IEEE 12th
International Conference on Computer Vision Workshops
(ICCV Workshops), Kyoto, Japan, 27 Sept.–4 Oct. IEEE.
pp. 689–696.

Published by NRC Research Press

Geomatica 2018.72:1-15.Downloaded from www.nrcresearchpress.com by GLASGOW UNIVERSITY LIBRARY on 09/17/18. For personal use only.