INT. J. GEOGRAPHICAL INFORMATION SCIENCE
VOL. 18, NO. 1, JANUARY–FEBRUARY 2004, 1–34

Research Article

Developing a conceptual framework for visually-enabled
geocollaboration

ALAN M. MACEACHREN and ISAAC BREWER
GeoVISTA Center, Department of Geography, 302 Walker Penn State
University, University Park, PA 16802, USA; e-mail: maceachren@psu.edu;
isaacbrewer@psu.edu: www.geovista.psu.edu

(Received 8 June 2002; accepted 24 March 2003 )

Abstract. Most work with geospatial data, whether for scientiﬁc analysis,
urban and environmental planning, or business decision making is carried out by
groups. In contrast, geographic information technologies have been built and
assessed only for use by individuals. In this paper we argue that, to support
collaboration with geospatial information, speciﬁc attention must be given to
tools that mediate understanding and support negotiation among participants.
In addition, we contend that visual representations have a particularly important
role to play as mediators of geocollaborative activities. With these contentions as
a starting point, we present a framework for study of visually-enabled
collaboration with geospatial information and for development, implementation,
and assessment of geoinformation technologies that support that collaboration.
The paper concludes with a brief description of two prototype geocollaborative
environments that illustrate the use of the framework developed and provide the
basis for discussing goals for futher research.

1.

increase in the role of maps,

Introduction
Recent conceptual and technical developments in information technology have
the potential to enable a dramatic change in the role of technology in human-
human interaction. (Fischer 2002, Roschelle and Pea 2002, Varian et al. 1998).
Similarly, developments in geographic information science (GIScience), (Kraak and
MacEachren 1999, Mark 1999, MacEachren and Kraak 2000), and in computer
graphics/visualization (Brown et al. 1999), suggest that we are also on the cusp of a
substantial
images, and computer graphics as
in a range of contexts including scientiﬁc inquiry,
mediators of collaboration,
environmental and urban planning, resource management, and education. In spite
of this potential, we have a limited conceptual basis from which to develop or study
the use of visually-enabled collaboration (using geospatial or other information).
The primary objectives of this paper are: to outline a conceptual framework for
visually-enabled collaboration with geospatial
information through geospatial
technologies (an activity that we label geocollaboration) and to demonstrate
application of this framework to a pair of case studies from our ongoing research.
The goal of the framework developed is to delineate important technological,

International Journal of Geographical Information Science
ISSN 1365-8816 print/ISSN 1362-3087 online # 2004 Taylor & Francis
http://www.tandf.co.uk/journals
DOI: 10.1080/13658810310001596094

2

A. M. MacEachren and I. Brewer

social, and cognitive parameters that must be considered as we extend, or reinvent,
geoinformation technologies to support work by groups. The framework is also
intended to provide a structure for understanding the interrelationships among the
parameters that deﬁne geocollaborative environments, for organizing a systematic
program of research in geocollaboration, and for developing approaches to multi-
user systems that support rather than impede group work. Particular attention in
the framework is given to visual representation as a mediator of group work and we
outline an approach to such shared representations grounded in semiotics and
theories of boundary objects. We illustrate use of the framework through case
studies with two visually-enabled geocollaboration prototypes developed in prior
work. One focuses on collaborative visualization and the other on group work
using geo-virtual environments (GeoVE).

2. Background

Like Roschelle and Teasley (1995) and Jankowski and Nyerges (2001a), we
consider collaborative systems to be a subset of the systems used for computer-
supported cooperative work (CSCW). Cooperation can involve any sharing of
information, perhaps by individuals performing very different
tasks (e.g., an
individual using information visualization to ﬁnd structure in patterns of web
activity cooperating with another developing a marketing plan for web advertising).
‘Collaboration’ is used here to identify those cooperative activities in which two or
more individuals work together on a single task or closely related subtasks,
constructing and maintaining a shared problem conception. Thus, we consider
computer-supported geocollaboration to involve a committed effort on the part of
two or more people to use geospatial information technologies to collectively frame
and address a task involving geospatial information.

Our approach to geocollaboration draws upon a diverse literature dealing with
group (multi-participant) work. That literature considers collaboration from the
perspectives of human sciences, computing, and their integration (Kraemer and
King 1988, Mandviwalla and Oldman 1994, Horrocks et al. 1999). Like Descortis
et al. (2000) we contend that a combination of conceptual perspectives, drawn from
multiple domains, will be essential for understanding collaborative activity in a
speciﬁc context or crafting an appropriate collaborative system design methodology
for that context. While space does not permit a detailed discussion of the relevant
literatures, we direct the reader to theoretical frameworks developed in the domains
of distributed cognition (Hutchins 1995), activity theory (Nardi 1996), cognitive
ergonomics (Descortis et al. 2000) and social aspects of groupware for CSCW (Dix
et al. 1998). These perspectives, particularly if integrated, have the potential to help
isolate and augment speciﬁc design issues in collaborative systems.

Within GIScience, there is a growing volume of literature on group work with
information (Nyerges 1999, MacEachren 2000, 2001, Jankowski and
geospatial
Nyerges 2001a). Much of the attention has focused on group spatial decision
support (GSDS) (an outgrowth of earlier work in spatial decision support systems
(SDSS)), with the focus on design of environments that merge GISystems with
multicriteria evaluation methods and decision support tools (Armstrong 1993,
Nyerges et al. 1997, Jankowski & Nyerges 2001b). While substantial progress has
been made in SDSS and GDSS (Jankowski and Nyerges 2001a), limited attention
has been given to collaboration focusing on, or mediated by, visual/graphic

Visually-enabled geocollaboration

3

displays. Thus the research, generally, fails to address many issues that are likely to
be critical for collaboration using the standard tools of GIScience (GISystems,
image analysis software, and dynamic maps).

Armstrong and Densham (1995) provide one exception to the lack to attention
of visual display for group work with geospatial information, detailing a prototype
visual aide to geocollaboration in the context of facility location. However, there
seems to have been no direct follow up to their ideas. Some work has also been
carried out on development of visual tools to support multicriteria decision-making
(Andrienko and Andrienko 2001). The general lack of attention to the role of visual
display as a mediator for collaborative work with geospatial
information is
particularly surprising, since all GISystems use visual, map-based interfaces.

The conceptual framework we detail in this paper will support integration of
visual displays as a mediator of group work in a range of domains for which group
work with geospatial information is critical. These include science (e.g. environ-
mental change, health-environment interactions, population dynamics), science
education, situation assessment and planning for crisis response, as well as decision
support for planning and environmental management (traditional application domains
for SDSS and GDSS), crisis management and related strategic planning activities.
Recent research in two non-GIScience domains provides a base from which to
address the potential and challenges associated with visual mediation tools to
support geocollaboration in these and other contexts: collaborative visualization
and collaboration in virtual environments. Each is discussed below, brieﬂy, with an
emphasis on the potential application to visually-mediated geocollaboration.

2.1. Collaborative visualization

Large, distributed multidisciplinary teams now play an important role in
scientiﬁc work. In the US, for example, there have been calls for geography to direct
more attention to ‘big science’ and multidisciplinary collaborations (Wilbanks et al.
1997) and a large proportion of science funding is allocated to multi-investigator
(collaborative) research projects (e.g.
through initiatives dealing with human
implications of global environmental change, biocomplexity, digital government,
and information technology research). Visualization systems with the potential to
facilitate this science have, however, been developed for use by single users.

To meet the needs of interdisciplinary, multi-investigator science as well as
planning and decision making, the focus of visualization research and development
has begun moving towards support for groups, including distributed groups (Brown
et al. 1996, Brodlie et al. 1998, Rhyne 1998, May 1999, Friesen and Tarman 2000,
Watson, 2001, Brodlie forthcoming). However, despite technological successes in
the implementation of shared visualization tools (including ones for geospatial data
visualization in the contexts of environmental management (Bajaj and Cutchin
1999), oceanographic and meteorological studies (Pang and Fernandez 1995), and
hazards research (Padula and Rinaldi 1999)), we know very little about the
impacts of shared visualization on group work or how to design effective group
geovisualization tools.

Wood et al. (1997) propose that the ideal collaborative visualization systems
should support both ‘instructor-driven’ collaborations (in which one individual
leads a group—termed ‘chauffer-driven’ in the CSCW literature) and interaction
among multiple independent participants. For the latter, they suggest that the

4

A. M. MacEachren and I. Brewer

environment should support data exchange, shared control, dynamic interaction,
ease of learning, and shared application modes. Perhaps the best-tested collabo-
rative system mediated by visualization is the UARC/SPARC collaboratory project
(Olson et al. 1998). The collaboratory (a virtual laboratory accessible from remote
locations, for discussion of development of the collaboratory concept (Cerf et al.
1993)) allows users to organize their data streams into hundreds of individualized
displays—3D visual renderings and virtual reality rooms—that are then shared
(asynchronously) with other collaborators (Olson and Olson 2000). While the
UARC/SPARC collaboratory includes collaborative visualization tools,
is
designed to support research in physics (thus is not
focused on geospatial
information) and empirical assessment of the collaboratory tools has not yet
focused on the social or cognitive impacts of the role that visualization tools serve
in the collaborative process.

it

In our own previous work (MacEachren et al. 1999, Brewer et al. 2000), we have
focused speciﬁcally on development (and usability) of collaborative geovisualization
tools to support group data exploration (one of several tasks that might be
undertaken in a geocollaborative activity). Some of this work is discussed below as
a case study application of
framework for visually-mediated
geocollaboration that we present in §3.

the conceptual

2.2. Collaboration in Virtual Environments

Proponents of Collaborative Virtual Environments (CVEs) contend that such
environments have the potential to improve both local and distributed collaborative
work signiﬁcantly (Pantelidis 2000). There are several different display-interaction
forms that can be lumped into the category of collaborative virtual environments;
these include large screen wall displays, table-top 3D manipulable displays, CAVEs,
and Immersadesks. CVEs have been developed for a wide range of applications,
examples include: creation of collaborative gaming environments (Szalava´ ri et al.
1998); visualization of seismic geoscientiﬁc data by co-located individuals (Lin et al.
1998); streamed geospatial imagery (Taylor 2001); development of collaborative
tools for battleﬁeld analysis (Jones et al. 1998); and simulations to facilitate learning
about complex environments (Roussos et al. 1999). Almost all CVEs rely upon
visual displays as a mediator among participants and create ‘spaces’ within which
participants interact. Thus they all rely upon spatial metaphors whether or not they
depict geospatial data.

Armstrong (2001) argues that

teleimmersive distributed environments for
working with geospatial information represent a grand challenge that, if met, can
enable productive work in many contexts. More broadly, Hindmarsh et al. (2000)
suggest that high quality graphical display of real and imagined scenes could
become the typical every day work medium for distributed interaction among
experts. However, these authors also point out that one of the identiﬁed barriers to
successful CVE implementation is our limited understanding of how people interact
with objects, and with each other, in virtual displays.

Research has been undertaken to improve understanding of traditional inter-
action with geospatial information so that the interaction can be duplicated within
a multimodal CVE. For example, Cohen and colleagues (1999, McGee et al. 2000)
have studied collaborative interaction by Marine Corps commanders with paper
maps for command and control operations. The speciﬁc goal was to improve the

Visually-enabled geocollaboration

5

understanding of interaction with 2D static maps, so that this understanding could
guide development and design of a voice, pen, and touch-based interface to a large
screen display (McGee and Cohen 2001, McGee et al. 2001). Related work on
CVEs for collaborative command and control applications (at the US Air Force
Research Laboratory) has resulted in a ﬁeld deployable multimodal system that
allows the display and manipulation of real time multimedia data on large screen
displays (Jedrysik et al. 2000). The goal underlying this work is to link command
centre wall displays with ﬁeld deployable data walls to improve collaboration
among multiple commanding agencies.

In an effort focused speciﬁcally on support for multiple, interacting users, May
(1999) developed the Human Information Workspace (HI-SPACE). HI-SPACE is a
large-screen, rear projection, table display environment that supports hands-free,
multi-user, untethered interaction with an electronic information space. Two unique
aspects of HI-SPACE are its support for multiple, simultaneous cursors and its
ability to support integration of physical objects, known as phicons, as part of the
rendered scene (ﬁgure 1).

In contrast to research on collaborative visualization (which has emphasized
software design and implementation), work on CVEs has been more human-
centred, directing considerable attention to how CVEs are used and how human
behaviour is modiﬁed. Associated human-centred research questions that have been
addressed deal with: interface design and system usability, support for multi-user

Figure 1. Vision of HI-SPACE group interaction environment. The table display shown
is on loan to the Penn State GeoVISTA Center from the Paciﬁc Northwest
National Laboratory, and is being used to facilitate joint research on collaborative
visualization.

6

A. M. MacEachren and I. Brewer

representation and presence, and representation of user’s individual views (Park
et al. 2000)—all topics that are relevant to visually mediated geocollaboration using
large screen displays. Related usability and interface design research with CVEs has
been directed to the development of 3D human-centred interfaces (Goddard and
Sunderam 1999), the use of software agents for enhanced usability (Noll et al.
1999), and the design and implementation of metaphors that reduce the cognitive
load for participants (Roussos et al. 1999). Findings indicate that users within a
CVE do not want to be tethered to glove-based or controller-based interaction (e.g.
a wand or pointing device). Therefore, a research goal is to develop methods that
make interaction with (and within) CVEs more natural.

One of the real barriers to co-located multi-person collaborative work within
current CVEs is that the systems often restrict control of the display to one user at
a time. Similarly, different-place collaboration within current CVEs is impeded because
the nature of social interaction within a CVE differs from that of real (face-to-face)
interaction, but current systems do not provide tools to address that difference
(Tromp et al. 1998). For example, when collaborators are in the same location, they
often use gestures to facilitate discussion about objects in the environment,
however, when collaborators are in different locations, they must develop alter-
natives (e.g. verbal expressions or virtual ‘gestures’) which are often less successful
and can interfere with understanding each other’s perspectives (Dix et al. 1998).

3. Conceptual framework

In this section, we develop a conceptual framework to support visually-enabled
geocollaboration. The objective of the framework is to provide a basis from which
to design, implement, and understand the use of collaborative geospatial infor-
mation technologies, with particular attention to dynamic visual displays as
mediators for group work.

The collaborative process has many dimensions. Here we identify six that we
consider particularly important from the perspectives of both system design and
evaluation. The overall approach we take is a human-centred one that puts as much
emphasis on the needs of human users as on the technology necessary to meet those
needs (Flanagan et al. 1997, Brown et al. 1999). The ﬁrst three dimensions of our
framework focus on the human components of a collaborative environment and
include: problem context, collaboration tasks, and perspective commonality. The
second three dimensions (while still attending to users) emphasize the computing
infrastructure (e.g. networking, visualization) that can support collaboration, thus
they are considered system dimensions. These system dimensions include: spatial
and temporal context, interaction characteristics, and tools to mediate group work.
We do not contend that these dimensions represent an exhaustive list. We do
believe, however,
for developing
geocollaboration environments, testing their usability, and understanding their
use and usefulness.

they are among the most

important

that

3.1. Problem context

Geocollaboration, as deﬁned above,

is an activity that can and should be
supported in a variety of problem contexts. Here, we identify four problem contexts
within which geocollaboration may be undertaken and for which the nature of that
collaboration (and the necessary enabling tools) is likely to differ:

Visually-enabled geocollaboration

7

. knowledge construction and reﬁnement. The focus here is on tools that
facilitate collaborative extraction of information from data and meaning from
that information.

. design. The focus here is on support for group work directed at creating an
entity. Examples include designing a new regional park, designing a new map
of US soil productivity, or collaboratively designing a GISystem application.
. decision-support. Focus here is on group decisions that make use of geospatial
information and its meaning to make decisions about places (e.g. decisions
about facility location, distribution of personnel and supplies in a crisis,
delineating the bounds of an ecological preserve). Decisions, of course, are
also part of both knowledge construction and design.

. training and education. The emphasis here is on facilitating group training and
learning activities. Examples range from support for earth science education
to training for emergency management or military activities.

3.2. Collaboration tasks

A variety of attempts have been made to develop typologies of tasks for group
work, see, for example (McGrath 1984, Horrocks et al. 1999). While they provide a
useful place to start, these typologies address the problem primarily from the
context of business management, thus require modiﬁcation and extensions to ﬁt
problem contexts such as scientiﬁc knowledge construction, spatial decision
support, highway design, or training and education.

For geocollaboration, we have developed a typology of tasks built upon a
framework that relates a pair of complementary meta-task categorizations (ﬁgure 2).
The ﬁrst, applicable to the contexts of group decision-making and design, borrows
from McGrath (1984) who, building on Hackman (1976), delineates four general
components within the process of group work, to: generate (ideas and options),
negotiate, choose, and execute. The second borrows from MacEachren and Kraak
(1997) who, building on earlier work by DiBiase (1990), and Tukey (1977),
characterize the uses of geovisualization in support of scientiﬁc research as having
four stages: exploration, analysis, synthesis, and presentation. These stages com-
plement those identiﬁed by McGrath and can be considered stages of group work in
knowledge construction and reﬁnement generally. They also are applicable to the
development of tools for active, collaborative learning (Fortner and Mayer 1996).

Figure 2. Decision-making tasks matched with knowledge construction tasks.

8

A. M. MacEachren and I. Brewer

3.3. Commonality of perspective

The study of human-computer interaction (HCI) often considers participant
characteristics that might inﬂuence tool and system success. These include physical
abilities, user disabilities, cognitive and perceptual abilities, personality differences,
cultural and international diversity, and age (Shneiderman 1998) as well as user
experience (Nielsen 1993). For collaborative systems, we must consider group
characteristics as well as those for individuals. For groups, perhaps the most
important distinction to make involves the commonality of perspective held by
group members about the problem, the choice of appropriate methods, and the
desired outcomes. As McGrath (1984) discusses, group work grounded in
cooperation (participants have a shared perspective) is quite different from that
(thus emphasizing negotiation among participants with
grounded in conﬂict
competing perspectives). Here, we re-characterize this dichotomy as a continuum
from conﬂict to cooperation. (ﬁgure 3).

Spatial decisions (e.g.

in land use planning, environmental management,
highway routing) are generally contentious. Geocollaboration methods and tools
for these applications must support not only shared understanding but also
resolution of disputes among competing points of view. Scientiﬁc knowledge
construction by research teams working together toward a common goal is likely to
be more cooperative. For such research teams, methods and tools must support
innovative thinking as well as comparison and synthesis of what might initially
seem to be divergent ideas. As team size grows or becomes more interdisciplinary,
the likelihood for tension among competing scientiﬁc paradigms will
increase,
increasing the need for tools that support conﬂict resolution. Similarly, panels of
scientists developing scientiﬁc policy may be quite contentious, requiring tools
similar to those applicable to any contentious decision-making.

3.4. Spatial and temporal context

The spatial and temporal context of group work activities fundamentally
determines the nature, and potentially the success or failure, of geocollaborative
work. As pointed out by Ellis et al. (1991) (and for geospatial information by
Armstrong (1993) and Shiffer (1998)), collaboration can involve participants
sharing work at the same or different place and the same or different time (ﬁgure 4).
For geocollaboration generally, a dynamic visual display becomes the mediator that
supports collaboration in these four ‘meeting situations,’ particularly for those that
are different-place.

Much of the research directed to geocollaboration has focused on same-time–
same-place group spatial decision support, collaborative planning, and similar
applications (Armstrong 1993). Nyerges and colleagues (Nyerges 1999, Jankowski
and Nyerges 2001a) have pursued a systematic program of research focused on
GIS-supported, same-time–same-place collaborative decision making, design and
implementation of group systems, and development and application of methods for

Figure 3. The range of perspective commonality that characterizes group work.

Visually-enabled geocollaboration

9

Figure 4. Sample geocollaboration applications for each of the four space-time situations.

evaluating these systems. Recent advances in geospatial information technology
that support large distributed databases and on-line GIS have lead to several
prototypes that facilitate different-place collaboration (Jones et al. 1997, Churcher
and Churcher 1999). Such efforts in GIScience toward different-place collaboration
are quite limited and have emphasized using web-based groupware integrated with
webGIS (through use of tools such as electronic whiteboards for sketching on maps
(Churcher and Churcher 1999, Rinner 2001)).

3.5. Interaction characteristics

Interaction among participants within a geocollaborative environment involves
(at least) three interrelated factors. First, is group size and aggregation (how many
participants are collaborating and what if any subgroups are they organized into?).
Second, is the topology of connections among group members or subgroups (who is
connected to whom?). Connection types include situations with every participant
connected to every other (e.g. a group of students using multi-participant chat and
electronic whiteboard tools to conduct a class project on regional landuse change),
hierarchical networks (e.g. a military command hierarchy where communication
between units goes through the unit leader), and many others. Third, are constraints
on form and ﬂow of information among participants (what promotes or impedes
information dissemination crucial to collaboration?) (ﬁgure 5). While partly a
technological issue, these constraints are often the result of group social structures.
For example, different modes of social and cultural organization will impose rules
or guidelines that control or constrain information exchange. A democratic
collaboration is likely to dictate two-way communication along all links without
directional preferences. On the other hand, military hierarchies and other
command-and-control applications will give preference to unidirectional commu-
nication. For example, communications from a crisis management command centre
may contain both information and directives but ﬂows back to the command centre
from the ﬁeld may be restricted only to information.

Social Network Analysis (Wasserman and Faust 1994) provides a formalized
approach to support
the relationships,
the study and characterization of
interdependencies, and structure and linkages of individual nodes in a network.
Social networks use explanations of the concepts, deﬁnitions and processes of
how individual social units are linked to one another to identify patterns among
relationships, and gain an understanding of the underlying network structure

10

A. M. MacEachren and I. Brewer

Figure 5. Three key factors in group interaction: topology of participant connections (who
is connected to whom), group size and aggregations (how many groups of
participants are involved and how big are the groups), and information constrints
(what are the technological and social
impediments to information ﬂow among
participants who share a connection).

(Wasserman and Faust 1994). Another important aspect of the connections among
participants is the degree of anonymity allowed or imposed. For related ideas in
the context of groupware and multi-user interface design see (Mandviwalla and
Oldman 1994, Prates et al. 1997).

Within same-time (synchronous) collaboration (whether same- or different-
place) the form and ﬂow of information can be further categorized temporally.
Possible categories are: (1) sequential interaction, one participant at a time talking
and/or manipulating system parameters, (2) simultaneous interaction, multiple
participants talking and/or manipulating system parameters at the same time,
(3) mixed participation, where one individual controls the display but all can
communicate verbally. These categories are conceptually similar to ones proposed
by Oviatt et al. (1997), for integrating modes of interaction (e.g. speech and gesture)
with single-user multimodal systems.

3.6. Tools to mediate group work

Considerable attention has been given to development of tools that mediate and
facilitate group work; the literature of CSCW is replete with examples, see: (Grudin
1990, Mandviwalla and Oldman 1994) for overviews. CSCW technologies, often
called groupware, can be characterized as information technology that allows
people to work together more effectively, with an emphasis on sharing tasks and
decision-making (Ackerman 1994). Many of these technologies are generic ones,
such as those for Internet chat and video conferencing. Others are targeted to the
four problem contexts delineated above: knowledge construction, design, decision-
making, and training/learning. We address each below, brieﬂy.

3.6.1. Knowledge construction

Research on groupware to enable knowledge construction has focused on
methods and tools that support information sharing, group problem conceptu-
strategies, e.g. development of
alization, and joint knowledge development

Visually-enabled geocollaboration

11

diagrammatic reasoning methods for structuring work (Shum et al. 1997). The
OASIS system is among the few efforts thus far to develop groupware for
geospatial knowledge construction (Mesrobian 1996). OASIS provides a ﬂexible,
extensible object oriented environment for visualization-enabled cooperative work. The
project, however, focuses primarily on tools that mediate among heterogeneous
software applications
that mediate among human
than on tools
collaborators. Our own collaborative visualization efforts also address visual
mediation of knowledge construction (and are discussed in more detail in §5 below)
(Brewer et al. 2000).

rather

3.6.2. Design

Most design work today (e.g. in software engineering or urban development)
requires the contributions of multiple individuals with interdisciplinary expertise.
Research, however, has just begun to address the role of technology in supporting
design teams. Patel et al. (1997), in one example, focused on collaborative software
design, analysing the functional and nonfunctional requirements necessary for
virtual teams to undertake different-place design activities. Their ﬁndings indicate
that tools—created to help groups develop and understand both task structure as
well as the role of collaborators in meeting overall group objectives—assist the
process of asynchronous collaborative design and rapid system development.

In work focusing on same-place, synchronous design, Arias et al. (2000) have
developed a virtual workbench to display map-based information that supports
collaborative participatory design of neighbourhood transportation systems and
bus stop location. Their research focuses on facilitating shared understanding among co-
located design teams by analysing the social and technical aspects of design teams
at work on real world geographical problems. They focus particularly on the role of
boundary objects (see §4.1 for discussion of boundary objects) and physical exter-
nalizations that promote team discussion and collaborative thought development.

3.6.3. Decision-making

Multiple (often conﬂicting) criteria, diverse participants, and vague problem
speciﬁcations characterize decision-making situations that involve geospatial infor-
mation (Xiang et al. 1992). A common approach to dealing with these factors is to
integrate multicriteria evaluation (MCE) methods and electronic voting tools with
GISystems (Jankowski et al. 1997). The basic aim of MCE is to integrate multiple,
often conﬂicting, objectives comprising multiple criteria,
to indicate decision
makers’ preferences, and to allow testing of ranked and weighted alternatives
(Carver 1991, Jankowski and Richard 1994). While MCE was integrated with GIS
in the 1990s (Carver 1991) (note: much of the follow up work in this vein appears
under the label SDSS), limited attention has been directed to the role of visual
displays as a mediator for the GIS-enabled MCE process speciﬁcally or in SDSS or
GDSS research, more generally. There is also a clear need for methods that account
for mixed information (qualitative and quantitative) in decision-making (Munda
1994). Visual display may be particularly useful as a mechanism through which
qualitative information can be integrated into the process.

12

A. M. MacEachren and I. Brewer

3.6.4. Training/Learning

Work in computer supported collaborative learning (CSCL) has been imple-
mented to support multiple educational levels. In the earth sciences, speciﬁcally,
Fortner and Mayer (1996) focused on K-12 collaborative learning activities that
make use of satellite images to support study of global environmental change.
These authors characterized collaborative learning as processes that are engaging
and that promote exploration, concept development, elaboration, direct application
and assessment (Fortner and Mayer 1996). Collaborative learning tools and online
discussion forums to promote distance education are being developed and deployed
to educate non-traditional professional students who cannot spend substantial
amounts of time away from work (DiBiase 2000, Janicki and Liegle 2001). The
supporting tools focus on asynchronous activities and (thus far) typically rely on
e-mail for instructor-student collaboration and threaded discussions for student-
student collaboration.

4. Visual mediation for geocollaboration

As noted above, the role of visualization (or visual representations more
generally) as a mediator of group work has been given very little attention. Below,
we distinguish between visual, mediating representations that depict the objects of
collaboration (information and perspectives on that information) and those repre-
sentations that depict the activity of collaboration (collaborators and their actions).
In §4.1, we consider the use of visual representations as devices through which
perspectives can be shared and information meaning rationalized. Next, in §4.2, we
consider problems of representing participants and their actions in ways that enable
group work (e.g. that facilitate dialogue among participants) while not interfering
with the information representations around which collaboration is taking place.

4.1. Representing information

Visual representations of geospatial information have the potential to provide a
display ‘space’ (frame of reference) within which participants can share and inte-
grate information, compare perspectives, and negotiate approaches and solutions to
problems. More speciﬁcally, visual displays can be used as:

. shared objects to talk about: to depict selected information, provide geo-

context, and enable information integration;

. shared objects to think with: to develop, clarify, and support structuring of

arguments;

. shared objects to coordinate perspectives and actions: to compare perspectives,
mediate among knowledge domains of participants, link perspectives across
scales, and enable joint activity.

This categorization extends one ﬁrst proposed by Arias and colleague between
objects to talk about and think with (Arias et al. 2000). Elsewhere, MacEachren
(submitted) focused on geovisualization more speciﬁcally as the object of collabo-
ration, a device to support dialogue, and a device to support coordinated work.
Armstrong and Densham (1995) present some initial ideas about the role of
cartographic representations as mediators for geocollaboration, in the context of
group decision-making speciﬁcally. They propose a set of new map types designed
to facilitate the process of making comparisons among alternative facility location

Visually-enabled geocollaboration

13

scenarios, thus map types that act as shared objects to coordinate perspectives (and
perhaps subsequent actions).

In what may be the only study thus far to investigate empirically the use of
maps and related graphics as mediators for group work with geospatial data,
Jankowski and Nyerges (2001b) found that maps were used primarily in the
analytic-integration phase of a simulated decision-making process (thus as shared
objects to talk about, or perhaps to think with). As the authors point out, the
limited role found for maps and graphics in the exploratory-structuring phase of the
process may have been due to the particular software conﬁguration used in their
study. The conﬁguration grafted their Spatial Group Choice software tools onto a
commercial GISystem (ArcView 2.11). It included no extensions (to the ArcView1
it lacked speciﬁc support for group
visual display methods and tools), thus,
dialogue or for coordinating perspectives or actions. That their results found only
limited use of standard GISystem-based mapping tools in a collaborative setting
reinforces our point that while groups can adapt to, and use tools built for
individual work, such tools will not support group work effectively.

In one of the few attempts to develop visual tools intended speciﬁcally to faci-
litate group work with geospatial information, Rinner (1997, 1999) focuses atten-
tion on how to graphically mediate geo-referenced discussions within a planning
context (thus on shared objects to think with and, potentially, to coordinate per-
spectives and actions). He considers geo-referenced discussions to have two primary
components: (1) arguments (contained in messages) and (2) geographical objects
(e.g. houses, parcels, roads). Rinner’s approach to enabling discussion incorporates
map-based graphics within a moderated discussion format that uses maps as
vehicles for sharing as well as storing information. The prototype system allows
users to access map locations to which arguments refer, attach a geographical refer-
ence to each new argument, access discussion messages through map symbols that
signify geographical objects, and attach new messages to a map object or region.
The dialogues through which groups solve problems or reach consensus with
Rinner’s environment, or ones like it, are grounded in the meanings attached to
both geographical objects and arguments in the dialogue. The meanings, in turn,
are constructed, shaped, and changed by the interaction of people with each other
and with systems that encode the information. To facilitate geocollaboration,
attention must be directed to enriching the connections between visual and database
representations and between both of these and the meanings (i.e. interpretations)
that each user brings to the group situation.

Semiotics, the science of signs (i.e. signiﬁcation) and sign systems, offers one
approach to creating a semantic framework through which the meanings associated
with geospatial
information in collaborative situations can be understood and
managed. A fundamental concept in semiotics is the ‘semiotic triangle’ (Pierce 1955)
which itself signiﬁes the three components making up a ‘sign,’ the referent, sign-
vehicle, and interpretant (ﬁgure 6). The referent is the entity being represented (e.g. a
particular object such as a lake or an abstraction such as a land use category). The
sign-vehicle stands for the referent; where blue text labels might stand for a speciﬁc
lake and the colour red might stand for the category ‘urban’ seen anywhere on the
display. The interpretant is the meaning or interpretation derived by a user from the
sign-vehicle about the referent. For a comprehensive discussion of the semiotic

14

A. M. MacEachren and I. Brewer

Figure 6. Following Pierce’s (1955) triadic approach to signs, a sign can be deﬁned as a
relationship among three components, the semiotic triangle. First is the referent. the
object being signiﬁed. Second is the sign vehicle, the object or device (e.g. a written
word, a map symbol) that stands for or signiﬁes the referent. Third is the interpretant,
the meaning derived from (or perhaps read into) the relationship.

triangle and of semiotics relevant to visual representation of geospatial information,
see (MacEachren 1995).

In a collaborative environment, maps and components of maps (e.g. a line
depicting a highway on an urban master plan or an isosurface depicting a severe
precipitation event in a scientiﬁc visualization environment) act as sign-vehicles
standing for objects in the world that can serve as the focus of a dialogue. In
Rinner’s (1997) environment, discussed above, the dynamic link between map
objects and arguments provides an explicit connection between the sign-vehicle (the
map or map object) and a wider semantic framework within which the interpretant
is instantiated. This connection, in turn, increases the potential for map objects (or
other visual display elements) to serve as effective external representations of
boundary objects.

Boundary objects are constructs (partially shared meaning relationships –
interpretants in semiotic terms) that provide a meeting ground among perspectives
held by different participants in a collaborative activity (Star 1989). They are
objects that all parties in a collaborative situation share some understanding of—
but often only partially. Thus, they provide an anchor/hook for building greater
shared understanding. In the case of Armstrong and Denshem’s (1995) cartographic
mediators for geocollaboration discussed above, their demand and supply maps are
likely to serve as external representations of boundary objects through which
participants can structure discussion. All participants have some understanding of
the concepts of, and components in, supply and demand and the map depictions
anchor those concepts in the characteristics of particular places. By jointly inter-
acting with the map, participants can begin to understand where their conceptions
coincide and differ.

Precipitation represents another concept (relevant to our case studies below)
that can serve as a boundary object, for example in a dialogue between a
climatologist and a hydrologist. The interpretant generated by the sign-vehicle of
‘precipitation’ (whether spoken, instantiated as text, or instantiated as a coloured
region on a map) is similar but not identical for the two individuals. The boundary

Visually-enabled geocollaboration

15

object can provide a portal from one perspective to the other (Harvey and
Chrisman 1998) and can thus facilitate resolution of conﬂict. For the example posed
above, the common understanding of precipitation provides an initial basis for
dialogue while the differences that become apparent as the dialogue progresses help
to establish a perspective that might go well beyond this one concept. In this case,
the initial display elements instantiate boundary objects to talk about. Perhaps
more challenging is the design and implementation of visual tools that instantiate
boundary objects to think with and/or to coordinate perspectives, particularly in
cases of conﬂict. A goal for visual tools designed to support coordination of
perspective is to provide such boundary objects within an environment that enables
identiﬁcation of differences in interpretants for any sign relationship and (for some
applications) reconciliation of those differences (ﬁgure 7). One example is use of
manipulable visual tools as an interface to parameters of a simulation model,
allowing collaborators to iteratively work toward a common understanding of the
impact of factors on a process (e.g. the downstream impact of different ﬂood
control devices).

For digital geospatial data, the sign relationship is often an indirect one, with
the real-world referent signiﬁed in the database through some abstract construct
and the visual sign vehicle treating that database sign vehicle as the referent of a
second linked sign. Since current geospatial databases (at least non-experimental
ones) provide no mechanism to encode meaning,
important information (the
interpretant of the database sign relationship) is lost. As a result, the display’s
human users must rely on a combination of their own prior knowledge, knowledge
of their collaborators, and characteristics of the display itself to provide a context
for generating an interpretant. Linking map-based sign-vehicles to arguments in a

Figure 7. Group semiotic triangles depicting four users with substantially different
intepretants for the same sign vehicle-referent relationship (top view) and subsequent
convergence of intepretants as a result of joint work.

16

A. M. MacEachren and I. Brewer

collaborative setting provides a mechanism through which meaning might be
captured and encoded in the database for subsequent use.

4.2. Representing participants and their actions

information about attitudes,

When individuals collaborate in the same-place, without the assistance of
technology, they are able to observe each other’s actions. This interpersonal contact
intentions,
provides important, often unspoken,
motivations, and strategies that can facilitate the process of dialogue among the
participants. These unspoken cues (shrugs, grimaces, ‘ums’ and ‘uhs’) are termed
backchannel feedback (Dix et al. 1998). Collaborators use such cues to indicate that
they are ready to interject, take control, or speak. Dix et al. (1998) provide an
indepth discussion of the role of back channel feedback in conversations and its
incorporation in system design. When technology intervenes, these aspects of nor-
mal dialogue are often missing. This absence is obvious for different-place collabor-
ation, where participants might be represented only by an avatar or text ID and
their actions represented only by outcomes, with the process of achieving outcomes
often hidden. Even in same-place collaboration, technology designed to enhance the
experience in some ways can interfere with normal dialogue (e.g. the stereo goggles
typically used in an immersive virtual environment restrict the participant’s view of
anything other than the display screen—for details, see §5.2 below).

Taking full advantage of visual tools designed to facilitate geocollaboration,
then, will require attention to the representation of participants and their actions.
Such representations must be integrated with displays of the information that
collaboration is about, in ways that do not impede participants’ abilities to use that
information. These representations of participants must provide mechanisms to
depict, for each participant:

. their own presence in the environment (providing context against which to

judge the location, viewpoint, and perspectives of other participants);

. their own actions on objects

in the environment and toward other

participants;

. other participant’s presence in the environment;
. other participant’s deictic actions toward objects, each other, and the user.

Potential representations of participants and actions can take two general
forms, representations embedded within the information display (e.g. the avatars
and light beam pointers described below for collaborative GeoVirtual Environ-
ments) or representations separate from the primary information display. The
advantage of the former is that the user’s attention can remain on the information
display at all times. The disadvantages are that the display is more complex and
that some actions cannot be represented effectively within the constraints of the
information display. A separate representation of participants and their actions,
that can be visible or hidden at the discretion of each participant, is more ﬂexible
and can usually encode more information but may distract participants from the
primary information display. One example of a minimal representation that limits
the potential for distraction from the primary task of group activity is Erickson and
Kellogg’s (2000) ‘social proxy’ graph, an abstract depiction of users, their presence,

Visually-enabled geocollaboration

17

and their activity; the social proxy graph is visible to all users and represents the
relative activity of each in a conversation over time.

For group work with geospatial information, there is a need to represent not
only who is participating at what level, but also which representations of data they
are using and what they are doing with those representations. We have implemented an
initial prototype participant watcher designed to support representation and analysis
of participants and their actions. The prototype watcher is designed to track the use
of a multi-window geovisualization display (speciﬁcally a map, scatter plot, and
parallel coordinate plot—PCP) used in knowledge construction activities (ﬁgure 8).
We are now working on a plan for usability assessment of this and alternative
representations of participants and their actions. As with our initial implementa-
tion, one anticipated use of the display is for post-session analysis of collaborative
work. Our efforts thus far have focused on representing who is interacting, when
each participant is interacting, and what each participant is doing. A more
challenging task for future research is to represent how the visible user activities
relate to user goals within the problem/task context.

5. Case studies

In this section, we present case studies of two visually-enabled geocollaboration
prototypes, one building on prior work in collaborative visualization, the other on
prior work in GeoVE. The case studies illustrate application of the conceptual
framework outlined in §3. In addition, they serve to begin addressing some issues
raised in section four concerning how to develop visual mediation methods and
tools that support geocollaboration effectively.

Both case studies focus on understanding multi-dimensional space-time environ-
mental data in an effort to achieve new insights concerning environmental processes
and to predict (and perhaps mitigate) environmental change. While the prototypes
share a focus on group work (by scientists) with spatio-temporal environmental
data, they differ in the kinds of technology used (desktop versus semi-immersive
large-screen), in the kinds of visual representations used to mediate collaboration
(2.5D animation versus 3D integrated space-time views), and in the spatial-
temporal context
for collaboration (emphasis on different-place–same- and
different-time compared to same- and different-place–same-time).

Our goal in this section is not to provide a comprehensive discussion of the
research projects highlighted (related discussion appears elsewhere,
relevant
citations are below). Instead, we use the projects (each of which inﬂuenced
framework outlined above) as a vehicle for
development of
demonstrating the use and usefulness of the conceptual framework presented and
for identifying research questions.

the conceptual

5.1. Same-time—different-place collaborative geovisualization

case

Our ﬁrst

study focuses on a prototype, desktop, different-place
geovisualization environment developed to support collaboration by a team of
multidisciplinary scientists as they explore complex spatiotemporal data. The
integrated software components designed
environment consists of a suite of
speciﬁcally to facilitate collaboration among users who are exploring time series of
climatic data and enable them to share knowledge as they identify patterns and
processes (ﬁgure 9). The system allows multiple users to control parameters of

18

A. M. MacEachren and I. Brewer

Figure 8. Design prototype collaboration display with activity tracking (controls at top
right) and ‘watcher’ tools (2 lower right panels). Created in Macromedia Flash1. The
prototype includes only placeholders for exploratory data analysis tools. Its purpose
is to illustrate the potential of such an observation tool. The two lower right panels
provide a dynamic representation of each participant and their collective actions. The
bottom panel indicates who is in control and which display component they are
interacting with (indicated by the shaded rectangle) as well as the relative proportion
of time each participant has been in control. Here, the ﬁrst participant (AMM) is in
control of the display and is interacting with the map. This user has been in control
of the display for about half of the session thus far (as indicated by the grey ﬁll in the
bars representing each user). The upper watcher panel provides summary information
about actions over time. The top half of the panel indicates every mouse click made.
For the session depicted, participants focused initial attention on the map (for nearly
half of the session to this point). Then attention shifted to the scatter plot (with
nearly continuous interaction). Finally, attention moved to the parallel coordinate
plot (with a period of consistent interaction followed by alternating periods of
inaction and action). The bottom half of the panel illustrates the zoom factor for the
map over time, as a user adjusted the scale gradually, then reverted to the default
scale. To the right, ﬁlled bars represent the proportion of the session during which
each display component was the focus of attention. The prototype also tracks mouse
movements and allows for replay of those movements. The primary intended
application of this watcher tool is to support post session analysis of the collaborative
session. This prototype was implemented by Eric Steiner.

temporal database queries and subsequent time series animation, see (Brewer et al.
2000, MacEachren et al. 2001)
for details. Actions (zoom, rotate, classify)
performed on one machine are passed to other connected machines through a
server-client system. Sections below apply the six-part framework presented above
to discussion of this collaborative geovisualization prototype.

Visually-enabled geocollaboration

19

5.1.1. Problem context

For this case study, two similar applications were targeted: understanding time
series temperature and precipitation regimes for the Susquehanna River basin of
Pennsylvania, New York and Maryland and understanding monthly temperature
patterns for Mediterranean Europe. For both, the scientists with whom we were
collaborating were interested in identifying topographical and spatial factors that
may affect regional (and global) climate regimes. In relation to the conceptual
framework outlined above, this collaborative prototype was designed to support
knowledge construction, but extensions have been considered that support risk
assessment and decision-making applications as well as science education.

5.1.2. Collaboration tasks

During in-depth individual and group interviews with six participating scientists,
we elicited responses regarding what types of tasks the scientists would attempt to
accomplish when using a distributed map-based data exploration and analysis
system. A detailed account of our interview methods and the initial ﬁndings is
reported in (Brewer et al. 2000). Here, we reexamine ﬁndings in relation to the four
kinds of collaboration tasks detailed above for knowledge construction: explore,
analyse, synthesize, and present.

For collaborative exploration, one participant discussed the role of maps in the
task of brainstorming, or posing ‘what if’ scenarios. Other participants emphasized
speciﬁc manipulation capabilities needed to support exploration (e.g. dynamically
selecting which data to depict,
‘focusing’ on subsets of data) and speciﬁc
mechanisms that support sharing of ideas (e.g. the ability to highlight features
or otherwise draw attention to them).

For collaborative analysis, the participants saw map-based computer displays
serving as a mediator between different data sources and scales of analysis that
would help place all users ‘on the same page’ during collaborative discussions. In
addition, split screen views were discussed as a way to support comparison (and
coordination) of perspectives. For different-place collaboration, the ability to know
what others are doing was seen as important by most participants as was the ability
to use voice communication to discuss perspectives.

For collaborative synthesis (group work to coordinate perspectives, develop an
understanding of differences among perspectives and, where practical, develop a
common perspective), substantial differences in typical map/display use across discip-
lines were noted. Among the more important were the different spatial and tem-
poral scales that disciplines emphasize and the need for collaborative environments
to support tools for relating scales. Display format was also an issue discussed.
Most users felt that a table-top display would have advantages over a wall display
for generating active participation among participants (and active participation should
lead to more effective and useful synthesis). Few (if any) existing tools support
group synthesis activities, making development of such tools a particular challenge.
indicated that we ‘can’t
communicate (spatial characteristics) without a map.’ Three participants noted
that maps were important for representing temporal (as well as spatial) information
(in time series analysis, query by season, or ﬁnding cycles and trends). In relation to
display format, large screen displays were seen as useful for presentation to groups
(with wall displays better than table-top displays for this purpose).

For collaborative presentation, one participant

20

A. M. MacEachren and I. Brewer

Figure 9. Same time/same place collaboration on linked desktops. Users can manipulate
orientation, scaling, and colour schemes of a 2.5D animated depiction that displays,
simultaneously,
spatially and temporally continuous environmental data (e.g.
temperature and precipitation superimposed on an extruded terrain surface). Left
panel shows one frame of an animated representation of user-selected climate data
(precipitation is shown) draped on a 2.5D terrain depiction. Upper right panel
contains controls for color scheme and animation. Lower right panel contains visual
query tools that allows user to select subsets of data using a combined linear-cyclic
interactive legend (in this case. all days for May, 1993).

Figure 10. Same-place collaboration at a large-screen ImmersaDesk.

Visually-enabled geocollaboration

21

Beyond these four tasks, there was consistency across the group in a view that
multivariate, multiscale map displays that depict change over time are important
prompts for collaborative work in environmental science. Overall, a common idea
was that maps help to provide the contextual reference information (boundaries,
roads, etc.) to allow interdisciplinary idea sharing. In addition, one participant
noted that physical scientists often treat maps as an input to process modelling while
social scientists consider maps to be presentational devices (emphasis added). Thus,
disciplinary conventions may have an impact on the mediating role of visual display
and the stages of group work where it is most successful.

5.1.3. Commonality of perspective

Individual

interviews addressed the potential for a distributed collaborative
system (derived from the prototype) to support group work on activities that
require integrating multiple scientiﬁc perspectives. Following from discussion of
analysis scales at which different disciplines focus, a key capability for colla-
boratively exploring environmental processes is to support representation of
connections among processes across scales. A second issue raised was the need to
support both individual work (allowing individuals to develop their ideas in a
private display space before sharing them with the group) and comparison of
perspectives (e.g. thus the ability to broadcast that display to the entire group for
discussion and possible synthesis).

5.1.4. Spatial and temporal context

As noted above, the focus of this case study was on same-time–different-place
collaboration. Interview results, however, also indicated that participants could
envision using the system for a range of collaborative situations. Situations
discussed included same-time–same-place planning and decision-making (particu-
larly as enabled by large screen displays) and different-time (both same- and
different-place) joint work on meeting preparation (particularly in support of
environmental planning). Since planning processes often involve multiple meetings
and discussions, the system could be used to build and retrieve a record of activities
leading to a decision (given tools to create annotated histories).

5.1.5. Interaction characteristics

The prototype system provides a variety of topological connection possibilities.
The client server system can support a relatively large number of connections
(w10). With the current implementation, there is no built-in method for estab-
lishing user control. Thus, the ﬁrst user to initiate an action controls all functions,
until they release the mouse. Collaboration among three or more users would
probably be somewhat chaotic unless an ‘etiquette’ for shared control could be
achieved (we have only tested the system with pairs of users). The system does have
a function that allows one operator (a moderator) to control every other operator’s
access privileges. The moderator can make participants active or inactive. During
our interviews, participants indicated that it was essential for users of a distributed
system to know who has control and that there be a formal method for gaining
and relinquishing system control, so that single individuals cannot dominate the
collaboration.

We suggest that, until mechanisms and affordances are developed to support

22

A. M. MacEachren and I. Brewer

practical shared control of a distributed collaborative system, co-equal interaction
will be most practical for groups of three or less. The number of participants could
increase substantially, however, for instructor-led collaboration. For example, if the
system described here were used for same-time–same-place collaboration in which
every participant had his or her own display, an instructor, team leader, or
moderator could use the ‘make active / inactive’ function to allow one participant at
a time to manipulate the system for shared questions and discussion. Another
possibility is to let the natural ﬂow of conversation dictate who has control by
maximizing back channel feedback in small group settings. The integration of more
natural conversational practices and norms into the interface design could
potentially improve collaborative work.

5.1.6. Tools to mediate understanding

The results of our interviews made it clear that several necessary tools for
mediating understanding were missing from the prototype. In addition to the need
for an indication of who was in control and a mechanism for sharing control (both
mentioned above and implemented in the prototype participant watcher discussed
in §4.2), participants also requested a suite of drawing and selection tools. To
facilitate effective member-to-member communication, participants also asked for
integration of video conferencing, telephone, and online chats and message boards.
Tools for attracting group attention were also suggested to be extremely important.
Moreover, participants asked for domain speciﬁc representations (and a way to
compare them), so that collaborators with different backgrounds could bring
themselves, or the group, up to speed on concepts and terminology. Particular
attention was placed on the ways in which individual users could direct or attract
attention of the entire group. The need to represent individual participants and
their actions was discussed by most participants. While avatar representations were
an option considered, most participants advocated some form of simpler color-
coding as the desired mode for representing individual users.

5.2. Same-time–same- and different-place collaborative GeoVE

Our second case study focuses on the use of large-screen immersive VE
technology (speciﬁcally an ImmersaDesk, IDesk for short) to facilitate group
discussion about environmental processes. We had the opportunity to test this
environment for both same-place and different-place group work focused on
exploratory analysis of times series geospatial data. For more details on the
conceptual approach to GeoVE developed, see: (MacEachren et al. 1999). The
different-place collaboration was achieved through assistance of environmental and
computer scientists at Old Dominion University (Cathy Lascara, Glen Wheless, and
their staff) who developed Cave5D, the software environment used (Wheless et al.
1996). Using high speed internet connections, two separate tests were conducted,
one linking our IDesk with another IDesk at Old Dominion and a second linking
our IDesk with one at the University of Iowa (working with Marc Armstrong, Judy
Brown, and their students/staff) (ﬁgure 10). As we did for the ﬁrst case study, we
apply the conceptual framework presented above to identify a set of key issues to
consider for geocollaboration supported by VE technologies.

Visually-enabled geocollaboration

23

5.2.1. Problem context

The problem context for this case study was, as above, knowledge construction
and reﬁnement. The application domain was regional climate processes, speciﬁcally
spatiotemporal relationships between temperature and precipitation. Data used
included daily temperature and precipitation values (from May through July, 1972).
again for the Susquehanna River basin. An issue of particular interest to the
scientists with whom we were collaborating was the precipitation-temperature
impacted the basin and
relationships associated with Hurricane Agnes as it
comparison of these relationships to those for smaller scale (ordinary) storms
associated with mid-latitude cyclones moving across the region.

The functionality provided by an IDesk using Cave5D as the software
development environment imposed substantial limits on the ability of collaborating
individuals to work on a simulated knowledge construction task—primarily due to
the interaction characteristics of the environment (see below). Our conclusion here
is that the IDesk environment, as tested, is better suited to instructor-led situations
than to those with multiple independent participants (thus to training and
education or command and control applications rather than scientiﬁc exploration
applications). This conclusion will be elaborated in sections below.

5.2.2. Collaboration tasks

The initial methods and tools implemented were ones intended to support same-
place dialogue related to knowledge construction, thus dialogue focused on data
exploration. The primary exploration goals in our case study were to understand
the space-time relationships of each attribute and the interrelationships between
attributes over time.

The Cave5D software used supports a rather small range of display and
interaction forms. Using the available 3D display capabilities, terrain was mapped
to an x-y-z extruded surface (using only a small portion of the z-dimension of the
view). Above this terrain depiction, x and y continued to represent latitude and
longitude while time was mapped to the remainder of the z dimension (ﬁgure 11). In
this space-time portion of the display space, the olive green ‘clouds’ are space-time
precipitation isosurfaces (regions in space-time with precipitation above a threshold
value). Hurricane Agnes is the largest event, spatially covering the entire Susque-
hanna River basin and lasting for several days (a regional ‘blanket’ of rain multiple
days thick). The blue-yellow layer ﬂoating above the hurricane event depicts
temperature, using a spectral colour scheme in which blue depicts cool, yellow
intermediate, and red high temperatures.

The implementation supports three kinds of exploration tasks. First, users can
visually inspect the 3D information structure by rotating the display object as if the
representation was a physical model being manipulated in the hand. Second, inves-
tigation of the relationships among attributes is supported by the ability to drag
layers (time slices in this case) through the precipitation display. The third kind of
exploration task supported is detailed investigation of spatial and temporal charac-
teristics of space-time events, through changes to the isosurface threshold used.

Our experience with simulated exploratory knowledge construction tasks in
this prototype highlighted a fundamental difference between task typologies for
decision-making and those to support knowledge construction. For decision-
making, decades of attention have been devoted to the process of group work and

24

A. M. MacEachren and I. Brewer

Figure 11. Terrain depiction (lower portion of display) merged with space-time representa-
tion of precipitation (green isosurfaces) and temperature (yellow-blue layer), with x-y
representing geographical position and z representing three months of time. The
threshold value for the isosurfaces can be manipulated by the users; a tighter
threshold acts to visually isolate the core precipitation regions (in space and time),
thus those most likely to have generated immediate ﬂash ﬂooding (deep in time) and
those likely to generate more sustained ﬂooding (broad in space). The temperature
layer can be moved through time by clicking and dragging. Dragging the layer up
through the hurricane event easily highlights short-term evaporative cooling that
follows the hurricane. What surprised our earth science colleagues about the display
was that it also allowed them to visually explore the similar, but much more subtle,
cooling associated with local thunderstorms (even though the data depicted are at
daily temporal resolution).

Figure 12. Same-place collaboration at a dual, large-screen stereo display.

Visually-enabled geocollaboration

25

we have relatively sophisticated group decision-making task typologies as a result
of that effort. With knowledge construction, however, both the tools and the
terminology we use to describe the process have focused on the individual scientist.
While there has been research to develop typologies of tasks related to visual data
exploration (Keller and Keller 1992, Knapp 1995, Qian et al. 1997) and to geo-
spatial data use more generally (Albrecht 1995), these typologies have not addressed
tasks that are speciﬁc to group work, such as choosing among or synthesizing
potentially contradictory explanations for an apparent relationship seen in the
display. Just as efforts to isolate speciﬁc group decision-making tasks from one
another have supported development of tools targeted at each group decision-
making task, a similar effort to delineate knowledge construction tasks at the level
of group interaction is essential. Such a typology, if collectively developed by the
GIScience community, would help us move from geospatial technologies that
support individual scientists to technologies that support scientiﬁc teams.

5.2.3. Commonality of perspective

This case study was restricted to situations in which there was a relatively high
commonality of perspective among participants, speciﬁcally climatologists using a
shared scientiﬁc paradigm to pursue narrow data exploration tasks. The prototype
emphasized support for direct interaction with the visual display. Due to the
expected high commonality of perspectives little attention was directed to tools that
help to share points of view, explain what is being seen, or integrate different
perspectives and interpretations. As noted above in discussion of the ﬁrst case
study, however, we are beginning to address the more challenging goal of visual
display support for multiple scientiﬁc perspectives. Our current work addresses this
issue in the context of large-screen, non-immersive GeoVE (see §6 below).

5.2.4. Spatial and temporal context

The prototype considered in this case study, was developed initially to support
same-place–same-time collaboration. The primary advantage of the IDesk environ-
ment for this application (over a standard desktop display environment) proved to
be the large screen. Its size (and upright orientation) allowed multiple people to
simultaneously share a similar view of the data. A disadvantage for same-place
group work is that use of stereo glasses limits participant’s ability to carry on a
normal dialogue about what they are seeing; because they cannot take advantage of
gestures and facial expressions as fully as if participants were discussing a large
paper wall map.

As noted, multiple IDesks were linked (using high-speed Internet connections)
to support different-place–same-time applications (in our trials, we have used only
two at a time, but the technology supports more). Remote collaboration requires
tools that support a dialogue. We opted initially for Internet tools that supported
real-time voice communications. The latter proved to be unreliable and we often
resorted to a pair of speaker telephones to communicate among multiple parti-
cipants working with each display. While voice-only dialogues might at ﬁrst seem to
add a constraint on collaboration not faced in the same-place situation, the use of
stereo glasses (as noted above) constrains same-place dialogue using an IDesk in a
similar way.

26

A. M. MacEachren and I. Brewer

5.2.5. Interaction characteristics

The IDesk and network technologies put speciﬁc constraints on interaction
characteristics. For same-place use, only one individual has control of the display
at a time (for convenience, referred to as the guide below) and the hand off of
control from one user to another interrupts any dialogue that is taking place. The
guide must not only hand the control ‘wand’ to another user but also switch glasses
with them, since (at least with our hardware implementation) a physical wire
connects the head tracking unit to one pair of glasses. The environment, thus,
favors an interaction topology in which one person controls the dialogue (thus an
instructor-led situation).

Group size is restricted to perhaps 3–5 individuals by display size and the
optimal viewing position (about one metre from the display and keyed to the
location of the control glasses worn by the guide). Picture quality deteriorates
rather quickly from this location (with the coherence of the stereo view decreasing
and the likelihood that users will become nauseous increasing proportionally).
Similarly, the sense of immersion decreases with distance from the screen.

For different-place collaboration, each guide can adjust their site’s viewpoint
independently (by zooming, panning, and rotating). In addition, each guide can
control which information layers are visible locally as well as globally. This capa-
bility meets a need identiﬁed in previous interviews (case study 1), to provide a
mechanism that supports independent work (local viewing) prior to showing that
work to all collaborators (global viewing). The implementation is, however, quite
limited because participants at any one site see an identical view and it is not
possible to toggle between an in-progress view and the shared view, other than by
turning each information layer completely on or completely off globally.

Overall, for different-place group interaction, the IDesk/Cave5D environment is
best suited to situations in which each group is organized with a team leader who
acts as moderator for collaboration from one team to another. With a voice link, of
course, any individual on one team can direct a comment or question to any
individual on another team, but without control of the display the potential to
answer effectively is limited.

5.2.6. Tools to mediate understanding

An IDesk combined with Cave5D software provides only limited tools to
visually mediate understanding. The software was developed for use in single-user
desktop display, and then ported to multi-walled ‘Caves’ and to the IDesk
hardware platform (still with an underlying single user structure). Even with
enhancements that support multiple locations, these single user roots remain
apparent and limiting. The environment provides only two speciﬁc features to
support same-place collaboration.

First, the screen size allows 2–5 individuals to be near enough to the screen to
use ordinary pointing gestures as a means to draw each other’s attention to features
being discussed. Second, the guide can make use of a laser pointer-like device to
pinpoint features being discussed. This pointer appears more similar to a light-saber
from Star Wars than to a standard laser pointer, because it generates a long narrow
light beam in 3D space. This remote pointer supports some of the functionality that
Florence, et. al (1996) envisioned for ‘wallboards’ (used at ‘spitting distance’), but
with substantial limits. Like a light-saber, its beam has a ﬁxed length. Thus, the

Visually-enabled geocollaboration

27

only way to point at a feature in the foreground is for the guide to move their hand
away from the screen. It is usually easier to pierce an object of interest than to point
at it.

For different-place collaboration, each guide is represented by one light beam.
The beam at any location will appear (to those at that location) to enter the ﬁeld of
view from the guide’s location, thus the origin of the beam will not be visible to the
local participants. For beams representing remote team guides, participants see the
beam plus a small avatar. The location of the avatar represents the team guide’s
viewpoint and the beam represents the guide’s direction of view. This rather
abstract representation (based on our informal experience) seems to be quite
effective in helping each team identify the perspective from which other teams are
viewing the scene and (together with voice communication) in helping to arrive at a
shared perspective.

6. Discussion and ongoing research

The overall goal of the conceptual framework for visually-enabled geocolla-
boration presented here is to guide the design, implementation, and assessment of
geocollaboration environments. The conceptual framework supports a structured
approach to each stage of the design, implementation, and assessment process.
Attention is paid to both the human components of the collaborative environment
(problem context, collaboration tasks, and perspective commonality) and the
system components that can support or impede collaboration (spatial and temporal
context, interaction characteristics, and tools to mediate understanding).

The use of the conceptual framework developed was illustrated through appli-
cation to post-hoc analysis of two prototypes, one focused on different-place—
same- and different-time collaborative geovisualization and the other on same-
time—same- and different-place collaborative GeoVE, both applied to knowledge
construction. This post-hoc analysis provided the basis for discussing strengths and
weaknesses of particular methods and tools applied to environmental science. More
importantly, however, this exercise helps to identify a set of research and IT/HCI
development challenges related to visually-enabled geocollaboration.

Among the most important overarching research challenges are the following:

. To develop a theoretical understanding of the cognitive and social aspects of
both local and remote collaboration mediated through display objects in a
geospatial context;

. To develop approaches to multi-user system interfaces that support rather

than impede group work;

. To understand the ways in which characteristics of methods and tools
provided to support collaboration inﬂuence the outcome of group work.
. To initiate a parallel, concerted effort focused on integrating, implementing,
and investigating the role of the visual, geospatial display in collaborative
science, education, design, and group decision support (GDSS);

We believe that meeting these goals will require an interdisciplinary approach
that draws upon and contributes to advances in a range of domains including
CSCW, CSCL, GDSS, ergonomics, cognitive system engineering, and distributed
cognition.

28

A. M. MacEachren and I. Brewer

Within the overarching challenges detailed above, we also identify a series of

speciﬁc visualization, HCI, and information technology objectives:

. If visual displays are to serve effectively as mediators for geocollaboration, it

is essential to:

. Assess the advantages and disadvantages of extending methods of
interactive geographical and information visualization (developed for
single users) to collaborative settings and compare such extensions with
new methods designed speciﬁcally to meet the unique characteristics of
group work;

. Examine the role of different kinds of visual representation (realistic
versus abstract, animated versus static) and related virtual environment
methods and technologies in geocollaborative settings;

. Because available control devices and kinds of interaction supported in
current visually-enabled collaborative environments rely on desktop meta-
phors, they impede dialogue, for example using popup ‘dialog’ boxes for
achieving actions such as turning display of layers on and off. More natural
interfaces that allow users to direct attention to (and talk about)
the
information being displayed, rather than to using the system, are needed to
facilitate dialogue.

. New interaction devices are needed that support multiple users in the same
place at the same time. This is particularly necessary to support multiple co-
equal collaborators (rather than instructor-led collaboration).

. For situations with low commonality of perspectives, interfaces must do more
than help collaborators realize each others’ viewing location. Tools are needed
to help them understand and share differing conceptual perspectives.

We have begun to experiment with three environments that address the
challenges identiﬁed. All use large screen display but de-emphasize immersion (by
omitting the head tracking used with the IDesk display). One of these environments
is the HI-SPACE table described above (ﬁgure 1). By allowing integration of
physical objects (phicons) with the visual display and supporting multiple users at
once, the HI-SPACE table decreases some of the impediments to group work
found in our early prototype tools. The HI-SPACE environment was designed for
same-place collaboration and we are now working with colleagues at PNNL to
extend it for different-place collaboration using linked tables.

The second environment we have begun to use is a new large-screen VE con-
structed by our collaborators in the Center for Academic Computing at Penn State
(ﬁgure 12). This new environment is not dependent on the Cave library. Instead, we
can use any software capable of generating 3D depictions. We are now using our
Java-based GeoVISTA Studio software to develop stereo applications for group
work (Takatsuka and Gahegan 2002). The hardware implementation uses a pair of
non-immersive, large-screen. stereo displays (driven by two pairs of rear-projection
video projectors). The displays are viewed with polarized glasses. The lack of head
tracking (and absence of wires between glasses and display) makes collaboration
among users more balanced (i.e. the environment is useful for both instructor-led
collaboration and group work among equals). Although one user is still in control
(using a gyro mouse), it is much easier to trade off that control and the display is
not constantly readjusting its perspective to that of one user while he or she moves

Visually-enabled geocollaboration

29

around. The dual display facilitates work by larger groups and, as shown, facilitates
discussion of both the visual representation of data (right screen) and the visual
program used to process and display those data (left screen). The environment is
also an order of magnitude less expensive than an IDesk (roughly $25 000 U.S.
rather than $250 000zUS).

The objective for the third environment, Dialogue-Assisted Visual Environment
for Geoinformation (DAVE_G), is to provide more natural, multi-user interfaces to
spatial information. The speciﬁc research goal is to develop principles for imple-
menting and assessing natural, multimodal, multi-user dialogue-enabled interfaces
to geographical information systems that make use of large-screen displays and
virtual environment technology. The DAVE_G project
incorporates computer
vision and speech processing as a means of interpreting and integrating user input
from spoken words, free hand gestures and gaze. The practical goal for this
research is to support decision-making tasks by experts and the general public.
For more details, see: http://www.geovista.psu.edu/grants/nsf-itr/index.html and
(Rauschert et al. 2002).

As discussed above, past research on group work with geospatial information
has not focused on the role of maps and other visual display forms. The potential of
visual display to enable geocollaboration is, however, beginning to be recognized
(MacEachren and Kraak 2001, Muntz et al. 2003). As outlined in these reports, a
fundamental challenge for GIScience and related information sciences is to: (1)
understand the roles for visual display and the types of display environments best
suited to geocollaboration (i.e., large screen, table top, wall displays, VR), and (2)
to implement and assess visually-enabled geocollaboration environments suited to a
range of problem contexts and tasks.

Acknowledgements

This material is based upon work supported by the National Science Founda-
tion under Grants No. 9978052 and No. 0113030 as well as by the Apoala Project
(US Environmental Protection Agency grant # R825195-01-0. http://www.geovista.
psu.edu/apoala/index.htm). Our thanks go to the following colleagues for their
parts in implementation of the prototypes or development of ideas: Mike Wheeler,
Hadi Abdo, George Otto, Jack Gundrum, Amy Grifﬁn, Mark Harrower, Daniel
Haug, Jeremy Mennis, Diansheng Guo, Masahiro Takatsuka. Boyan Brodaric,
Frank Hardisty, Erik Steiner, Craig Williams, Yannis Fermantzis, Dennis
McQuerry, and three anonymous reviewers.

References
ACKERMAN, F. editor, 1994, Working Together through Groupware (Westport, CT: Praeger).
ALBRECHT, J., 1995, Universal GIS operations:
task-oriented systematization of GIS

functionality. Unpublished PhD, University of Vechta, Germany.

ANDRIENKO, G., and ANDRIENKO, N., 2001, Interactive visual tools to support spatial Multi-
criteria Decision Making. In User Interfaces to Data Intensive Systems, pp. 127–131.
ARIAS, E., EDEN, H., FISCHER, G., GORMAN, A., and SCHARFF, E., 2000, Transcending the
individual human mind – creating shared understanding through collaborative
design. ACM Transactions on Computer-Human Interaction, 7, 84–113.

ARIAS, E. G., and FISCHER, G., 2000, Boundary objects: their role in articulating the task at
hand and making information relevant to it. In Proceedings of International ICSC
Symposium on Interactive and Collaborative Computing (ICC’2000) (University of
Wollongong, Australia: ICSS Academic Press), pp. 567–574.

30

A. M. MacEachren and I. Brewer

ARMSTRONG, M. P., 1993, Perspectives on the development of group decision support

systems for locational problem-solving. Geographical Systems, 1, 69–81.

ARMSTRONG, M. P., 2001, The four way intersection of geospatial

information and
information technology. White paper prepared for NRC/CSTB Workshop on
Information and Information Technology, 19
Intersections between Geospatial
September, 2001. http://www7.nationalacademies.org/cstb/wp_geo_armstrong.pdf

ARMSTRONG, M. P., and DENSHAM, P. J., 1995, Cartographic support for collaborative

spatial decision-making. Auto Carto 12, ACSM/ASPRS Technical Papers, 4, pp. 49–58.

BAJAJ, C., and CUTCHIN, S., 1999, Web based collaborative visualization of distributed and
parallel simulation. IEEE Parallel Visualization and Graphics Symposium (Los
Alamitos, CA: IEEE), pp. 47–54.

BREWER, I., MACEACHREN, A. M., ABDO, H., GUNDRUM, J., and OTTO, G., 2000,
Collaborative
of
environmental processes. IEEE Information Visualization Symposium (Los Alamitos,
CA: IEEE), pp. 137–141.

understanding

visualization:

geographic

enabling

shared

BRODLIE, K., in press, Models of collaborative visualization. In Exploring Geovisualization,

edited by J. Dykes, A. M. MacEachren and M-J.Kraak (Amsterdam: Elsevier).

BRODLIE, K. W., DUCE, D. A., GALLOP, J. R., and WOOD, J. D., 1998, Distributed

cooperative visualization. State of the Art Reports at Eurographics, 98, pp. 27–50.

BROWN, C., BENFORD, S., and SNOWDON, D., 1996, Collaborative visualization of large scale
hypermedia databases. Proceedings of the ERCIM workshop on CSCW and the web.
pp. orgwis.gmd.de/projects/W4G /proceedings/visual.html.

BROWN, J. R., vAN DAM, A., EARNSHAW, R., ENCARNAC¸ A` O, J., GUEDJ, R., PREECE, J.,
SCHEIDERMAN, B., and VINCE, J., 1999, Human-centered computing, online
communities and virtual environments, special report on the First Join European
Commision/National Science Foundation Advanced Research Workshop, June 1–4,
1999, Chateau de Bonas, France. Computer Graphics, 33, 42–62.
CARVER, S., 1991, Integrating multi-criteria evaluation with geographical

information

systems. International Journal of Geographical Information Systems, 5, 321–339.

CERF, V. G., CAMERON, A. G. W., LEDERBERG, J., RUSSELL, C. T., SCHATZ, B. R., SHAMES,
P. M. B., SPROULL, L. S., WELLER, R. A., and WULF, W. A., 1993, National
Collaboratories: Applying Information Technology for Scientiﬁc Research (Washington,
D.C.: National Academies Press).

CHURCHER, C., and CHURCHER, N., 1999, Realtime conferencing in GIS. Transactions in

Geographic Information Systems, 3, 23–30.

COHEN, P., MCGEE, D., OVIATT, S., WU, L., CLOW, J., KING, R., JULIER, S., and
ROSENBLUM, L., 1999, Multimodal interaction for 2D and 3D environments. IEEE
Computer Graphics and Applications, July/August, pp. 10–13.

DESCORTIS, F., NOIRFALISE, S., and SAUDELLI, B., 2000, Activity theory, cognitive
three views of a transport company.

ergonomics and distributed cognition:
International Journal of Human-Computer Studies, 53, 5–33.

DIBIASE, D., 1990, Visualization in the earth sciences. Earth and Mineral Sciences, Bulletin of
the College of Earth and Mineral Sciences, Penn State University, 59, 13–18 (also:
www.geovista.psu.edu/publications/others /dibiase90/swoopy.html).

DIBIASE, D., 2000, Is distance education a Faustian bargain? Journal of Geography in Higher

Education, 24, 130–135.

DIX, A. J., FINLAY, J. E., ABOWD, G. D., and BEALE, R., 1998, Human-Computer

Interaction, 2nd edition (Englewood Cliffs: Prentice Hall).

ELLIS, C. A., GIBBS, S. J., and RELN, G. L., 1991, Groupware: Some issues and experiences.

Communications of the ACM, 34, 39–58.
ERICKSON, T., and KELLOGG, W. A., 2000, Social

translucence: designing systems
that support social processes. ACM Transactions on Computer-Human Interaction, 7,
59–83.

FISCHER, G., 2002, External and sharable artifacts as sources for social creativity in
the Fifth International Roundtable
communities of
Conference: Computational and Cognitive Models of Creative Design, pp. 9–13.
http://www.cs.colorado.edu/ygerhard/papers/ccmcd2001.pdf

interest. In Proceedings of

FLANAGAN, J., HUANG, T., JONES, P., and KASIF, S., 1997, National Science Foundation

Visually-enabled geocollaboration

31

Workshop on Human-Centered Systems: Information, Interactivity, and Intelligence
(2 July 1997). Available: www.ifp.uiuc.edu /nsfhcs/ﬁnal_report/toc.html.

FLORENCE, J., HORNSBY, K., and EGENHOFER, M. J., 1996, The GIS wallboard: interactions
information on large-scale displays. In International Symposium on
with spatial
Spatial Data Handling, edited by M. J. Kraak and M. Molenaar (London: Taylor
and Francis), 7, 449–463.

FORTNER, R. W. M., and MAYER, V. J., 1996, Constructing Earth system science learning
through multidisciplinary studies of global change. Geoscience and Remote Sensing
‘Remote Sensing for a Sustainable Future.’ (Los
Symposium, 1996. IGARSS ’96.
Alamitos, CA: IEEE), pp. 1166–1168.

FRIESEN, J. A., and TARMAN, T. D., 2000, Remote high-performance visualization and
collaboration. IEEE Computer Graphics and Applications, July/August, 45–49.
GODDARD, T., and SUNDERAM, V. S., 1999, Toolspace: Web based 3D collaboration. In
Proceedings of Fourth International Conference on the Virtual Reality Modeling
Language and Web 3D Technologies. http://www.c-lab.de/vrml99/home.html
GRUDIN, J., 1990, Groupware and cooperative work: problems and prospects. In The Art of
Human-Computer Interface Design, edited by B. Laurel (Reading, MA: Addison-
Wesley), pp. 171–185.

HACKMAN, J. R., 1976, Group inﬂuences on individuals. In Handbook of Industrial and
Organizational Psychology, edited by M. D. Dunnettee (Chicago, IL: Rand-
McNally), pp. 1455–1525.

HARVEY, F., and CHRISMAN, N., 1998, Boundary objects and the social construction of GIS

technology. Environment and Planning A, 30, 1683–1694.

HINDMARSH, J., FRASER, M., HEATH, C., BENFORD, S., and GREENHALGH, C., 2000,
Object-focused interaction in collaborative virtual environments. ACM Transactions
on Computer-Human Interaction, 3, 477–509.

HORROCKS, S., RAHMATI, N., and ROBBINS-JONES, T., 1999, The development and use of a
framework for categorising acts of collaborative work. In Proceedings of the 32nd
Hawaii International Conference on System Sciences (Los Alamitos, CA: IEEE
Computer Society).

HUTCHINS, E., 1995, How a cockpit remembers its speeds. Cognitive Science, 19, 265–288.
JANICKI, T., and LIEGLE, J. O., 2001, Development and evaluation of a framework for
creating web-based learning modules: A pedagogical and systems perspective. Journal
of Asynchronous Learning Networks, 5, 58–84.

JANKOWSKI, P., and NYERGES, T., 2001a, Geographic Information Systems for Group
Decision Making: Towards a participatory, geographic information science (New York:
Taylor & Francis).

JANKOWSKI, P., and NYERGES, T., 2001b, GIS-supported collaborative decision-making:
results of an experiment. Annals of the Association of American Geographers, 91, 48–70.
JANKOWSKI, P., NYERGES, T. L., SMITH, A., MOORE, T. J., and HORVATH, E., 1997, Spatial
group choice: A SDSS tool for collaborative spatial decision-making. International
Journal of Geographical Information Science, 11, 577–602.

JANKOWSKI, P., and RICHARD, 1994, Integration of GIS-based suitability analysis and
multicriteria evaluation in a spatial decision support system for route selection.
Environment and Planning B, 21, 323–340.

JEDRYSIK, P. A., MOORE, J. A., STEDMAN, T. A., and SWEED, R. H., 2000, Inter-
active displays for command and control. Aerospace Conference Proceedings (Los
Alamitos, CA: IEEE), pp. 341–351.

JONES, P. M., HAYES, C., WILKINS, D., BARGAR, R., SNIEZEK, J., ASARO, P., MENGSHOEL,
O., KESSLER, D., LUCENTI, M., CHOI, I., TU, N., and SCHLABACH, M., 1998,
CoRAVEN: Modelling and design of a multimedia intelligent infrastructure for
collaborative intelligence analysis. In Proceedings of the 1998 IEEE International
Conference on Systems, Man, and Cybernetics (Los Alamitos, CA: IEEE), pp. 914–919.
JONES, R. M., COPAS, C. V., and EDMONDS, E. A., 1997, GIS support for distributed group-
work in regional planning. International Journal of Geographical Information Science,
11, 53–71.

KELLER, P., and KELLER, M., 1992, Visual Cues: Practical Data Visualization (Los Alamitos,

CA: IEEE Computer Society Press).

32

A. M. MacEachren and I. Brewer

KNAPP, L., 1995, A task analysis approach to the visualization of geographic data. In Cogni-
tive Aspects of Human-Computer Interaction for Geographic Information Systems, edited
by T. L. Nyerges (Dordrecht, Netherlands: Kluwer Academic Publishers), pp. 355–371.
KRAAK, M.-J., and MACEACHREN, A. M., 1999, Visualization for exploration of spatial data
International Journal of Geographical

introduction to special

issue).

(editorial
Information Science, 13, 285–287.

KRAEMER, K. L., and KING, J. L., 1988, Computer-based systems for cooperative work and

group decision making. ACM Computing Surveys, 20, 115–146.

LIN, C., LOFTIN, R. B., and STARK, T., 1998, Virtual reality for geosciences visualization.
In Proceedings of Computer Human Interaction. 3rd Asia Paciﬁc (Los Alamitos, CA:
IEEE), pp. 196–201.

MACEACHREN, A. M., 1995, How Maps Work: Representation, Visualization and Design

MACEACHREN, A. M., 2000, Cartography and GIS: facilitating collaboration. Progress in

(New York: Guilford Press).

Human Geography, 24(3), 445–456.

MACEACHREN, A. M., 2001, Cartography and GIS: Extending collaborative tools to support

virtual teams. Progress in Human Geography, 25, 431–444.

MACEACHREN, A. M., in press, Moving geovisualization toward support for group work. In
Exploring Geovisualization, edited by J. Dykes A. M. MacEachren and M-J. Kraak
(Amsterdam: Elsevier).

MACEACHREN, A. M., BREWER, I., and STEINER, E., 2001, Geovisualization to mediate
collaborative work: tools to support different-place knowledge construction and
decision-making. In Proceedings of 20th International Cartographic Conference
(Utrecht: International Cartographic Association), pp. 2533–2539.

MACEACHREN, A. M., EDSALL, R., HAUG, D., BAXTER, R., OTTO, G., MASTERS, R.,
FUHRMANN, S., and QIAN, L., 1999, Virtual environments
for geographic
visualization: Potential and challenges. In Proceedings of the ACM Workshop on
New Paradigms in Information Visualization and Manipulation, www.geovista.psu.edu
/publications/NPIVM99/ammNPIVM.pdf), pp. 35–40.

MACEACHREN, A. M., and KRAAK, M.-J., 1997, Exploratory cartographic visualization:

advancing the agenda. Computers & Geosciences, 23, 335–343.

MACEACHREN, A. M., and KRAAK, M.-J., 2001, Research challenges in geovisualization.

Cartography and Geographic Information Science, 28, 3–12.

MANDVIWALLA, M., and OLDMAN, L., 1994, What do groups need? A proposed set of
generic groupware requirements. ACM Transactions on Computer-Human Interaction,
1, 245–268.

MARK, D., (editor), 1999, NSF Workshop Report—Geographic Information Science: Critical
Issues in an Emerging Cross-disciplinary Research Domain (Washington, DC: NSF).
MAY, R. A., 1999, HI-SPACE: A Next Generation Workspace Environment. Unpublished

Masters Thesis, Washington State University, Pullman, WA.

MCGEE, D. R., and COHEN, P. R., 2001, Creating tangible interfaces by augmenting physical
objects with multimodal language. In Proceedings of 9th International Conference on
Human-Computer Interaction (New York, NY: ACM Press), pp. 113–120.
MCGEE, D. R., COHEN, P. R., and WU, L., 2000, Something from nothing: Augmenting a
paper based work practice via multimodal interaction. In Proceedings of the ACM
Designing Augmented Reality Environments DARE 2000 (New York, NY: ACM
Press), pp. 71–80.

MCGEE, D. R., PAVEL, M., ADAMI, A., WANG, G., and COHEN, P. R., 2001, A visual
the Workshop on
Interfaces (PUI’01) (New York, NY: ACM Press). http://

modality for the augmentation of paper. In Proceedings of
Perceptive User
www.cs.ucsb.edu/conferences/PUI/PUIWorkshop/PUI-2001/a2.pdf

MCGRATH, J. E., 1984, Groups: Interaction and performance (Englewood Cliffs, NJ: Prentice-

Hall).

MESROBIAN, E. M. R., SHEK, E., NITTEL, S., LAROUCHE, M., and KRIGUER, M., 1996,
OASIS: an open architecture scientiﬁc information system. In Proceedings of Sixth
International Workshop on Research Issues in Data Engineering, 1996. Interoperability
of Nontraditional Database Systems (Los Alamitos, CA: IEEE Computer Society),
pp. 107–116.

Visually-enabled geocollaboration

33

MUNDA, G. P. N. P. R., 1994, Qualitative multicriteria evaluation for environmental

management. Ecological Economics, 10, 97–112.

MUNTZ, R. R., BARCLAY, T., DOZIER, J., FALONTSOS, C., MACEACHREN, A. M., MARTIN,
J. L., PANCAKE, C. M., and SATYANARAYAN, M., 2003, IT Roadmap to a Geospatial
Future (Washington, D.C.: National Academies Press).

NARDI, B., editor, 1996, Context and Consciousness: Activity Theory and Human-Computer

Interaction. (Cambridge, Mass: MIT Press).

NIELSEN, J., 1993, Usability Engineering (New York: Academic Press).
NOLL, S., PAUL, C., PETERS, R., and SCHIFFNER, M., 1999, Autonomous agents in
collaborative virtual environments. In Proceedings. IEEE 8th International Workshops
on Enabling Technologies: Infrastructure for Collaborative Enterprises (WET ICE ’99)
(Los Alamitos, CA: IEEE Computer Society), pp. 208–215.

NYERGES, T., 1999, Progress in spatial decision making using geographic information
systems. In Geographic Information Research: Trans-Atlantic Perspectives, edited by
M. Craglia and H. Onsrud (London: Taylor & Francis), pp. 129–142.

NYERGES, T. L., MONTEJANO, R., OSHIRO, C., and DADSWELL, M., 1997, Group-based
geographic information systems for transportation improvement site selection.
Transportation Research C, 5, 349–369.

OLSON, G. M., ATKINS, D. E., CLAUER, R., FINHOLT, T. A., JAHANIAN, F., KILLEEN, T. L.,
PRAKASH, A., and WEYMOUTH, T., 1998, The upper atmosphere research
collaboratory. Interactions (May/June), 48–55.

OLSON, G. M., and OLSON, J. S., 2000, Distance matters. Human-Computer Interaction, 15,

139–178.

OVIATT, S., ANGELI, A. D., and KUHN, K., 1997, Integration and synchronization of input
modes during multimodal human-computer interaction. In Proceedings of
the
Conference on Human Factors in Computing Systems (CHI’97) (New York, NY:
ACM Press), pp. 415–422.

PADULA, M., and RINALDI, G. R., 1999, Mission critical web applications: A seismological

case. Interactions, July–August, 52–66.

PANG, A., and FERNANDEZ, D., 1995, REINAS instrumentation and visualization. In
Proceedings, OCEANS ’95. MTS/IEEE. Challenges of Our Changing Global
Environment (Los Alamitos, CA: IEEE), pp. 1892–1899.

PANTELIDIS, V. S., 2000, The RAVE, CAVE, and Collaborative Virtual Environments
(Greenville, North Carolina: http://www.coe.ecu.edu/vr/rave/RAVEtext.htm).
PARK, K. S., KAPOOR, A., and LEIGH, J., 2000, Lessons learned from employing multiple
perspectives in a collaborative virtual environment for visualizing scientiﬁc data. In
Proceedings of the Third International Conference on Collaborative Virtual Environ-
ments (New York, NY: ACM Press), pp. 73–82.

PATEL, U., D’CRUZ, M. J., and HOLTHAM, C., 1997, Collaborative design for virtual team
collaboration: a case study of jostling on the web. In Symposium on Designing Inter-
active Systems Proceedings of the conference on Designing interactive systems: processes,
practices, methods, and techniques (New York, NY: ACM Press), pp. 289–300.

PIERCE, C. S., 1955, Logic as semiotic: The theory of signs. In Philisophical Writings of
Pierce, edited by H. Buchler (New York: Dover Publications), pp. 98–119.
PRATES, R. O., DE SOUZA, C. S., and GARCIA, A. C. B., 1997, A semiotic framework for

multi-user interfaces. SIGCHI Bulletin, 29, 28–39.

QIAN, L., WACHOWICZ, M., PEUQUET, D., and MACEACHREN, A., 1997, Delineating
operations for visualization and analysis of space-time data in GIS. GIS/LIS ’97
(Washington, D.C.: ACSM), pp. 872–877.

RAUSCHERT, I., AGRAWAL, P., FUHRMANN, S., BREWER, I., WANG, H., SHARMA, R.,
CAI, G., and MACEACHREN, A., 2002, Designing a human-centered, multimodal gis
interface to support emergency management. In ACM GIS’02, 10th ACM Symposium
on Advances in Geographic Information Systems (New York, NY: ACM Press),
pp. 119–124.

RHYNE, T.-M., 1998, Case study #1: Collaborative geographic visualization. Course Notes:
ACM SIGGRAPH ’98, #35, Interactive visualization & web-based exploration in the
physical and natural sciences, Orlando, pp. www.education.siggraph.org/rhyne/vis-tut/
gisvis-tut/casegisvis.html.

34

Visually-enabled geocollaboration

RINNER, C., 1997, Discussing plans via the World-Wide Web. In Proceedings of 15th ECAADE
(Vienna University of Technology: Osterreichischer Kunst- und Kulturverlag).
RINNER, C., 1999, Argumaps for spatial planning. In Proceedings of TeleGeo’99, First
International Workshop on Telegeoprocessing (Lyon, France: Claude Bernard
University), pp. 95–102.

RINNER, C., 2001, Argumentation maps: GIS-based discussion support for online planning.

Environment and Planning B-Planning & Design, 28, 847–863.

ROSCHELLE, J., and PEA, R. D., 2002, A walk on the wild side: How wireless handhelds may
change CSCL. To be presented at CSCL 2002: ACM Conference on Computer
Supported Collaborative Learning (Boulder, CO: University of Colorado), 10 pp.
http://www.cs.colorado.edu/y13d/cscl2002/docs/CSCL2002_Proceedings.pdf
ROSCHELLE, J., and TEASLEY, S. D., 1995, The construction of shared knowledge in
collaborative problem solving. In Computer Supported Collaborative Learning, edited
by C. O’Malley (Berlin: Springer-Verlag), pp. 69–97.

ROUSSOS, M., JOHNSON, A., MOHER, T., LEIGH, J., VASILAKIS, C., and BARNES, C., 1999,
Learning and building together in an immersive virtual world. Presence, 8, 247–263.
SHIFFER, M. J., 1998, The evolution of public participation GIS. Cartography and

Geographic Information Systems, 25, 89–94.

SHNEIDERMAN, B., 1998, Designing the User Interface—Strategies for Effective Human-
Computer Interaction, Third edition (Reading: Addison-Wesley Longman).
SHUM, S. J. B., MACLEAN, A., BELLOTTI, V. M. E., and HAMMOND, N. V., 1997, Graphical

arguementation and design cognition. Human-Computer Interaction, 12, 267–300.

STAR, S. L., 1989, The structure of ill-structured solutions: Boundary objects and hetero-
geneous distributed problem solving. In Readings in Distributed Artiﬁcial Intelligence,
edited by M. Huhns and L. Gasser, (Menlo Park, CA: Morgan Kaufmann), 2, pp. 37–54.
SZALAVA´ RI, Z., ECHSTEIN, E., and GERVAUTZ, M., 1998, Collaborative gaming in aug-
mented reality. In Proceedings of VRST ’98 (New York, NY: ACM Press), pp. 195–204.
TAKATSUKA, M., and GAHEGAN, M., 2002, GeoVISTA Studio: A codeless visual
for geoscientiﬁc data analysis and visualization.

programming environment
Computers & Geosciences, 28, 1131–1144.

TAYLOR, S. R. A., 2001, Streaming Geospatial

Imagery into Virtual Environments.

Unpublished PhD Dissertation, Australian National University.

TROMP, J., BULLOCK, A., STEED, A., SADAGIC, A., SLATER, M., and FRE´ CON, E., 1998,
Small group behavior experiments in the Coven Project. IEEE Computer Graphics &
Applications, Nov/Dec, 53–63.

TUKEY, J. W., 1977, Exploratory Data Analysis (Reading, Mass: Addison-Wesley).
VARIAN, H., ALLEN, F., BRYNJOLFSSON, E., SCHEMENT, J., SHENKER, S., SPROULL, L., and
SUTCH, R., 1998, Fostering Research on the Economic and Social Impacts of Informa-
tion Technology: Report of a Workshop. (Washington, DC: National Academy Press).
WASSERMAN, S., and FAUST, K., 1994, Social Network Analysis: Methods and Applications

(Cambridge, UK: Cambridge University Press).

WATSON, V. R., 2001, Supporting scientiﬁc analysis within collaborative problem solving
environments. HICSS-34 Minitrack on Collaborative Problem Solving Environments
(Los Alamitos, CA: IEEE).

WHELESS, G. H., LASCARA, C. M., VALLE-LEVINSON, A., BRUTZMAN, D. P., HIBBARD, W.
L., PAUL, B., and SHERMAN, W., 1996, The Chesapeake Bay Virtual Ecosystem:
Initial results from the prototypical system. International Journal of Supercomputer
Applications and High Performance Computing, 10, 199–210.

WILBANKS, T., ADAMS, R., CHURCH, M., CLARK, W., DE SOUZA, A., GILMARTIN, P., GRAF, W.,
HARRINGTON, J., HORN, S., KATES, R., MACEACHREN, A., MURPHEY, A., RUSHTON, G.,
SHEPPARD, E., TURNER, B., and WILLMOTT, C., 1997, Rediscovering Geography: New
relevance for science and society (Washington, DC: National Academy of Sciences).

WOOD, J., WRIGHT, H., and BRODLIE, K., 1997, Collaborative visualization. Proceedings,
IEEE Information Visualization ’97 (Los Alamitos, CA: IEEE Computer Society),
pp. 253–259.

XIANG, W. N., GROSS, M., FABOS, J. G., and MACDOUGALL, E. B., 1992, A fuzzy-group
multicriteria decision making model and its application to land-use planning.
Environment and Planning B, 19, 61–84.

