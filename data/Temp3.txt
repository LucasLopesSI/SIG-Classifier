The Cartographic Journal
The World of Mapping

ISSN: 0008-7041 (Print) 1743-2774 (Online) Journal homepage: http://www.tandfonline.com/loi/ycaj20

Digital Representation of Historical Globes:
Methods to Make 3D and Pseudo-3D Models of
Sixteenth Century Mercator Globes

Cornelis Stal, Alain De Wulf, Karen De Coene, Philippe De Maeyer, Timothy
Nuttens & Thérèse Ongena

To cite this article: Cornelis Stal, Alain De Wulf, Karen De Coene, Philippe De Maeyer, Timothy
Nuttens & Thérèse Ongena (2012) Digital Representation of Historical Globes: Methods to
Make 3D and Pseudo-3D Models of Sixteenth Century Mercator Globes, The Cartographic
Journal, 49:2, 107-117, DOI: 10.1179/1743277412Y.0000000002

To link to this article:  http://dx.doi.org/10.1179/1743277412Y.0000000002

Published online: 22 Nov 2013.

Submit your article to this journal 

Article views: 21

View related articles 

Citing articles: 3 View citing articles 

Full Terms & Conditions of access and use can be found at
http://www.tandfonline.com/action/journalInformation?journalCode=ycaj20

Download by: [University of Georgia]

Date: 02 April 2016, At: 12:49

The Cartographic Journal
# The British Cartographic Society 2012

Vol. 49 No. 2

pp. 107–117 May 2012

R E F E R E E D P A P E R

Digital Representation of Historical Globes: Methods to
Make 3D and Pseudo-3D Models of Sixteenth Century
Mercator Globes

Cornelis Stal, Alain De Wulf, Karen De Coene, Philippe De Maeyer, Timothy
Nuttens and The´re`se Ongena

Department of Geography, Ghent University, Krijgslaan 281-S8, Ghent, Belgium
Email: Cornelis.Stal@UGent.be

In this paper, the construction of digital representations of a terrestrial and celestial globe will be discussed. Virtual digital
(3D) models play an important role in recent research and publications on cultural heritage. The globes discussed in this
paper were made by Gerardus Mercator (1512–1594) in 1541 and 1551. Four techniques for the digital representation are
discussed and analysed, all using high-resolution photographs of the globes. These photographs were taken under studio
conditions in order to get equal lighting and to avoid unwanted light spots. These lighting conditions are important, since
the globes have a highly reflective varnish covering. Processing these images using structure from motion, georeferencing
of separate scenes and the combination of the photographs with terrestrial laser scanning data results in true 3D
representations of the globes. Besides, pseudo-3D models of these globes were generated using dynamic imaging, which is
an extensively used technique for visualisations over the Internet. The four techniques and the consequent results are
compared on geometric and radiometric quality, with a special focus on their usefulness for distribution and visualisation
during an exhibition in honour of the five hundredth birthday of Gerardus Mercator.

Keywords: globes, Mercator, 3D modelling, virtual reality, comparison

INTRODUCTION

In 2012, the celebration of the ﬁve hundredth birthday of
Gerardus Mercator will take place. In honour of this special
occasion, 3D models were generated of two of his famous
globes for visualisation purposes. It concerns a terrestrial
globe, constructed in 1541 (Figure 1) and a celestial globe
of 1551. Both globes are on display at the Mercator
Museum in the city of Sint-Niklaas near Antwerp, Belgium.
The importance of virtual representations of globes has
been discussed by different authors, such as Adami (2009),
Gede (2009a, b) or Hruby et al. (2005, 2006). These
authors mainly focus on the data acquisition of the virtual
representations of the globes. Adami (2009) discusses the
use of 3D scanners or range cameras in order to generate
triangulated models of globes
that can be used to
investigate the real shape of the sphere. Based on his work,
it becomes clear that the use of 3D scanners is suitable for
deformation measurements and supplements the research
on the internal structure of the globe. Furthermore, he
analyses the projective representation of the map content by
using specialized software. Image-based representations of
historical globes by projecting image parts on a sphere are
also discussed (Dorffner, 1996; Hruby et al., 2006), as well

DOI: 10.1179/1743277412Y.0000000002

as possible digital formats and viewers for these globes
(Gede, 2009a, b; Hruby et al., 2005). An earlier example of
such image based visualisation can be found on http://
www.hcl.harvard.edu. Hruby et al. (2005, 2006) combine
coloured images of the globe with black and white scans of
the reprinted gores, in order to improve the readability of
the textures. For the virtual representations of the globes
used in this article, only the two globes were used as data
source. The research of these authors will be used for a
comparative study in this paper, complemented with the
structure from motion modelling technique and dynamic
imaging. The focus of this paper is on the 3D representa-
tion of globes for visualisation purposes, using the different
implementations of the authors mentioned above.

After a brief presentation of the globes in the section on
‘Mercator globes’, the acquisition of the photographs in
terms of studio conﬁguration, camera conﬁguration and
image pre-processing is the topic of the section on ‘Image
acquisition and pre-processing’. Four modelling and visua-
lisation techniques are discussed: dynamic images for the
pseudo-3D model (the section on ‘Dynamic images’), laser
scanning and image draping (the section on ‘Laser scanning
and image draping’), structure from motion (the section on
‘Structure from motion’) and georeferencing and merging

Downloaded by [University of Georgia] at 12:49 02 April 2016 108

The Cartographic Journal

of globes for commercial and ﬁnancial reasons. Columbus’
discovery of America enlarged political life with a lot of new
territorial disputes. The Treaties of Tordesillas (1494) and
Zaragoza (1529) deﬁned a border meridian between
Portuguese and Spanish foreign trade territories. Globes
were especially suited for the representation of an overview of
the whole world. They were excellent representations of
territorial claims and were therefore favoured and patronized
by the rulers. Both Gemma Frisius and Mercator dedicated
their globes to Charles V or his entourage and in return
received exclusive rights on the reproduction of their globes
(Brotton, 2003). Mercator’s terrestrial globe from 1541, the
ﬁrst globe dealt with in this paper, includes corrections on
Gemma Frisius’ globe (1535), while combining the antique
worldviews of Ptolemaeus and Strabo with the works of
Marco Polo and more of his contemporary cartographers
such as Jacob Ziegler (1470–1549), Olaus Magnus (1490–
1557) and Martin Waldseemu¨ller (1470–1520). The result is
a globe with a diameter of 41.5 cm of which the map image
contains 12 north–south-oriented ribbons. The second
globe we will discuss is a celestial globe constructed in
1551 with approximately the same dimensions as the
terrestrial globe (Blondeau, 1993). While the Discoveries
changed the image of the world, the celestial representation
remained largely based on Ptolemaeus’ Almagest. But
instead of the common ecliptic coordinates, Mercator used
equatorial coordinates for the constellations of the stars. In
spite of the differences, both the terrestrial and celestial
globes were sold together. That is probably why they have
been mounted in a black-painted wooden construction with
four bases and a circular frame along the ecliptic plane.
Furthermore, a copper circular ring is mounted on this
wooden frame with a longitudinal direction (Watelet, 1994).

IMAGE ACQUISITION AND PRE-PROCESSING

images were taken with a Canon EOS 60D digital
All
camera. However,
the aperture, exposure time, ﬁlm
exposure and focal length varied during different acquisi-
tion steps, in order to acquire optimal images (Table 1).
Both globes are varnished, which results in highly reﬂective
areas on the surface of the globes. Therefore, all photo-
graphs were taken using a polarized ﬁlter. Furthermore,
light sources around the globes needed to be controlled. In
order to do so, a ‘light tent’ (http://www.lighttent.eu) was
used to generate diffuse lighting and thereby avoid or
minimize direct light beams on the globes. This ‘light tent’
has a cubed shape with an opening in one of the six sides.
The other sides are covered with a white synthetic textile. A
light spot is placed in the front left and front right sides of
the tent, accompanied with a frontal soft box. A synthetic
textile sheet was placed in front of this soft box, to make

Table 1. Camera parameters during the image acquisition

Ecliptic plane

Polar area

Lens
Aperture
Film speed
Exposure time

50/1.8 mm
f/8
ISO 200
0.6–1.0 seconds

35/2.0 and 24/2.8 mm
f/5.6 and f/2.8
ISO 1600
0.067–0.008 seconds

Figure 1. Terrestrial globe in the Mercator Museum, Sint-Niklaas,
Belgium (source: Paul Hermans, http://www.wikipedia.org)

fragments of the globe (the section on ‘Georeferencing and
merging fragments’). The section on ‘Visualizing the
results’ considers the use of different software packages to
visualize 3D models. Digital images of the globe were used
for all modelling techniques. While the dynamic images do
not result in a 3D-model, the others do. In the case of laser
scanning and image draping, the images are supplemented
with a point set, generated by a 3D laser scanner. By
scrutinizing the advantages and disadvantages of each
technique, summarized in the section on ‘Discussion’, the
optimal workﬂow for the construction of virtual globe
representations will become clear.

MERCATOR GLOBES

Gerardus Mercator (Gerard De Cremer, 1512, Rupelmonde,
Belgium; 1594, Duisburg, Germany) is one of the most
important sixteenth century cartographers in the Low
Countries. Even to this day global navigation makes use of
his major achievement. His cylindrical map projection
represents lines of constant course (i.e. rhumb lines or
loxodromes) as straight segments (Nova et aucta orbis terrae
descriptio ad usum navigantium emendate accommodata,
1569). Besides, Mercator created a large set of cartographic
products. His map of Palestine (Amplissima terrae sanctae
descriptio, 1537) still ﬁts in the medieval tradition of maps
with biblical interpretation. With the heart-shaped projec-
tion on his Orbis
imago (1538), Mercator sought to
represent the globe on a plane surface. In Duisburg, he
realized his map of Europe (1554) and most of his later
maps. In 1578, he released Ptolemaeus’ Geographia with the
intention to correct the maps according to the author’s mind
(Watelet, 1994). The originally three independent volumes
Galliae tabulae geographicae, Belgii inferioris geographicae
tabulae and Germaniae tabulae geographicae were combined
in Mercator’s atlas and later completed by his son (Atlas sive
cosmographicae meditationes de fabrica mundi et fabrica
ﬁgura, 1585).

Although maps received ample treatment in his oeuvre,
Mercator decided in around 1541 to prefer the construction

Downloaded by [University of Georgia] at 12:49 02 April 2016 Digital Representation of Historical Globes

109

standard GretagMacBeth colour checker (http://www.
xrite.com). Based on the grey scale, the colour temperatures
of the terrestrial and celestial globes were set to 5100 and
5000 K, respectively, in order to get neutral grey values. The
colour checker was used to set the colour balance correctly.
On top of that, a set of ﬁltering procedures was executed on
all images to improve the contrast, sharpness and clarity of
the images. The results of these procedures enable better
image matching during the structure from motion model-
ling, as well as a better and sharper approximation of the real
colours of the globes by the images. To compare the results
of these procedures with the original images, a fragment of
the celestial globe is shown in Figure 3.

IMAGE PROCESSING

Dynamic images
For the generation of dynamic images, the Object2VR
software package of Garden Gnome was used (http://
www.gardengnomesoftware.com). This software package
requires a series of images of the object and uses each image
as a video frame for a movie of the object (Collmann,
2011). In this case, both the position of the camera and the
orientation of the frame of the globe were kept static, in
order to generate a single row moving image on the ecliptic
plane. During the acquisition of the different images, the
sphere of the globe itself was rotated with a step size of
approximately 10u. After each rotation, an image of the
globe was taken in the ecliptic plane. No supplementary
images of the polar areas were included in this process. The
resulting 36 images were organized chronologically and
converted to either a QTVR or Flash ﬁle format. These
formats can easily be embedded in an Internet page using a
Java script, calling the involved model ﬁle and appropriate
viewer. Many interactive model viewers are available for this
purpose. On the one hand, the possibility to generate
animations in these formats is a big advantage when the
the
model

is placed on the Internet as

increases

it

Figure 2. Conﬁguration of the spots, camera and globe (top view)

this light even more diffuse. During the entire acquisition
process of the images, the conﬁguration of the constant
beaming lights and semi-opaque sheets was not changed.
Only the rotation angle of the globes was altered during the
acquisition of the images. The centres of all light beams
were aligned with the ecliptic plane of the globe. This
conﬁguration is illustrated in Figure 2.

The Canon EOS 60D single lens reﬂex digital camera
contains an 18 MP CMOS sensor, with a size of
22.3614.9 mm and each colour capturing cell has a size
of 4.4 mm. To achieve an optimal overall sharpness of the
images, each photograph of the ecliptic plane was focused
on approximately one-third of the sphere, north or south of
the ecliptic plane. A tripod was used to keep a constant
distance between the camera and the globe. Polar zones
were photographed by hand, using variable camera para-
meters as a function of the illumination of the photo-
graphed area. These parameters are shown in Table 1.

The lens used for the ecliptic plane images is included in a
database of Adobe’s Lightroom and Photoshop image
processing software. Therefore, a correction of the geometric
aberration on all images of the ecliptic plane was possible
(Ojanen, 1999). The images of the series of both the
terrestrial and celestial globe contain a grey value scale and a

Figure 3. Fragment of the celestial globe before (left) and after (right) image correction

Downloaded by [University of Georgia] at 12:49 02 April 2016 110

The Cartographic Journal

Figure 4. Screenshots of a dynamic image in a QuickTime environment

accessibility of the globe for the public. On the other hand,
the generated ﬁles are quite large to download (85 Mb for
the QTVR and 82 Mb for the Flash, with a frame size of
345665184 pixels), but these sizes could be reduced by
using a lower resolution. However, there is no relation
between the different images other than their sequence.
This means that the resulting products do not contain real
3D information, although it visually looks like a 3D model,
hence the term pseudo-3D model. A set of samples of the
results are presented in Figure 4, demonstrating three
neighbouring frames of a dynamic image.

set

Laser scanning and image draping
3D scanning was used as modelling technique for globe
representation, as a variant of the use of 3D range cameras
(Adami, 2009). The technique is mainly applied in research
about the real shape of the globe, e.g. aberrations from a
hypothetic sphere. However, the results can be used for
is
visualisation purposes as well, when the point
coloured by image draping. A dense point set of the globes
was acquired with a Leica HDS 6100 laser scanner. Using
this phase-based terrestrial laser scanner (TLS), it is possible
to acquire approximately 80 million points within 3.5 min-
utes. This type of scanner is very useful for applications in
civil engineering (Nuttens et al., 2010) and cultural
heritage (Stal et al., 2011), wherein high accuracy is
indispensable and in which the distance between the
scanner and the object to measure is conﬁned. Corres-
ponding with a mean distance between the scanner and the
globes of 1.75 m, an absolute single point accuracy of a few
millimetres can be reached. The ﬁnal data set contains an
(x,y,z)-coordinate and an intensity value of the reﬂected
signal for each point. The point set was acquired with a
horizontal and vertical angular incremental a of 0.018u.
With an average distance between the scanner and the globe
of 1.75 m, a minimum point spacing of 0.5 mm can be
calculated (stan a).

The point set, acquired by the terrestrial laser scanner,
can be combined with a photograph taken with a Canon
EOS 60D DSLR camera in combination with a 50/1.8 mm
lens. The acquisition of a single point set by TLS will result
in occlusion zones. In order to have the same perspective
geometry of the point set and the images, resulting in the

same occlusion zones, both the point set and the image
have to be acquired from the same position. In other words,
the centre of the laser scanner and the optical centre of the
camera – the so called ‘no-parallax point’ (NPP) – should
coincide, as demonstrated in Fig. 5 (Littleﬁeld, 2006). To
determine the NPP of a speciﬁc camera and lens in relation
to the centre of the laser scanner, two parameters have to be
determined in the horizontal plane. The horizontal offset is
shown in Figure 5. As demonstrated in this ﬁgure, it will
become clear that rotating the camera around the z-axis will
keep the NNP on the same position.

The placement of the NPP of a camera on the same
location as the optical midpoint of the scanner can be
obtained using the Nodal Ninja 3II camera bracket
(Figure 6). This bracket contains two measuring rods to
perform an axis set-up and is used for panoramic photo-
graphing as well (Lee et al., 2010).
The horizontal offset contains:

N the tripod mount length, which is camera dependent
N the entrance pupil length, which is lens dependent (L2)

(L1) (Figure 7 – left);

(Figure 7 – right).

In this case, a tripod mount length of 42 mm (L1) and an
entrance pupil length of 17.5 mm (L2) have been used for
the combination of the Canon EOS 60D camera and the
50 mm lens. This resulted in a ﬁnal horizontal offset of
38.5 mm, but this value will differ for each camera and lens
combination. The correct parameters can be calculated by
manual offset determination, but online databases,
like
PanoTools Wiki (http://wiki.panotools.org, 2011), are
available with these parameters for widely used camera and
lens combinations.

Texturing the point set is done by creating a set of
corresponding points, which are points that are unambigu-
ously recognisable in the point set and on the image
(Nuttens et al., 2010). During the preparation of this
campaign, nine circular black and white targets with a radius
of 1.5 cm were glued on different places of the light tent
and the frame of the globe as illustrated in Figures 8 and 9.
During the target placement, an equal spread in the x-, y-
and z-directions was taken into account. Therefore, targets
were placed on the copper ring (Figure 8), the wooden
frame and the back and front of the light tent (Figure 9).

Downloaded by [University of Georgia] at 12:49 02 April 2016 Digital Representation of Historical Globes

111

Figure 5. TLS set-up and corresponding camera offset

Linking points in the point set with pixels in the images
follows the same procedure as the registration of multiple
point sets after a regular TLS campaign, where recognition
of the targets is made possible by the big contrast of the
intensity values of these targets.

The acquired point set is textured using Leica’s Cyclone
point processing software. The ‘Texture Mapping’ tool in
this software package enables the draping of a photograph
four points for
on a point set, using a minimum of
orthorectiﬁed photos and a minimum of seven points for
perspective photos. In both cases,
the photo will be
referenced on the point
set, based on unambiguous
matching points. These points will be selected in both the
point set as on the image, as demonstrated in Figure 8.

Figure 6. Camera bracket (Nodal Ninja 3 II, http://www.nodalninja.
com)

The selected pairs of points are used to calculate the
translation, rotation and scaling parameters, using a Direct
Linear Transformation (Abdel-Aziz and Karara, 1971). The
system of linear equations is solved in order to obtain the
internal and external
image parameters. Optionally, lens
distortion parameters are determined using iterative colli-
near equations (Hu et al., 2008; Ming and Armenakis,
2010). User-deﬁned threshold criteria are used by the
algorithm, in order to accept or reject the result. These
threshold criteria are based on the root mean square error
(RMSE).

After linking all required targets in the point set and onto
the images, the RMSE value is calculated. If a registration is
performed using the targets as unambiguous points, an
RMSE value between 0.50 and 1.00 pixels can be obtained.
The registration of the point set and the image, based on
other recognisable features in the data, will result in a
RMSE value of one pixel (Stal et al., 2011). The ﬁnal result,
after texturing, is a new point set, containing the measured
(x,y,z)-coordinate, the intensity of the reﬂected signal and
the RGB-value of the corresponding pixel of a photo for
each scanned point. Figure 10 demonstrates a screenshot of
the textured point set based on the perspective photo. In
the left ﬁgure, the intensity is visualized by a colour value,
going from low (red) to high (blue). The right image
demonstrates the textured point set with RGB-values.

Structure from motion
Structure from motion is a technique in computer vision to
acquire 3D geometry from 2D images (Pollefeys et al.,
2000; Robertson and Cipola, 2009). Assuming a set of
images, where each point of the study object is projected on

Downloaded by [University of Georgia] at 12:49 02 April 2016 112

The Cartographic Journal

Figure 7. Tripod mount length (L1, left) and entrance pupil length (L2, right) (source: http://wiki.panotools.org, 2011)

is

for

sufﬁcient

the use of

a minimum of three images, the 3D positions of these
points can be calculated by solving a system of geometrical
matrices. If the geometric properties of an image are
the
two images
known,
reconstruction of a 3D point. In most situations, an
uncalibrated camera is used and the true position and
orientation of the camera are unknown. In these cases, the
projection of a 3D object on a 2D image plane and the
inverse transformation of 2D image coordinates to 3D
modelling object coordinates, requires the extrinsic and
intrinsic camera parameters and the focal length (Robertson
and Cipola, 2009). The intrinsic parameters and the focal
length will be taken from the metadata of each image
(EXchange Image Format, EXIF). The extrinsic transfor-
mation parameters will be calculated via the detection of

matching points on the images. Different automatic
matching techniques have been developed over the last
decades (Chen et al., 2007; Heipke et al., 1992) and
implemented in (commercial) software (Zhang et al., 1996).
While digital photogrammetry strongly relies on the presence
of camera calibration ﬁles for the orientation of the images,
structure from motion software,
like AutoDesk Photo-
Fly (http://www.labs.autodesk.com) or Agisoft PhotoScan
images and the
(http://www.agisoft.ru), use series of
software automatically calculates the position of the camera,
camera calibration parameters and relative scaling factors.
This entire process can be split up into three steps
(Verhoeven, 2011), which will be further discussed.

The alignment process consists of three steps. First, a set
of characteristic points is automatically generated on each

Figure 8. Registration point in the photo (left) and the point set (right)

Downloaded by [University of Georgia] at 12:49 02 April 2016 Digital Representation of Historical Globes

113

Figure 9. Target placement on the wooden frame, copper ring and the light tent

image. In the second step, these points are matched with
characteristic points of other images. Finally, the scene
structure is estimated based on this image matching. The
result of this processing step is a 3D point set of matching
points and a graphic representation of the image position.
In preparation for the globe reconstruction, the globe’s
frame has been masked in the software and only the map-
image is used for the alignment. In reality, the globe has
been rotated during the acquisition of the photographs, but

by masking the frame, the photographs appear to have been
taken ‘around the globe’. The software interprets this
situation as if the globe were in a static situation and the
images were taken around the globe, without presence of
the wooden frame and copper ring.

Based on the aligned set of photographs, a 3D mesh is
constructed. This mesh is calculated by reconstructing the
local depths of each photograph. Based on the 3D
matching points set, the local depth maps are merged into

Figure 10. TLS point set with intensity (left) and RGB-values (right)

Downloaded by [University of Georgia] at 12:49 02 April 2016 114

The Cartographic Journal

Figure 11. Reconstruction of the camera positions and 3D representation of the terrestrial globe

an overall 3D mesh. After this, the 3D mesh is reﬁned by
projecting pixels of different neighbouring images on the
overall mesh. More information about the mathematical
background of this modelling step is given by Robertson
and Cipola (2009) and Seitz et al. (2006). A screenshot of
the result of the photo alignment and geometry building
step is given in Figure 11.

To texture the generated 3D mesh, all images need to be
draped onto this mesh. Before starting this process, the
dimensions of the texture images will be deﬁned. In
combination with the projection parameters of each image,
the ﬁnal texture map is blended. This blending process is
performed by taking the maximum or minimum value of all
corresponding pixels, or by taking the average of these pixel
values.

After creating the textured 3D mesh and possible
alignment of different
(elliptic and polar
sub-meshes
meshes), the Agisoft software enables the export of the
model to different ﬁle formats. Based on the requirements
of the ﬁnal product, the texture map can be ignored, e.g.
export to Autodesk Exchange Format (dxf), or included
in the model, e.g. Wavefront object ﬁle (obj), Stanford
polygon ﬁle (ply) and Collada ﬁle (dae). With these data
formats, it is possible to assign a colour to each face in the
mesh, or to generate a separate image ﬁle, containing the
texture of the mesh. In general, the resolution of textures in
separate ﬁles is higher than the assigned colours of faces.

Georeferencing and merging fragments
The last technique with which to make a 3D model of the
globe is by georeferencing fragments of images of the globe
(Figure 12), as presented by Dorffner (1996) and Hruby
et al. (2005, 2006). An absolute coordinate system will be

used in order to generate a virtual representation. It is thus
important to discuss some theory of map projections, in
order to be able to predict and describe distortions (Gede,
2009a). During the acquisition and processing of the
images of the globes, these globes are assumed to be
spherical and the centre of this sphere is supposed to be on
the central optical axis of the camera. According to these
properties, the globe is projected on the camera sensor,
using the vertical perspective projection (Snyder, 1987). If
the centre of the sphere and the optical axis do not coincide,
a more complex tiled perspective projection is used. Next to
the focal length of the camera, the distance between the
camera and the globe determines the position of the
horizon and the size of the error on the (pseudo) parallels.
The area,
length and angular errors on the (pseudo)
meridians and (pseudo) parallels will increase for increasing
distances from the centre of projection.

As a result, it is essential to take map fragments from the
images as near to the centre of the projection as possible.
The terrestrial globe has a grid painted on it, with meridians
each 15u and parallels each 10u. This grid is digitalized in a
geographic information system (GIS) and the resulting grid
is georeferenced within a world-wide reference system. The
image fragments were chosen from different images, but
only one single central fragment was chosen from one single
image. To cover the entire earth’s surface, a total of 432
fragments were selected, and the corners of each fragment
were linked to the digital grid.

The technique of generating 3D models by georeferen-
cing fragments of the images has some drawbacks. First of
all, the procedure has a relatively time consuming workﬂow.
To cover the entire earth’s surface, 432 fragments have to
be cut from a selected photograph. After this, all four
corners of the 432 fragments have to be aligned with the

Downloaded by [University of Georgia] at 12:49 02 April 2016 Digital Representation of Historical Globes

115

Figure 12. Reconstruction of the globe by georeferencing

image on a small part of

digital grid. Another drawback is the fact that only four
points on the edges of a fragment will be used as
unambiguous reference points. In the centre of a cell, the
deformations will be maximal and the error vector points to
the centre of the globe. This is caused by the non-spherical
interpolation of the fragments, and the ﬂat projection of a
ﬂat
the sphere. Moreover,
erroneous geographic placement of objects on the map of
the globe in relation to the used grid will result in
geometric displacements as well (Hruby et al., 2006).
This displacement will occur in all discussed methods in this
article, but with the explicit use of an absolute reference
system for the model, and a grid with a user deﬁned
resolution, the error will occur most prominently.

Visualizing the results
The results of this research can be consulted in different
commercial and non-commercial viewers. A very useful
software package for 3D mesh visualisation, analysis and
modiﬁcation is MeshLab (http://www.meshlab.sourceforge.
net). All ﬁle types mentioned in this article can be handled in
this open source software, along with many other ﬁle types.
For the visualisation of wrl ﬁles in an Internet browser,
Cortona 3D (http://www.cortona3d.com) could be used,
but we experienced better performance with stand-alone
software. The consultation of the dynamic images in a
browser requires a Flash or QuickTime plug-in. The digital
models of the Mercator globes will be presented within the
framework of the ‘Mercator Digital’ exhibition (http://
www.kokw.be).

DISCUSSION

The generation of 3D models of globes is a challenging task
and the presented approaches all have different advantages
and drawbacks, depending on the desired quality, proces-
sing speed and more importantly: the purpose of the

modelling. Within the context of the case study used in this
article, the main purpose of the 3D models was to present
the globes to the public during the Mercator exposition.
The ﬁrst discussed technique (dynamic imaging) is useful
for both visualisation purposes and the research on the
cartographic content of the globes. During the reconstruc-
tion of the globe, which is solely based on images, no
further deformations occurred after the acquisition of the
images. Actually, the result can be seen as a dynamic
database, enabling fast scrolling through a set of original
high resolution images. However, neither 3D visualisation,
nor geometrical analysis can be performed with these
results, but
the results are easily publishable on the
Internet. This in contrast to the 3D scanning technique,
whereby deformation measurements of
the globes are
possible, as discussed in Adami (2009). In the conﬁguration
employed using the light tent, a full coverage by the scanner
was not possible, since the main purpose of this project was
visualisation and the quality of
the images was not
satisfactory outside this light tent. A full coverage would
require targets around the globe and a free ﬁeld of view.
However, a 3D analysis would still be possible for the
the image draping
the globe, but
measured part of
technique, as discussed in this article, does not seem to be
suitable for visualisation purposes of detailed textures. The
georeferencing of
images or image parts is the most
common technique for globe visualisation in literature.
The method of Dorffner (1996) was used to perform the
referencing of the images in a GIS-based environment. The
method is very straightforward on the one hand, but time-
consuming on the other hand. Since no sphere was used but
rather a rectangular grid as a framework for the georeferen-
cing, the number of images had to be substantial in order to
keep the geometrical deformation limited.

Based on the results of this article, the most promising
technique for 3D modelling of the globes is structure from
motion. Although the processing of the images requires a
high-performance computer, the results are satisfactory

Downloaded by [University of Georgia] at 12:49 02 April 2016 116

The Cartographic Journal

Table 2. Advantages and disadvantages of the used reconstruction techniques

Dynamic imaging (Obj2VR)
Advantage
Easy-to-use and no high-performance hardware required
Good exchangeability and accessibility via the Internet
Terrestrial laser scanning and image draping (Leica HDS 6100 and Leica Cyclone)
Advantage
High accuracy geometric model
Quality of point set independent of environmental light sources
Structure from motion (Agisoft PhotoScan)
Advantage
Straightforward 3D model generation
Flexibility in resulting digital formats
Georeferencing and merging images (ESRI ArcGIS)
Advantage
User controlled processing

Drawback
No true 3D results
Geometric quality analysis impossible

Drawback
Expensive acquisition hardware
Full coverage of both laser scanner and camera not possible

Drawback
High-performance computer required
Black-box processing

Drawback
Time-consuming
High geometric distortion in the centre of unit cells

from both a visualisation and a geometric point of view.
Before the ﬁnal presentation of the structure from motion
results, the models required some post-processing near the
North Pole and South Pole. Both the terrestrial- and the
celestial globe will be presented in 3D during the Mercator
exhibition.

parameters. However, the improvement of the geometric
accuracy of the products from the structure from motion
technique requires further research. Nevertheless, this 3D
modelling technique already offers very satisfactory visual
results.

CONCLUSION

In this article, an overview has been provided of modelling
techniques for the virtual representation of two historical
globes, focusing on visualisation purposes. Images of two
historical globes, constructed by Mercator, are taken under
studio conditions and pre-processed in order to have an
improved approximation of the real colours of the globes by
the images. Thereafter, the images are used for different
processing techniques. It has become apparent that all four
techniques – dynamic imaging, laser scanning, structure
from motion and image georeferencing – have different
advantages and drawbacks. After analysing and performing
all four techniques, the following statements are formulated
in Table 2. The discussed methods using terrestrial laser
scanning and manual georeferencing are not very suitable
for 3D globe representation in this context. The laser
scanning method can be used for geometric analysis rather
than texture analysis of the globes, but this is beyond the
scope of this paper. The results generated by georeferencing
are acquired in a time-consuming process and are of much
lower quality than the results generated by dynamic
imaging and structure from motion.

Based on these statements and experiences, we conclude
that for the particular case of mid-sized historical globes,
the dynamic imaging and photogrammetric modelling (in
this case: structure from motion modelling) techniques are
the most suitable for the generation of virtual globes aimed
at public exhibitions. The results from the dynamic imaging
are very useful for further semantic and historical research of
the globes. Globe details, like compass cards, cartouches
and text in general, are clearly represented in the model.
The resolution of the original images is retained and the
constant angular increment of the globe still results in a 3D
impression. Some of the image resolution will be lost
by structure from motion processing, but this reduction
is mainly manageable by using the correct processing

BIOGRAPHICAL NOTES

Cornelis Stal (1985, Waalre,
The Netherlands) is a PhD
student working on the
combination of
airborne
and terrestrial laser scanning
for 3D city modelling. His
special
in the
(automatic) generation of
geometric, radiometric and
semantic rich 3D models,
derived from irregular point
sets and other spatial data-
sets. This means that both
laser scanning as a discipline in the land survey and geo-IT
(GI-systems, GI-programming, GI-management, …) are
important pillars of his research.

interest

is

ACKNOWLEDGEMENTS

The authors would like to express their gratitude to the
‘Koninklijke Oudheidkundige Kring van het Land van
Waas’ (KOKW) for their permission and opportunity to
take images of the two historical globes and the ability to
present the results of this research during the Mercator’s
exposition. The Research Foundation Flanders (FWO) is
also gratefully acknowledged for funding the work pre-
sented in this paper.

REFERENCES

Abdel-Aziz, Y. and Karara, H. (1971). ‘Direct Linear Transformation
into Object Space Coordinates in Close-range Photogrammetry’,
in Symposium on Close-Range Photogrammetry, pp. 1–18,
Urbana, IL, Jan 26–29.

Adami, A. (2009). ‘From real to virtual globe: new technologies for
digital cartographic representation’, e-Perimetron, 4, pp. 144–
160.

Downloaded by [University of Georgia] at 12:49 02 April 2016 Digital Representation of Historical Globes

117

Blondeau, R. (1993). Mercator van Rupelmonde, Lannoo, Tielt.
Brotton, J. (2003). Trading Territories Mapping the Early Modern

World, The University of Chicago Press, Chicaco, IL.

Chen, L., Lo, C., Liu, C. and Chen, A. (2007). ‘Orientation Modeling
by Matching Image Templates of a GCP Database’, in 28th Asian
Conference on Remote Sensing, p. 6 (on CD-ROM), Kuala
Lumpur, Nov 12–16.

Collmann, R. (2011). ‘Developments in virtual 3D imaging of cultural

artefacts’, Ariadne, 66, p. 10 (on CD-ROM).

Dorffner, L. (1996). ‘Der digitale Behaim-Globus – Visualisierung und
Vermessung des historisch wertvollen Originals’, Cartographica
Helvetica, 14, pp. 20–24.

Gede, M. (2009a). ‘The Projection Aspects of Digitising Globes’, in
XXIVth International Cartographic Conference, p. 10 (on CD-
ROM), Santiago, Nov 15–21.

Gede, M. (2009b).

‘Publishing globes on the Internet’, Acta

Geodetica Geographica Hungaria, 44, pp. 114–148.

Heipke, C., Kornus, W., Strunz, G., Thiemann, R. and Colomina,
I. (1992). ‘Automatic photogrammetric processing of spot imagery
for point determination, DTM generation and orthoprojection’,
International Archives of Photogrammetry and Remote
Sensing, 29, pp. 465–471.

Hruby, F., Plank, I. and Riedl, A. (2005). ‘Potential of Virtual 3D-
Facsimiles - Exemplified by the Earth Globe of Gerard Mercator
(1541)’, in 22nd ICA Cartographic Conference, p. 9 (on CD-
ROM), La Corun˜a, Jul 9–16.

Hruby, F., Plank, I. and Riedl, A. (2006). ‘Cartographic heritage as
shared experience in virtual space: a digital representation of the earth
globe of Gerard Mercator (1541)’, e-Perimetron, 1, pp. 88–98.
http://wiki.panotools.org, 2011. PanoTools Wiki (accessed 24 March

2011).

Hu, C., Wang, Y. and Yu, W. (2008). ‘Mapping digital image texture
onto 3D model from LiDAR data’, International Archives of
Photogrammetry, Remote Sensing and Spatial Information
Sciences, 37, pp. 611–614.

Lee, H., Tateyama, Y. and Ogi, T.

‘Realistic Visual
Environments for Immersive Projection Display System’, in 16th
International Conference on Virtual Systems and Multimedia
(VSMM), pp. 128–132, Seoul, Oct 20–23.

(2010).

Littlefield, R. (2006). Theory of the no-parallax points, http://
www.janrik.net/PanoPostings/NoParallaxPoint/TheoryOfTheNo
ParallaxPoint.pdf (accessed 23 March 2011).

Ming, J. and Armenakis, C. (2010). ‘Fusion of optical and terrestrial
laser scanner data’, International Archives of Photogrammetry,
Remote Sensing and Spatial Information Sciences, 38, pp. 156–
161.

Nuttens, T., de Wulf, A., Bral, L., de Wit, B., Carlier, L., de Ryck, M.,
Stal, C., Constales, D. and de Backer, H. (2010). ‘High Resolution
Terrestrial Laser Scanning for Tunnel Deformation Measurements’,
in The XXIV FIG International Congress 2010, p. 10 (on CD
ROM), Sidney, NSW, Apr 11–16.

Ojanen, H. (1999). Automatic Correction of Lens Distortion by Using
Digital Image Processing. Technical Report. Rutgers University,
New Brunswick, NJ, USA, p. 5 (on CD-ROM).

Pollefeys, M., Koch, R., Vergauwen, M. and van Gool, L. (2000).
‘Automated reconstruction of 3D scenes from sequences of
images’, ISPRS Journal of Photogrammetry and Remote
Sensing, 55, pp. 251–267.

Robertson, D. and Cipola, R. (2009). ‘Structure from motion’, in
Practical Image Processing and Computer Vision, ed. by Varga,
M., p. 23, John Wiley & Sons, Hoboken, NJ.

Seitz, S., Curless, B., Diebel, J., Scharstein, D. and Szeliski, R. (2006).
of Multi-view Stereo
‘A Comparison
Reconstruction Algorithms’,
in IEEE Computer Society
Conference on Computer Vision and Pattern Recognition, pp.
519–526, New York, Jun 17–22.

and Evaluation

Snyder,

J.

(1987).

in Map
Projections – A Working Manual, ed. by Snyder, J., USGS
Professional Paper, pp. 169–181, USGS, Reston, VA.

‘General perspective projection’,

Stal, C., de Wulf, A., Nuttens, T., de Maeyer, P. and Goossens,
R. (2011). ‘Reconstruction of a Midieval Wall: Photogrammetric
Mapping and Quality Analysis by Terrestrial Laser Scanning’, in
31th EARSeL Symposium, p. 12 (on CD-ROM), Prague, May
30–Jun 3.

Verhoeven, G. (2011). ‘Taking computer vision aloft – archaeological
three-dimentional Reconstruction from aerial photographs with
PhotoScan’, Archaeological Prospection, 18, pp. 67–73.

Watelet, M.

(1994), Gerardus Mercator Rupelmundanus,

Mercatorfonds, Antwerpen.

Zhang, J., Zhang, Z., Shen, W. and Wang, Z. (1996). ‘VirtuoZo
digital photogrammetry system: its theoretical foundation and key
algorithms’, International Archives of Photogrammetry and
Remote Sensing, 31, pp. 424–429.

Downloaded by [University of Georgia] at 12:49 02 April 2016 