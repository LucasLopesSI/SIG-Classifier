The Cartographic Journal
# The British Cartographic Society 2013

Vol. 50 No. 1

pp. 43–48

February 2013

R E F E R E E D P A P E R

Ephemeral Conflation

Carlos-Humberto Gonza´ lez1, Carlos Lo´pez-Va´ zquez1,2 and Miguel-A´ ngel Bernabe´1

1 Laboratorio LatinGEO, ETSI Topografı´a, Geodesia y Cartografı´a Universidad Polite´cnica de Madrid (U.P.M.), Km.
7.5 Autovı´a de Valencia – E-28031 Madrid, Espan˜a. 2Laboratorio LatinGEO, del Servicio Geogra´fico Militar y la
Universidad ORT del Uruguay, 8 de Octubre 3255 – C.P. 11600 Montevideo, Uruguay
Email: carloshgnimbus@gmail.com

The great availability of geographic information, due to Spatial Data Infrastructure development, the existence of data
collected by volunteers, etc., makes the problems of geometric interoperability of data very conspicuous. Traditionally,
conflation is being carefully carried out and evaluated by experts. Yet there are practices that involve occasional users who
will look up the information in mobile devices without the intention of keeping a copy. Evaluation will be carried out
?with different criteria, involving the Human Visual System and perhaps even the characteristics of the physical devices
?as well. In this paper, we coin the term ‘Ephemeral Conflation’ to characterize that context and the procedures to
evaluate it.

Keywords: conflation, cartography, ephemeral conflation, ephemeral cartography, strong metrics, weak metrics

INTRODUCTION

A variety of circumstances have been the cause of an ever
growing availability of geographic information,
its easy
online accessibility and its production both inside and
outside the traditional institutions. People in turn are getting
familiar with new services and mobile devices capable of
accessing and displaying information in an ofﬁce, a park, a
street or a stadium. These people constitute a new kind of
users for the geographic information: they are not specialists,
aspire to quick answers and will make only a visual evaluation
of the information. They make up a large group with quickly
changing needs and are currently being considered by
traditional producers. The Spatial Data Infrastructures
provide access mechanisms and ease of query which enable
location and fast retrieval of geographic information of
dissimilar origin, which will be jointly displayed. As the
technological issues of location and data transfer begin to be
solved, new challenges, now associated to the data itself,
arise. When trying to jointly represent data of different
lineages, geometric discrepancies may become evident. In
order to lessen these discrepancies, a preprocessing of the
geometry is needed as a part of a process called conﬂation.
The term was borrowed from the area of arts and humanities
by Saalfeld (1983) for studies of geometric alignment of
geospatial data of different sources; it comes from the latin
conﬂatiˇo, which means the action and effect of
fusing
(Cambridge Dictionaries Online, 2011). In the scientiﬁc
literature, the expressions fusion (Wald, 1999) and harmo-
nization (Thornton, 1977) of data are also employed among

DOI: 10.1179/1743277412Y.0000000014

other related terms. Formally, the process of fusing two or
more geospatial datasets into one is what is meant by
conﬂation. Of the product thus obtained, new information
may be extracted that none of the parts making up the set
may provide separately. However, by and large, the conﬂa-
tion of different cartographies does not generate a third one
without problems or errors (Saalfeld, 1983). Such issues are
still pending a satisfactory resolution, with signiﬁcant
research efforts at present. There is an urgent need to
overcome the present difﬁculties, mainly motivated by the
opportunity of using the large volume of heterogeneous
geospatial data available on the Internet, from different
origins, methodologies, scales, accuracies, etc., and from
different sources (government agencies, private companies,
universities,
to the same
geographic area,

individuals, etc.)

refer

that

As an example of the previous statement, some references
show new solutions to traditional problems of the conﬂation:
Ruiz et al. (2011) recently presented a state of the art of
conﬂation. They described the different deﬁnitions of the
term conﬂation with its nuances by different authors; it
deﬁnes each stage of the procedure, its metrics, possible
applications, it reports which software exists, and ﬁnally
proposes a general classiﬁcation of the conﬂation. All the
literature recognizes as the ﬁrst step the identiﬁcation of the
homologue of two map objects. This is addressed in full by Li
et al. (2011). They focus on an optimized method for the
identiﬁcation of homologous objects when they are linear
entities. Sledge (2011) recognizes the progress achieved

44

since Saalfeld’s seminal work, but also recognizes that the
conﬂation problem is still a challenge. The author presents a
method for geometric conﬂation (once identiﬁed homo-
logous objects) in the case of the polygonal type (usually
represented in the mapping of structures) in the case of a
couple cartographic vector – raster.

The ‘Espan˜a Virtual’ (EV, Virtual Spain) Project seeks to
research and develop the representation of the physical
world in a virtual environment via the Internet and in real
time. For this purpose, the entire existing geographic
information is considered as a potential source.

Among the use scenarios raised is the hypothesis of an
ephemeral use of the data. This means, in this context, that
the user is seeking a utilitarian or immediate end, solving a
particular query or quickly visualizing without having the
intention of storing, only looking for the information
displayed on screen. This information query is made in a
variety of contexts, for example, outdoors or with barely
adequate lighting, in closed rooms, during the daytime or
at night, or even with low battery in the device, etc., and the
information is evaluated by the user’s eyes just as it is
displayed. On the other hand, it would be possible to talk
about permanent uses in which conﬂation results in a
product that will persist in time, which could be subject to a
scrutiny and ﬁne analysis, and without temporal constraints.
This is the hypothesis used in the production and evaluation
of the great majority of both public and private cartographic
products. Please note that for this application, the conﬂation
of any data type, vector, raster, etc., is always materialized in an
end image that can be displayed on the screen of a device.

Lo´ pez-Va´zquez and Gonza´lez (2009) have applied
different geometric conﬂation algorithms to an urban area
in Spain using as the successful metrics the traditional
accuracy statistics described in FGDC (1988) and denoted
hereinafter as NSSDA. To evaluate the goodness of
conﬂation, the available control points are split into two
groups. The ﬁrst one are used with the different conﬂation
methods to carry out the calculation. The other control
points are used as witnesses of
the
transformation, since their displacements are also known.
From now on, the statistics based on traditional accuracy
will be called strong metric.

the accuracy of

The visual impact of the conﬂation achieved is not always
directly related to the value of strong metrics. After the
effect has been conﬁrmed, it would be ﬁtting to determine
if the cognitive process is relevant in this context.

CONTEXT AND EPHEMERAL CONFLATION

So far, the conﬂation operation between the map A and the
map B did not allow for the context where the displayed
information would be visualized. Conﬂation was regarded
as a process whose end product was intended to be carefully
analysed by specialists, drawn up in a laboratory, ﬁled,
measured unhurriedly and with a general purpose. To
certain extent, the efforts made so far to improve the
conﬂation techniques conform to this model.

In the present-day context, new use scenarios

for
geographic data are raised. Without establishing an order
of precedence, it may be pointed out that:

The Cartographic Journal

substantial processing is being anticipated;

N querying of a map A and a map B could require online
conflation, since the combination AzB perhaps was not
previously built;
N a likely small zone in relation to the area covered by A or
B will be analysed. Zooming will be generously used to
see the details;
N the result will always be visualized by humans. No other
N the device, context, lighting and so on will not always be
the most favorable and it may not be definitely assumed
that we should count on a desktop or special lighting;
N it should be assumed that the time consumed by the user
in the query of such geographic information will be the
minimum or strictly needed;
N the user always evaluates ultimately a raster image on the
N the user seeks a utilitarian end and the acquisition of the
required information, immediately discarding the pro-
duct obtained as needed;
N demands and offers of three-dimensional applications
and services in real time are foreseen on the near
temporal horizon.

screen of the device;

Likewise, Hoarau (2011) notes that the mapping displayed
on a mobile device has additional rules to the similar
mapping expressed in traditional media, expressed in other
physical media. When trying to optimize the deployment of
a map in a mobile context, they alter the parameters of the
mapping in question. The work focuses on the challenge of
how these parameters can be altered without losing the
quality of the original mapping. He proposes a metric to
evaluate the quality of the displayed map, relative to a
reference map, based on the conservation of semiotic
quality between them. Also Silva et al. (2011) highlight the
importance of context and culture for reading cartography.
The study focuses on the colour factor and its relevance to
the display of data and information content. They note that
although this is a well-studied area, and there are many
good works, new technologies have demanded more
detailed studies. They add that while there are rules and
tools, they have not always been taken into consideration by
the providers of mapping services. They state that the green
colour in the USA is usually associated with the colour of
money. Tsou (2011) raises two issues in the development of
cartography deployed via the Internet. First, he highlights
the importance of user-centred design, interface, content
and functionality of the map. Second, he stresses the
importance attached to mapping aimed to a general
audience without speciﬁc training in the geographic area,
as opposed to the traditional case of technical readers with
speciﬁc cartographic expertise.

The ephemeral cartography products being currently
released are not new, as it might be believed in the ﬁrst
instance. History shows that ephemeral cartography was
born already in the Antiquity, when for example, a hunter
or a seafarer had to communicate to another one certain
geographic information, drawing rudimentary strokes on
the sand, the ground or the ice – crosses, points, arrows,
symbols, etc. – that may be regarded as a primitive map of
the main facts. Rundstrom (1990) mentions the logbook of
Captain John Ross as he sailed through the high latitudes of
the Northern Hemisphere, where instances of ephemeral

Ephemeral Conflation

45

cartography are described on the sand, snow and air among
the Inuit people of Alaska, Center and Eastern Canada
and Western Greenland. The existence of this ephemeral
cartography does not necessarily imply that it was not
precise enough for the intended purposes. The author also
remarks on the maps of the Inuit people that were used by
the explorers of those regions. He also mentions that in
general the approach to the study of maps in their cultural
environment has only been accepted from the 1970s.

Perkins describes through ﬁve uses cases concerning
collaborative cartography (Web 2.0), considering a con-
textual approach, how the use of
Information and
Communication Technologies (ICT) generate new carto-
graphic products. Over the past few years people can create
their own maps using ICT, and one of the use cases
presented under the name of ‘artistic encounters’ shows an
example of ephemeral cartography (Perkins, 2007).

As another example of ephemeral mapping, we can
include the use of sound in the mapping via the Internet, a
new dimension to explore. Similarly to what has already
been cited for the colour (Tsou, 2011), Caquard et al.
(2008) point to the potential that sound can offer to
internet mapping. This element is another dimension of the
context in which the maps are displayed. As an example, a
very widespread use is the voice associated with the maps
displayed on the GPS navigation devices for land vehicles.
They acknowledge that this area is still awaiting develop-
ment. The authors note that the maps with sounds are
associated with emotions that affect our relationship with
the environment, and these emotions in turn can be
explored with the use of sound.

Perkins argues that to date the use of maps has been
chieﬂy focused on the cognitive aspect and has not taken
into consideration the context where cartography is used.
In the traditional approach corresponding to the historical-
technological period prior to the emergence of ICT, the
recipient of cartography was an expert user, or at least a user
having a certain degree of training in map reading, and he
was decontextualized from the environment. The popular-
isation and access to the ICT has enabled updating of the
maps being shown on screens, their easy distribution and
exchange. The medium then becomes more widely social,
task-oriented, ephemeral and mobile (Perkins, 2008).

In contrast, it is possible to characterize the persistent or
traditional scenario as one consisting of speciﬁc queries,
with technical, scientiﬁc goals, generating a persistent
product, in a lab-type context, with ﬁxed objectives, and
evaluated with objective, standardized and well established
metrics.

As a ﬁrst consequence,

it may be stated that in the
scenario under analysis, the goodness of the ephemeral
conﬂation operation will be unavoidably weighted by the
limitations of the Human Visual System (HVS). Even
though that is certain (partially) in the case of traditional
paper cartography, the popularity of criteria of the style ‘J
of one millimeter to the scale’ should be recognized, as they
point to the possibility of analysing very carefully and under
ideal conditions the product for evaluation of its accuracy.
In a mobile LCD type device, the J millimetre criterion is
irrelevant. Another consequence of the new scenarios is the
emphasis on local adjustment versus global adjustment. In

traditional conﬂation, the map was regarded and evaluated
as a whole. Although this is a very controversial aspect [see
Ariza-Lo´ pez and Atkinson-Gordo (2008) and Mohamed
Ghouse (2008) among others], the number obtained with
any traditional cartographic accuracy metric is taken on as
representative of the entire region even though there were
zones with very good accuracy and not so good for others.
It is likely that in the envisioned applications, a local (not
global) conﬂation will have to be carried out, adjusting
carefully whatever will be shown to the user and ignoring
data belonging to far away regions within the same
cartography A or B. This has important
implications
regarding methods, since the majority of them are based
on homologous points, and improvement would not be
possible if there are no homologous points in the active
zoom window. It is even possible that the user interface to
be developed should show an unfocused image, some
movement, vibration, etc., adjusting polygons and points as
the user interacts with the zoom function, thus denouncing
an ongoing operation of geometric adjustment.

By assuming that the human user will not quantitatively
evaluate the result of the conﬂation, it is reasonable that the
precedence between methods should also reﬂect those
characteristics. It may be argued that the opinion – i.e.
qualitative evaluation – provided by the user may be
affected by a few details of the product.

Dilemuth (2005) also notes that the maps represented on
mobile devices have characteristics that are peculiar, with
speciﬁc challenges. He compared a map displayed in the
mobile device to another digital representation of the same
geographical area but with a level of representation (scale)
bigger, which is used for reference.

As a consequence, it is our opinion that a new term
should be coined characterizing the results of that new
conﬂation,
foreign to traditional metrics, displayed on
medium-quality small screens, tablets and mobile tele-
phones, without technical, scientiﬁc or archive pretensions,
and only with utilitarian goals. We propose to designate
that type of conﬂation as ‘ephemeral conﬂation’. By naming
it with a different term, speciﬁc considerations seem to be
legitimized.

STRONG AND WEAK METRICS

The same as geometric conﬂation where results may be
characterized by using as a traditional accuracy metric, such
as the one described by the FGDC in 1988, an equivalent
metric is needed for ephemeral conﬂation.

The traditional metrics are intrinsic to the data and do not
consider the context and the user. In order to distinguish it
from those taking into account the context and the HVS, any
metric characterizing the ephemeral conﬂation will be called
a weak metric. There are several strong metrics possible, such
as the root mean square error, taken on by the NSSDA
(FGDC, 1988), the Fre´chet distance (Aronov et al., 2006),
the Hausdorff distance (Knauer et al., 2009), etc. However,
to our best knowledge, expressions for weak metrics of vector
data are unknown.

Within the scope of image processing, there are examples
of weak metrics cases, so-called ‘just noticeable differences’

46

The Cartographic Journal

Figure 1. Aspect of
the best result (according to the NSSDA
metric) for a particular event of the simulation. Correct vector data
in red; best result obtained among the conﬂation methods used in
yellow. Taken from the authors

(JND) which is deﬁned as the minimum difference a typical
user can perceive between an original image and its copy. If
the JND threshold is not reached, the reproduction is
considered perfect in relation to the HVS. An important
aspect is the capability to see the differences. It depends on
the context factors such as the distance of visualisation,
lighting, contrast, etc. Its common application allows
comparing objectively altered images and determining
which one is closest to the original according to the
impression of a typical observer (Lubin, 1997). It is possible
to deﬁne a measure to compare two images in terms of the
observer’s ability to see the differences between them. This
measure is the JND map which acts as a function between
the two images and the parameters describing the
visualisation conditions (Larimer, 2008).

The analogy with the issue in question is great, but
unfortunately, the type of images to which these metrics are
applied are typically photographs with continuous variation
of colours and wefts, while in the applications of the
described new scenarios, display of mapping with sharp lines
and uniform background colours is expected, so that these
techniques would not be directly applicable.

EXAMPLES

Lo´ pez-Va´zquez and Gonza´lez (2009) proposed a frame-
work to evaluate the metrics of the different conﬂation
algorithms in two spatial raster and vector type datasets.
Several conﬂation methods were applied selecting randomly
control points from a given set. Figures 1 and 2 show a
the urban area of Gandı´a (Spain). The
portion of
orthophoto belongs to the collection of the National Plan
of Aerial Orthophotography (PNOA in its Spanish acro-
nym) and the vector cartography of
the red lines
corresponds to the Numerical Cartographic Base. In yellow,

the same particular event of

Figure 2. Aspect of the worst result (according to NSSDA metric)
for
result
obtained among the conﬂation methods used in yellow. Taken from
the authors

the simulation. Worst

the lines corrected by two conﬂation methods are shown
(Figures 1 and 2, respectively) which are the ones that
yielded the best and the worst results respectively based on
the (FGDC, 1998) criterion.

The experiment was carried out as part of a Monte Carlo
procedure (Besag and Diggle, 1997). Figure 2 shows a
particular event of the simulation carried out, conﬂated with
the method which ended up being the best (for this event
GRIDDATA_V4), while Figure 3 shows the same event
with the method which ended up being the worst (for this
event IDW_2).

The best and worst character is related to the strong
metric. After ordering the different results obtained with
the different conﬂation methods, according to the metric
established by the NSSDA standard and in the light of the
present example, with the data and for the speciﬁc mapping,
it may be veriﬁed that this order of precedence so formed is
not meaningful for the user. The distance between the best
and the worst, according to the strong metrics,
is not
perceived in a similar manner by the user who observes that
all the elements of the series are indistinguishable. In the
case of the example presented in Figures 1 and 2, both
conﬂations are equally defective.

In Figures 3 and 4, two views are shown at a different
scale (zoom) of
raster–vector
the same conﬂation of
cartographies, corresponding this time to the town of
Gandı´a (Spain). No matter what the selected traditional
metric (strong metric) was, it was numerically identical for
both images, since the traditional metric accuracy is applied
to the raw data (without taking into account the visualisa-
tion scale) and theoretically, it is not associated to zones or
sectors thereof. In this case, the area of visualisation is the
relevant matter. Yet the visualisation experience of both
ﬁgures is remarkably different. In the ﬁrst case, it may be
accepted that when the user visualizes the image, he
remains satisﬁed without major adjustments. In the other
case, there is no certainty regarding the true position of the

Ephemeral Conflation

47

Figure 3. A view of the raster–vector conﬂation. For many con-
texts and users, the displayed image may be passed as acceptable.
Taken from the authors

spatial features. In addition, the present example may be
considered to illustrate the initial comments of the section
on ‘Strong and weak metrics’.

CONCLUSIONS

In the above-mentioned new use scenarios, we propose to
reﬂect upon the process of geographic data conﬂation, to
which the new name of ephemeral conﬂation has been
applied, as going through several stages, extending the ones
described by Saalfeld in 1983 and subsequent authors for
geometric conﬂation. It is started with the geographic
databases of a server and concludes with the end user. Given
the utilitarian end of this type of applications, it is the
observer’s visual system that will ﬁnally evaluate the success
of the ﬁnal product displayed on a screen as a raster image.
In this context, the strong metrics are not appropriate to
characterize and measure this process and the image
displayed on screen, since it ignores the impact of the
perception of the HVS. For this reason, in this paper, we
coin the term ‘weak metrics’ for those metrics that take into
account the subject’s perception and jointly with the strong
metrics can evaluate the success of the end result. We have
not found in the literature ‘weak metrics’ in the sense we
give it in the present work, and adapting results to other
areas, typically medicine or psychology, to the present
problem has not been achieved either.

BIOGRAPHICAL NOTES

Carlos Humberto Gonza´lez
is Bachelor in Surveying En-
gineering from UDELAR
University (Uruguay), and
in Computer Science from
UAS University (Uruguay).
He got his graduate studies
at ITC, Delft, The Nether-
lands; BGR, Hannover, Ger-
many; National Observatory, Rio de Janeiro, Brazil, and
Litoral University, Argentina. Currently, he is studying PhD
in Geomatics at Technical University of Madrid (U.P.M.),

Figure 4. Another detail of the same conﬂation of Figure 3. Note
the red lines (vector) and the displacement of the homologous fea-
tures in the raster mapping. In this case, the perception is quite
uncomfortable. Taken from the authors

Spain. He participated in the ‘Virtual Spain’ Project in
LatinGEO, UPM. He carried out teaching activities in
UDELAR, Uruguay (1988–1997) and worked at Geo-
graphic Information Department, Ministry of Transport and
Public Work (Uruguay) (2008–today).

ACKNOWLEDGEMENTS

These results are part of the work of the CENIT Espan˜a
Virtual Project, co-funded by the CDTI within the Ingenio
2010 Program and by the National Center of Geographic
Information of Spain.

REFERENCES

Ariza-Lo´ pez, F. J. and Atkinson-Gordo, A. D. (2008). ‘Analysis of
some positional accuracy assessment methodologies’, Journal of
Surveying Engineering, 134, pp. 45–54.

Aronov, B., Har-Peled, S., Knauer, C., Wang, Y. and Wenk, C. (2006).
in

revisited’, Lecture Notes

‘Fre´chet distance for curves,
Computer Science, 4168, pp. 52–63.

Besag, J. and Diggle, P. J. (1997). ‘Simple Monte Carlo tests for spatial
pattern’, Journal of the Royal Statistical Society, Series C
(Applied Statistics), 26, pp. 327–333.

Cambridge Dictionaries Online. (2011). http://dictionary.cambrid-
ge.org/dictionary/british/conflate (accessed 20 December 2011).
Caquard, S. Brauen, G., Wright, B. and Jasen, P. (2008). ‘Designing
sound in cybercartography: from structured cinematic narratives to
unpredictable sound/image interactions’, International Journal
of Geographical Information Science, 22, pp. 1219–1245.
Dilemuth, J. (2005). ‘Evaluation for mobile display’, Cartography

and Geographic Information Science, 32, pp. 285–301.

FGDC. (1988). Geospatial Positioning Accuracy Standards; Part 3:
National Standard for Spatial Data Accuracy. FGDC-STD-007 3.
Federal Geographic Data Committee, Washington, DC, USA.

Hoarau, C. (2011).

‘Reaching a compromise between contextual
constraints and cartographic rule: application to sustainable maps’,
Cartography and Geographic Information Science, 38, pp. 79–88.
Knauer, C., Loffler, M., Scherfenberg, M. and Wolle, T. (2009). ‘The
directed Hausdorff distance between imprecise point sets’, Lecture
Notes in Computer Science, 5878, pp. 720–729.

Larimer, J. (2008). ‘Human factors considerations: seeing information
on a mobile display’,
in Mobile Displays: Technology and
Applications, ed. by Bhowmik, A. K., Li, Z. and Bos, P. J., pp.
23–50, John Wiley & Sons, Ltd, Chichester.

Li, L. and Goodchild, M. F. (2011). ‘An optimisation model for linear
feature matching in geographical data conflation’, International
Journal of Image and Data Fusion, 2, pp. 309–328.

48

The Cartographic Journal

Lo´ pez-Va´zquez, C. and Gonza´lez, C. H. (2009). ‘The Need of a
Framework to Compare Geometric Conflation Algorithms’,
in
12th AGILE International Conference on Geographic
Information Science, pp. 1–5, Hannover, Jun 2–5.

Lubin, J. (1997). ‘A human vision system model for objective picture
in International Broadcasting Con-

quality measurements’,
vention, p. 498, Amsterdam, Sep 12–16.

Mohamed Ghouse, S. M. Z. S. (2008). Modeling spatial variation of
data quality in databases. PhD thesis. Department of Geomatics,
University of Melbourne, Melbourne, Vic., Australia, pp. 148.

Perkins, C. (2007).

‘Community mapping’, The Cartographic

Perkins, C. (2008). ‘Cultures of map use’, The Cartographic Journal,

Journal, 44, pp. 127–137.

45, pp. 150–158.

Ruiz, J. J., Ariza, F. J., Uren˜a, M. A. and Bla´zquez, E. B. (2011).
‘Digital map conflation: a review of the process and a proposal
for
Journal of Geographical
Information Science, 25, pp. 1439–1466.

International

classification’,

Rundstrom, R. A. (1990). ‘A cultural

interpretation of inuit map

accuracy’, Geographical Review, 80, pp. 155–168.

Saalfeld, A. (1983). Conflation: automated map compilation. PhD
thesis. CS-TR-3066, 1–133. University of Maryland College Park,
College Park, MD, USA.

Silva, S., Sousa Santos, B. and Madeira, J. (2011). ‘Using a color in
visualization: a survey’, Computers & Graphics, 35, pp. 320–333.
Sledge, I., Keller, J., Wenbo, S. and Davis, C. (2011). ‘Conflation of
vector buildings with imagery’, Geoscience and Remote Sensing
Letters, 8, pp. 83–87.

Thornton, M. (1977). ‘Financial statistics: collection and analysis’,
the Royal Statistical Society, Series D (The

Journal of
Statistician), 26, pp. 243–257.

Tsou, M.-H. (2011). ‘Revisiting web cartography in the United States:
the rise of user- centered design’, Cartography and Geographic
Information Science, 38, pp. 250–257.

Wald, L. (1999). ‘Some terms of reference in data fusion’, IEEE Transactions

on Geosciences and Remote Sensing, 37, pp. 1190–1193.

Copyright of Cartographic Journal is the property of Maney Publishing and its content may not be copied or

emailed to multiple sites or posted to a listserv without the copyright holder's express written permission.

However, users may print, download, or email articles for individual use.

