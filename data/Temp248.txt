International Journal of Geographical Information
Science

ISSN: 1365-8816 (Print) 1362-3087 (Online) Journal homepage: http://www.tandfonline.com/loi/tgis20

Shape-adaptive geometric simplification of
heterogeneous line datasets

Timofey E. Samsonov & Olga. P. Yakimova

To cite this article: Timofey E. Samsonov & Olga. P. Yakimova (2017): Shape-adaptive geometric
simplification of heterogeneous line datasets, International Journal of Geographical Information
Science, DOI: 10.1080/13658816.2017.1306864

To link to this article:  http://dx.doi.org/10.1080/13658816.2017.1306864

Published online: 24 Mar 2017.

Submit your article to this journal 

View related articles 

View Crossmark data

Full Terms & Conditions of access and use can be found at
http://www.tandfonline.com/action/journalInformation?journalCode=tgis20

Download by: [University of Newcastle, Australia]

Date: 24 March 2017, At: 03:40

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE, 2017
http://dx.doi.org/10.1080/13658816.2017.1306864

RESEARCH PAPER
Shape-adaptive geometric simpliﬁcation of heterogeneous
line datasets

Timofey E. Samsonov

a and Olga. P. Yakimova

b

aDepartment of Cartography and Geoinformatics, Faculty of Geography, Lomonosov Moscow State
University, Moscow, Russia; bDepartment of Computer Security and Mathematical Methods of Information
Processing, Faculty of Mathematics, Demidov Yaroslavl State University, Yaroslavl, Russia

ARTICLE HISTORY
Received 12 November 2016
Accepted 11 March 2017

KEYWORDS
Line generalization;
geometric simpliﬁcation;
segmentation; shape
analysis; algorithms

ABSTRACT
Line generalization is an essential data processing operation in geo-
graphic information systems and cartography. Many point reduction
and simpliﬁcation algorithms have been developed for this purpose.
During the last three decades, several attempts have been made to
develop approaches of generalization that adapt to the geometric
properties of the processed lines. They typically incorporate line seg-
mentation based on quantitative descriptions of the line shape. Little
attention has been paid to the cases in which heterogeneous lines of
diﬀerent geometric character are mixed in one dataset. One common
example is administrative borders, which often contain natural and
artiﬁcial, smooth and sharp, schematic and non-schematic, and regular
and irregular shapes. The tuning of the simpliﬁcation algorithm based
on a quantitative description of the shape would be ineﬀective here,
since diﬀerent algorithms must be applied to lines of diﬀerent char-
acters. In this article, we present a general method and generalization
model for the simpliﬁcation of such datasets. The properties of sche-
matism, smoothness and regularity are used to diﬀerentiate various
line characters. Three line characters, including irregular non-sche-
matic, irregular schematic and regular orthogonal schematic, were
selected for the current study. The developed generalization model
consists of preprocessing, processing and postprocessing stages. Line
segmentation based on the detection of diﬀerent characters is per-
formed during the preprocessing stage. Then, Li–Openshaw, Douglas–
Peucker and orthogonal simpliﬁcation are applied to the appropriate
segments in the processing stage. Postprocessing enables the addition
of extra regularity to the simpliﬁed shape. A visual and quantitative
assessment of the results is provided and demonstrates the eﬀective-
ness of the developed approach in comparison with the global appli-
cation of a single simpliﬁcation algorithm.

1. Introduction

Interest in automated line generalization has existed for nearly half a century. Geometric
simpliﬁcation is one of the most requested operations amongst the variety of line
generalization algorithms and is essential for obtaining the level of detail adequate for
the selected mapping scale or analysis resolution. Numerous algorithms based on

CONTACT Timofey E. Samsonov
© 2017 Informa UK Limited, trading as Taylor & Francis Group

tsamsonov@geogr.msu.ru

2

T. E. SAMSONOV AND O. P. YAKIMOVA

various criteria such as perpendicular distance (Douglas and Peucker 1973), eﬀective
area (Visvalingam and Whyatt 1993), turning angle or curvature (Visvalingam and Whyatt
1993, Rosenfeld and Johnston 1973, Gökgöz et al. 2015), edge length or ratio (Teh and
Chin 1989), bend area (Wang and Müller 1998) and others have been developed. These
are organized as sequential or iterative procedures (Li 2006) but can also be cell-based
(Li and Openshaw 1992, Raposo 2013) or implemented via optimization (Sester 2005,
Haunert and Wolﬀ 2010).

The variety of line shapes in natural and artiﬁcial environments is inﬁnite. The same is
true regarding the number of issues that may arise during the line simpliﬁcation process.
Whereas many algorithms have been developed for the common case of line or polygon
features, some of them include a speciﬁc combination of elements developed for the
particular type of source data. These include buildings (Bayer 2009, Damen et al. 2008,
Buchin et al. 2011) which tend to have artiﬁcially sharp or curved angles. Also, coastlines
and contours may be characterized by a hierarchical structure of bends, which can be
considered during generalization (Wang and Muller 1993, Ai 2007).

At the same time, there are heterogeneous line datasets in which lines of completely
diﬀerent character may be mixed together. Administrative borders are a common
example. These lines may follow parallel and meridian directions in one area, thus
In some other
being arranged in a clearly perceived orthogonal schematic pattern.
areas, they may comprise long and straight edges without orthogonality but still be
visually schematic and artiﬁcial. Finally, they may coincide with rivers and mountain
ridges, being naturally non-schematic without any regularity. An example of this type
from Russian administrative borders is presented in Figure 1. The reader can clearly see
the coexistence of the three described line shapes in one dataset.

Figure 1. Administrative borders with mixture of heterogeneous line characters (the Akhangelsk and
Komi regions in Northern European Russia).

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

3

Figure 2. Line shape cube.

These diﬀerences in line shape can be conceptualized by the shape cube in which
three dimensions correspond to schematism, smoothness and regularity (Figure 2).
Schematic lines are simple in shape and do not include a complex hierarchy of bends
of various sizes which is typical for non-schematic lines. Smooth lines are perceived as
having gradually changing tangent directions. They contrast with sharp lines, in which
edgy corners are clearly perceived due to the large deviation angles of the line. Finally,
regularity means the repetition of some property of a line along its curve. For example,
the repetition of right angles leads to orthogonal regularity, or some shapes can be
repeated. Non-schematic lines can also be regular, e.g. contour lines may sometimes
exhibit a fractal regularity. The symmetry can also be viewed as a type of regularity
(Haunert 2012).

If diﬀerent line shapes are combined in one dataset, no single standard algorithm
such as those mentioned above would be eﬀective globally for geometric simpliﬁcation.
This problem illustrated in Figure 3, which contains example administrative borders from
Figure 1. As observed, the orthogonal schematic pattern can only be generalized
correctly using some specialized algorithm, such as Simplify Building from the ArcGIS
software package. The algorithm developed by Douglas and Peucker (1973) maintains
the shape of the sharp schematic irregular line but distorts the angles in the orthogonal
schematic segment. It also destroys the character of smooth non-schematic lines making
them sharp and schematic. Finally, Li and Openshaw’s (1992) algorithm makes sharp
schematic segments smooth, which is also a generalization error. However, it works well
for smooth non-schematic segments.

In this paper, we present an approach to the generalization of heterogeneous line
datasets. In Section 2, we review the related literature to generalization of speciﬁc types
of lines and shape-adaptive approaches. Our workﬂows and generalization model are
expounded in Section 3 of the paper. Finally, experimental results for Russian and US
administrative units are presented and discussed.

4

T. E. SAMSONOV AND O. P. YAKIMOVA

Figure 3. Comparative generalization of lines with diﬀerent geometric characters.

2. Background and objectives

Weibel (1996) noted that many algorithms developed for line generalization neglect
signiﬁcant constraints that are well established in cartographic practice. Consequently,
the results can be used for a small amount of simpliﬁcation. Amongst the constraints
intrinsic to a line, Weibel identiﬁed the minimize shape distortion (metric) and preserve
original line character (gestalt) constraints. The ﬁrst concerns the preservation of line
length and angularity with minimal areal displacement. The second requires preserva-
tion of the intrinsic character expressing the process of the generation of a feature
represented by a cartographic line.

The line character and shape structure can be assessed from the analysis of coordi-
nates in diﬀerent (and extending) spatial contexts including individual vertices, bends
and line segments. Usually, the characteristics derived at individual vertices such as the
turning angle or eﬀective area are used for various decisions in line generalization
algorithms, e.g. identiﬁcation of characteristic points (Dutton 1999). The characteristic
key points are detected in Nie and Huang (2011) using the universal corner detection

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

5

algorithm developed by Chen He and Yung (2008) which is based on a calculation of the
line curvature in the local and global context. The key points are used to divide the line
into segments and then to generalize each segment using the Li–Openshaw algorithm.
However, the morphological properties of the lines between key points are not
considered.

Point-wise characteristics give a basis for describing the shape of the point sequence
and the following segmentation of the line into homogenous parts (Buttenﬁeld 1991).
Between point-wise and segment-wise analysis is bend analysis, introduced in the land-
mark paper by Wang and Müller (1998). They formalized the term bend as a line segment
with a constant sign of the turning (inﬂection) angle and oﬀered diﬀerent bend general-
ization operations including elimination (for small bends), combination (for close similar
bends) and exaggeration (for isolated bends). The shape of the individual bend is
described by various numerical characteristics such as size (area) and compactness.
Although Wang and Müller’s bend-oriented methodology is very close to the manual
it has not evolved into new generalization algorithms based on its
methodology,
concepts and the segmentation-based approach has dominated in geometric line
simpliﬁcation research thus far.

Buttenﬁeld (1987) was one of the ﬁrst to emphasize the necessity of analysing the line
shape for parameterizing generalization algorithms. She argued that tolerance values in
line generalization should be modiﬁed to preserve realism (which implies accuracy and
recognizability) of the generalized version of each feature. For this purpose, she intro-
duced hierarchical measurements of geometry that implicitly accommodate the scale-
dependent nature of cartographic detail and proposed a digital method for identiﬁca-
tion of feature types based upon these measurements. Then, tolerance values were
selected according to these measurements.

Plazanet et al. (1995, 1998) developed the method of line segmentation into frag-
ments with diﬀerent shape characteristics. This segmentation was performed to allow
the establishment of a sequence of appropriate generalization tools and parameter
values. The authors applied a hierarchical segmentation process in which the line is
recursively split until all the segments become homogeneous. For each segment, several
measures can be calculated which allows the subsequent classiﬁcation. For each class, its
own procedural solutions must be applied further (Plazanet et al. 1998).

Mustiere (2005) proposed local and adaptive approach to road generalization,
in
which diﬀerent algorithms may be successively applied to each part of a road. The
choice of algorithm is determined from examples using supervised learning techniques
based on a particular set of measures. Garcia Balboa and Ariza López (2008) developed a
method for generalization-oriented road line classiﬁcation via an artiﬁcial neural net-
work. The classiﬁcation of the sections is applied in expert mode based on line sinuosity
ranging from very smooth to very sinuous. Another domain-speciﬁc segmentation
algorithm was developed for coast lines (Saga 1995).

Park and Yu (2011) developed a hybrid line simpliﬁcation approach for cartographic
generalization. Their methodology for segmenting and simplifying linear features is
based on the quantitative characteristics of a line. Those authors analysed the perfor-
mance of existing simpliﬁcation algorithms based on the geometric attributes of line
shapes. Then, the analysed data were used as a criterion for segmenting line data and
selecting simpliﬁcation algorithms appropriate for each segment. The Douglas and

6

T. E. SAMSONOV AND O. P. YAKIMOVA

Peucker (1973), sleeve-ﬁtting (Zhao and Saalfeld 1997) and turning function (Rangayyan
et al. 2008) algorithms were selected for testing on diﬀerent line geometries. The
authors selected the algorithm with the smallest positional error amongst all of the
algorithms. The method was tested on buildings, roads and rivers data from topographic
maps. There are several important issues in this approach that should be noted for the
following analysis:

● Only the positional accuracy is used to select the best algorithm; the line character
and angularity are not considered. This implies that the result cannot be guaran-
teed to have cartographic quality.

● Clustering is used to derive the training data, and the number of classes must be
chosen by the user. It is well known that clusters are not always clearly identiﬁed;
this may result in the random assignment of line segments to the wrong classes.
● The examples chosen are mostly homogenous in nature (e.g. buildings, roads and
rivers) and separated into diﬀerent layers, which makes segmentation more
straightforward than when all types of geometries are mixed in one line dataset,
as in the case of administrative borders.

All the mentioned methods are based on analysis of the quantitative information
regarding the line shape and its variability. However, the general line character, which is
a Gestalt characteristic according to Weibel (1996), when expressed in terms such as
rectangular, smooth, sharp or edgy, is more qualitative than quantitative. Such a char-
acteristic can be used dually in generalization. First, it may work as prior knowledge
regarding line character and as the constraint during the generalization. In this case, the
algorithm simpliﬁes the geometry in a speciﬁc manner that removes the detail and
preserves line character simultaneously. This approach is mostly developed in general-
ization of buildings, where orthogonal line character is prioritized (Staufenbiel 1973).
Second, the shape characteristic can be used as a constraint only, without prior knowl-
edge regarding the line character. This case is commonly implemented in line schema-
tization algorithms which transform the initial shape into some simplistic caricature,
such as in an orthogonal (Meulemans et al. 2010), curved (Van Goethem et al. 2015) or
arbitrary manner (Buchin et al. 2016).

One of the early works on building generalization was the dissertation by Staufenbiel
(1973), in which a rule-based system for building generalization was introduced. Sester
(2005) developed a framework for building generalization based on least squares
adjustment that allows building wall squaring and the preservation of rectangularity
and characteristic building parts. Shan and Sampath (2006) developed an algorithm for
building extraction from lidar data points; the algorithm was intended to extract long
line segments and the two main building orientations. A similar task, but for digitizing
raster building datasets, was solved by Gribov and Bodansky (2006). There is also a
family of recursive approaches to building generalization (Bayer 2009). Another method
that is often applied to building generalization is mathematical morphology (Cámara
and López 2000, Damen et al. 2008).

An optimization technique for the topological simpliﬁcation of building footprints
was developed by Haunert and Wolﬀ (2010). Their complex methodology is based on
selecting a subsequence of the original polygon edges. Then, these edges are connected

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

7

by so-called shortcuts deﬁned by intersections of consecutive or extended edges in the
selected sequence. The solution is obtained by deriving the minimal number of output
edges that satisﬁes the deﬁned distance threshold. An algorithm for polygon and
subdivision simpliﬁcation presented by Buchin et al. (2011, 2016) is based on so-called
edge moves that allow area and topology-preserving subdivision simpliﬁcation. The
polygons are iteratively simpliﬁed until the desired number of edges is reached.

In most of the observed algorithms, a global processing strategy is applied to all the
objects. Simultaneously, the uniﬁed approach does not seem appropriate for the line
datasets with a mixture of line shapes such as the administrative borders case presented
above. The necessity of applying diﬀerent generalization approaches in diﬀerent spatial
contexts was emphasized previously by Touya et al. (2010) and Buttenﬁeld et al. (2013)
and implies the need for the development of a shape-adaptive approach to cartographic
line simpliﬁcation. Such an approach should be targeted at preservation of the general
line character and merits the development of line character recognition algorithms, which
perform qualitative line segmentation. Next, each part may be generalized by the most
appropriate algorithm or segmented further into fragments that are homogenous in terms
of some quantitative measures (Buttenﬁeld 1987, Plazanet et al. 1998, Mustiere 2005).

In this paper, we focus on the development of qualitative line segmentation and
demonstrate how this approach may help in preserving diﬀerent line characters in one
heterogeneous dataset during generalization at small scales.

3. Methodology

3.1. Statement of the task

We developed an approach for the geometric simpliﬁcation of lines consisting of three
line characters: non-schematic, irregular schematic and orthogonal (special case of the
sharp regular schematic). The developed approach consists generally of three steps:
preprocessing, processing and postprocessing. The preprocessing stage involves opera-
tions such as ﬁltering, segmentation and squaring. Processing involves the iterative
geometric simpliﬁcation of the segments, in which every segment is simpliﬁed using
the dedicated algorithms; then, small segments are merged with neighbours and
simpliﬁcation is performed again. Postprocessing implements the regularization of the
results, similar to preprocessing, but it is performed on the simpliﬁed geometry. All these
operations are described in further detail below.

Before we proceed with algorithms and methods, it is necessary to clarify what we

expect to see when looking for the abovementioned line characters.

Having a polyline consisting of simple edges (without arcs and curves), we deﬁne the
schematic line segment as one having edges that are suﬃciently long to be perceived
separately. Formally, we need to set the length tolerance D. Then, every edge ei ¼
(cid:1)(cid:1)(cid:1)(cid:1)! with length li ¼ eij
j (cid:2) D will be classiﬁed as belonging to a schematic segment.
pi; piþ1
Otherwise, it is classiﬁed as non-schematic.

j

j

We prefer to deﬁne D in millimetres on screen, because this allows the user to
abstract from the resolution of the source data and conduct experimental work by
changing the value of D and the scale of the visualization. Then, the number of
recognized schematic segments will depend on these easily understandable parameters.

8

T. E. SAMSONOV AND O. P. YAKIMOVA

The diﬀerentiation between sharp and smooth lines depends on the inﬂection angle
at each vertex δi ¼ ﬀðei(cid:4)1; eiÞ ¼ arccos ei(cid:4)1 (cid:5) ei
(cid:6). We may set a constant
ð
j (cid:7) δ,
value δ as the borderline angle between smooth and sharp vertices. Hence, if δij
then the vertex is considered to be smooth; otherwise, it is considered to be sharp. Note
that schematicity is deﬁned for edges, whereas sharpness/smoothness analysis is
deﬁned for vertices.

Þ= ei(cid:4)1 (cid:5)j j
j

jei

j
j

ð

Þ

½

j

j

Finally, to recognize orthogonal line character as a special case of the regular sharp
schematic character, we need to ﬁnd the vertices that satisfy the following two condi-
tions simultaneously:

(1) Each edge at the vertex must be schematic: li(cid:4)1 (cid:2) S; li (cid:2) S, where S is a speciﬁc
length tolerance for orthogonal schematic segments which may diﬀer from D.
This condition ensures that both edges composing the angle are suﬃciently long
such that the angle at the vertex can be visually estimated.

(2) The angle at the vertex should be approximately equal to 90°. Some corners on the
map are perceived as right or almost right, although in fact they are slightly more or
less than 90° which results in a deviation αi ¼ 90° (cid:4) δi
j. Borderlines often do not
follow the accurate right angle sequence. Errors of digitization and coordinate
precision will also aﬀect the angle values. Thus, we also need some angle tolerance
A that allows us to consider the angle as right if its value is in the 90° (cid:8) A
neighbourhood. This results in the second orthogonal angle condition, αi (cid:7) A.

j

At this stage, we have not focused on the diﬀerentiation between smooth and sharp
characters and have considered all non-schematic lines to be smooth and all schematic
lines to be sharp. This assumption seems to be acceptable for two reasons. First, non-
schematic lines consist of short edges according to our deﬁnition and the line deviation at
a point will be invisible. Next, our method is focused on small-scale generalization, where
smooth schematic structures are rare compared with when large scales are considered.

3.2. Preprocessing

The goal of the preprocessing stage is to decompose line into geometrically homoge-
neous fragments that can be further eﬀectively processed using the appropriate simpliﬁ-
cation algorithms. To achieve this goal, we propose several procedures such as ﬁltering,
segmentation and squaring, which enable the removal of the redundant vertices, the
decomposition of the line into segments and the preparation the orthogonal segments for
speciﬁc simpliﬁcation procedures. An example of segmentation is presented in Figure 4.
The initial object is depicted by the thin black line and the detected segments are shown
in colour. We will refer to this ﬁgure in further explanations.

3.2.1. Filtering
Because of the variable point density along the line and the possible noise in the
coordinates, we need to remove redundant vertices and thus clear the line for the
eﬀective segmentation. The goal is not to simplify the line but rather to optimize its
representation via some ﬁltering procedure, which leads to shape that is visually the
same but is represented by a smaller number of vertices. Hence, it is better to perform

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

9

Figure 4. Shape-adaptive segmentation of a line with heterogeneous geometry.

this operation using some of the point-reduction (Li 2006) algorithms. The algorithm
parameter must be set small because only the redundant points that do not aﬀect the
overall line character must be removed.

We applied a simple sequential point-reduction algorithm based on the perpendicular
distance, which is similar to the sleeve-ﬁtting algorithm (Zhao and Saalfeld 1997). The
algorithm is controlled by a single parameter d which is the shortest distance from the current
point to the segment connecting the two anchor points, similar to the Douglas–Peucker
iterative algorithm. However, in contrast to the Douglas–Peucker algorithm, the sleeve-ﬁtting
approach is sequential in terms of the Li’s (2006) classiﬁcation. We also control the topological
consistency during the ﬁltering by checking whether the newly created segment intersects
with any existing line in a dataset. This strategy was oﬀered earlier by Pallero (2013).

In our method, d is speciﬁed in millimetres on screen and is tied to the scale of
preprocessing (the source scale). When the algorithm is executed, the parameter is
transformed into the real-world distances such that it corresponds correctly to the
coordinates of the line vertices.

We will notate the points that were added to the result as pi, where i is a new point
index recalculated for the ﬁltered line. An example of the resulting line is represented in
Figure 4 where the sleeve rectangle covers all the initial points between p0 and p1 that
remain after ﬁltering. These points are inside the rectangle having a width of 2d and the
axial line between p0 and p1. Then, the next sleeve covers all the initial points between

10

T. E. SAMSONOV AND O. P. YAKIMOVA

p1 and p2, etc. The process of ﬁltering can be conceptualized as the sequential ﬁtting of
such sleeves to the initial line shape.

3.2.2. Segmentation
Segmentation includes the identiﬁcation of orthogonal, schematic and non-schematic
segments.

The identiﬁcation of orthogonal segments assumes the detection and chaining of the
neighbouring right angles in the line. The angles are calculated between every pair of
adjacent line edges which both have length more than S. Let si ¼ min li(cid:4)1; li
Þ be the
length of the shortest angle side. If αi (cid:7) A and si ¼ S, then the angle is marked as right.
Next, we infer that A must be corrected for the cases in which si > S. The reason for
this correction is that the squaring of the angles with long edges will lead to a signiﬁcant
shifting of the vertices, which can eventually result in the distortion of the shape and
topological errors. Therefore, the value of A should be small for angles formed by long
edges and vice versa.

ð

The corrected angle tolerance Ai is calculated using the following equation:
(cid:3)

(cid:4)

Ai ¼ A 1 (cid:4)

si (cid:4) S
ksi

;

(1)

where k (cid:2) 1 is an inhibition parameter. The greater the value of k, the slower is the decrease
of angle tolerance in proportion to the increase of the shortest angle side. This transforma-
tion is illustrated in Figure 5, with S ¼ 2 mm and A ¼ 10(cid:9). When k ¼ 1:0, then the propor-
tion is inversely linear: if the edge increases ﬁvefold, then angle tolerance decreases ﬁvefold
(10°–2°). However, for k ¼ 2:0, the decrease in angle tolerance will be just 1.67-fold (10°–6°).
The inclusion of this parameter allows us to consider the angles with relatively long
sides for squaring and to perform experiments for the selection of the optimal value of k
which will be described later.

After the orthogonal edges are extracted, all non-orthogonal edges that are longer
than D are classiﬁed as schematic. Then, all the remaining edges are classiﬁed as non-
schematic. The edges of all three types are chained into segments for further processing.
Finally, we return to the example in Figure 4 to assess all stages of the line segmenta-
tion. First, the initial line is ﬁltered using the sleeve-ﬁtting algorithm which results in the
remaining set of points P ¼ pif g. Second, the segment p0 . . . p7 is classiﬁed as orthogo-
nal according to the deﬁned angular (A) and linear (S) thresholds. Third, the segment
p7 . . . p12 is classiﬁed as irregular schematic according to the linear threshold D. Finally,
the remaining points p12 . . . p25 are classiﬁed as a non-schematic segment.

The ﬁnal stage of the preprocessing step is the squaring of the orthogonal segments.

3.2.3. Squaring of orthogonal segments
It is a well-established rule in cartographic generalization to transform fuzzy spatial
relations into strict relations; this results in transformation of almost perpendicular
lines into perpendicular lines (Touya et al. 2014). Thus, before further simpliﬁcation,
we need to force the angles in right angle sequences to be exactly right.

The squaring is performed according to the following procedure for each orthogonal

segment:

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

11

Figure 5. Relationships between the corrected angle tolerance and the length of the shortest angle side.

(1) Compute the total lengths of odd and even edges. The largest sum corresponds

to the main orientation of the sequence.

(2) For each edge in the main orientation, compute the convergence angle γ

i

between the edge and the y-axis direction.

(3) Obtain the weighted average of γ

i as the descriptor of main orientation:

γ

av ¼

P

liγ

i

P
i

:

li

i

(4) Rotate each edge in the main direction around its middle point so that its
convergence is strictly equal to γ
av. If the edge contains the endpoint of the
segment, it is rotated around the endpoint. Thus, the rotation does not aﬀect the
geometry of the adjacent line segment.

(5) Reconstruct each secondary edge by building the line going through its middle point
and perpendicular to the adjacent main direction segments. The endpoints of the new
secondary edge are aligned with endpoints of the adjacent main direction edges.

The squared line can then be simpliﬁed via specialized procedures that address this

type of line shape.

3.2.4. Assessment of the parameters for orthogonal segment detection
To assess the eﬀectiveness of the selected parameters for the detection of orthogo-
nal segments, we selected one example fragment of the dataset and carried it
through the full chain of preprocessing. The resulting points were attributed the
following values:

12

T. E. SAMSONOV AND O. P. YAKIMOVA

(1) Orthogonal – right angle vertex with si (cid:2) S.
(2) Two schematic – vertex with si (cid:2) S, and αi > A.
(3) One schematic – only one adjacent edge is longer than S whereas the other is

shorter than S.

(4) Non-schematic – vertex with si < S.

Figure 6(a) shows the inﬂuence of the angle tolerance A on the detection of right
angles. Obviously, the larger the tolerance, the greater is the number of detected right

Figure 6. Squaring of the detected right angle sequences with varying (a) angle tolerances (k ¼ 3,
S ¼ 2), (b) linear tolerances (k ¼ 3, A ¼ 15(cid:9)), (c) inhibition values (A ¼ 15(cid:9), S ¼ 2).

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

13

angles. The dataset is constructed by using the two polylines adjacent at the south-
eastern point, which cannot be considered as orthogonal because it is an endpoint.

Figure 6(b) illustrates the inﬂuence of the length tolerance S on the results of the right
angle detection. Here, smaller lengths do not mean larger number of right angles. This can
be learned by comparing the facets with S ¼ 1:0 and 2:0 mm in Figure 6(b). The angle at
the black point for S ¼ 1:0 is not considered to be orthogonal because of the corrected
angle tolerance for that angle, which depends on the length of the shorter edge.

Finally, Figure 6(c) illustrates the inﬂuence of the inhibition parameter k on the
detection of right angles. Here, larger inhibition expectedly leads to increases in the
number of detected right angles.

The combination of parameters for this example that leads to the largest number of
detected orthogonal points is A ¼ 15:0(cid:9), S ¼ 2:0 mm and k ¼ 3:0. This combination will
be considered later in the results section during the assessment of line segmentation.
These values may not be optimal for other datasets and need to be parameterized
accordingly (see Section 5).

3.3. Processing

3.3.1. Simpliﬁcation of orthogonal segments
The preservation of line character in the case of an orthogonal line means that all angles
must be kept squared after generalization.

First, the user must set a target scale that is R times smaller than the source scale.
Then, edges shorter than S0 at the target scale must be removed. Hence, the result
depends on the zoom level selected by the user.

To decide how the generalization should be made, a set of possible conﬁgurations
was derived. Resulting conﬁgurations were classiﬁed into Z-like, U-like, endpoint and
short, as presented in Figure 7.

The simpliﬁcation of an orthogonal segment is based on a substitution procedure in which
the deleted edge and its neighbours are replaced by a new conﬁguration. Three possible
substitutions were included in the algorithm: median, shortcut and diagonal (Figure 7).

In median substitution, the removed edge ei

is replaced by the new perpendicular
edge, which is connected to the ei(cid:4)2 and eiþ2 or their extensions. Median substitution
is best because it tends to equalize the proportions between the neighbouring bends
and makes the orthogonal pattern more regular, which is valuable for small-scale
generalization. Thus,
it was set as the default substitution for U-like and Z-like
conﬁgurations.

Shortcut substitution is implemented by the connection of ei(cid:4)1 with eiþ2 or, alterna-
tively, ei(cid:4)2 with eiþ1. Shortcuts are applied in cases in which the median substitution
leads to topological error (e.g. intersection). Both shortcuts are constructed; one that has
no topological error is selected then. There is also a special case of shortcut substitution
for the ﬁrst or last edge in a sequence. For example, e2 is moved along e1 until p2
coincides with p1 so that e1 vanishes. If the shortcut leads to topological error, it is not
applied and the diagonal substitution is tried locally instead.

Diagonal substitution is applied on short orthogonal segments consisting of three
points and involves simply connecting the ﬁrst and last point in a segment.
If we
inﬁnitely decrease the resulting scale, then every orthogonal segment will eventually

14

T. E. SAMSONOV AND O. P. YAKIMOVA

Figure 7. Edge substitution strategies for various conﬁgurations of orthogonal
line segments.
Endpoints are symbolized by hollow dots, the old conﬁguration is a dotted line, the contracted
edge is marked by an X and the new conﬁguration is depicted in colour.

be represented by some 3-point conﬁguration that would need such a substitution.
Because this process leads to the inevitable loss of orthogonality, the resulting single
edge is then classiﬁed as schematic. The diagonal substitution is also performed when
both median and shortcut substitutions lead to topological errors, as mentioned above.
If it also leads to topological errors, no substitution is performed.

An example simpliﬁcation of the orthogonal segment is presented in Figure 8.

3.3.2. Simpliﬁcation of schematic and non-schematic segments
Previously in Figure 3, we demonstrated that the Li–Openshaw algorithm works well for
non-schematic segments. Due to its being based on regular grid tessellation of space, the
Li–Openshaw algorithm preserves equally the same number of edges per square unit on
screen. Moreover, the points falling into each cell can be replaced by 1 point that averages
the ﬁrst and last point, according to one of the approaches oﬀered by Li and Openshaw
(1992). The resulting points are not a subset of the source points in this case and the Li–
Openshaw algorithm eventually works like a moving average. Therefore, we implemented
the Li–Openshaw algorithm for the geometric simpliﬁcation of non-schematic segments.
One of the additional advantages of the Li–Openshaw procedure is that it cannot lead to
topological errors, such as intersections with existing lines. Li (2006) also noted in his book that

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

15

Figure 8. Example simpliﬁcation of an orthogonal line segment. The R parameter corresponds to the
reduction in scale (times).

It is a misconception to say that the Li–Openshaw algorithm is only suitable for the
generalization of natural boundaries. If the rasterization approach is adopted and the points
on the original line are used, then the Li–Openshaw algorithm can also be used for the
simpliﬁcation of artiﬁcial lines, for example, cadastral boundaries. (page 154)

He provided a simple example using an artiﬁcial line, in which only the ﬁrst point is
retained in each cell. However, we claim that the Li–Openshaw algorithm is ineﬀective
for the generalization of schematic segments because it cannot assess the importance of
points in a global context.

In contrast, the Douglas–Peucker algorithm is based on a procedure that ﬁnds the
chords between existing points. It tends to maximize the number of points covered by
each chord while satisfying the distance constraint. This maximization tendency leads to
the line shape that is familiar to every cartographer and usually looks overgeneralized
and edgy in comparison with that yielded by other algorithms. This line shape is what
we are essentially looking for while trying to simplify schematic lines. Therefore, we
implemented the Douglas–Peucker algorithm for the geometric simpliﬁcation of irregu-
lar schematic segments, taking the correction by Ebisch (2002) into account.

Additionally, to ensure that the Douglas–Peucker simpliﬁcation does not lead to
topological errors, we performed its recursive procedure not only until the distance
error threshold is satisﬁed in each resulting segment but also until there were no
intersections with existing segments, i.e. the recursive splitting will continue until the
distance condition is satisﬁed and there are no topological errors in the result.

The generalization of these types of segments is controlled by a single tolerance
parameter T that corresponds to grid resolution in the Li–Openshaw algorithm and

16

T. E. SAMSONOV AND O. P. YAKIMOVA

perpendicular distance in the Douglas–Peucker algorithm. The value of T is deﬁned in
millimetres on screen; thus, the result depends on the zoom level selected by the user.

Iterative merging

3.3.3.
Line segmentation has one major drawback: it leads to visual irregularities when some
segments become too small at the resulting scale. Imagine that we have a small non-
schematic segment between the two schematic segments, and its length is equal to
1 mm at the resulting scale. If we do not specially treat it, it will appear like a small
disturbance in the sequence of schematic segments, and it must be removed.

We can generalize this situation into nine possible conﬁgurations, which are repre-
sented in Figure 9. The left column in this ﬁgure represents the situation after the
processing was performed. The middle segment in each row is shorter than the deﬁned
threshold (S0); this situation must be resolved to remove the noisy small details from the
generalized line representation.

Figure 9. Strategies to merge short segments with neighbours. The merged segment is located in
the centre of the left (before) column. See comments in the text for explanation.

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

17

We oﬀer the line merging operation as a solution to this problem. Depending on the
particular conﬁguration, the middle segment can be merged with one of the neighbours
or with both neighbours.

The ﬁrst three cases (A–C in Figure 9) represent the situation in which the short
orthogonal segment must be removed. If it is surrounded by two schematic (A) or non-
schematic (C) segments, it is merged with both of them, which results in one segment of
the corresponding type. If the orthogonal segment is surrounded by two segments of
diﬀerent types (B), it is merged with the schematic segment, because an orthogonal
segment is a special case of a schematic segment.

The second group of cases (D–F in Figure 9) concerns the resolution of the short
schematic segment surrounded by non-schematic and orthogonal segments. In case D,
the short schematic segment is contracted by two edge moves (Buchin et al. 2016) of
adjacent orthogonal edges towards the midpoint of the central segment. Edge moves
allow us to maintain the orthogonality of the resulting segment. In the remaining cases
E and F, the small schematic segment is integrated into the structure of the neighbour-
ing non-schematic segment(s).

The third group of cases (G–I in Figure 9) relates to the merging of non-schematic
segments. These conﬁgurations are treated similarly to the previous case. The small non-
schematic segment (conﬁguration G) is contracted by two edge moves of adjacent
orthogonal segments. Finally, a small non-schematic segment can be freely integrated
into the neighbouring schematic segments (conﬁgurations H and I).

The merging operation is performed ﬁrst for orthogonal segments, then for
schematic segments and ﬁnally for non-schematic segments. In each group of seg-
ments, the merging is performed from shorter to longer segments. This strategy
allows for increasing the length of the longer segments primarily by the shortest
segments. Some of the segments become longer than the threshold after they
assimilate short neighbours of another type; this ﬁnally leads to the smaller number
of merged lines.

After the merging is performed, the processing of the segments is performed again.
Then, the possibility of new merging is analysed. The process continues iteratively until
there are no short segments to merge with neighbours.

3.4. Postprocessing and generalization model overview

Postprocessing is similar to the preprocessing stage but is performed on the already
processed (generalized) dataset and at the resulting scale. We added this stage to
supply the user with the ability to make the image more regular and to unify the
density of points along the line. Additionally, this procedure allows for the identiﬁca-
tion and squaring of segments that were not classiﬁed as orthogonal at the source
scale (due to the edge length) but can be treated at the resulting scale. We will
describe how the postprocessing aﬀects the result of generalization in the next section
of the paper.

The overall scheme of the developed generalization model, which incorporates
is illustrated in Figure 10 so that the reader can

several stages and algorithms,

18

T. E. SAMSONOV AND O. P. YAKIMOVA

Figure 10. A graphical representation of the developed generalization model.

assess the whole technological process at a glance. The scheme illustrates the
idea of applying diﬀerent simpliﬁcation approaches to lines of diﬀerent
initial
character.

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

19

4. Results

4.1. Methodology implementation and user workﬂow

The developed methodology was implemented in the MapSimplify application* using
the C# language. All algorithms were implemented in serial, partly because it is simpler
to control the topological consistency in a serial
implementation than in a parallel
implementation. The Esri Shapeﬁle format was used to load the source data and save
the results. The user interface of the program is presented in Figure 11. The general-
ization result was controlled by setting the various parameters mentioned above and
selecting the desired combination of the three generalization algorithms. Postprocessing
is also possible by setting the corresponding checkbox.

The typical user workﬂow is the following. First, the user must load the data and set the
scale of the preprocessing. This step aﬀects the number of detected orthogonal, schematic
and non-schematic segments because the parameters for their extraction are deﬁned in
millimetres on screen. Then, the optimal combination of the preprocessing scale and para-
meters may be found by changing their values and performing preprocessing. The same ‘trial
and error’ workﬂow can be applied in the processing stage. Finally, the postprocessing option
may be checked if the user wants greater regularity in the resulting shapes.

Figure 11. MapSimplify application, which implements the developed method.

*Available to download at http://autolab.geogr.msu.ru/software/MapSimplify.

20

T. E. SAMSONOV AND O. P. YAKIMOVA

4.2. Experimental setup

We selected rayon borders in the Komi and Arkhangelsk regions of Russia to assess the
eﬀectiveness of the proposed method. The source data were a 1:1000,000 digital
topographic map of Russia provided by DATA+, LLC. The dataset contains 116 lines
comprising 7090 points in total, with the average number of points per line being 61.

The experimental work included the following:

(1) the visual and numerical assessment of segmentation derived with diﬀerent

preprocessing parameters;

(2) the assessment of preprocessing execution time;
(3) the visual comparison of the generalization results derived by various algorithms;
(4) the numerical assessment of the horizontal accuracy of the results derived by

various algorithms;

(5) the assessment of processing execution time and
(6) the visual assessment of the postprocessing results.

4.3. Preprocessing

We performed the preprocessing at the source scale of the data (1:1000,000; 1 km on
Earth is 1 mm on the screen) with varying values of the line deviation d, right angle
tolerance A, orthogonal edge length S, schematic edge length D and inhibition k
parameters.

4.3.1. Visual assessment of segmentation
After the preprocessing, each vertex pi was attributed with the type of the segment ei
that starts in pi. An example visualization of this attribution is presented in Figure 12.
This point-wise representation illustrates the fact that non-schematic segments are
characterized by high density of points in comparison with schematic ones.

This representation is converted to the segmentation of edges, which is presented in
Figure 13 and can be compared to the manual segmentation in Figure 4. One can note
that the resulting picture, especially in Figure 13(a), is close to the manual interpretation
of the line characters. Increasing the orthogonal edge length in Figure 13(b) leads to
reclassiﬁcation of many small orthogonal segments as non-schematic, whereas the
dramatic decrease in the schematic edge length D results in the reclassiﬁcation of
many non-schematic segments as schematic.

4.3.2. Numerical assessment of segmentation
The inﬂuence of the preprocessing parameters is shown in Figure 14. This ﬁgure
illustrates the changes in the execution time and percentage ratio of diﬀerent line
characters in the resulting segmentation under the variation of preprocessing para-
meters. The ratio itself is indicated by vertical bars under each parameter value, and
the leading line character class is highlighted. The sparklines in the right column
illustrate a trend in line character percentage and execution time as a function of the
increasing parameter value. The y-axis scale is similar for all sparklines; thus, one can
assess not only the trend but also its magnitude.

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

21

Figure 12. Example point classiﬁcation after preprocessing.

Increasing the line deviation d leads to a systematic decrease in the percentage of
non-schematic segments. It is foremost absorbed by the increase in the orthogonal
segment percentage and then by the percentage of schematic segments. We assume
that small values of d (generally less than 0.5 mm) work eﬃciently as the intended
ﬁltering purpose. However,
if this value becomes larger, the sleeve-ﬁtting algorithm
tends to generalize and schematize the line, which is an unwelcome eﬀect. Based on our
experience, we suggest 0.25 mm as the optimal value of d.

Increasing the orthogonal edge length S predictably leads to a smaller percentage of
orthogonal segments, whereas its distribution between schematic and non-schematic
segments depends on the value of D. Most of the previously orthogonal segments move
to the non-schematic class until S ¼ D. At this point, a large fraction of orthogonal
segments can be attributed as schematic. This means that if we want to classify short
orthogonal segments as schematic, we must set D to be smaller. However, small values
of D may lead to the improper generalization of naturally non-schematic segments,
which then will be attributed as schematic.

The schematic edge length D, while always greater than S, only inﬂuences the ratio
between schematic and non-schematic segments which decreases proportionally with D.
The inﬂuence of the right angle tolerance A is worth considering. An increase in A
generally leads to the absorption of schematic segments by the orthogonal class,
whereas the decrease in the percentage of non-schematic segments is quite modest.
This result reveals that some regularity, such as orthogonality, is mostly typical for simple

22

T. E. SAMSONOV AND O. P. YAKIMOVA

Figure 13. Example line segmentation after preprocessing.

schematic segments and is not a characteristic feature of smooth natural non-schematic
lines (as they are represented in the source cartographic data).

Finally,

increasing the inhibition parameter k aids in extracting more orthogonal
segments with long edges. Predictably, they are reclassiﬁed mostly from schematic
segments, while the changes in the percentage of non-schematic segments are invoked
by the reclassiﬁcation of small edges close to S.

Using these insights, the user of the generalization model may tune the parameters

sensibly to identify the best preprocessing results.

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

23

Figure 14. Line character ratios (% of total length) under diﬀerent preprocessing parameter values.
Coloured parameter values are used when other parameters are changed. Preprocessing was
performed at 1:1000,000 (1 mm on screen = 1 km) scale.

4.3.3. Numerical assessment of execution time
The computational complexity of diﬀerent preprocessing components can be assessed by
analysing the resulting processing time in the bottom row of each parameter section in
Figure 14. All the parameters can be ordered in the decreasing order of their inﬂuence on

24

T. E. SAMSONOV AND O. P. YAKIMOVA

computation time as follows: S ! A ! k ! d ! D. Generally, the identiﬁcation and
squaring of orthogonal segments (which are controlled by S, A and k) requires much
processing time in this particular example, which contains many such segments. More
candidates are found if the orthogonal edge length becomes smaller. At the same time,
the preprocessing also takes more time. Filtering and schematic edge search have an
insigniﬁcant inﬂuence on the processing time. The average time for preprocessing is 8 ms.

4.4. Processing

During the analysis of the processing results, we compared the lines obtained by the
developed method with the lines derived by applying the Douglas–Peucker and Li–
Openshaw algorithms globally.

As we stated earlier, the processing stage is controlled by three main parameters: the
scale reduction factor R, the generalization tolerance T and the resulting orthogonal
edge length S0, which is also used as a length tolerance for merging the short segments.
The generalization tolerance T acts as a perpendicular distance for the Douglas–Peucker
algorithm and as a cell size for the Li–Openshaw algorithm.

We performed generalization of the preprocessed dataset with R = 2, 4, 6, 8, 10; T = 0.5,
1, 2 mm and S′ = 1, 2, 4 mm as parameters in all possible combinations. The results were
ﬁrst assessed visually, and then in terms of spatial accuracy and processing time.

4.4.1. Visual assessment of derived line characters
Four ﬁgures were derived for each approach, with R = 2, 4, 8, 16 for visual comparison,
illustrating the progressive simpliﬁcation of the line dataset.

The Li–Openshaw (Figure 15) algorithm works well for non-schematic segments,
giving a line character that both smoothly and precisely ﬁts the shape of the original
one. Progressive generalization leads to smoother lines with less detail that nicely
represent natural features such as rivers. However, the Li–Openshaw approach fails to
represent the shape of the schematic and orthogonal segments, making them round
cornered. The reader is referred to Figure 13, in which diﬀerent types of segments are
highlighted.

On contrast, the Douglas–Peucker (Figure 16) algorithm works better in schematic
parts of the line and helps to keep their edgy and angular nature. However, this edgy
character is applied over the entire dataset, making natural line segments look artiﬁcial.
Additionally, the Douglas–Peucker algorithm does not preserve right angles, which leads
to the distortion of orthogonal segments.

Finally, Figure 17 illustrates that the proposed generalization model eﬀectively inte-
grates the best qualities from the previously mentioned algorithms with the specialized
approach for orthogonal segments. The orthogonal nature of the corresponding line
parts is emphasized; this can be considered a typiﬁcation process applied to the
orthogonal line bends. The reader is referred to Figure 13 again; it shows that non-
schematic segments are generalized similarly to that in the Li–Openshaw example
(Figure 15) and that schematic segments generalized similarly to that in the Douglas–
Peucker example (Figure 16), except for the cases in which line merging occurs.

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

25

Figure 15. Geometric line simpliﬁcation with the Li–Openshaw algorithm.

4.4.2. Numerical assessment of spatial accuracy
The Modiﬁed Hausdorﬀ Distance (MHD) introduced in Dubuisson and Jain (1994) was
used as a measure of spatial accuracy. Given the two point sets A ¼ a1; . . . ; aNa
g and
B ¼ b1; . . . ; bNb
g, the average distance between A and B can be calculated as
P
(cid:2)dðA; BÞ ¼ 1=Na
a2Adða; BÞ, where dða; BÞ ¼ minb2B k a (cid:4) b k . Similarly, the inverse
Þ
average distance between B and A is calculated as (cid:2)dðB; AÞ ¼ 1=Nb
b2Bdðb; AÞ,
where dðb; AÞ ¼ mina2A k b (cid:4) a k .

P

f

f

ð

Þ

ð

Given the distances between A and B, the MHD is calculated as:

MHD A; Bð

(cid:5)
Þ ¼ max (cid:2)d A; Bð

Þ; (cid:2)d B; Að
Þ

(cid:6)

;

(2)

In simple terms, the MHD is the maximum of the average distance from A to B and
the average distance from B to A. The lower the value of MHD, the closer A and B are
to each other. This measure is inspired by the classic Hausdorﬀ distance (where
d A; Bð
Þ) but is more robust because it averages the distances and
is thus not aﬀected much by outlier points.
In our experiment, the corresponding

Þ ¼ maxa2Ad a; Bð

26

T. E. SAMSONOV AND O. P. YAKIMOVA

Figure 16. Geometric line simpliﬁcation with the Douglas–Peucker algorithm.

segments before and after simpliﬁcation were used as A and B point sets. The average
value of MHD for all segments was used as an integral measure of the spatial accuracy.
A numerical assessment of the spatial accuracy is presented in Figure 18. The
vertical sparkline series in the last column illustrate how MHD changes with the
algorithm, whereas the horizontal series illustrates the changes in MHD as a function
of scale.

The ﬁrst observation derived from this report is that the MHD expectedly grows with
scale reduction and the parameter of the algorithm. The proposed approach leads to the
least predictable changes in MHD. At some scales, the MHD has some anomalous peaks,
which is most likely a result of the segmentation of orthogonal
lines, which is not
controlled by any accuracy constraint. The Li–Openshaw algorithm tends to increase
the MHD, while the Douglas–Peucker is the most predictable algorithm, yielding an
almost linear dependency between the scale reduction and the spatial accuracy.

The second observation is that the Li–Openshaw and Douglas–Peucker algorithms
generally lead to the most and the least accurate results, respectively, in terms of MHD,
whereas the proposed mixed method leads to intermediate accuracy, which can be fairly
judged by the comparison of the MHD for the cases in which S0 ¼ T.

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

27

Figure 17. Geometric line simpliﬁcation with the proposed approach. Schematic segments are
simpliﬁed using the Douglas–Peucker algorithm, non-schematic segments are simpliﬁed using the
Li–Openshaw algorithm and orthogonal segments are simpliﬁed using the customized approach.

4.4.3. Numerical assessment of execution time
The execution time for diﬀerent algorithms is systematized in Figure 19. In our imple-
mentation, the Douglas–Peucker appeared to be the fastest algorithm with nearly
constant execution time (4 ms) for this particular example. The overhead expenses
when searching for the longest distance in each iteration of the Douglas–Peucker
algorithm are signiﬁcantly greater than when constructing the simpliﬁed line from the
selected points. When the number of initial points is the same for each parameter value,
the algorithm performs nearly in constant time.1

The Li–Openshaw algorithm performs quicker in case of large scale reductions and
coarse grid resolutions. Much of the processing time is taken by extraction of line
portions that fall into each cell. The number of grid cells reduces signiﬁcantly in case
of large scale reduction, since the grid size is deﬁned in screen units in a resulting
scale, and not in a real-world units. The diﬀerence in the processing time is dramatic
for minor scale reductions and ﬁne grid tesselations comparing to the Douglas–
Peucker algorithm (Li–Openshaw is up to 9 times slower than Douglas–Peucker for

28

T. E. SAMSONOV AND O. P. YAKIMOVA

Figure 18. Generalization accuracy based on the modiﬁed Hausdorﬀ distance (MHD).

R ¼ 2, T ¼ 0:5); this diﬀerence vanishes in case of large scale reduction where algo-
rithm may perform even faster than the Douglas–Peucker processing (3 vs. 4 ms for
R ¼ 10, T ¼ 2). Thus, Li–Openshaw algorithm is computationally eﬀective for signiﬁcant
generalizations.

The processing speed of our approach depends slightly on the resulting orthogonal
edge tolerance S0, which is included in the table for additional information. The larger
the value of S0, the slower is the processing in general because this forces the algorithm
to substitute more edges in orthogonal segments. However, some exceptions to this
rule are possible (S0 ¼ 4 is faster than S0 ¼ 2 and even S0 ¼ 1). These exceptions can be
attributed to a quicker iterative merging procedure when orthogonal segments are
greatly simpliﬁed (S0 ¼ 4). The processing time of our approach is similar to that of
the Li–Openshaw algorithm in the case of small generalizations, which means that the
processing of non-schematic segments via ﬁne grid tessellation requires the most time.
in the case of great scale reductions and
Additionally,

the processing is faster

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

29

Figure 19. Processing time for diﬀerent geometric simpliﬁcation algorithms.

generalization tolerances, which can be attributed to the faster processing of non-
schematic segments by the Li–Openshaw algorithm.

4.5. Postprocessing

As stated earlier, the postprocessing stage is very similar to preprocessing and is
performed with the same parameters but at the target scale, not the source scale. An
example of postprocessing result is presented in Figure 20. The eﬀect is that the line
appears to be slightly more simpliﬁed and nearly orthogonal angles are now strictly
orthogonal (highlighted by the blue circles in the ﬁgure).

This stage of processing can be helpful in adding more spatial order and regularity to
the line characters after generalization. The drawback of postprocessing in its current
implementation is that it makes lines slightly more schematic and edgy because it

30

T. E. SAMSONOV AND O. P. YAKIMOVA

Figure 20. An example of the postprocessing of a generalized line dataset. Squared angles are
highlighted by blue circles.

removes small, round corners. This drawback is why the postprocessing stage is optional
in our generalization model.

5. Discussion

The results presented in this paper demonstrate that it is possible to generalize lines
with diﬀerent characters using one integrated approach and to implement the line
character constraint during the generalization. The key to the solution is the observation
that every line simpliﬁcation algorithm results in a speciﬁc line character style. The
methodology seems to be eﬀective, and the results prove the concept. There are several
methodological issues that should be considered for the current use of the developed
generalization model and future research.

5.1. Robustness

The ﬁltering and simpliﬁcation stages of the developed generalization model ensure the
topological consistency of the result. The sleeve-ﬁtting, orthogonal simpliﬁcation and
Douglas–Peucker algorithms are supplied with additional procedures that identify inter-
sections on the ﬂy and correct the execution in a way that resolves such errors. Li–
Openshaw algorithm cannot, by its principle, lead to topological errors. Therefore, the
proposed generalization model can be considered robust.

5.2. Scale limitations

The proposed generalization model has been developed for small scales. It must be
noted that the possible scale range for the generalization depends on the spatial extent
of the initial feature. The greater the extent of the processed line, the wider the scale range
at which our generalization model can be used for geometric simpliﬁcation. If the line is
too small to be represented at the target scale, it must be eliminated or collapsed to a

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

31

point feature depending on the goals of the generalization. Line selection can also be
used to remove the clutter at extremely small scales.

5.3. Dataset limitations

The selected mixture of line characters is typical for administrative borders; therefore,
the developed method is elaborated speciﬁcally for this type of spatial feature. Although
another type of spatial feature may consist of diﬀerent line characters, the general
workﬂow described in this paper will remain the same. Moreover, the particular pre-
processing and processing operations can be supplemented with the algorithms needed
to simplify each additional character correctly.

5.4. Selection of parameters

is initialized by using many input parameters
The developed generalization model
that must be adapted to the source dataset and the required degree of general-
ization. The preprocessing is controlled by ﬁve geometric criteria plus the scale of
observation. The processing requires three geometric parameters and the scale of the
output visualization. Finally, postprocessing is also possible – fortunately,
is
initiated by preprocessing parameters. The need to set the corresponding values
for these conditions results in 10 parameters that must be learned by the user.
Although we managed to ﬁnd some useful values for many of them, an important
direction of future research is to develop a methodology to select most of the general-
ization parameters automatically, at least to initiate the process of tuning of the
generalization model. This selection can be implemented via an in depth analysis of
line shape characteristics.

it

5.5. Other issues

There are also three low-level issues with the presented approach related to the joining
of the segments, the accuracy of orthogonal simpliﬁcation and the processing of
regularities other than orthogonality.

The joining issue occurs when neighbouring segments join at a sharp angle, which
leads to an abrupt change in geometry. This is not a problem if these changes are the
properties of the source dataset. However, if they are produced by our simpliﬁcation
procedures (especially orthogonal) near the segment joints, they must be avoided or
resolved. The accuracy issue requires us to apply a more sophisticated approach to the
generalization of orthogonal segments that is based not only on the substitution of
small edges but also on the most precise approximation of the whole shape. Next, the
regularity issue concerns the possibility to generalize other types of regular line shapes,
such as those based on circular arcs or repetitions of angles other than right angles. This
issue is more valuable for large-scale mapping.

Finally, more examples at a wider range of scales must be generalized to reveal the
advantages and shortcomings of the presented generalization approach and its applic-
ability under diﬀerent geographical conditions. To illustrate that it is possible to derive
satisfactory results for other territories, we generalized the data for the state of Montana,

32

T. E. SAMSONOV AND O. P. YAKIMOVA

Figure 21. Generalization of county boundaries for the US state of Montana using the developed
approach.

USA (Figure 21). The reader can see that diﬀerent line characters are also mostly
preserved, except for the cases in which the degree of scale reduction (eightfold here)
requires the diagonal substitution and merging of the orthogonal segments.

6. Conclusion

In this paper, the methodology and generalization model for the geometric simpliﬁcation of
heterogeneous line datasets were presented. A heterogeneous line dataset consists of lines
that have diﬀerent geneses (natural and artiﬁcial) and therefore often have contrasting
shape characters. Such datasets are diﬃcult to generalize because every generalization
algorithm tends to harmonize the processed shape via similar geometric manipulations
over the whole dataset. This harmonization inevitably leads to the necessity of applying
diﬀerent simpliﬁcation approaches to diﬀerent parts of the line.

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

33

Because the line character is a qualitative rather than quantitative characteristic, it is
possible to classify the line characters in some general cases, which results in a con-
ceptual line shape cube (Figure 2) based on schematism, smoothness and regularity. In
this paper, we studied the cases of smooth irregular non-schematic, sharp irregular
schematic and orthogonal (a case of sharp regular schematic) lines. These line characters
are typical of administrative boundaries, and all can be present in a single dataset.

The developed approach is based on automatic line segmentation into the abovemen-
tioned line types and applying the appropriate simpliﬁcation approaches to segments
individually. The Li–Openshaw algorithm was selected for non-schematic segments, the
Douglas–Peucker algorithm was selected for schematic segments and a customized ortho-
gonal simpliﬁcation approach was developed for corresponding segments. All parts of the
method were implemented in a generalization model that consists of preprocessing,
processing and postprocessing stages. The results demonstrate the eﬀectiveness of the
approach in the preservation of line characters during the generalization.

However, there is much to be investigated further. The most important research
direction is to implement the recognition of the remaining line characters, especially
diﬀerent types of regularities, amongst which only orthogonal regularity was discussed
in this paper. Experimental studies at a wider scale range are also needed, especially at
large cartographic scales. Additionally, parallel computations must be implemented for
all possible elements of the developed generalization model, which will require some
elaboration of particular stages. This development may lay the foundation for intellec-
tual expert systems that select the most appropriate algorithm to generalize the input
dataset or its morphologically homogenous segments.

Note

1. The actual variations can be identiﬁed via a more thorough analysis of CPU cycles or the use
of more fractional units than milliseconds, but we decided that such an analysis would not
yield much value for this particular study.

Acknowledgements

The authors would like to thank the three anonymous reviewers and the editors Prof. Robert
Weibel and Prof. May Yuan, whose comments helped to improve the paper.

Disclosure statement

No potential conﬂict of interest was reported by the authors.

The reported study was funded by RFBR according to the research project 15-07-06789.

Funding

ORCID

Timofey E. Samsonov
Olga. P. Yakimova

http://orcid.org/0000-0001-5994-0302

http://orcid.org/0000-0001-8816-2802

34

T. E. SAMSONOV AND O. P. YAKIMOVA

References

Ai, T., 2007. The drainage network extraction from contour lines for contour line generalization.
ISPRS Journal of Photogrammetry and Remote Sensing, 62 (2), 93–103. doi:10.1016/j.
isprsjprs.2007.04.002

Bayer, T., 2009. Automated building simpliﬁcation using a recursive approach. In: A. Ruas, ed.
Cartography in Central and Eastern Europe. Berlin, Heidelberg: Springer Berlin Heidelberg, 121–
146. doi:10.1007/978-3-642-03294-3_8

Buchin, K., et al., 2016. Area-preserving simpliﬁcation and schematization of polygonal subdivi-
sions. ACM Transactions on Spatial Algorithms and Systems, 2 (1), 1–36. doi:10.1145/2818373
Buchin, K., Meulemans, W., and Speckmann, B., 2011. A new method for subdivision simpliﬁcation
with applications to urban-area generalization. In: D. Agrawal, et al., eds. Proceedings of the 19th
ACM SIGSPATIAL international conference on advances in geographic information systems New
York, NY, USA. ACM, 261–270. doi:10.1145/2093973.2094009

Buttenﬁeld, B.P., 1987. Automating the identiﬁcation of cartographic lines. Cartography and

Geographic Information Science, 14 (1), 7–20. doi:10.1559/152304087783875372

Buttenﬁeld, B.P., 1991. A rule for describing line feature geometry. In: B.P. Buttenﬁeld and R.B.
McMaster, eds. Map generalization: making rules for knowledge representation. London: Longman
Scientiﬁc and Technical, 150–171.

Buttenﬁeld, B.P., Stanislawski, L.V., and Brewer, C.A., 2013. Adapting generalization tools to
physiographic diversity for the United States National hydrography dataset. Cartography and
Geographic Information Science, 38 (October 2014), 37–41. doi:10.1559/15230406382289

Cámara, M. and López, F., 2000. Mathematical morphology applied to raster generalization of
urban city block maps. Cartographica: the International Journal for Geographic Information and
Geovisualization, 37 (1), 33–48. doi:10.3138/A428-760T-1647-84P2

Chen He, X. and Yung, N.H.C., 2008. Corner detector based on global and local curvature proper-

ties. Optical Engineering, 47 (5), 057008. doi:10.1117/1.2931681

Damen, J., Van Kreveld, M., and Spaan, B., 2008. High quality building generalization by extending
In: 12th ICA Workshop on Generalisation and Multiple

the morphological operators.
Representation, 20–21 June 2008 Montpellier, France. 1–12.

Douglas, D. and Peucker, T., 1973. Algorithms for the reduction of the number of points required to
represent a digitized line or its caricature. Canadian Cartographer, 10 (2), 112–122. doi:10.3138/
FM57-6770-U75U-7727

Dubuisson, M.P. and Jain, A., 1994. A modiﬁed hausdorﬀ distance for object matching.

In:
Proceedings of 12th international conference on pattern recognition. Vol. 1. IEEE Comput. Soc.
Press, 566–568. doi:10.1109/ICPR.1994.576361

Dutton, G., 1999. Scale, sinuosity, and point selection in digital line generalization. Cartography and

Geographic Information Science, 26 (1), 33–54. doi:10.1559/152304099782424929

Ebisch, K., 2002. A correction to the Douglas–Peucker line generalization algorithm. Computers &

Geosciences, 28, 995–997. doi:10.1016/S0098-3004(02)00009-2

Garcia Balboa, J.L. and Ariza López, F.J., 2008. Generalization-oriented road line classiﬁcation by means
of an artiﬁcial neural network. GeoInformatica, 12 (3), 289–312. doi:10.1007/s10707-007-0026-z
Gökgöz, T., et al., 2015. A new algorithm for cartographic simpliﬁcation of streams and lakes using
deviation angles and error bands. ISPRS International Journal of Geo-Information, 4, 2185–2204.
doi:10.3390/ijgi4042185

Gribov, A. and Bodansky, E., 2006. Reconstruction of orthogonal polygonal lines. In: H. Bunke and
A.L. Spitz, eds. Document analysis systems VII: proceedings of 7th international workshop, DAS
2006, LNCS 3872, Nelson, New Zealand, 13–15 February 2006. Berlin, Heidelberg: Springer Berlin
Heidelberg, 462–473. doi:10.1007/11669487_41

Haunert, J.H., 2012. A symmetry detector for map generalization and urban-space analysis. ISPRS
Journal of Photogrammetry and Remote Sensing, 74, 66–77. doi:10.1016/j.isprsjprs.2012.08.004
Haunert, J.H. and Wolﬀ, A., 2010. Optimal and topologically safe simpliﬁcation of building foot-
In: D. Agrawal, et al., eds. GIS '10 Proceedings of the 18th SIGSPATIAL international

prints.

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

35

conference on advances in geographic information systems. New York, NY: ACM, 192–201.
doi:10.1145/1869790.1869819

Li, Z., 2006. Algorithmic foundation of multi-scale spatial representation. Boca Raton, FL: CRC Press.

doi:10.1201/9781420008432

Li, Z. and Openshaw, S., 1992. Algorithms for automated line generalization based on a natural
principle of objective generalization. International Journal of Geographical Information Systems, 6
(5), 373–389. doi:10.1080/02693799208901921

Meulemans, W., Van Renssen, A., and Speckmann, B., 2010. Area-preserving subdivision schema-
tization. In: S. I. Fabrikant, et al., eds. Geographic information science: Proceedings of 6th interna-
tional conference, GIScience 2010, LNCS 6292, Zurich, Switzerland, 14–17 September 2010. Berlin,
Heidelberg: Springer Berlin Heidelberg, 160–174. doi:10.1007/978-3-642-15300-6_12

Mustiere, S., 2005. Cartographic generalization of roads in a local and adaptive approach: A
knowledge acquistion problem. International Journal of Geographical Information Science, 19
(8–9), 937–955. doi:10.1080/13658810509161245

Nie, H. and Huang, Z., 2011. A new method of line feature generalization based on shape
characteristic analysis. Metrology and Measurement Systems, XVIII (4), 597–606. doi:10.2478/
v10178-011-0057-5

Pallero, G., 2013. Robust line simpliﬁcation on the plane. Computers & Geosciences, 61, 152–159.

doi:10.1016/j.cageo.2013.08.011

Park, W. and Yu, K., 2011. Hybrid line simpliﬁcation for cartographic generalization. Pattern

Recognition Letters, 32 (9), 1267–1273. doi:10.1016/j.patrec.2011.03.013

Plazanet, C., Aﬀholder, J.G., and Fritsch, E., 1995. The importance of geometric modeling in linear
feature generalization. Cartography and Geographic Information Science, 22 (4), 291–305.
doi:10.1559/152304095782540276

Plazanet, C., Bigolin, N.M., and Ruas, A., 1998. Experiments with learning techniques for spatial
model enrichment and line generalization. GeoInformatica, 2 (4), 315–333. doi:10.1023/
A:1009753320636

Rangayyan, R.M., et al., 2008. Polygonal approximation of contours based on the turning angle

function. Journal of Electronic Imaging, 17 (2), 23016. doi:10.1117/1.2920413

Raposo, P., 2013. Scale-speciﬁc automated line simpliﬁcation by vertex clustering on a hexagonal
tessellation. Cartography and Geographic Information Science, 40 (5), 427–443. doi:10.1080/
15230406.2013.803707

Rosenfeld, A. and Johnston, E., 1973. Angle detection on digital curves.

IEEE Transactions on

Computers, C-22 (9), 875–878. doi:10.1109/TC.1973.5009188

Saga, S.A., 1995. Structural knowledge to support the generalization of a coast line. In: Proceedings

of the 20th international cartographic conference. 1491–1495.

Sester, M., 2005. Optimization approaches for generalization and data abstraction. International
doi:10.1080/

Geographical

Information

871–897.

Science,

(8–9),

19

Journal
of
13658810500161179

Shan, J. and Sampath, A., 2006. Urban terrain and building extraction from airborne LIDAR data. In:
Q. Weng and D.A. Quattrochi, eds. Urban remote sensing. CRC Press, 21–47. doi:10.1201/b15917-
4

Staufenbiel, W., 1973. Zur Automation der Generalisierung topographischer Karten mit besonderer
Berücksichtigung großmaßstäbiger Gebäudedarstellungen. Thesis (PhD). Universität Hannover.

Touya, G., et al., 2014. Modelling geographic relationships in automated environments.

Teh, C.H. and Chin, R.T., 1989. On the detection of dominant points on digital curves.

IEEE
Transactions on Pattern Analysis and Machine Intelligence, 11 (8), 859–872. doi:10.1109/34.31447
In: D.
Burghardt, et al., eds. Abstracting geographic information in a data rich world: methodologies
International Publishing, 53–82.
and applications of map generalisation. Cham: Springer
doi:10.1007/978-3-319-00203-3_3

Touya, G., Duchêne, C., and Ruas, A., 2010. Collaborative generalisation: formalisation of general-
isation knowledge to orchestrate diﬀerent cartographic generalisation processes.
In: S.I.
Fabrikant, et al., eds. Geographic information science: proceedings of 6th international conference,

36

T. E. SAMSONOV AND O. P. YAKIMOVA

GIScience 2010, LNCS 6292, Zurich, Switzerland, 14-17 September 2010. Berlin, Heidelberg:
Springer Berlin Heidelberg, 264–278. doi:10.1007/978-3-642-15300-6_19

Van Goethem, A., et al., 2015. Exploring curved schematization of territorial outlines.

IEEE
Transactions on Visualization and Computer Graphics, 21 (8), 889–902. doi:10.1109/
TVCG.2015.2401025

Visvalingam, M. and Whyatt, J.D., 1993. Line generalisation by repeated elimination of points. The

Cartographic Journal, 30 (1), 46–51. doi:10.1179/caj.1993.30.1.46

Wang, Z. and Müller, J.C., 1998. Line generalization based on analysis of shape characteristics.
Cartography and Geographic Information Science, 25 (1), 3–15. doi:10.1559/152304098782441750
Wang, Z.S. and Muller, J.C., 1993. Complex coastline generalization. Cartography and Geographic

Information Science, 20 (2), 96–106. doi:10.1559/152304093782610333

Weibel, R., 1996. A typology of constraints to line simpliﬁcation. In: M.-J. Kraak, M. Molenaar, and E.
M. Fendel, eds. Proceedings of 7th international symposium on spatial data handling, Delft, The
Netherlands, 12–16 August 1996. London : Taylor & Francis, 533–546.

Zhao, Z. and Saalfeld, A., 1997. Linear-time sleeve-ﬁtting polyline. In: Autocarto 13, ACSM/ASPRS’97

technical papers. Seattle, Washington, 214–223.

