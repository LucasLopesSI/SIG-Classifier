bs_bs_banner

Research Article

Transactions in GIS, 2013, 17(4): 488–506

How Reliable are Citizen-Derived Scientiﬁc Data?
Assessing the Quality of Contrail Observations Made by
the General Public

Amy Fowler, J. Duncan Whyatt, Gemma Davies and Rebecca Ellis

Lancaster Environment Centre, Lancaster University

Abstract
Citizen science projects encourage the general public to participate in scientiﬁc research. Participants can
contribute large volumes of data over broad spatial and temporal frames; however, the challenge is to
generate data of sufﬁcient quality to be useable in scientiﬁc research. Most observations made by citizen-
scientists can be independently veriﬁed by “experts”. However, veriﬁcation is more problematic when the
phenomena being recorded are short-lived. This article uses a GIS methodology to verify the quality of
contrail observations made by the general public as part of the OPAL Climate Survey. We verify observa-
tions using datasets derived from a variety of different sources (experts, models and amateur enthusiasts)
with different spatial and temporal properties which reﬂect the complex 3D nature of the atmosphere.
Our results suggest that ~70% of citizen observations are plausible, based on favorable atmospheric con-
ditions and the presence or absence of aircraft; a ﬁnding which is in keeping with other, more conven-
tional citizen science projects. However, questions remain as to why the quality of the citizen-based
observations was so high. Given the lack of supporting data on observers, it is impossible to determine
whether the dataset was generated by the activities of many participants or a small but dedicated number
of individual observers.

1 Introduction

1.1 Citizen Science

in that participants become “sensors” of

Citizen science projects encourage the general public to participate in scientiﬁc research
(Silvertown 2009). Participants act as voluntary ﬁeld assistants and contribute data beyond the
scope of traditional monitoring schemes. Citizen science complements Volunteered Geographic
Information (VGI)
their local environment
(Goodchild 2007a). However, whilst VGI encourages anyone to contribute geographic data to
collaborations such as Wikimapia (Goodchild 2007b) and OpenStreetMap (Haklay 2010),
citizen science follows a more specialized and organized route to data collection. Currently,
citizen-scientists contribute to a broad range of scientiﬁc research exploring for example, outer
space (Lintott et al. 2008), the biodiversity of plant and animal species (Couvet et al. 2008),
invasive species populations (Delaney et al. 2008) and noise pollution (Maisonneuve et al.
2009).

Address for correspondence: Amy Fowler, Lancaster Environment Centre, Lancaster University, Lancaster, LA1 4YQ, UK. E-mail:
a.fowler1@lancaster.ac.uk
Acknowledgements: This research was funded by a NERC-ESRC Interdisciplinary Studentship (ES/F013116/1). The authors would like to
thank Dr Geoff Jenkins (Met Ofﬁce and Royal Meteorological Society) for supplying the OPAL contrails dataset and guidance on the
research; Dr Gaby Radel (University of Reading) and Dr Richard Forbes (ECMWF) for model outputs to calculate relative humidity with
respect to ice values; Laurent Duval (Radarvirtuel.com) for access to ﬂight path data; Dr Brian Davison (Lancaster University) for
National Contrail Observer Network observations; Dr Andy Horseman, Dr Annette Ryan (both Lancaster University) and Dr Tom Pugh
(Institute of Meteorology and Climate Research/Atmospheric Environmental Research, Karlsruhe Institute of Technology) for assistance
with data processing and Simon Chew (Lancaster University) for the production of Figure 4.

© 2013 John Wiley & Sons Ltd

doi: 10.1111/tgis.12034

How Reliable are Citizen-Derived Scientiﬁc Data?

489

The contribution of “citizen-scientists” is of particular importance to both the scientiﬁc
research community and the participants themselves. Participants provide a solution to the
problem of limited funding and available researchers to collect data (Delaney et al. 2008).
They can generate large volumes of data, over broad spatial scales and for extended time
periods (Engel and Vorshell 2002, Goodchild and Li 2012). Involvement in such projects can
also provide educational and health beneﬁts to participants as well as increasing their under-
standing of the scientiﬁc research process (Trumbull et al. 2000).

However, the challenge is to collect data which is of sufﬁcient quality to be used in scien-
tiﬁc research; that is, data which is considered “ﬁt for use” in, for example, a particular opera-
tion, decision or planning application (Aalders in Shi et al. 2002). This is especially the case
when volunteered geographical information does not comply with spatial data quality stand-
ards (Haklay et al. 2010) and is under constant scrutiny by potential users (see for example:
Root and Alpert 1994). Some citizen science projects have shown evidence of “quality-
assuring” citizen-derived data at multiple stages of the data collection process based on the
nature of the task undertaken by the volunteers (see for example: Engel and Vorshell 2002,
Galloway et al. 2006). Wiggins et al. (2011) argue that the quality of any dataset, including
citizen-derived data, is not determined by a single attribute but through decisions made in the
design of the activity, collection of data and subsequent data processing.

Previously, the quality of citizen-derived data has been assessed at the point of capture, for
example, through the close supervision of participants when mammal trapping (Newman et al.
2003) or through developing projects which meet the needs of potential participants, such as
creating projects in conjunction with educators which engage children (Galloway et al. 2006).
In many instances the quality of citizen-derived data can often be improved by training
(MacDonald and Strachan 1999), through offering ﬁnancial incentives (Barreto et al. 2003) or
the targeted recruitment of participants (Phillips et al. 2006). Veriﬁcation of data quality post
capture is often possible because of the tangible nature of the phenomenon being observed.
“Experts” are able to revisit sites of observation and verify whether citizen-derived results
compare with previous records, for example in vegetation surveys (James 2011) and living
organism monitoring (Darwell and Dulvy 1996). In the context of VGI, the quality of volun-
teer contributions have been assessed through the positional accuracy of the entry, for example
entries made to the OpenStreetMap dataset were compared against existing datasets generated
by the Ordinance Survey (Goodchild, 2007a, Haklay 2010).

1.2 Open Air Laboratories Climate Survey

This article introduces a methodology to assess the quality of citizen-derived observations of
an “intangible phenomena”, that of condensation trails or contrails. These observations were
made under the auspices of the Open Air Laboratories (OPAL) Climate Survey, one of a series
of mass participation citizen science projects coordinated by the OPAL Network. OPAL repre-
sents a collaboration between 15 academic and scientiﬁc institutions, led by Imperial College
London and the Natural History Museum (http://www.opalexplorenature.org/), which enables
scientists and members of the general public to contribute to scientiﬁc research around select
environmental themes (see Davies et al. 2011). The Climate Survey, designed by the UK Met
Ofﬁce and Royal Meteorological Society was launched in March 2011 and comprised of four
activities designed to gain a better understanding of the interactions between human activity
and the climate which cannot easily be assessed using standard scientiﬁc methods; one of these
activities was the observation of aircraft condensation trails or contrails.

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

490

A Fowler, J D Whyatt, G Davies and R Ellis

1.3 Condensation Trails (Contrails)

Contrails are anthropogenic cirrus clouds formed under certain atmospheric conditions when
heat and water vapor emitted from aircraft exhausts mix with cool ambient air (Schumann
2005). They form at different altitudes depending on the latitude of the aircraft, typically
between 26,000 and 40,000 feet in mid-latitudes (Minnis 2002). They can dissipate instantly
or persist in the atmosphere for many hours; their formation is dependent upon atmospheric
variables including ambient pressure, humidity, temperature and the engine parameters of air-
craft (Appleman 1953, Radel and Shine 2010). Contrails will typically form and persist in the
atmosphere as cirrus clouds if the temperature is less than -40°C and relative humidity with
respect to ice (RH(ice)) is greater than 100% (Minnis et al. 2004, Schumann 2005). In condi-
tions of high RH(ice) (>100%) contrails can persist within the atmosphere for many hours and
spread to be several miles wide.

The presence of contrails is of importance for regional and global climate change
(Schumann 2005); dispersed contrails can reduce the amount of short wave-radiation reaching
the Earth’s surface as well as reducing long-wave radiation leaving the Earth’s atmosphere and
entering space. They can induce radiative forcing, warming the Earth’s atmosphere and hence
reducing the diurnal range of the Earth’s surface temperature (Minnis et al. 2004). Travis et al.
(2002) examined the diurnal temperature range over the US for three days following the 11th
September 2001 terrorist attacks when all commercial aircraft were grounded, and noted an
anomalous increase in the average diurnal temperature range which they attributed to the
absence of contrails.

Contrail occurrence has previously been conﬁrmed using both ground-based observations
and satellite imagery. Contrails are detected through satellite imagery based on the physical
properties of the cirrus clouds (Minnis 2002). Satellites provide complete and continuous
spatial coverage and allow contrails to be detected automatically; however algorithms often
confuse dispersed contrails with non-anthropogenic cirrus cloud (Duda et al. 2009). Ground-
based observers, in contrast, are often able to differentiate between different contrail types;
however, observations are by necessity restricted to limited geographic locations and time
periods. For example, a campaign as part of the Global Learning and Observations to Beneﬁt
the Environment (GLOBE) educational program hosted by NASA involving 417 schools
within the US collected observations for 15 months (Duda et al. 2009); similarly, in another
project in the US trained observers at 17 military bases recorded observations for 12 continu-
ous months (Minnis et al. 2003) and at four times daily at four different locations within the
UK for a period of 4–6 months (Radel and Shine 2010).

1.4 Aims and Objectives

In this article we present the results from a critical assessment of the quality of contrail obser-
vations made during the OPAL Climate Survey. Independent veriﬁcation of contrail observa-
tions is problematic due to the ephemeral nature of the atmosphere and transient nature of
contrails. Therefore, we have uniquely developed a methodology which combines Geographi-
cal Information System (GIS) techniques with statistical analysis in order to compare the
citizen-derived contrail observations with four supporting datasets. The properties of these
supporting datasets reﬂect the complex 3D nature of the atmosphere and have been derived
from a variety of different sources (experts, computer models and amateur enthusiasts) with
different spatial, temporal and altitudinal attributes. GIS provides an environment in which

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

How Reliable are Citizen-Derived Scientiﬁc Data?

491

seemingly disparate datasets can be integrated and new information generated to assess the
quality of the citizen-derived observations.

This article will determine the extent to which the citizen-derived observations agree with
contrail observations made by trained meteorological observers. It will also assess whether the
“right” atmospheric conditions existed at the time of observation for contrail formation
(RH(ice) and presence of aircraft). It will also assess the internal consistency of the data and
the extent to which its quality has been inﬂuenced by the complexity of the task (recognizing
different types of contrails). Our approach, which Goodchild and Li (2012) describe as the
“geographic approach” in VGI, involves verifying a phenomenon recorded at a given geo-
graphic location through the use of existing scientiﬁc knowledge.

The structure of this article is as follows: Section 2 introduces the properties of the citizen-
derived data and supporting datasets. Section 3 describes the GIS methodology employed in
the analysis. Section 4 details the results of the analysis, and ﬁnally Section 5 discusses these
results and draws conclusion from this research, as well as considering possible directions for
future research.

2 Data

The following section describes the OPAL contrail dataset and the properties of the four sup-
porting datasets used in the analysis.

2.1 OPAL Contrail Activity

The OPAL contrails dataset is comprised of observations made by OPAL participants. Partici-
pants were encouraged to refer to ﬁve reference photographs (Figure 1) when classifying sky
state (O,A,B,C,D). Observations with associated time (to the nearest 10 minutes); date (DD/
MM) and postcode district (AA1) were recorded using a standardized form. The form allowed
participants to submit data in a consistent manner; observations could be made on any day at
any time and records could be submitted by Freepost, on the OPAL website or by text
message. The postcode district (AA1) was selected as a determiner for location. The OPAL
management team considered a full postcode unit (AA1 2BB) to be too detailed to guarantee
the locational privacy of the individual. Use of the postcode district restricted the spatial accu-
racy of the resulting analysis, because it generalized observations into larger geographic areas.
Furthermore, no data were captured on the demographics of the participants or their levels of
expertise in observing contrails; therefore it was not possible to generate metrics to assess the
quality of data generated by individual observers or assign levels of trust to individual partici-
pants (Goodchild and Li 2012).

The contrails activity ran from 1 February to 30 June 2011 with a total of 15,958 indi-
vidual observations submitted by participants. Initial validation was performed in order to
ensure that all the ﬁelds required for analysis (postcode, date, time, sky state) were complete
for each observation, before the observations were veriﬁed using supporting datasets. Spatial
and temporal ﬁlters were subsequently applied to the complete dataset in order to create a
subset for analysis. Observations were selected that fell within England (geographic range of
OPAL Surveys) for the period 5 March to 27 May 2011 inclusive between 09:00 and 18:00.
This date and time range was chosen to be consistent with the availability of the supporting
datasets. This resulted in a subset of 8,784 records being used in subsequent analysis (Table 1).
Throughout this 84 day period there was a good geographic spread of observations across

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

492

A Fowler, J D Whyatt, G Davies and R Ellis

Figure 1 OPAL contrail reference photographs (source: OPAL Climate Survey Fieldguide).
Sky state denoted by letter (A,B,C,D). Overcast state not shown

Table 1 OPAL observations removed during the ﬁltering process

Reason for removal

Incorrect postcode
Outside England
Outside date range
Outside time range

Observations
removed

Observations
remaining

107
1,175
2,691
3,201

15,851
14,676
11,985
8,784

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

How Reliable are Citizen-Derived Scientiﬁc Data?

493

Figure 2 Frequency of observations by postcode district from the core dataset

England (Figure 2) with minimum of 32, maximum of 228 and mean of 105 observations per
day.

2.2 Supporting Datasets

Given the ephemeral nature of the atmosphere, four different datasets were used to verify the
OPAL observations, each with different spatial, temporal and altitudinal properties. A brief
description of each is provided below.

2.2.1 Photos

OPAL observers were encouraged to take photographs to support
their observations
(Figure 3a). This is the only direct evidence through which to positively verify citizen observa-
tions (complete spatio-temporal agreement). OPAL received 205 photographs of contrails
from 3 March 2011 to 26 April 2011. However, in order to relate the photographs to indi-
vidual observations the participants had to record location by postcode, date, time and sky
state. Only 24 photographs had this supporting information in the subset used in this analysis.

2.2.2 National Contrail Observer Network

The National Contrail Observer Network (NCON) is run by independently trained meteo-
rological observers who make contrail observations alongside standard meteorological

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

494

A Fowler, J D Whyatt, G Davies and R Ellis

Figure 3 Supporting datasets

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

How Reliable are Citizen-Derived Scientiﬁc Data?

495

observations at 0900 GMT daily. However, observations are only made once daily and there
are only ﬁve stations currently active across England (Figure 3b). NCON records of current
sky state are more detailed than those required by OPAL with observers using a standardized
recording card to identify percentage of cloud cover by contrails, number of planes and
number of contrails within observable sky and a description of the contrails present, noting
the number of contrails of each type. NCON observations were subsequently re-coded to cor-
respond with OPAL categories.

2.2.3 Radarvirtuel.com

The Radarvirtuel website (http://www.radarvirtuel.com) provides real-time aircraft locations
with associated altitudes and call signs. Aircraft ﬂight data were automatically captured at one
minute intervals from the website using the cron daemon, assembled into hourly layers and
stored as a comma separated text ﬁles and shapeﬁles (Figure 3c). Real-time location data have
been previously used in academic research to determine the height of speciﬁc aircraft in relation
to other atmospheric properties vital in contrail formation; however, they have not previously
been used to verify citizen-derived observations (see Duda et al. 2004, Stuefer et al. 2005). The
spatial and temporal coverage of the aircraft is variable because the website relies upon enthusi-
asts, who could also be considered “citizen scientists”, who use receivers to track aircraft. Due to
the voluntary nature of the dataset, receivers may be switched off or irregularly distributed geo-
graphically, hence spatial and temporal coverage may be variable. Throughout the 84 day period
used in this analysis, there were typically 700 aircraft per hour at all altitudes (~15% fewer air-
craft at weekends) with no consecutive days with low or limited coverage.

2.2.4 Relative humidity with respect to ice from the European Centre for Medium

Range Weather Forecasting (ECMWF) model

Relative humidity with respect to ice (RH(ice)) data were generated by the ECMWF meteoro-
logical model by Reading University (see acknowledgements) and supplied in NetCDF format.
This multi-dimensional dataset stratiﬁes the atmosphere into 91 vertical levels ranging from
10 m to 75,000 m above sea level. The maximum RH(ice) value at any vertical level within the
atmosphere when the temperature was <-40°C (Figure 3d) was extracted from the ECMWF
model output using Matlab code provided by Reading University to create single gridded sur-
faces for three-hourly time slices. These parameters corresponded with optimum conditions for
contrail formation and persistence reported in the literature. Raster layers were then projected
from Geographic coordinates onto the British National Grid. The model outputs provide com-
plete spatial coverage of England at ~28 x 28 km resolution; however, outputs are only pro-
vided at three-hourly intervals (0900, 1200, 1500).

3 Methodology

The main aim of this article is to assess the quality of the citizen-derived contrail observations
using evidence from the supporting datasets. We therefore developed a methodology using GIS
which enabled the OPAL observations to be analyzed against the supporting datasets based on
their spatial, temporal and altitudinal properties. As the conceptual diagram in Figure 4 illus-
trates, we used GIS to generate a buffer around each OPAL observation. This was then used to
select data from each of the supporting datasets within a given time frame. In order to assess

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

496

A Fowler, J D Whyatt, G Davies and R Ellis

Figure 4 Conceptual diagram illustrating methodological assumptions

the quality of the contrails dataset certain assumptions were made, based on the spatial and
temporal properties of the OPAL observations and supporting datasets.

3.1 Spatial Window

Each OPAL observation was made by a ground-based participant, observing the sky above. In
this analysis instead of considering only the sky view directly overhead, a buffer of ﬁve miles
was applied to each point observation in order to represent the possible ﬁeld of vision of the
observer.

As discussed earlier, each participant could only be located by postcode district (AA1).
This made it impossible to locate the participant with precision and had implications for how
attributes from supporting datasets were related to each OPAL observation. The subset of
OPAL observations contained 542 unique locations, with postcode districts ranging in size
from <1 to >300 square miles, with a mean area of 34 square miles. Given the considerable
variation in geographic area, and lack of information to locate the participant more precisely,
the centroid of the postcode district was used to represent the location of each participant and
a buffer applied accordingly.

In order to make allowances for variations in postcode district area throughout the OPAL
dataset and to capture the majority of each postcode district, a ﬁve mile buffer was applied to
each postcode centroid to capture supporting datasets (see Figure 4). This distance represents a

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

How Reliable are Citizen-Derived Scientiﬁc Data?

497

compromise since observers of contrails in dense urban environments will generally have nar-
rower ﬁelds of vision than those in rural environments: 476 of the 542 OPAL postcodes (88%)
in the core dataset fell completely within the ﬁve mile buffer. A smaller buffer would have
increased the likelihood of failing to capture the full extent of a postcode district, especially in
rural areas; whereas a larger buffer would have increased the likelihood of capturing multiple
postcodes, especially in urban areas.

In order to reduce processing time we used ﬁxed buffers in preference to variable buffers

(in which the size of the buffer would be related to the size of the postcode district).

3.2 Temporal Window

The OPAL observations were grouped into 30 and 60 minute blocks; for example if an obser-
vation was made at 10:20 it would be grouped with observations made between 10:00 and
10:30 at the 30 minute level and 10:00 and 11:00 at the 60 minute level. This decision to
group observations was dictated by the temporal properties of the supporting datasets and the
manner in which they were downloaded and stored. Ideally, contrail observations would only
be compared against atmospheric conditions which had previously occurred and a dynamic
time window computed around each observation to retrieve supplementary data accordingly.
In the absence of information on contrail duration under different sky states we decided to
adopt a common time frame and evaluate all observations in a consistent manner.

Grouping data into 60 minute blocks presents more opportunities to capture points from
the supporting datasets (e.g. aircraft positions within one hour of the OPAL observations).
However, grouping data into 30 minute blocks restricts analysis to supporting data that are
closer in time to the OPAL observations.

3.3 Altitudinal Window

Given the vertical structure of the atmosphere, aircraft were selected from the Radarvirtuel
dataset if they were ﬂying between 26,000 and 40,000 ft (the typical height for contrail forma-
tion, see: Minnis, 2002) within the ﬁve mile buffer of each OPAL observation (see Figure 4).

As stated earlier (Section 2.2.4) a raster surface was generated with the maximum RH(ice)
value at any vertical level, where the temperature was <-40°C. RH(ice) values were extracted
to district postcode centroids.

3.4 Processing

Data analysis was undertaken using Python scripts within ArcGIS 10 (ESRI, 2010). Firstly,
OPAL observations were grouped into three-hourly blocks to coincide with the three-hourly
ECMWF data; a script was written to extract RH(ice) values to postcode district centroids for
each OPAL observation. OPAL observations, NCON and Radarvirtuel points were then
grouped temporally using the assumptions outlined in Section 3.2. A ﬁve mile buffer was then
computed for each OPAL observation and the buffered OPAL observations were spatially
joined with the NCON and Radarvirtuel datasets. An output similar to that shown in Figure 5
was produced for each of the 8,784 OPAL observations. Figure 5 illustrates an OPAL observa-
tion made at postcode CO10 in Suffolk (East Anglia) and shows there is a selection of points
representing aircraft locations between 09:00 and 10:00 which pass through the ﬁve mile
buffer. The ﬁgure also shows that the citizen-based observation taken close to the NCON site
at Cavendish was in agreement with that made by a trained observer.

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

498

A Fowler, J D Whyatt, G Davies and R Ellis

Figure 5 Example output for postcode CO10, Suffolk (11/03/2011 at 0900)

4 Results

In the following section we present the results of our analysis of the OPAL dataset and assess
the quality of the citizen-derived observations. We initially compare the OPAL observations

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

How Reliable are Citizen-Derived Scientiﬁc Data?

499

with each of the supporting datasets in turn, before making a further assessment based on all
supporting datasets in combination. Our analyses explicitly consider the spatial, temporal and
altitudinal properties of the data throughout. Firstly, we compare the OPAL observations
against the photographs taken by participants and observations made by trained meteorologi-
cal observers (NCON).

4.1 Photographs

Only 24 OPAL observations included photographs of contrails in addition to information on
date, time, postcode and sky state. This constitutes only 0.27% of the entire OPAL dataset (n
= 8,748). The sky state of each photograph was determined by the authors using the reference
images shown in Figure 1. Our classiﬁcation was then compared with that given by partici-
pants and was 100% in agreement; however, this assessment of quality is limited to a very
small sample (<1%) of the total OPAL dataset.

4.2 National Contrail Observer Network (NCON)

The OPAL observations were next compared with observations made by trained meteorologi-
cal observers as part of the National Contrail Observer Network, which were made once daily
at 0900 GMT at ﬁve stations in England. In this assessment all 8,784 observations were used,
including overcast. 88 OPAL observations coincided with NCON observations (ﬁve mile
buffer) within a 30 minute window and 91 within a 60 minute window (~1% of the total
dataset). When the sky state given by OPAL participants (O,A,B,C,D) was compared to that
provided by trained observers, there was 84.1% agreement when a 30 minute time window
was adopted and 84.6% agreement when a 60 minute time window was adopted. In both
cases the most disagreement between OPAL and NCON observations occurred with sky state
“C” (long contrails, but not spreading), followed by sky state “A” (no contrails).

The following examples illustrate quality issues between OPAL and NCON observations.
A NCON observer at Hazelrigg, Lancashire at 0900 on 18 March 2011 recorded sky state D
(long-lived spreading contrails). An OPAL observer based in postcode LA1 at 0910 on the
same day recorded sky state A (no contrails). A NCON observer at Carlton in Cleveland,
North Yorkshire at 0900 also on 18 March 2011 recorded sky state D. In contrast, an OPAL
observer based in postcode TS9 at 0900 on the same day recorded sky state C (long contrails,
not spreading). In both instances of disagreement the observations were made at similar times
(within 10 minutes). Disagreement could be a consequence of the spatial inaccuracy of locat-
ing the observer by the centroid of the postcode district. Alternatively it could be the result of
differences in interpretation of the sky state in relation to the images provided by OPAL
(Figure 1). Duda et al. (2009) has similarly reported on the difﬁculties of being able to differ-
entiate between contrails and natural cirrus cloud.

The analysis presented so far illustrates a strong agreement between the OPAL observa-
tions and citizen-generated photographs and those made by trained meteorological observers.
We have conﬁdence in this agreement because of the manner in which the data from the sup-
porting datasets is derived. The photographs represent a direct record of the contrail taken by
the observer whilst the NCON dataset comprises of observations made by trained meteoro-
logical observers. However, both comparisons are based on very small samples (~1%) of the
total OPAL dataset for limited locations and limited times of day.

Therefore, we next compare OPAL observations to the Radarvirtuel dataset and modeled
levels of relative humidity. These datasets provide us with wider spatial and temporal frames

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

500

A Fowler, J D Whyatt, G Davies and R Ellis

with which to assess the quality of the citizen-derived data and additionally provide informa-
tion on height. We initially compare the OPAL observations with the Radarvirtuel dataset and
relative humidity values on an individual basis before combining the two to facilitate a
stronger test of quality.

4.3 Radarvirtuel

In this assessment the OPAL dataset was compared against the Radarvirtuel dataset, which
provided information on the location of aircraft in “real time”. This dataset presents a difﬁ-
culty, however, in that OPAL participants record the presence or absence of contrails whilst
Radarvirtuel provides information on the presence or absence of airplanes. As previously
stated it is possible to observe aircraft in the sky with no contrails present if the atmospheric
conditions are unfavorable for contrail formation. Overcast observations were removed from
the OPAL dataset as it was not possible to use aircraft presence or absence to verify an over-
cast sky state; this resulted in a subset of 6,553 observations being used in the analysis.

The following criteria were used to assess the OPAL observations. If an OPAL observation
coincided with the presence of aircraft and if the sky state was classed as B, C or D we could
be reasonably conﬁdent the OPAL observation was correct (sky states B, C and D require an
aircraft to have formed a contrail); if the sky state was classed as A (no contrails) we could not
be certain that the observation was correct. If the OPAL observation did not coincide with the
presence of aircraft and was classiﬁed B, C or D we could not be conﬁdent the observation
was correct, because the presence of an aircraft is needed to create a contrail; if sky state A
was given then we could be sure this observation was correct.

Using these criteria we compared OPAL observations against Radarvirtuel data using the
30 and 60 minute windows. Using the 60 minute window we found that 59.6% of OPAL
observations matched our criteria. Using the 30 minute window this level of agreement
dropped to 54.1%.

The assumptions made in the analysis of the Radarvirtuel dataset are very crude. There is
a moderate agreement between OPAL observations and the Radarvirtuel data. The agreement
is slightly better under the 60 minute window as this longer time-frame is likely to result in
more Radarvirtuel data falling within our ﬁve mile buffer; however, the smaller window of 30
minutes better reﬂects the short-lived nature of most contrails. There are also limitations in
using the Radarvirtuel dataset due to the “patchy” spatial and temporal coverage of these
data. It is conceivable some OPAL observations with sky state B, C or D were deemed “incor-
rect” because there were no aircraft but could in fact have been “correct” if the Radarvirtuel
website failed to capture all aircraft.

4.4 ECMWF

As previously discussed, contrails will typically form and persist in the atmosphere when the
relative humidity with respect to ice (RH(ice)) >100%. In this analysis we wanted to determine
whether OPAL observations fell within plausible bounds of relative humidity. The quality of
each OPAL observation was determined by comparing the sky state (A-D) with the relative
humidity (RH(ice)) value generated by the ECMWF model. “Overcast” sky states were
removed from the analysis; reducing the OPAL dataset to 6,553 observations. During the time
frame of this analysis modeled values of RH(ice) varied between 8% and 158% where
T<-40°C at any height within the atmosphere. The mean value of RH(ice) was 90% (standard
deviation 28.7).

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

How Reliable are Citizen-Derived Scientiﬁc Data?

501

A sensitivity test was ﬁrst undertaken to determine an appropriate threshold at which to
assess agreement between OPAL observations and RH(ice) values. This was considered neces-
sary since whilst it is known RH(ice) needs to be >100% for contrails to form, model
(ECMWF) uncertainties mean there may be some variance around this value. The sensitivity
test was conducted at 1% intervals between 90% and 110%. In this analysis if sky state A or
B (no contrails, short contrails) was recorded by the participant and the RH(ice) value was
below the threshold value there was considered to be agreement. If sky state C or D (long con-
trails, not spreading and spreading) was recorded by the participant and the RH(ice) value
was above the threshold value of the OPAL observation, there was also considered to be
agreement.

The best agreement between OPAL observations and RH(ice) values occurred at the
100% threshold, and this is consistent with values reported in the literature (Minnis et al.
2004, Schumann 2005). At this threshold 72% of OPAL sky state classiﬁcations (AB,CD) were
deemed correct. The mean value of RH(ice) for categories A, B and D was, as expected, above
or below the 100% threshold (A = 74%, B = 79%, D = 108%). Sky state C, however, proved
more problematic with a mean RH(ice) value of 97% suggesting misclassiﬁcation on the part
of OPAL observers (Figure 6). Sky state C also proved most problematic when OPAL observa-
tions of contrails were compared to those made by trained observers (see Section 4.2).

The correspondence between OPAL observations and model predictions of RH(ice) is also
likely to vary over a given time frame since the RH(ice) data are only available in three hour
time slices. Figure 7 illustrates examples of good and poor agreement between OPAL sky state
and modeled values of RH(ice). Figure 7a shows a time slice of generally low relative humidity
across England (conditions not suitable for contrail formation) and sky states A and B
recorded by OPAL participants. Figure 7b, in contrast, shows highly variable RH(ice) across
England and a much more varied interpretation of the sky states by OPAL participants.

The comparison of the OPAL observations with the Radarvirtuel dataset and relative
humidity values shows lower levels of agreement than between photographs and NCON
observations. However, these data may be utilized over much wider spatial and temporal
frames and additionally provide insights into conditions favorable for contrail formation. To
increase our conﬁdence in the quality of OPAL observations, we now compare them with the
combined conditions of aircraft presence and absence from the Radarvirtuel dataset and levels
of relative humidity from the ECMWF model.

4.5 Radarvirtuel and ECMWF

A combined assessment was made of the OPAL dataset using the Radarvirtuel dataset and
relative humidity values. In the Radarvirtuel only analysis, if an aircraft was present and sky
state recorded as “A”, then we were unsure of the validity of the observation since our analy-
sis did not take atmospheric conditions into consideration (if RH(ice) is <100% then contrails
will not persist). In this analysis, observations were re-examined when sky state “A” was
recorded and aircraft were present. If RH(ice) <100% then observations were considered
“correct”. Under this assumption the level of agreement across all sky states increased to 71%
using the 60 minute window, and 63% using the 30 minute window. This result shows that
when the ECMWF and Radarvirtuel datasets are used in combination there is no signiﬁcant
reduction in agreement at the 60 minute level and at the 30 minute level the agreement is
increased. Our conﬁdence in analysis of data quality improves as a result of using these two
datasets in combination.

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

502

A Fowler, J D Whyatt, G Davies and R Ellis

Figure 6 Variance in relative humidity with respect to ice RH(ice) by sky state

5 Discussion and Conclusions

In this article we have used GIS to critically assess the quality of contrail observations made by
citizen scientists participating in the OPAL Climate Survey. The ephemeral nature of the
atmosphere and the conditions necessary for contrail formation present some inherent chal-
lenges when verifying the citizen observations. Unlike previous citizen science projects in
which “experts” can revisit sites of observation to verify observations, this is not possible with
atmospheric phenomenon. Therefore, a novel methodology was adopted which uniquely
employed GIS techniques and multiple datasets to assess the quality of citizen-derived contrail
observations. This methodology has been advantageous in allowing multiple datasets with dif-
ferent spatial, temporal and altitudinal properties which reﬂect the complex nature of the
atmosphere to be combined within the analysis.

We noted that when citizen observations were compared with the photographs and obser-
vations made by trained meteorological observers there was a strong agreement between the

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

How Reliable are Citizen-Derived Scientiﬁc Data?

503

Figure 7 Comparison between OPAL observations and expected RH(ice) values

datasets (100% between OPAL and photographs and 84.6% and 84.1% between NCON and
OPAL at the 60 and 30 minute level respectively). However, this comparison was drawn
from a very small sample of the total OPAL dataset (~1%) with limited temporal and spatial
coverage.

We found that when combined with other datasets with wider spatial and temporal cover-
age, the quality of observations remained high, with 54–60% of observations coinciding with
the presence or absence of aircraft and 72% with plausible levels of relative humidity in the
upper atmosphere. When OPAL observations were assessed against the Radarvirtuel dataset
and ECMWF data in combination, levels of agreement were similar at the 60 minute level
(71.3%) and increased at the 30 minute level (62.8%). The unique nature of this analysis
means that we are not able to directly compare our results with those from other studies.
However, our results do compare favorably with those of Duda et al. (2009) who noted there
was 75% agreement between contrail observations made by schoolchildren and satellite
images. It is similarly difﬁcult to compare our results with those generated by other citizen
science projects in which tangible environmental phenomenon have been identiﬁed. However,
we are encouraged by the fact that levels of agreement are similar, for example, in a GLOBE
project activity in which school pupils and scientists were asked to identify land cover type the

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

504

A Fowler, J D Whyatt, G Davies and R Ellis

agreement between the two groups was between 60% and 70% (Becker et al. 1998); and in a
project which involved comparing volunteer and professional identiﬁcations of stream micro-
invertebrates the agreement varied between 65% and 96% (Engel and Vorshell 2002).

We also assessed the internal consistency of the data and explored the extent to which the
complexity of the task (sky state classiﬁcation) inﬂuenced the quality of the citizen-based
observations. Sky state C proved the most problematic when assessed using NCON observa-
tions and ECMWF outputs. The reason for this is unknown; it could be the result of partici-
pants confusing sky states C and D and over-reporting sky state D. Previous citizen science
projects have reﬂected on the complexity of the tasks that volunteers have been asked to com-
plete. For example, some volunteers have expressed difﬁculty in identifying speciﬁc organisms
compared to professional scientists (Fore et al. 2001). In these instances appropriate training
was considered an effective means to overcome discrepancies between professional and volun-
teer results (Foster-Smith and Evans 2003). However, participants were closely supervised in
their recording, unlike the contrails activity described in this article.

There are inherent challenges in assessing atmospheric phenomenon due to their ephem-
eral nature. There will always be questions asked about the conﬁdence which can be placed in
the citizen observer when there can never be a return to the site of the observation as atmos-
pheric conditions will have changed. In the assumptions adopted in this methodology, based
on practical decisions for ease of analysis, observations were grouped in 60 and 30 minute
windows based on the time they were made. Ideally, contrail observations would only be com-
pared to previous atmospheric conditions and aircraft locations.

The analysis also presented some more generic problems related to the design and proper-
ties of the contrails activity designed by OPAL. Unfortunately, the decision to include only a
postcode district as an identiﬁer of location restricted the accuracy of the analysis. We were
able to identify where and when each contrail observation was made, but not by whom (see
James 2011). A full postcode would have given us more conﬁdence in observer location and
would have enabled us to use smaller buffers in our analysis. The contrail activity also failed to
capture demographic information about each participant or assign a unique identiﬁer to each
observer. This meant that it was not possible to assess the ability of individual observers to see
if their ability to classify sky state improved over time. This is in contrast to other long-term
citizen science projects which have been able to assess volunteer performance over time and
identify improved observations, for example in marine species (Foster-Smith and Evans 2003)
and invasive plant species recognition (Jordan et al. 2012).

In future analysis the time frame in which the observations were grouped could be
reduced (e.g. to 15 minutes). However, our results suggest that the level of agreement decreases
when shorter time periods are adopted. We would ideally need data on the typical duration of
contrails under different atmospheric conditions to further reﬁne our analysis. There were also
limitations based on the properties of the supporting datasets, for example meteorological data
with a higher temporal resolution could have been used. The analysis could have been devel-
oped further by associating each OPAL observation with the call signs of aircraft logged in the
Radarvirtuel dataset, along with information on aircraft engine parameters and ﬂight destina-
tion. This analysis would be similar to the research conducted by Stuefer et al. (2005) in Fair-
banks, Alaska whereby contrail observations were made and linked directly to aircraft ﬂying
on the FAA radar, and would directly verify each contrail observation.

Overall, this research has demonstrated how GIS has allowed us to extend our quality
assurance of citizen-derived data through comparison with multiple datasets containing
attributes with different spatial, temporal and altitudinal properties. It has also given us the
opportunity to evaluate observations of an intangible phenomenon. Based on our analysis, the

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

How Reliable are Citizen-Derived Scientiﬁc Data?

505

citizens were mostly able to correctly identify the sky state, a ﬁnding echoed by Duda et al.
(2009) and Becker et al. (1998). However, as Goodchild and Li (2012) note, the greatest
number of contributions of volunteered information to a particular dataset are usually made
by a few individuals. We have no way of knowing whether the ~70% agreement achieved in
our analysis is the result of the activities of many participants or the concerted efforts of the
dedicated few.

References

Aalders J G L 2002 The registration of quality in a GIS. In Shi W, Fisher P F, and Goodchild M F (eds) Spatial

Data Quality. London, Taylor and Francis 186–99

Appleman H 1953 The formation of exhaust condensation trails by jet aircraft. Bulletin of American Meteoro-

Barreto C, Fastovsky D, and Sheehan P 2003 A model for integrating the public into scientiﬁc research. Journal

logical Society 34: 14–20

of Geoscience Education 50: 71–75

Becker M L, Congalton R G, Budd R, and Fried A 1998 A GLOBE collaboration to develop land cover data col-

lection and analysis protocols. Journal of Science Education and Technology 7: 85–96

Couvet D, Jiguet F, Julliard R, Levrel H, and Teyssedre A 2008 Enhancing citizen contributions to biodiversity

science and public policy. Interdisciplinary Science Review 33: 95–103

Darwell W and Dulvy N 1996 An evaluation of the suitability of non-specialist volunteer researchers for coral

reef ﬁsh surveys: Maﬁa Island, Tanzania – a case study. Biological Conservation 78: 223–31

Davies L, Bell J N B, Bone J, Head M, Hill L, Howard C, Hobbs S J, Jones D T, Power S A, Rose N, Ryder C,
Seed L, Stevens G, Toumi R, Voulvoulis N, and White P C L 2011 Open Air Laboratories (OPAL): A
community-driven research programme. Environmental Pollution 159: 2203–10

Delaney D, Sperling C, Adams C, and Leung B 2008 Marine invasive species: Validation of citizen science and

implications for national monitoring networks. Biological Invasions 10: 117–128

Duda D P, Minnis P, Nguyen L, and Palikonda R 2004 A case study of the development of contrail clusters over

the Great Lakes. Journal of Atmospheric Science 61: 1132–46

Duda D P, Palikonda R and Minnis P 2009 Relating observations of contrail persistence to numerical weather

analysis output. Atmospheric Chemistry and Physics 9: 1357–64

Engel S R and Vorshell J R 2002 Volunteer biological monitoring: Can it accurately assess the ecological condi-

tion of streams? American Entomologist 48: 164–77

Esri 2010 ArcGIS Version 10. Redlands, CA, Esri
Fore L S, Paulsen K, and O’Laughlin K 2001 Assessing the performance of volunteers in monitoring streams.

Freshwater Biology 46: 109–23

servation 113: 199–213

Foster-Smith J and Evans S M 2003 The value of marine ecological data collected by volunteers. Biological Con-

Haklay M 2010 How good is OpenStreetMap information? A comparative study of OpenStreetMap and Ord-
nance Survey datasets for London and the rest of England. Environment and Planning B 37: 682–703
Haklay M, Basiouka S, Antoniou V, and Ather A 2010 How many volunteers does it take to map an area well?
The validity of Linus’ Law to volunteered geographic information. Cartographic Journal 47: 315–22
Galloway A W E, Tudor M T, and van der Haegen M 2006 The reliability of citizen science: A case study of

Oregon white oak stand surveys. Wildlife Society Bulletin 34: 1425–29

Goodchild M F 2007a Citizens as voluntary sensors: Spatial data infrastructure in the world of Web 2.0. Inter-

national Journal of Spatial Data Infrastructures Research 2: 24–32

Goodchild M F 2007b Citizens as sensors: The world of volunteered geography. Geojournal 69: 211–21
Goodchild M F and Li L 2012 Assuring the quality of volunteered geographic information. Spatial Statistics 1:

110–20

James T 2011 National Biodiversity Network: Improving wildlife data quality. WWW document, http://www.
nbn.org.uk/Tools-Resources/NBN-Publications/Guidance-Documents/NBN-Imp-Wildlife-Data-Quality-
web.aspx

Jordan R C, Brooks W R, Howe D V, and Ehrenfeld J G 2012 Evaluating the performance of volunteers in

public conservation lands. Environmental Management 49: 425–34

Lintott C, Schawinski K, Slosar A, Land K, Bamford S, Thomas T, Raddick M J, Nichol R C, Szalay A,
Andreescu D, Murray P, and van den Berg J 2008 Galaxy Zoo: Morphologies derived from visual inspec-
tion of galaxies from the Sloan Digital Sky Survey. Monthly Notices of the Royal Astronomical Society
389: 1179

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

506

A Fowler, J D Whyatt, G Davies and R Ellis

Macdonald D W and Strachan R 1999 The Mink and the Water Vole. Analyses for Conservation. Oxford, UK,

Wildlife Conservation Research Unit and the Environment Agency

Maisonneuve N, Stevens M, Niessen M E, and Steels L 2009 NoiseTube: Measuring and mapping noise pollu-
tion with mobile phones. In Athanasiadis I N, Mitkas P A, and Rizzoli A E (eds) Information Technologies
in Environmental Engineering. Amsterdam, The Netherlands, IOS Press: 215–28

Minnis P 2002 Contrails. In Holton J, Pyle J, and Curry J (eds) Encyclopedia of Atmospheric Sciences. London,

Minnis P, Ayers J K, Nordeen M L, and Weaver S P 2003 Contrail frequency over the United States from surface

Minnis P, Ayers J K, Palikonda R, and Phan D 2004 Contrails, cirrus trends and climate. Journal of Climate 17:

Academic Press: 509–20

observations. Journal of Climate 16: 3447–62

1671–85

Newman C, Buesching C, and MacDonald D 2003 Validating mammal monitoring methods and assessing the
performance of volunteers in wildlife conservation: “sed quis custodiet ipsos custodies?”. Biological Con-
servation 113: 189–97

Phillips T, Lewenstein B V, and Bonney R 2006 A case study of citizen science. In Cheng D, Metcalfe J, and
Schiele B (eds) At the Human Scale: International Practices in Science Communication. Beijing, China:
Science Press: 317–34

Radel G and Shine K P 2010 Validating ECMWF forecasts for the occurrence of ice supersaturation using visual
observations of persistent contrails and radiosonde measurements over England. Quarterly Journal of the
Royal Meteorological Society 136: 1723–32

Root T and Alpert P 1994 Volunteers and the NBS. Science 4: 120
Schumann U 2005 Formation, properties and climatic effects of contrails. C.R.Physique 6: 549–65
Silvertown J 2009 A new dawn for citizen science. Trends in Ecology and Evolution 24: 467–71
Stuefer M, Meng X, and Wendler G 2005 MM5 Contrail forecasting in Alaska. Monthly Weather Review 133:

Travis D J, Carleton A M, and Lauritsen R G 2002 Climatology: Contrails reduce daily temperature range.

3517–26

Nature 418: 601

Trumbull D, Bonney R, Bascom D, and Cabral A 2000 Thinking scientiﬁcally during participation in a citizen

science project. Science Education 84: 265–75

Wiggins A, Newman G, Stevenson R D, and Crowston K 2011 Mechanisms for data quality and validation in
citizen science. In Proceedings of the Computing for Citizen Science Workshop, Seventh International
IEEE eScience Conference, Stockholm, Sweden: 14–9

© 2013 John Wiley & Sons Ltd

Transactions in GIS, 2013, 17(4)

