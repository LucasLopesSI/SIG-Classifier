International Journal of Geographical Information
Science

ISSN: 1365-8816 (Print) 1362-3087 (Online) Journal homepage: http://www.tandfonline.com/loi/tgis20

Multi-objective spatially constrained clustering for
regionalization with particle swarm optimization

Weixiong He, Haifeng Ling, Zhanliang Zhang & Congcong Gong

To cite this article: Weixiong He, Haifeng Ling, Zhanliang Zhang & Congcong Gong (2017):
Multi-objective spatially constrained clustering for regionalization with particle swarm optimization,
International Journal of Geographical Information Science, DOI: 10.1080/13658816.2017.1418363

To link to this article:  https://doi.org/10.1080/13658816.2017.1418363

Published online: 20 Dec 2017.

Submit your article to this journal 

Article views: 12

View related articles 

View Crossmark data

Full Terms & Conditions of access and use can be found at
http://www.tandfonline.com/action/journalInformation?journalCode=tgis20

Download by: [University of Oregon]

Date: 27 December 2017, At: 05:29

INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE, 2017
https://doi.org/10.1080/13658816.2017.1418363

ARTICLE

Multi-objective spatially constrained clustering for
regionalization with particle swarm optimization

Weixiong He, Haifeng Ling, Zhanliang Zhang and Congcong Gong

Field Engineering College, PLA University of Science and Technology, Nanjing, PR China

ARTICLE HISTORY
Received 9 September 2017
Accepted 13 December 2017

KEYWORDS
Spatial analysis;
regionalization; constrained
clustering; multi-objective
optimization; particle swarm
optimization

ABSTRACT
Regionalization is an important part of the spatial analysis process, and
the solution should be contiguity-constrained in each region. In gen-
eral, several objectives need to be optimized in practical regionaliza-
tion, such as the homogeneity of regions and the heterogeneity
among regions. Therefore, multi-objective techniques are more suita-
ble for solving regionalization problems. In this paper, we design a
multi-objective particle swarm optimization algorithm for solving
regionalization problems. Towards this goal, a novel particle represen-
tation for regionalization is proposed, which can be expressed in
continuous space and has ﬂexible constraints on the number of
regions. In the process of optimization, a contiguous-region method
is designed that satisﬁes the constraints and improves the eﬃciency.
The decision solution is selected in the Pareto set based on a trade-oﬀ
between the objective functions, and the number of regions can be
automatically determined. The proposed method outperforms six
regionalization algorithms in terms of both the number and the quality
of the solutions.

Introduction

Region building (Kolars 1977) has been one of the most important techniques in
exploratory spatial analysis for a long time. For most researchers, regionalization can
help discover patterns in spatial data sets and generate useful hypotheses. Generally,
regionalization is a form of classiﬁcation in which a large set of spatial objects is divided
into contiguous regions based on a set of deﬁned homogeneity criteria (Christina and
Komathy 2013). Regionalization approaches have been widely used in many disciplines,
including environmental science (Sadri and Burn 2011, Adams et al. 2016), ecology
(Cheruvelil and Bremigan 2013) and economics (Niesterowicz et al. 2016).

In general, regionalization is considered a spatially constrained clustering problem,
because the purpose of clustering is to partition an unlabelled data set into groups of
similar objects (Esmin et al. 2015). However, a key challenge of regionalization,
compared with general clustering problems,
require
embedded spatial adjacency constraints (Kim et al. 2015). Two regionalization strate-
gies are proposed to address this problem: in one strategy, the conventional cluster-
ing method is used to obtain the original solutions. Then, the regionalization solution

solutions

spatial

that

is

CONTACT Haifeng Ling
© 2017 Informa UK Limited, trading as Taylor & Francis Group

hf.ling@ymail.com

Downloaded by [University of Oregon] at 05:29 27 December 2017 2

W. HE ET AL.

is generated from the original solutions by selection or modiﬁcation, such as by k-
means (Wise et al. 1997), hierarchical clustering (Darand and Daneshvar 2014) or
spectral clustering (Yuan et al. 2015).
In the other strategy, the spatial constraints
are considered in the clustering process, such as Automated Zoning Procedure (AZP;
Openshaw and Rao 1995), Spatial Kluster Analysis by Tree Edge Removal (SKATER;
Neves 2006) or Dynamically Constrained Agglomerative clustering and Partitioning
(REDCAP; Guo 2008, Guo and Wang 2011).

However, the methods in previous studies have two main limitations: First, the objective
function lacks ﬂexibility and multi-objective optimization is not supported. For those
methods, only one ﬁxed objective function, namely, the homogeneity measure of regions,
is used for optimization. However, multiple objective conditions should be considered to
obtain a better solution in most cases. For regionalization problems, it is more reasonable to
optimize two objectives simultaneously: the homogeneity of regions and the heterogeneity
among regions. The second limitation is that the proper number of regions needs to be
speciﬁed in advance for those methods. However, the number of regions is diﬃcult to
determine in practice. In most cases, we can only estimate a range of region quantity.

To address the limitations of previous work, the multi-objective method is introduced
into the regionalization ﬁeld. Better solutions can be obtained by using multi-objective
optimization method, and the number of regions can be automatically determined by
balancing all objectives (Abubaker et al. 2015). Diﬀerent from single-objective optimization
problems, multi-objective optimization problems have a series of solutions instead of one.
These solutions are called the Pareto-optimal solution set and are regarded as equally good.
Generally, particle swarm optimization (PSO), which is a heuristic algorithm that is inspired
by the behaviour of bird ﬂocking, is well-suited for multi-objective problems, because the
Pareto-optimal solution set can be estimated roughly in a single algorithm run using the
concept of population (Garcia-Piquer et al. 2015). Coello and Lechuga (2002) proposed the
multi-objective optimization algorithm based on PSO (MOPSO). Since then, several PSO-based
multi-objective approaches for improving the diversity of particles and enhancing the accu-
racy of the Pareto-optimal solutions have been proposed, such as Micro-MOPSO (Cabrera and
Coello 2010), BB-MOPSO (Zhang et al. 2012), HMPSOFS (Zhang et al. 2017) and MOPSO/GMR (Li
et al. 2017). However, it is diﬃcult to use the existing methods on multi-objective regionaliza-
tion directly, because regionalization is a combinatorial problem with a continuity constraint.
The purpose of this paper is to propose an implementation of multi-objective regiona-
lization based on particle swarm optimization (MRPSO). To utilize PSO to solve regionaliza-
tion problems better and more ﬂexibly, we make four contributions in this paper:

● A novel particle representation for regionalization is designed, which more ﬂexibly
speciﬁes the number of regions and helps PSO search the solutions in continuous
space.

● Two conﬂicting objective functions are introduced, namely, the homogeneity of

regions and the heterogeneity among regions.

● A contiguous-region method in PSO that satisﬁes the contiguity constraint and
increases the eﬃciency greatly in searching for the regionalization solution is
explored.

● This approach can automatically determine the appropriate number of regions by

trading oﬀ between the conﬂicting objective functions.

Downloaded by [University of Oregon] at 05:29 27 December 2017 INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

3

The remainder of this paper is organized as follows. The following section brieﬂy
describes the background regarding regionalization and multi-objective PSO.
In
‘Proposed method’ section, we describe our MRPSO approach in detail.
‘Experiments
and discussion’ section presents a comprehensive set of experimental results. The ﬁnal
section presents our conclusions.

Background

Regionalization

There are three major data types for constructing regions: lattice data (Cressie 1992),
interaction data and point pattern data (Guo and Wang 2011). We primarily
spatial
consider regionalization with lattice data, because lattice data are widely used in various
disciplines. In general, each spatial object in a lattice data set has an attribute vector,
such as a census data set with a birth rate for each city.

The regionalization problem with lattice data is deﬁned as follows: consider all the spatial
objects S = {s1, s2, . . ., sn}, where si = (si1, si2, . . ., sid) is a d-dimensional attribute vector, sij is the
attribute value of spatial object i on attribute j and n is the number of spatial objects in S. The
regionalization of S is the partitioning of S into k regions {G1, G2, . . ., Gk} with the following
i¼1
Gi ¼ S, (2) Gi\Gj (cid:1) ∅ such that i; j 2 1; 2; (cid:2) (cid:2) (cid:2) ; k
properties: (1) n
is
k
spatially contiguous for i 2 1; 2; (cid:2) (cid:2) (cid:2) ; k

g and i(cid:1)j, (3) Gi

g.

f

f

In general, regionalization can be regarded as a kind of clustering problem with the
constraint that all spatial objects in each region are spatially contiguous. In recent years,
many clustering methods have been proposed with the development of machine learning.
However, the spatial contiguity constraint is still one of the most challenging issues in
regionalization. In the early years, the AZP was proposed by Openshaw and Rao (1995),
which starts with an initial random regionalization and obtains better solutions by assigning
the spatial objects to neighbouring regions iteratively. However, with the AZP method, it is
easy to fall into a local optimum and the computational cost is high. The SKATER method
was proposed by Neves (2006), which is based on minimum spanning trees and constructs a
spatially contiguous solution by removing edges. Based on the SKATER method, the
REDCAP algorithm family was proposed by Guo (2008) and Guo and Wang (2011). It uses
diﬀerent agglomerative clustering methods to generate the minimum spanning tree, and
two kinds of restriction strategies are designed.

Multi-objective PSO

The PSO algorithm was proposed by Eberhart and Kennedy (1995). It has been recog-
nized an eﬃcient method for searching for approximate optimal solutions due to its
simplicity and eﬃciency (Poli et al. 2007). The PSO algorithm was inspired by bird
foraging and relies on simple velocity update rules to make particles move. In the PSO
algorithm, each particle represents a potential solution, and the particles achieve global
optimization by moving in D-dimensional search space. The velocity vi and the position
xi of particle i are updated as follows:

vi t þ 1

ð

Þ ¼ w (cid:2) vi tð Þ þ c1r1 pBesti (cid:3) xi

ð

Þ þ c2r2 gBest (cid:3) xi

ð

Þ

(1)

Downloaded by [University of Oregon] at 05:29 27 December 2017 4

W. HE ET AL.

xi t þ 1

ð

Þ ¼ xi tð Þ þ vi t þ 1

ð

Þ

(2)

where vi ¼ vi1; vi2; . . . ; viD
Þ is the velocity of particle i; t represents the generation
ð
number; w is the inertial weight factor; xi ¼ xi1; xi2; . . . ; xiD
Þ is the position of the ith
particle; c1andc2 are local and global learning factors, respectively; r1andr2 are ran-
dom numbers between [0, 1]; pBesti stands for the previous best position for particle
i; and gBest stands for the global best position. The particle position is updated by
Equation (2).

ð

To use the PSO optimizer to solve multi-objective problems, we adopt the concept
of Pareto optimality, which is usually used to maintain the set of feasible solutions in
multi-objective problems (Kasprzak and Lewis 2001). Diﬀerent solutions may optimize
one of the objective functions, but cannot optimize all objective functions simulta-
neously. As a result, it is diﬃcult to evaluate the quality of a set of solutions. Pareto
optimality was proposed to address this problem. Given two vectors x; y 2 Rk,
x dominates y if xi (cid:4) yi for i = 1,
. . ., k; otherwise, x is non-dominated by y. A
vector is Pareto-optimal if it is non-dominated with respect to F (F is the feasible
region), and the Pareto Set P(cid:5) ¼ x 2 F jx isPareto (cid:3) optimal

g.

f

In single-objective PSO, pBest and gBest can be determined simply and uniquely.
However, the multi-objective PSO algorithm will produce a set of non-dominated
solutions, which are equally good mathematically. For this reason, the selection of
pBest and gBest is diﬃcult. In general, the updating of pBest is relatively simple, in
which the position of the current particle and previous best position are compared and
the non-dominated one is chosen as pBest. If they do not dominate each other, then
one is selected randomly.

Selecting gBest is more complicated than selecting pBest, and the main selection
strategies can be divided into two categories: (1) Stochastic selection in the Pareto
set (Coello and Lechuga 2002) is very simple and achieves satisfactory results in most
it tends to increase the selection probability in regions where
cases. However,
particles are concentrated, and reduces
(2)
Selection based on crowding distance (Raquel and Naval 2005, Dai et al. 2015)
calculates the crowding distance as shown in Figure 1. The crowding distance of
particle pi
is the size of the largest cuboid that encloses pi without including any
other particle. Then, a particle with maximum distance is selected as gBest. This
approach tends to generate a well-distributed set of non-dominated solutions. For
this reason, the crowding distance strategy will be used in this paper to choose the
gBest particle.

the diversity of

the population.

Proposed method

In this section, the MRPSO method is described in detail. MRPSO consists of three main
parts: objective functions, optimization and decision-making. First, to obtain a reason-
able solution and determine the appropriate number of regions automatically, two
conﬂicting objective functions are deﬁned. Second, we illustrate the process of optimi-
zation from two aspects: particle representation and the contiguous-region method.
Finally, the most suitable solution in the Pareto set is selected by utilizing a decision-
making technique.

Downloaded by [University of Oregon] at 05:29 27 December 2017 INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

5

pi-1

f2

cuboid 

pi

pi+1

f1

Figure 1. Calculation of crowding distance.

Objective functions

In general, a multi-objective optimization algorithm can optimize several objective func-
tions simultaneously to obtain an optimal result. Therefore, we choose two conﬂicting
objectives to optimize: the homogeneity of regions and the heterogeneity among regions.
The two objective functions are not only the criteria for measuring the quality of the
partitioning but also reﬂect the diﬀerent tendencies of the number of regions. In the case
of an uncertain number of regions, the homogeneity measure tends to increase the region
quantity, whereas the heterogeneity measure tends to reduce it. Together, they form a
dynamic balance, which plays an important role in obtaining a suitable number of regions.

Homogeneity measure

To measure the homogeneity of regions in a regionalization solution, the overall devia-
tion (Dev) is introduced. The formula is as follows:

Dev Gð Þ ¼

X

X

Gk2G

i2Gk

δ i; μ
ð

Þ

k

(3)

where G is the collection of all regions in the solution, Gk is the kth region, i is the ith
spatial object in region Gk, δ :; :ð
Þ is the dissimilarity function (e.g. the Euclidean distance
between attribute vectors) and μ
k is the median attribute value of all spatial objects in
region Gk. As the homogeneity measure in regions, the smaller the value of Dev, the
greater the similarity of the spatial objects in each region. In extreme cases, each spatial
object becomes a region. Then, Dev = 0 and the number of regions reaches the
maximum. As an objective, the overall deviation should be minimized.

Heterogeneity measure

Optimizing the single objective function, Dev would increase the number of regions and
reduce the heterogeneity among regions. To prevent this, another objective function is
introduced: mean boundary diﬀerence (Mbd). The formula is as follows:

Downloaded by [University of Oregon] at 05:29 27 December 2017 6

W. HE ET AL.

Mbd Gð Þ ¼

min
i2Gk; j2Ni; j‚Gk;

δ i; jð

Þ

(cid:2)

X

1
Gj

j

Gk2G

(cid:3)

(4)

where |G| is the number of regions in the solution, Ni is the neighbour set of spatial
object i, j is the spatial object in the neighbour set and δ :; :ð
Þ is the dissimilarity function.
The diﬀerence between one region and another is represented by the dissimilarity of
If there are multiple contiguous regions, the minimum
boundary-adjacent objects.
dissimilarity is used. As an index for measuring the heterogeneity, a larger value of
Mbd leads to a better solution and tends to reduce the number of regions. To minimize
this objective simultaneously with Dev, this objective should be negated (−Mbd).

These two objective functions are recommended in this paper, but they are not ﬁxed.
Other objective functions can be used if necessary. The objective functions should be
conﬂicting, because non-conﬂicting objectives can always be combined into a single
objective. In addition, conﬂicting objective functions can obtain an appropriate number
of regions and more reasonable solutions.

Particle representation for regionalization

In PSO, each particle represents a partitioning scheme for all spatial objects; this is called
particle representation. The particle representation is important for the algorithm eﬃ-
ciency, because the optimizer searches the representation space directly. For the PSO
technique, this representation is suitable for ﬁnding solutions in continuous non-linear
optimization problems (Rao and Lakshmi 2012). However, regionalization problems are
combinatorial and discrete. Therefore, a novel particle representation for regionalization
problems is designed in this paper.

For the regionalization problem of n spatial objects, each particle is represented by an
(n + 1)-dimensional vector. The ﬁrst n dimensions in the particle vector are the position
values, and the range is (0,1]. The additional dimension dn + 1 is used to represent the
number of regions k. The value of dn + 1 lies in the interval (kmin−1,kmax], where kmin and
kmax represent the minimum number of regions and the maximum number of regions,
respectively, and kmin (cid:6) 2. Under this particle representation, the conversion of the
particle into a regionalization solution of n spatial objects is resolved as follows:

l

m

G ¼ dnþ1 (cid:2) d1; d2; (cid:2) (cid:2) (cid:2) dn
½

(cid:7)T

(5)

where G is an n-dimensional integer vector of a regionalization solution, and each
value in the vector determines the region to which the corresponding spatial object
belongs.
(cid:2)d e is the ceiling function for each object in the vector. As a result, the spatial
objects with same value in G belong to the same region. A description of the particle
representation is shown in Figure 2.

The particle representation has several major advantages for our application: most
importantly, the number of regions is ﬂexible in practice. When the number of regions is
uncertain, the range (kmin−1,kmax] can be wide. However, the range should be narrowed
to improve performance, or a single value can be used in some cases. Furthermore, it
can take full advantage of PSO in continuous space.

Downloaded by [University of Oregon] at 05:29 27 December 2017 INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

7

2

6

1

3

4

7

5

8

region 1
region 2
region 3

2

6

1

3

4

7

5

8

particle represent

position

value

1

2

3

4

5

6

7

8

k

0.80

0.73

0.71

0.18

0.12

0.26

0.58

0.44

3.4

position

k value

Round up

1

3

2.71

2.49

2.45

0.60

0.42

0.87

1.97

1.49

2

3

3

3

4

1

5

1

6

1

7

2

8

2

Figure 2. Particle representation for the regionalization problem. First, there are eight spatial objects
to be partitioned, and the particle is a nine-dimensional vector. Second, the position values are
multiplied by k and rounded up to determine the regions to which the objects belong. Finally, the
regionalization according to the particle representation is shown.

Contiguous-region method

As already discussed, PSO methods search for feasible solutions by iterating particle velocity,
which makes it possible to ﬁnd a global or near-optimal solution (Kim et al. 2016). However,
two problems will be encountered if the PSO algorithm is used directly. First, if the spatial
continuity constraint is added to the PSO framework in advance, it will greatly limit the search
range of PSO and increase the diﬃculty of obtaining feasible solutions. Second, with the
increase of the size of the data set, the PSO algorithm will suﬀer from combinatorial explosion,
and its global search ability and convergence performance will deteriorate signiﬁcantly.

For the ﬁrst problem, a general strategy is to relax the constraints in the search
process of PSO, and then address the results (Ling et al. 2011). PSO will ﬁnd some ‘good
in the case of relaxed constraints, but those solutions will have diﬃculty
solutions’
meeting the requirements of spatial continuity. Hence, we should modify the ‘good
solutions’ to satisfy the spatial continuity requirements while maintaining the original
partition as much as possible.

For the latter problem, the main reason for combinatorial explosion is that the PSO
optimizer does not use any prior information about regionalization. For most regiona-
lization problems, the probability of assignment to same region is higher when the
spatial objects are more similar. This property of regionalization can be used to ﬁnd the
optimal solution more easily.

In this paper, the contiguous-region method is designed in consideration of these two
factors. To improve the eﬃciency of this technology, the dissimilarity matrix D (also called the
distance matrix) of all spatial objects is calculated in advance, where element dij
in D
represents the dissimilarity between spatial objects i and j. The steps are as follows:

Step 1: The topological centre of each region is determined. The concept of the
topological centre is inspired by degree centrality in graph theory, which is deﬁned as
the number of links that are incident upon a node (Newman 2010). Similarly, the

Downloaded by [University of Oregon] at 05:29 27 December 2017 8

W. HE ET AL.

(a)

(c)

(e)

(b)

(d)

(f)

Figure 3. Process of the contiguous-region method. (a) The original solution is generated by PSO. (b)
Topological centres are found in each region. (c) The dissimilarities between the adjacent objects of
region and the topological centres are calculated. (d,e) The most similar object to topological centre
is added to the corresponding region. (f) The solution with the adjacency constraint is generated
using the contiguous-region method.

topological centre of a region is the spatial object that has the most adjacent objects in
the region. For example, the three objects in the dashed circles are the topological
centres of the three regions in Figure 3(b).

Step 2: The k topological centres are preserved, and all other spatial objects are
Initially, there are k regions, each of which
partitioned according to those centres.
contains one topological centre. A series of nested merging operations are performed
until all the spatial objects have been partitioned into the k regions. In the merging
process, we obtain the dissimilarity between each adjacent object and the correspond-
ing region in dissimilarity matrix D, as shown in Figure 3(c). Then, we compare all the
adjacent objects and ﬁnd the most similar object. Subsequently, this object is added to
the corresponding region, as shown in Figure 3(d,e).

There are two feasible strategies for calculating the dissimilarity between a spatial
object and the adjacent region: one is to use the dissimilarity between the object and
the adjacent objects in the region, and the other is to obtain the dissimilarity between
the object and the topological centre of the region. In this paper, the second way is used
because it avoids the ‘chaining’ problem (Hastie et al. 2009).

Downloaded by [University of Oregon] at 05:29 27 December 2017 INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

9

Figure 4. Example application of the contiguous-region method. (a) The spatial object distribution
before the contiguous-region method has been applied. (b) The object distribution after contiguous-
region method has been applied.

An example application of the contiguous-region method is shown in Figure 4. The
example shows that the method can be used to generate solutions with the adjacency
constraint, while preserving the original distribution as much as possible. In the actual
search process, a rough partitioning of the regionalization problem is obtained by PSO
ﬁrst. Then, the contiguous-region method is used to obtain a spatially constrained and
reasonable partition based on the rough solution. The improved solutions will help PSO
obtain a better partition in the updating of particles.

The computational complexity of the contiguous-region method is determined by the
number of adjacent elements.
In the best case, every spatial object has only two
neighbours, and the merging process only requires a comparison of each object with
one other object. Thus, its computational complexity is O (N). In the worst case, each
spatial object is adjacent to all other objects, and each iteration needs to compare each
its computational complexity is O (N2).
object with all other objects.
Therefore, the theoretical complexity of the contiguous-region method is between O
(N) and O (N2). For most practical problems, the number of neighbours of each spatial
object is relatively small and can be considered constant. In this case, the computational
complexity of the method is reduced to O (N).

In this case,

Decision-making

Generally, decision-making is an important issue when faced with a huge set of Pareto-
optimal solutions. Each Pareto-optimal solution performs well on one objective function
and has a degraded performance on the other objective function. Therefore, a decision
maker needs to establish a trade-oﬀ between the objective functions to select the most
appropriate solution.
In this paper, a distance-based method is used to select the
decision solution.

For all Pareto-optimal solutions, the virtual point at which each objective function
attains its best value is called the utopia point (Armano and Farmani 2016). The closest
solution to the utopia point is selected as the decision solution. The selection of a
decision solution by this method is illustrated in Figure 5.

Downloaded by [University of Oregon] at 05:29 27 December 2017 10

W. HE ET AL.

decision solution

f2

Utopia point

f1

Figure 5. Distance-based method for ﬁnding the decision solution.

Calculate  the  dissimilarity  matrix and  the  adjacency matrix of all spatial objects. Let 
NonDom be the repositioned Pareto non-dominated set.
Step 1: Initialization.
(cid:2) Initialize  swarm randomly, including  position and  velocity  of  particles (using 

particle representation in section 3.2).

(cid:2) Make the initial particles spatially contiguous (using method in section 3.3)
Step 2: Evaluate objective functions for each  particle in swarm (using functions in section 
3.1).
Step 3: Update NonDom set: 
(cid:2) For each  particle in  swarm, if  particle  dominates any  element in  NonDom, then 
elements that  are  dominated by  particle, and add  particle  into 

Step 4: Update process of particles:
(cid:2) Update pBest, select gBest in NonDom using crowding distance, and update  particle 

(cid:2) For each particle in swarm, make the solution of particle spatially contiguous. Then,
evaluate objective functions for particle (using method in section 3.3 and 3.1).

(cid:2) Update NonDom set.
Step 5: Repeat Step 4 until reaching the specified number of iterations.
Step 6: Select decision solution in NonDom (using method in section 3.4).

delete all the 
NonDom.

by Eq. (2).

Overall: O(TMN)~ O(TMN2)
N: the number of 
spatial 
objects
M: the number of particles
T:  the  specified number of 
iterations

Step 1: O(MN)~O(MN2)
Step 2: O(MN)
Step 3: O(N)
Step 4: O(MN) ~O(MN2)
Step 5: O(TMN)~O(TMN2)
Step 6: O(N)

Figure 6. The procedure and theoretical complexity of MRPSO algorithm. The left block is the
pseudocode of MRPSO, and the right block is the complexity analysis.

The MRPSO algorithm is presented in Figure 6. As described in ‘Heterogeneity
measure’ section, the complexity of the algorithm is related to the number of neigh-
bours of each spatial element. Its theoretical complexity is between O (TMN) and O
(TMN2), where T is the number of iterations, M is the number of particles and N is the
number of spatial objects. Fortunately, T and M are the parameters of the algorithm and
can be manually controlled, and the scale of the problem is only related to N. Thus, the
theoretical complexity of MRPSO is between O (N) and O (N2) when T and M are set.

In practice, the computational complexity of MRPSO is closer to O (TMN) due to the
limited number of neighbours. To verify the correctness, we use the artiﬁcial spatial data
set for an experiment. The artiﬁcial data set is shown in Figure 7(a), where each grid is a
spatial object with a random attribute value and is adjacent to the eight nearest grids.
Therefore, we can change the size of the data set on which we run the MRPSO. In the

Downloaded by [University of Oregon] at 05:29 27 December 2017 INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

11

)
s
(
e
m
T

i

1000.0

900.0

800.0

700.0

600.0

500.0

400.0

300.0

200.0

100.0

0.0

(a)

N
(b)

Figure 7. Experiments on computational complexity of MRPSO. (a) The artiﬁcial data set. (b) The
computation time of MRPSO with the change of N. (The experiments are run on MATLAB R2014a,
with Windows 7 sp3, Core i5 (2.4 GHz) and 8 GB RAM.)

experiment, M = 20 and T = 200. With the increase of the number of spatial objects, the
mean computation time on 20 independent runs is shown in Figure 7(b). From the
experimental results, the computation time increases approximately linearly.

Experiments and discussion

This section evaluates the performance of the proposed method. First, three real-world
data sets with counties of China as spatial objects are analysed. Then, the baseline
methods and measurement indicators are introduced. Finally, the performance and
algorithmic eﬃciency of the MRPSO are compared with baseline methods on all three
real-world data sets, and the results are discussed in detail. The above experiments are
run on MATLAB R2014a, with Windows 7 sp3, Core i5 (2.4 GHz) and 8 GB RAM.

Data sets

The spatial units that are used in the experiments are the counties of mainland China
(excluding the two islands of Hainan and Taiwan). Three real-world data sets, which were
collected from yearbooks of CNKI (http://nianjian.cnki.net/), are used to test our method,
including disposable income per capita, architectural area per capita and inbound
tourism. Summary statistics of the data sets are shown in Table 1.

All the data sets are complex and unbalanced, and the gap between the maximum
and the minimum is huge. Therefore, a reasonable partitioning is important for

Table 1. Summary statistics of the data sets.

#
Region
units

Study
area

Data source

Maximum

Minimum

Disposable income per capita China
China
Architectural area per capita
China
Inbound tourism

382
382
382

48,841 RMB
62.5 m2
259,907 (thousand persons/time)

12,616 RMB
0.47 m2
52 (thousand persons/time)

Downloaded by [University of Oregon] at 05:29 27 December 2017 12

W. HE ET AL.

government applications. The data sets present population and economic development
distributions that are very irregular, with most of the population and high economic
growth concentrated in a few units. For example, the inbound tourism data set is shown
in Figure 9(a).

Each data set is preprocessed before applying the constrained clustering algorithms,
including calculation of the adjacency matrix and the dissimilarity matrix of all the
spatial objects.

Baseline methods

Two kinds of baseline methods are used for comparison with the MRPSO method: the
SKATER algorithm and the REDCAP algorithm family. In this section, we implement the
SKATER algorithm and ﬁve algorithms of REDCAP in MATLAB R2014a.

SKATER is a good regionalization method, which is based on minimum spanning
trees. First, the number of regions is speciﬁed in advance. Second, a connectivity graph
that reﬂects the neighbourhood relations is constructed and a minimum spanning tree is
build. Finally, the tree is partitioned by recursively removing edges until a speciﬁed
number of regions are generated.

REDCAP is an algorithm family of regionalization methods. First, a spatially contig-
uous tree is produced by hierarchical clustering approaches. Then, the edges of the
spatially contiguous tree are removed to generate regions. There are three kinds of
hierarchical clustering strategies: complete linkage (CLK), average linkage (ALK) and
single linkage (SLK). For each clustering strategy, two diﬀerent spatial contiguity con-
straints can be applied: ﬁrst-order constraints and full-order constraints. In the experi-
mental section, we use the First-Order CLK, First-Order ALK, Full-Order SLK, Full-Order
CLK and Full-Order ALK algorithms for comparison.

Evaluation metrics

For the multi-objective optimization problem, a set of non-dominated solutions can be
obtained by applying the theory of Pareto optimality. Two evaluation metrics are used
for the multi-objective solutions (Li et al. 2016): the positions of the non-dominated
solutions and the number of non-dominated solutions.

For the positions of the non-dominated solutions, it is better for the solutions to be
closer to the lower-left corner in the coordinate axis, since the two objective functions
need to be minimized. In addition, better solutions have a wider range due to the
diversity of solutions. As a result, the position has an important inﬂuence on the quality
of the solutions. In addition, a larger number of solutions are better. In this paper, these
two metrics are used to evaluate the multi-objective solutions.

Experimental set-up and results

This section presents the results of applying various constrained clustering algorithms to
the real-world data sets. First, the baseline methods are run nine times on each data set
for comparison, and the number of regions k is diﬀerent for each run, such as k = 2,

Downloaded by [University of Oregon] at 05:29 27 December 2017 INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

13

k = 3, . . ., k = 10. This is because MRPSO can obtain a series of solutions in a single run,
while the baseline methods can only obtain one solution with a speciﬁed value of k.

Second, MRPSO is a heuristic approach, and the result of each run is not exactly the
same. To evaluate the stability of the decision solution, we mainly focus on the
Coeﬃcient of Variance (CV):

CV ¼ σ=μ

(6)

where σ is the standard deviation and μ is the average value. The greater the absolute
value of CV, the worse the stability. MRPSO is run 21 times on each data set, and the
statistical results of the decision solution are shown in Table 2. In summary, the CV value
remains at a low level, thereby indicating that the decision solution of MRPSO is stable.
Thus, we take the median value as the representative solution, according to the number
of solutions. In our implementation, we adopt the parameter w = 0.85, c1 = c2 = 0.7,
itermax = 1000, Np = 20, kmin = 2 and kmax = 10.

Positions of the solutions

We ﬁrst compare the distributions of solutions that are generated by diﬀerent methods on
all data sets, and both objective functions need to be minimized. In the upper-left and
middle parts of the coordinate axis, the solution positions of MRPSO are signiﬁcantly better
than those of other algorithms on all objective functions. Most importantly, the solution
positions of MRPSO are better in the ‘knee’ section (Matake et al. 2007), which is where the
most suitable solution may exist (Tibshirani et al. 2001). A few of the points that were
obtained by MRPSO are inferior to those of the other algorithms in the lower-right corner of
the coordinate axis; the reason for this will be analysed in the discussion section.

The statistical ranges of the non-dominated solutions that are obtained by all methods are
shown in Table 3, and the best results are shown in bold. Each range is calculated as the
diﬀerence between the maximum and minimum values of the solutions in the objective
functions. For the Dev objective function, MRPSO performs the best on data set #1. On data sets
#2 and #3, the Full-Order-ALK algorithm has the widest range, but MRPSO is very close to it. For

Table 2. Statistical results of the decision solution using MRPSO (over 21 independent runs).
Data set
#1

Objective function

σ

μ

#2

#3

Overall deviation
Mean boundary diﬀerence
Overall deviation
Mean boundary diﬀerence
Overall deviation
Mean boundary diﬀerence

3054.87
−10,719.46
3.579
−10.944
1271.19
−16,840.11

131.77
506.84
0.174
0.793
37.05
1920.47

CV

0.043
−0.047
0.048
−0.072
0.029
−0.114

Objective function

Table 3. Statistical ranges of non-dominated solutions obtained by all methods.
Full-ALK
Data set
5241
#1
1536
1.65
8.01
585.4
7209

Overall deviation
Mean boundary diﬀerence
Overall deviation
Mean boundary diﬀerence
Overall deviation
Mean boundary diﬀerence

First-ALK
5236
1479
1.65
8.94
533.3
6511.7

First-CLK
5233
1573
1.61
11.85
491.3
6254.6

SKATER
4797
1310
1.65
8.93
520.83
7928.6

MRPSO
6597
1975
1.57
32.7
559.99
18,205

#2

#3

Full-CLK
5573
1495
1.58
8.56
493.5
6840

Full-SLK
5740
1182
1.47
12.77
399.2
10,317

Downloaded by [University of Oregon] at 05:29 27 December 2017 14

W. HE ET AL.

the Mbd objective function, the MRPSO method has widest range on all data sets and
outperforms the other methods.

Number of Pareto-optimal solutions

Regarding the number of solutions, fewer Pareto-optimal solutions are obtained by the
baseline methods, even if they are run nine times, because some solutions are domi-
nated by the others. The numbers of Pareto-optimal solutions on each data set are
shown in Table 4. The performances of most of the baseline methods are unsatisfactory.
The number of Pareto-optimal solutions is less than ﬁve in most cases. Only one Pareto-
optimal solution is obtained in three cases, and only the Full-Order-SLK algorithm
obtains all nine Pareto-optimal solutions on data set #1. The number of Pareto-optimal
solutions that are obtained by the MRPSO algorithm is not consistent in every process.
Table 4 presents the average values and standard deviations of the 21 runs of MRPSO.
The average number of solutions is larger than 20 on each data set and the standard
deviation is less than 5. The large number of Pareto-optimal solutions ensures the
smoothness of the Pareto front in MRPSO.

Eﬃciency comparison

respectively. When the numbers of

The complexity analysis of the contiguous-region method and MRPSO has been pre-
sented in ‘Heterogeneity measure’ and ‘Particle representation for regionalization’ sec-
tions,
the
computational complexity of MRPSO is between O (N) and O (N2). A detailed complexity
comparison of the methods is provided in Table 5. The computational complexities of
the baseline methods are provided in the original papers (Neves 2006, Guo 2008). The
complexity of MRPSO is lower than those of most baseline algorithms.

iterations and particles are ﬁxed,

However, the actual running times of the seven regionalization methods are diﬃcult
to compare, because the running time of MRPSO depends on the numbers of iterations
and particles, and all the baseline methods are also inﬂuenced by the number of regions

Table 4. Numbers of Pareto-optimal solutions obtained by all methods.
SKATER
Data set
5
#1
3
#2
3
#3

First-ALK
4
3
2

First-CLK
5
5
2

26.4 ± 4.9
23.5 ± 3.8

Full-ALK
7
1
1

30.1 ± 3.7

MRPSO

Full-CLK
7
2
1

Full-SLK
9
3
4

Table 5. Complexity comparison of seven regionalization methods.
Method
SKATER
First-Order ALK
First-Order CLK
Full-Order ALK
Full-Order CLK
Full-Order SLK
MRPSO
aN is the number of spatial objects.

Theoretical complexitya
O (NlogN)
O (N2logN)
O (N2)
O (N2logN)
O (N2logN)
O (N3)
O (N)~O (N2)

Downloaded by [University of Oregon] at 05:29 27 December 2017 INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

15

0
0
0
1

0
0
9

0
0
8

0
0
7

0
0
6

0
0
5

0
0
4

0
0
3

0
0
2

0
0
1

2
4
0
1

.

6
0
0
1

.

5
3
9

.

±

±

±

.

2
4
5
4

.

4
6
5
4

.

7
8
5
4

4
7
1
1

.

4
5
9

.

2
5

.

±

±

±

.

9
1
1
4

.

8
3
0
4

.

9
8
0
4

9
6
4
1

.

9
2
8

.

8
6
7

.

±

±

±

.

1
3
6
3

.

6
9
6
3

.

3
7
6
3

2
7
7

.

3
7
5

.

0
1

±

±

±

.

1
8
1
3

.

3
9
1
3

.

6
7
1
3

6
9
5

.

7
8
6

.

5
0
7

.

±

±

±

.

8
4
7
2

.

7
1
7
2

.

7
3
7
2

7
0
7

.

±

.

1
9
2
2

1
7
4

.

2
3
6

.

±

±

4
2
2

.

2
7
2
2

9
2
5

.

1
8
4

.

6
9
4

.

±

±

±

.

6
0
8
1

.

9
1
8
1

.

9
2
8
1

1
1
3

.

3
3
3

.

3
9
2

.

±

±

±

.

4
5
3
1

.

5
5
3
1

.

5
9
3
1

2
0
2

.

4
7
2

.

4
4
2

.

±

±

±

.

9
1
9

.

8
9
8

.

7
3
9

8
0
1

.

2
1
1

.

1
5
1

.

±

±

±

.

7
5
4

.

8
5
4

.

7
6
4

1
#

2
#

3
#

t
e
s

t
e
s

t
e
s

a
t
a
D

a
t
a
D

a
t
a
D

x
a
m

r
e
t
i

.
)
s
n
u
r

t
n
e
d
n
e
p
e
d
n

i

0
2

n
o
(

s
n
o
i
t
a
r
e
t
i

f
o

s
r
e
b
m
u
n

h
t
i

w
O
S
P
R
M

f
o

s
e
m

i
t

i

g
n
n
n
u
r

l

a
u
t
c
A

.

6

e
l
b
a
T

t
n
e
r
e
ﬀ
d

i

Downloaded by [University of Oregon] at 05:29 27 December 2017 16

W. HE ET AL.

0
1

=

k

1
0

.

±

.

9
6
5

9
1
0

.

9
0
0

.

3
1
0

.

3
2
0

.

2
1
0

.

7
0
0

.

9
0
0

.

3
1
0

.

3
1
0

.

7
0
0

.

2
1
0

.

5
1
0

.

1
1
0

.

7
0
0

.

9
1
0

.

2
1
0

.

4
1
0

.

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

.

5
9
6

.

2
7
5

.

1
6
6

.

0
9
6

.

8
4
5

.

0
7
5

.

6
4
6

.

3
0
6

.

0
5
6

.

4
4
6

.

7
5
5

.

6
0
6

.

3
0
7

.

4
2
5

.

8
1
7

.

6
4
6

.

8
2
7

5
0
0

.

3
1
0

.

1
1
0

.

9
0
0

.

9
1
0

.

7
0
0

.

9
0
0

.

9
0
0

.

8
0
0

.

6
1
0

.

2
1
0

.

7
0
0

.

9
0
0

.

6
0
0

.

9
0
0

.

2
0

.

2
0

.

1
0

.

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

.

4
8
4

.

2
8
5

.

1
0
5

.

7
5
5

.

8
7
5

.

5
6
4

.

2
9
4

.

4
4
5

.

1
0
5

.

2
4
5

.

6
4
5

.

5
7
4

.

1
3
5

.

8
8
5

.

1
4
4

.

5
9
5

.

9
3
5

.

7
9
5

4
1
0

.

1
0

.

1
0

.

9
0
0

.

4
1
0

.

6
0
0

.

6
0
0

.

4
0
0

.

4
0
0

.

9
0
0

.

6
0
0

.

9
0
0

.

8
0
0

.

6
1
0

.

7
0
0

.

5
0
0

.

1
0

.

2
1
0

.

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

.

9
9
3

.

1
8
4

.

1
3
4

.

5
5
4

.

7
7
4

.

9
8
3

.

6
1
4

.

2
5
4

.

9
0
4

.

4
4
4

.

6
4
4

0
4

.

3
5
4

.

2
8
4

.

7
6
3

.

1
8
4

.

5
4
4

.

8
7
4

5
0
0

.

1
1
0

.

4
0
0

.

4
0
0

.

7
0
0

.

6
0
0

.

7
0
0

.

9
0
0

.

5
0
0

.

7
0
0

.

7
0
0

.

4
0
0

.

7
0
0

.

3
0
0

.

6
0
0

.

6
0
0

.

6
0
0

.

9
0

.

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

.

8
1
3

.

9
7
3

.

3
4
3

.

1
6
3

.

6
7
3

.

8
1
3

.

5
3
3

.

2
7
3

.

6
2
3

5
3

.

8
5
3

3
3

.

7
7
3

8
3

.

1
0
3

.

7
7
3

.

4
5
3

.

4
7
3

2
0
0

.

6
0
0

.

5
0
0

.

3
0
0

.

3
0
0

.

5
0
0

.

4
0
0

.

7
0
0

.

7
0
0

.

4
0
0

.

4
0
0

.

6
0
0

.

5
0
0

.

9
7
1

.

3
0
0

.

4
0
0

.

4
0
0

.

9
0
0

.

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

.

6
4
2

.

5
8
2

.

6
6
2

.

5
7
2

.

2
8
2

.

8
4
2

6
2

.

7
8
2

.

5
5
2

.

6
6
2

.

2
8
2

.

1
6
2

.

2
8
2

.

7
8
2

.

8
3
2

.

4
8
2

.

6
7
2

.

4
8
2

3
0
0

.

9
0
0

.

4
0
0

.

5
0
0

.

3
0
0

.

3
0
0

.

3
0
0

.

2
0
0

.

3
0
0

.

4
0
0

.

4
0
0

.

3
0
0

.

3
0
0

.

3
0
0

.

3
0
0

.

3
0
0

.

4
0
0

.

4
0
0

.

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

.

2
8
1

.

3
0
2

.

9
9
1

.

7
9
1

.

0
0
2

.

7
8
1

.

6
9
1

.

2
0
2

.

5
8
1

.

2
9
1

.

1
0
2

.

0
9
1

.

0
0
2

.

1
0
2

.

4
7
1

.

4
0
2

.

8
9
1

.

0
1
2

2
0
0

.

3
0
0

.

4
0
0

.

4
0
0

.

2
0
0

.

2
0
0

.

6
0
0

.

2
0
0

.

3
0
0

.

3
0
0

.

2
0
0

.

2
0
0

.

4
0
0

.

2
0
0

.

2
0
0

.

2
0
0

.

3
0
0

.

2
0
0

.

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

.

6
2
1

.

3
3
1

.

2
3
1

.

1
3
1

.

1
3
1

.

7
2
1

.

0
3
1

.

2
3
1

.

6
2
1

.

0
3
1

.

2
3
1

.

6
2
1

.

1
3
1

.

1
3
1

.

0
2
1

.

7
3
1

.

3
3
1

.

7
3
1

2
0
0

.

2
0
0

.

2
0
0

.

1
0
0

.

1
0
0

.

2
0
0

.

3
0
0

.

2
0
0

.

3
0
0

.

1
0
0

.

1
0
0

.

1
0
0

.

1
0
0

.

2
0
0

.

1
0
0

.

1
0
0

.

2
0
0

.

2
0
0

.

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

0
8

.

9
7

.

0
8

.

9
7

.

7
7

.

7
7

.

8
7

.

7
7

.

6
7

.

0
8

.

8
7

.

6
7

.

7
7

.

6
7

.

5
7

.

0
8

.

1
8

.

1
8

.

1
0
0

.

1
0
0

.

1
0
0

.

1
0
0

.

1
0
0

.

1
0
0

.

2
0
0

.

1
0
0

.

1
0
0

.

1
0
0

.

1
0
0

.

1
0
0

.

1
0
0

.

1
0
0

.

1
0
0

.

1
0
0

.

1
0
0

.

1
0
0

.

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

±

0
4

.

0
4

.

0
4

.

9
3

.

9
3

.

0
4

.

8
3

.

8
3

.

8
3

.

9
3

.

9
3

.

9
3

.

.

8
3

8
3

.

9
3

.

1
4

.

1
4

.

1
4

.

1
#

2
#

3
#

1
#

2
#

3
#

1
#

2
#

3
#

1
#

2
#

3
#

1
#

2
#

3
#

1
#

2
#

3
#

d
o
h
t
e
M

R
E
T
A
K
S

K
L
A
-
t
s
r
i
F

K
L
C
-
t
s
r
i
F

K
L
A
-
l
l

u
F

K
L
C
-
l
l

u
F

K
L
S
-
l
l

u
F

9

=

k

8

=

k

7

=

k

6

=

k

5

=

k

4

=

k

3

=

k

2

=

k

t
e
s

a
t
a
D

.
)
s
n
u
r

t
n
e
d
n
e
p
e
d
n

i

0
2

n
o
(

f
o

s
e
u
a
v

l

k

t
n
e
r
e
ﬀ
d

i

h
t
i

w
s
d
o
h
t
e
m
e
n

i
l

e
s
a
b

e
h
t

f
o

s
e
m

i
t

i

g
n
n
n
u
r

l

a
u
t
c
A

.

7

e
l
b
a
T

Downloaded by [University of Oregon] at 05:29 27 December 2017 INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

17

-13000

-11000

-7000

-5000

-13000

-11000

-7000

-5000

-13000

-11000

-7000

-5000

-45

-40

-35

-30

-25

-20

-15

-10

-5

0

-45

-40

-35

-30

-25

-20

-15

-10

-5

0

-45

-40

-35

-30

-20

-15

-10

-5

0

Dev

dataset #2

Dev

4

Dev

Dev

dataset #1

dataset #3

Dev

4500

4000

3500

3000

2500

2000

5

4.8

4.6

4.4

4.2

4

3.8

3.6

3.4

3.2

3

2.8

1500

1400

1300

1200

1100

1000

900

800

MRPSO

SKATER

-9000
-Mbd
1-(a)

MRPSO

SKATER

MRPSO

SKATER

-Mbd
2-(a)

-Mbd

3-(a)

Dev

4500

4000

3500

3000

2500

2000

5

4.8

4.6

4.4

4.2

3.8

3.6

3.4

3.2

3

1450

1350

1250

1150

Dev

1050

950

850

750

MRPSO

First-Order-CLK

First-Order-ALK

-9000
-Mbd
1-(b)

MRPSO

First-Order-CLK

First-Order-ALK

-Mbd
2-(b)

MRPSO

First-Order-CLK

First-Order-ALK

-12
-Mbd

3-(b)

Dev

4500

4000

3500

3000

2500

2000

5.1

4.9

4.7

4.5

4.3

4.1

3.9

3.7

3.5

3.3

3.1

2.9

1500

1400

1300

1200

1100

Dev

1000

900

800

700

MRPSO

Full-Order-ALK

Full-Order-CLK

Full-Order-SLK

-9000
-Mbd
1-(c)

MRPSO

Full-Order-ALK

Full-Order-CLK

Full-Order-SLK

-25
-Mbd
2-(c)

MRPSO

Full-Order-ALK

Full-Order-CLK

Full-Order-SLK

-Mbd

3-(c)

-22

-20

-18

-16

-14

-12

-10

-8

-6

-4

-2

0

-22

-20

-18

-16

-14

-10

-8

-6

-4

-2

0

-22

-20

-18

-16

-14

-12

-10

-8

-6

-4

-2

0

Figure 8. Non-dominated solutions obtained by seven methods on real-world data sets.

k. For example, when the number of particles is 20, the running times of MRPSO with
diﬀerent numbers of iterations are listed in Table 6, and the actual running times of all
the baseline methods are listed in Table 7.

From the results, the running times of the baseline methods are shorter than those of
MRPSO, but these methods can only obtain one solution in a single algorithm run. In
contrast, MRPSO can obtain a series of non-dominated solutions in a single run. In
addition, the running time of MRPSO is acceptable, even when parameter itermax is large.

Discussion

From the comparison of the results, MRPSO outperforms SKATER and the REDCAP
algorithm family on all evaluation metrics. The SKATER and REDCAP methods can ﬁnd
better solutions in the lower-right corner of the coordinate axis in Figure 8. In these
cases, all baseline methods are run with larger numbers of regions (such as k = 8, k = 9),
and achieve better performance on the Dev objective function (Y-axis in Figure 8). This is
because all the baseline methods are single-function optimization methods, with the
within-region homogeneity measure as the objective function, and do not consider the
heterogeneity among regions. This is why the Full-Order ALK and Full-Order CLK algo-
rithms can only ﬁnd one Pareto-optimal solution in Table 4.

In addition, the single-objective methods have a tendency to produce unbalanced
solutions in the partition process. Speciﬁcally, to improve the similarity within each

Downloaded by [University of Oregon] at 05:29 27 December 2017 18

W. HE ET AL.

(a)

(c)

(b)

(d)

Figure 9. (a) Original data set of inbound tourism; (b) partitioning result of the SKATER method; (c)
partitioning result of the Full-Order-ALK algorithm of REDCAP; (d) decision solution of MRPSO.

region, few or even one spatial object tends to be partitioned as a separate region when
there is a large gap between a spatial object and the other objects. For example, the
inbound tourism data set and the results of diﬀerent methods are shown in Figure 9.
Some regions with one spatial unit in the partitioning result are obtained using the
SKATER and REDCAP methods, and the number of spatial objects in each region is
unbalanced, as shown in Figure 9(b,c). However, the decision solution that is obtained
using MRPSO is more balanced than those that are obtained by the baseline methods, as
shown in Figure 9(d), because two conﬂicting objectives are considered and the con-
tiguous-region method is used.

Conclusions

In this paper, MRPSO is proposed. First, two conﬂicting objective functions are intro-
duced and a novel particle representation for regionalization problems is designed to
obtain better solutions. Second, a contiguous-region method is proposed for embed-
ding spatial contiguity constraints into the solution.
In addition, a distance-based
technique is introduced for selecting the decision solution in the Pareto set.

In the experiment, six state-of-the-art regionalization algorithms are compared to
MRPSO. We use two metrics to evaluate the performances of the methods: the positions
of solutions and the number of Pareto-optimal solutions. According to the experimental
results, MRPSO outperforms the other algorithms in terms of both evaluation metrics. In
the future, additional objective functions will be investigated and other heuristic strate-
gies will be used to improve the performance.

Downloaded by [University of Oregon] at 05:29 27 December 2017 INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE

19

Acknowledgement

This study is supported by National Natural Science Foundation of China (61473263).

Disclosure statement

No potential conﬂict of interest was reported by the authors.

This study is supported by National Natural Science Foundation of China [grant number:
61473263].

Funding

References

Abubaker, A., Baharum, A., and Alrefaei, M., 2015. Automatic clustering using multi-objective

particle swarm and simulated annealing. PLoS One, 10, e130995.

Adams, M.D., Kanaroglou, P.S., and Coulibaly, P., 2016. Spatially constrained clustering of ecologi-
cal units to facilitate the design of integrated water monitoring networks in the St. Lawrence
Basin. International Journal of Geographical Information Science, 30, 390–404.

Armano, G., and Farmani, M.R., 2016. Multiobjective clustering analysis using particle swarm

optimization. Expert Systems with Applications, 55, 184–193.

Cabrera, J.C.F. and Coello, C.A.C., 2010. Micro-MOPSO: a multi-objective particle swarm optimizer

that uses a very small population size. Berlin Heidelberg: Springer.

Cheruvelil, K.S. and Bremigan, M.T., 2013. Multi-scaled drivers of ecosystem state: quantifying the

importance of the regional spatial scale. Ecological Applications, 23, 1603–1618.

Christina, J., and Komathy, K., 2013. Analysis of hard clustering algorithms applicable to regiona-
lization. In: 2013 IEEE conference on information & communication technologies, 11-12 April 2013,
Thuckalay, India. Washington DC: IEEE, 606–610.

Coello, C.C., and Lechuga, M.S., 2002. Mopso: a proposal for multiple objective particle swarm
optimization. In: Proceedings of the 2002 congress on evolutionary computation, 12-17 May 2002,
Honolulu. Washington DC: IEEE, 1051–1056.

Cressie, N., 1992. Statistics for spatial data. Terra Nova, 4, 613–617.
Dai, C., Wang, Y., and Ye, M., 2015. A new multi-objective particle swarm optimization algorithm

based on decomposition. Information Sciences, 325, 541–557.

Darand, M. and Daneshvar, M.R.M., 2014. Regionalization of precipitation regimes in Iran using
principal component analysis and hierarchical clustering analysis. Environmental Processes, 1,
517–532.

Eberhart, R., and Kennedy, J., 1995. A new optimizer using particle swarm theory.

In: sixth
international symposium on micro machine and human science, 4-6 october 1995, Nagoya,
Japan. Washington DC: IEEE, 39–43.

Esmin, A.A.A., Coelho, R.A., and Matwin, S., 2015. A review on particle swarm optimization algorithm

and its variants to clustering high-dimensional data. Artiﬁcial Intelligence Review, 44, 23–45.

Garcia-Piquer, A., et al., 2015. Toward high performance solution retrieval

in multiobjective

clustering. Information Sciences: An International Journal, 320, 12–25.

Guo, D., 2008. Regionalization with dynamically constrained agglomerative clustering and parti-

tioning (REDCAP). International Journal of Geographical Information Science, 22, 801–823.

Guo, D. and Wang, H., 2011. Automatic region building for spatial analysis. Transactions in Gis, 15, 29–45.
Hastie, T., et al., 2009. The elements of statistical learning, second edition: data mining, inference,

and prediction. Journal of the Royal Statistical Society, 173, 693–694.

Kasprzak, E.M. and Lewis, K.E., 2001. Pareto analysis in multiobjective optimization using the collinear-

ity theorem and scaling method. Structural & Multidisciplinary Optimization, 22, 208–218.

Downloaded by [University of Oregon] at 05:29 27 December 2017 20

W. HE ET AL.

Kim, H., Chun, Y., and Kim, K., 2015. Delimitation of functional regions using a p-regions problem

approach. International Regional Science Review, 38, 187–200.

Kim, K., et al., 2016. Spatial optimization for regionalization problems with spatial interaction: a
heuristic approach. International Journal of Geographical Information Science, 30, 451–473.
Kolars, J., 1977. Locational analysis in human geography. Tijdschrift Voor Economische En Sociale

Geograﬁe, 68, 363–367.

Li, L., Wang, W., and Xu, X., 2016. Multi-objective particle swarm optimization based on global

margin ranking. Information Sciences, 375, 30–47.

Li, L., Wang, W., and Xu, X., 2017. Multi-objective particle swarm optimization based on global

margin ranking. Information Sciences, 375, 30–47.

Ling, H., et al., 2011. An improved PSO algorithm for constrained multiobjective optimization
problems. In: 2011 International conference on computer science and service system, 27–29 June
2011, Nanjing, China. Washington DC: IEEE, 3859–3863

Matake, N., et al., 2007. Multiobjective clustering with automatic k-determination for large-scale
data. In: Proceedings of the 9th annual conference on Genetic and evolutionary computation, 7–11
July 2007, London. New York: ACM, 861–868

Neves, M.C., 2006. Eﬃcient regionalization techniques for socio-economic geographical units using
minimum spanning trees. International Journal of Geographical Information Science, 20, 797–811.

Newman, M., 2010. Networks: an introduction. Oxford: Oxford University Press.
Niesterowicz, J., Stepinski, T.F., and Jasiewicz, J., 2016. Unsupervised regionalization of the United
States into landscape pattern types. International Journal of Geographical Information Science, 30, 1–
19.

Openshaw, S. and Rao, L., 1995. Algorithms for reengineering 1991 census geography. Environ Plan

A, 27, 425–446.

Poli, R., Kennedy, J., and Blackwell, T., 2007. Particle swarm optimization. Swarm Intelligence, 1, 33–57.
Rao, A.R.M. and Lakshmi, K., 2012. Discrete hybrid PSO algorithm for design of laminate compo-
sites with multiple objectives. Journal of Reinforced Plastics and Composites, 30, 1703–1727.
Raquel, C.R., and Naval, Jr, P.C., 2005. An eﬀective use of crowding distance in multiobjective
In: Proceedings of the 7th annual conference on Genetic and

particle swarm optimization.
evolutionary computation, 25–29 June 2005, Washington DC. Washington DC: ACM, 257–264
Sadri, S. and Burn, D.H., 2011. A Fuzzy C-Means approach for regionalization using a bivariate

homogeneity and discordancy approach. Journal of Hydrology, 401, 231–239.

Tibshirani, R., Walther, G., and Hastie, T., 2001. Estimating the number of clusters in a data set via

the gap statistic. Journal of the Royal Statistical Society, 63, 411–423.

Wise, S., Haining, R., and Ma, J., 1997. Regionalisation tools for the exploratory spatial analysis of

health data. Berlin Heidelberg: Springer.

Yuan, S., et al., 2015. Constrained spectral clustering for regionalization: exploring the trade-oﬀ
between spatial contiguity and landscape homogeneity. In: IEEE international conference on data
science and advanced analytics, 19–21 Oct 2015, Paris. New York, NY: IEEE, 1–10

Zhang, Y., Gong, D.W., and Cheng, J., 2017. Multi-objective particle swarm optimization approach for

cost-based feature selection in classiﬁcation. New York, NY: IEEE Computer Society Press.

Zhang, Y., Gong, D.W., and Ding, Z., 2012. A bare-bones multi-objective particle swarm optimiza-

tion algorithm for environmental/economic dispatch. Information Sciences, 192, 213–227.

Downloaded by [University of Oregon] at 05:29 27 December 2017 