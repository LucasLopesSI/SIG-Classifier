Geoinformatica
https://doi.org/10.1007/s10707-020-00405-y

SST: synchronized spatial-temporal trajectory
similarity search

Peng Zhao1 · Weixiong Rao1 · Chengxi Zhang1 · Gong Su2 · Qi Zhang2

Received: 2 June 2019 / Revised: 19 November 2019 / Accepted: 1 April 2020 /

© Springer Science+Business Media, LLC, part of Springer Nature 2020

Abstract
The volume of trajectory data has become tremendously large in recent years. How to effec-
tively and efficiently search similar trajectories has become an important task. Firstly, to
measure the similarity between a trajectory and a query, literature works compute spatial
similarity and temporal similarity independently, and next sum the two weighted similar-
ities. Thus, two trajectories with high spatial similarity and low temporal similarity will
have the same overall similarity with another two trajectories with low spatial similarity and
high temporal similarity. To overcome this issue, we propose to measure the similarity by
synchronously matching the spatial distance against temporal distance. Secondly, given this
new similarity measurement, to overcome the challenge of searching top-k similar trajec-
tories over a huge trajectory database with non-trivial number of query points, we propose
to efficiently answer the top-k similarity search by following two techniques: trajectory
database grid indexing and query partitioning. The performance of our proposed algorithms
is studied in extensive experiments based on two real data sets.

Keywords Trajectory · Spatial-Temporal Similarity · Top-k Search

(cid:2) Weixiong Rao

wxrao@tongji.edu.cn

Peng Zhao
peng.zhao@tongji.edu.cn

Chengxi Zhang
chenxizhang10@126.com

Gong Su
gongsu@us.ibm.com

Qi Zhang
q.zhang@ibm.com

1

2

School of Software Engineering, Tongji University, Shanghai, China

IBM Watson Research Lab, Ossining, NY, USA

Geoinformatica

1 Introduction

Recent years have witnessed unprecedented amounts of GPS trajectories generated by
location-based services (LBS). Analysis of the trajectories is an important task for many
applications such as carpooling, route planning, traffic analysis and mobility pattern analy-
sis [1]. Among such applications, trajectory search is a fundamental task to find the top-k
most similar trajectories to an input query. For example, to find potential carpooling part-
ners, we would like to search the most similar routes in terms of matching spatial distance
and time schedule.

In literature, many trajectory similarity measurements have been propose. Some works
(e.g., [2–6]) measure spatial similarity only. Such similarity measurements obviously suf-
fer from ineffectiveness issue. For example, in the carpooling recommendation system,
spatial similarity is insufficient to evaluate the similarity between two trajectories: the car-
pooling partners should match the required time schedule. Others (e.g., [7–10]) take into
account both spatial similarity and temporal similarity. Among these works, some sepa-
rately measure spatial similarity from temporal similarity. For example, a very recent work
[9] separately computes spatial and temporal similarities and then linearly combines the two
parts by a weight parameter, incurring the mismatching issue (that will be illustrated soon).
Though the previous work [11] measures Frechet distance by introducing a time-constraint
parameter which matches point pairs within a temporal matching window, the mismatching
issue still remains due to the fact that the similarity is rather sensitive to the window.

We illustrate the mismatching issue above in Fig. 1. Four trajectories Ta, ..., Td all pass
through the positions p1, ..., p4. For example, by constant speed, trajectory Ta moves from
p1 at the timestamp 10:00am to p4 at 11:00am. Unlike Ta, trajectory Tb first moves from
p1 at the timestamp 10:00am to p3 at 10:20am by constant speed and yet spends 40 min-
utes from p3 to p4 due to traffic jam (highlighted by dashed line). Given these trajectories,
using spatial similarity alone cannot distinguish the temporal difference between the two
trajectory pairs Ta and Tb, Ta and Tc. Using the similarity in [9] still cannot differentiate the
pair Ta and Tb from the one Ta and Tc because their spatial similarity and temporal simi-
larity computed by time stamps are same. In terms of similarity in [11], the similarity of Ta
and Tb is equal to the one of Ta and Tc for the temporal window greater than 20 minutes
because p3 ∈ Tb can be matched to p3 ∈ Ta and p2 ∈ Tc can be matched to p2 ∈ Ta,
and not if the window is smaller than 20 minutes. In real applications, such as trajectory
near-duplicate detection, [9] identifies duplicate or similar trajectories in database, thus sup-
porting data cleaning. We see Ta and Td are in opposite directions with same spatial path
and time stamps. Due to the fact that spatial and temporal similarity are separately computed
in [9, 9] identifies Ta as a duplicate of Td and one of them is wrongly removed from the
database.

To overcome the mismatching issue, we represent a trajectory by line segments and
measure the trajectory similarity based on the matched point pairs across the trajectories.
Specifically, given two trajectories (say Tb and Tc), we project every existing point pi ∈ Tb

Fig. 1 Example of temporal difference

Geoinformatica

with i = 1...4, denoted by pi,b, to the nearest point pi(cid:3) on one segment in Tc, denoted by
pi(cid:3),c, in terms of spatial-temporal distance. We call (cid:4)pi, p(cid:3)
(cid:5) the matching point pair. Simi-
i
lar situation occurs on the project of every point pi ∈ Tb to p(cid:3)
∈ Ta. As shown in Fig. 1,
i
depending upon the spatial-temporal point-to-point distance, the point p1,b could be pro-
jected to the point p1,c and yet p2,b to some middle point within the segment between p1,c
and p2,c, and the point p1,c could be projected to the point p1,b and yet p2,c to one middle
point within the segment between p3,b and p4,b.

Based on the matching point pairs across two trajectories (totally 8 pairs in Fig. 1), we
accumulate each matching point-point distance to measure the final trajectory similarity
(denoted by MPS). To the best of our knowledge, this is the first study of a trajectory sim-
ilarity that takes synchronized spatial-temporal similarity of each matching point pair into
account. In contrast, existing trajectory similarity measurements [2–12] can be categorized
into spatial-only similarity or separated spatial-temporal similarity. A comparison between
MPS and existing similarities is shown in Table 1. We give more details in related work
Section 2.1.

Based on the defined similarity, we design an efficient trajectory search framework to
retrieve the top-k most similar trajectories from a database for an input query. Literature
approaches [5, 9, 10, 13–16] typically build a trajectory index over trajectory points or
segments. When the database contains a huge amount of trajectories, the number of such
points or segments is non-trivial, incurring high space cost and search cost. In addition,
the typical search strategy takes query points as expansion centers to retrieve trajectory
candidates, until a certain stopping condition is met. When given a long query with non-
trivial number of query points, there exists significant overlapping search space across query
points, leading to redundant candidates and high search cost.

To overcome the efficiency issues above, in the offline phase, we build an trajectory
index on top of trajectory skeletons. Specifically, we divide the area of interest into grid
cells. After each trajectory is mapped to the grid cells, we propose to cluster the grid cells
and the clusters of grid cells can be intuitively treated as the skeletons of trajectories, leading
to much compact indexing structure. Next in the online phase, we divide a long query into
small partitions and answer the query by the search space regarding small partitions, greatly
mitigating the overlapping search space issue. As a summary, this paper makes the following
contributions.

–

The proposed MPS can effectively measure trajectory similarity based on the spatial-
temporal distance of matching point pairs across trajectories. It avoids the mismatching
issue and achieves 1.22 times higher hit ratio than state-of-the-art spatial-temporal
trajectory similarity [9] in effectiveness experiments.

– We develop two techniques to efficiently answer top-k queries: 1) a grid cell clustering
algorithm used to build the compact index structure on top of clustered grid cells and
2) a query-partition-based search algorithm involving the trade-off between the amount
of trajectory candidates and non-overlapping search space.

Table 1 Existing trajectory similarities

Spatial(S)

Hausdorff, Frechet [2], BDS [5],
DTW [6], LCSS [3], EDwP [4]

Spatial-temporal(ST)

Separated ST
[11, 12], SimST [7–10]

Synchronized ST

MPS

Geoinformatica

– We conduct extensive evaluations on two real data sets to investigate the performance
of the proposed algorithms in terms of effectiveness and efficiency. The best algorithm
Table 3 runs 43.1 times and 15.3 times faster than the baseline method on Shanghai and
New York data sets, respectively.

The rest of the paper is organized as follows. Section 2 reviews related work and
Section 3 gives the data model. Section 4 illustrates the top-k search framework and a base-
line solution. Next, Sections 5 and 6 present the offline indexing algorithm and online query
partitioning-based search algorithm, respectively. After that, Section 7 reports evaluation
result. Section 8 finally concludes this paper.

2 Related work

2.1 Trajectory similarity

In literature, many existing trajectory similarity measurements have been proposed [2–12]
and we categorize them in Table 1.

These similarity measurements can be grouped into two columns, (1) Spatial similari-
ties, such as Hausdorff, Frechet [2], BDS [5], and DTW [6]. These functions directly use
the Euclidean distance for corresponding sample point pairs or its variants to define the
similarity, and the temporal information of sample points is not strictly required when cal-
culating such similarity functions. (2) The spatial-temporal functions, which takes temporal
information of sample points into account, can be divided into two subgroups, separated
ST and synchronized ST. In separated ST similarities, there are two types: time constraint
metrics and linear combination metrics. In time constraint metrics, these studies [11] and
[12] combine time constraints with typical functions (ED, Frechet, LCSS, etc.) to mine
the spatial-temporal regularity of trajectories. In terms of linear combination metrics, e.g.,
SimST [7–10], they use a linear combination to combine spatial and temporal similarities.

The spatial-only similarity measurements ignore the temporal information of each same
point in trajectory. Thus, these measurements can not be applied on many real time-
dependent applications (e.g., ridesharing recommendation). The separated ST similarity
measurements take into account the temporal information, but the temporal information
of each point in trajectory is not strictly matched with its spatial location. This would
cause the mismatching issue as illustrated in Example 1. Different from existing measure-
ments, our work computes spatial similarity and temporal similarity synchronously at each
matched pair points. As reported in Section 7.2, MPS is more discriminative than other
measurements.

2.2 Trajectory indexing

Indexing structure on historical trajectory are normally based on original trajectory points
or segments, map-matched road segments and grid cells. For historical trajectories, they
are highly skewed distributed, retrieving trajectories point-by-point [13–15] or segment-by-
segment [17] both are inefficient when the search processes meet a dense trajectory area.
The previous work [18, 19] first identified meaningful frequent patterns (FPs) from the map-
matched trajectories and then transformed the trajectories into shorter lists of connecting
FPs ad road segments for lower space cost. The index build on the shorter lists, instead of
trajectories, can support range queries for much faster running time. Recent works [8, 9,

Geoinformatica

20] using map-matching [21] technique to transform original trajectories into road segment
sequences and then create an inverted list of trajectory identifiers on each road segment in a
road network. These works are highly dependent on road networks which may be updated
periodically and unable to work with free-space moving objects.

Gridding-based approach has been considered in recent work [5], which uses grid cells
as signatures to retrieve similar trajectories efficiently. However, grid width setting and sim-
ilarity measurement are highly connected in [5]. It requires a user-defined max distance
parameter Dmax (e.g., Dmax = 100m). The grid width in [5] is set as Dmax to achieve high
top-k efficiency. The grid width parameter tuning involves the non-trivial efforts to make
a trade-off between effectiveness and efficiency. Our proposed point-matching based sim-
ilarity measurement MPS is independent from the grid width. Thus, the effectiveness is
decoupled from the efficiency of top-k query processing in our work.

2.3 Top-k trajectory search

Top-k trajectory search has been widely studied in [9, 10, 13–16]. Typically, they involve
a definition step and a query processing step. First, a similarity function is defined to eval-
uate the similarity between two trajectories, typically taking into account spatial proximity
and curve similarity. Next, an efficient algorithm is developed to retrieve trajectories close
to a query trajectory. Several trajectory similarity functions are proposed for different appli-
cations. For example, BCT [13] considers similar trajectories of some query locations, and
UOTS [16] and ATSQ [22] extend these to the spatial and textual domains, while PTM [10]
and SimST [9] extend them into spatial and temporal domains.

The work of SimST is the state-of-the-art that applies spatial-temporal similarity in trajec-
tory similarity join application. However, SimST has two main limitations, 1) the trajectory
indexing and search are based on the road network, thus it can not be generally applied on
free-space trajectories. 2) the trajectory spatial similarity and temporal similarity compu-
tations are separately computed in SimST, this approach may cause false positive issues in
spatial-temporal similarity search applications.

Different from these studies, our integrated framework is an improved top-k search in
terms of three aspects: more reasonable similarity measurement (i.e., synchronized spatial-
temporal similarity computation on each matched point pair in Section 3), more efficient
database indexing (i.e., gridding-based indexing for free space trajectories and merging the
common trajectory IDs maintained in grid cells in Section 5) and simpler query processing
(i.e., query partitioning in Section 6).

3 Data model

3.1 Trajectory database and query

Consider that a taxi equipped with a GPS sensor is moving around. The moving trajectory
follows a continuous curve either in free space or constrained to road networks. GPS sensors
typically collect GPS samples by a certain period (e.g., every 1 minute). By connecting two
neighbour GPS positions with a line segment, we then approximate the continuous curve
into an ordered sequence of line segments.

Given a trajectory database T , each trajectory T ∈ T consists of the sequence of line
segments, denoted by T = (cid:4)(cid:2)1, ..., (cid:2)|T |(cid:5), constructed from (|T | + 1) points (cid:4)p1, ..., p|T |+1(cid:5).
For a certain segment (cid:2)i with 1 ≤ i ≤ |T |, the points pi and pi+1 become the start and end

Geoinformatica

points of (cid:2)i denoted by (cid:2)i.s and (cid:2)i.e, respectively. Each sample point pi = (cid:4)li, ti(cid:5) contains
a multi-dimensional location li (e.g., the longitude and latitude in a two-dimensional GPS
coordinate) and an associated timestamp ti. Recall that moving objects in many practical
scenarios such as urban traffic frequently follow daily patterns. We are thus interested in
temporal patterns in terms of the timestamps within the range of 24 hours.

Similarly, we consider an input query Q = (cid:4)(cid:2)1, ..., (cid:2)|Q|(cid:5) consisting of a sequence of line
segments. The query Q is used to search the top-k most similar trajectories T ∈ T . We can
intuitively treat the query Q as a trajectory.

3.2 Similarity deﬁnition

To define the similarity Sim(Q, T ) between an input query Q and a moving trajectory T ,
we first note that Q might be only similar to a small portion of T and vice versa. We thus
compute Sim(Q, T ) in terms of the similarity from each segment Li ∈ Q to trajectory T and
the one from each segment (cid:2)j ∈ T to query Q. It means that the computation of Sim(Q, T )
involves the weighted aggregation of Sim(Q → T ) and Sim(T → Q).

Sim(T , Q) = α · Sim(Q → T ) + (1 − α) · Sim(T → Q)
(cid:2)j ∈Q Sim((cid:2)j → T )
|Q|

+ (1 − α) ·

= α ·

(cid:2)

(cid:2)

(cid:2)i ∈T Sim((cid:2)i → Q)
|T |

(1)

In the equation above, the parameters α and (1 − α) indicate the weights of the similarity
Sim(Q → T ) from Q to T and the one Sim(T → Q) from T to Q, respectively. We set
α = 0.5 by default. Since a query Q can be treated also as a trajectory, we thus do not
differentiate Sim(Q → T ) from Sim(T → Q) and Sim((cid:2)j → T ) from Sim((cid:2)i → Q).
Thus, in the rest of this section, we in general focus on the similarity Sim((cid:2) → T ) from one
segment (cid:2) to a trajectory T . Once Sim((cid:2) → T ) is computed, we then comfortably follow
the equation above to compute Sim(T , Q).

Segment-to-Segment Similarity: To compute Sim((cid:2) → T ), we align the segment (cid:2) to the

most similar segment on trajectory T , i.e.,

Sim((cid:2) → T ) = max
(cid:2)(cid:3)∈T

Sim((cid:2) → (cid:2)

(cid:3)

)

Since we represent each trajectory by line segments, the key is segment similarity. With-
out loss of generality, we consider two line segments (cid:2)1 = (s1, e1) and (cid:2)2 = (s2, e2), and
define the similarity Sim((cid:2)1 → (cid:2)2):

Sim((cid:2)1 → (cid:2)2) = min
p∈(cid:2)1
Sim(p → (cid:2)2) = max
q∈(cid:2)2

Sim(p → (cid:2)2)

Sim(p, q)

Sim(p, q) = β · f (DistS(p, q)) + (1 − β) · f (DistT (p, q))

In above equations, p ∈ (cid:2)1 (resp. q ∈ (cid:2)2) denotes a point p (resp. q) within segment (cid:2)1
(resp. (cid:2)2). The similarity Sim((cid:2)1 → (cid:2)2) is to find the most dissimilar point p ∈ (cid:2)1 matched
with point q ∈ (cid:2)2, i.e., the minimal point-to-segment similarity Sim(p → (cid:2)2) in Eq. 3. In
terms of Sim(p → (cid:2)2), we need to find most similar point q ∈ (cid:2)2 for point p, i.e., the
maximal point-to-point similarity Sim(p, q) in Eq. 4. Given the idea above, we give detail
of these similarities reversely one by one.

(2)

(3)

(4)

(5)

Geoinformatica

Point-to-Point similarity: We compute Sim(p, q) by the spatial-temporal distance between
two points. The spatial distance DistS(p, q) between the locations of p and q can
be computed e.g., by using a L2 distance DistS(p, q) = ||p.l, q.l||2, and temporal
distance DistT (p, q) between the timestamps of p and q is computed e.g., by using
DistT (p, q) = |p.t − q.t|. Based on the distance, we employ the function f () to trans-
form the distance to a normalized similarity value, e.g., f (x) = e−x, which has been
widely used in [8–10, 13], i.e., f (DistT ) = e−DistT and f (DistS) = e−DistS . Finally, the
parameters β ∈ [0, 1] and (1 − β) indicate the weights of spatial and temporal similari-
ties, respectively. When β = 1 (resp. β = 0), Sim(p, q) involves only the spatial (resp.
temporal) similarity. By default we set β = 0.5.

Point-to-Segment similarity: To compute Sim(p → (cid:2)2), we follow the previous work [17]
to find a point q ∈ (cid:2)2 which maximizes Sim(p, q). We denote q∗ the optimal point q ∈ (cid:2)2
satisfying the condition Sim(p, q∗) = maxq∈(cid:2)2 Sim(p, q). Such a point q∗ can be found
as follows. Note that the point-to-segment similarity Sim(p → (cid:2)2) may not be a convex
function. This is particularly true when a real (sub-)trajectory from (cid:2)2.s to (cid:2)2.e involves
a complex curve shape. To this end, for a given error bound δ, we follow the classic work
[23] to find an approximated point q(cid:3) to meet the condition |Sim(p, q∗)−Sim(p, q(cid:3))| ≤ δ
by iterative interpolation.

Segment-to-Segment similarity: The similarity Sim((cid:2)1 → (cid:2)2) again needs to find an
optimal point p∗ satisfying the condition Sim(p∗ → (cid:2)2) = minp∈(cid:2)1 Sim(p → (cid:2)2).
As before, we could find an approximated point p(cid:3) to meet the condition |Sim(p∗ →
(cid:2)2)) − Sim(p(cid:3) → (cid:2)2)| ≤ ε for an error bound ε.
We take Fig. 2 to illustrate the computation of Sim((cid:2)1 → (cid:2)2). For β = 0, we only
consider the temporal similarity in Eq. 5, and the points on (cid:2)1 are matched to the most
similar points on (cid:2)2 according to Eq. 4. The most dissimilar point p∗ from (cid:2)1 to (cid:2)2 is s1
which is matched to s2 as defined in Eq. 3. Similarly, with β = 1, this similarity in Eq. 5
involves the spatial similarity only and the optimal point p∗ (resp. q∗) could be point t1
(resp. projection of t1 within (cid:2)2). Yet in the general case with β ∈ [0, 1], the optimal point
p∗ (resp. q∗) could be a middle point within (cid:2)1 (resp. some middle point within (cid:2)2). (cid:2)

Fig. 2 Segment-to-Segment Similarity

Geoinformatica

In summary, the similarity Sim(T , Q) is computed based on the matching point pairs
(cid:4)p∗, q∗(cid:5) when query Q and trajectory T are both represented by line segments. As shown in
the previous works [2, 17], the segment-based similarity measurements are robust towards
various sampling rate of trajectories. In addition, Sim(T , Q), depending upon the point-to-
point spatial-temporal distance, incorporates both temporal and spatial similarities. Hence,
the proposed similarity is more discriminative and meaningful than the previous works [9,
10] that will be verified in our experiments.

4 Solution overview

Problem 1 Given a trajectory database T and a query Q, the top-k query is to find a
trajectory set K ⊆ T satisfying |K| = k and

∀T ∈T \K∀T ∗∈KSim(T , Q) ≤ Sim(T

∗

, Q)

To answer the top-k query above, Algorithm 1 follows the typical candidate generation
and refinement paradigm [5, 9, 10, 13–15]. First in the offline phase (line 1), we prepro-
cess the trajectory database T by BuildIndex to build an indexing structure I . Then
for each incoming query trajectory Q in the online phase (line 2), we divide Q into mul-
tiple partitions P by QueryPartition(Q). Each partition consists of multiple query
segments. Next for each partition, we search the associated trajectory candidates and add
the candidates to the set C by RetrieveCands (line 6). After that, we need to update
the lower/upper bounds of query-trajectory similarity between query Q and the trajectory
candidates C by UpdateBounds (line 7).

In the while loop (lines 4-7), we repeat the candidate search until a search stopping
condition is satisfied. An example of the stopping condition is given as follows. For the
candidates c ∈ C, we approximate the query-trajectory similarity Sim(Q, c) to find the
top-k-th greatest low bound, denoted by lbtopk(C, Q). For those still unscanned trajectories
i.e., T \ C, we compute the greatest query-trajectory similarity upper bound, denoted by
ub(T \ C, Q). If the condition |C| > k and lbtopk(C, Q) > ub(T \ C, Q) holds, the correct
top-k results are guaranteed to be inside the set C and we then safely stop the search (line
4). We refine the candidates in C to return the final top-k query results (line 7).

Baseline approach The key of Algorithm 1 is how to efficiently perform the functions
BuildIndex and QueryPartition. We give a baseline approach and highlight the
challenges.

Geoinformatica

We implement BuildIndex by using a multi-dimensional R-tree structure I to index
trajectory segments. Each leaf node of the R-tree accommodates a certain number of trajec-
tory segments. Besides two end points (cid:2).s and (cid:2).e, each segment (cid:2) maintains an associated
trajectory ID tid, i.e., (cid:4)(cid:2).s, (cid:2).e, tid(cid:5). Next, to implement QueryPartition, we simply
assume that each partition P contains only one query segment with |P | = |Q|, i.e., no query
partitioning is performed. Then we independently search the R-tree I to retrieve trajectory
candidate set Ci regarding each query segment (cid:2)i ∈ Q. In terms of each query segment,
we apply the best-first approach in [24] and maintain a priority queue to store all the R-tree
entries that have not been visited yet, where the priority queue is sorted by the spatial-
temporal similarity. Thus, we can sequentially retrieve the most similar trajectory segments
from the priority queue into the candidate set Ci of query segment (cid:2)i. When trajectory can-
didates Ci w.r.t all query segments (cid:2)i are added to the set C = (cid:11)1≤i≤|Q|Ci, we perform
UpdateBounds to update the similarity upper/lower bound for the candidates in C, if
necessary. The similarity upper/lower bounds between query Q and trajectory (candidate) c
can be comfortably computed by bidirectional spatial-temporal similarity estimation in [9].
Though the baseline approach above works, but it suffers from inefficiency issue due to
following two challenges. 1) When the database contains a huge amount of trajectories (e.g.,
1 million taxi trips of Shanghai, China in our dataset), the trajectory index I built directly on
top of trajectory segments (or points) [5, 9, 10, 13–15] requires non-trivial space and search
cost. 2) For each query segment (cid:2)i ∈ Q, we need to find a candidate set Ci. When a long
query Q contains a non-trivial number of query segments, there exists significant overlap
among the candidate sets C1...C|Q|, leading to redundant candidates and search cost. For
example, the full trajectory prediction [25] needs to find similar trajectories for a half-day
long query trajectory.

To address the challenges above, we propose following two techniques (see Fig. 3). In
the offline phase, we maintain a compact index on top of trajectory skeletons, instead of
detailed trajectory segments (or points). By dividing the area of interest to grid cells, we can
map trajectories into the grid cells. When those grid cells contain common trajectories, we
then only maintain a list of common trajectory IDs and replace those IDs in each grid cell
with an entry that references the list. The lists of common trajectory IDs can be intuitively
treated as trajectory skeletons that merge the grid cells. After that, we index these grid cells
by a spatial data structure (e.g., R-Tree). Using the merged cells could greatly optimize the
memory size for indexing trajectories. In the online phase, we propose to divide a long query
trajectory into partitions. Each partition consists of multiple query segments, leading to
|P | ≤ |Q|. We perform query search on the granularity of query partitions to find trajectory
candidates regarding each partition. This search granularity greatly reduces the issue of
subspace search overlap.

Fig. 3 Solution Framework

Geoinformatica

5 Grid cell merging

5.1 Indexing structure

Basic indexing structure Consider a trajectory database T = (cid:4)T1, T2, ..., TN (cid:5), we index
the trajectories by a hybrid data structure consisting of a multi-dimensional data structure
(e.g., an R-tree) and inverted list of trajectories. As shown in Fig. 4a, trajectory segments
are mapped to divided grid cells. A trajectory segment may span multiple grid cells and a
cell could contain the IDs of multiple trajectories. We then index these grid cells by using
a multi-dimensional structure, e.g., R-tree in Fig. 4b. Each leaf node of the R-tree accom-
modates a certain number of grid cells. After that, we construct an inverted list structure,
where each indexed grid cell is referred by an inverted list of trajectories containing at least
one segment passing through the cell.

Grid cell merging When the number of indexed grid cells is high, the indexing structure
suffers from the similar challenge as the baseline approach. To this end, we propose to
merge grid cells, motivated by the following observation.

Some neighboring grid cells may contain many common trajectory IDs. As shown in
} all redundantly contain the exact same trajectory
Fig. 4c, the three cells {gc2 , gc3 , gc4
IDs {T1, T2, T3, T4}. Such redundancy not only incurs high space cost of the inverted
lists to index trajectories, but also leads to non-trivial query processing cost. For example,
assume that a query Q spans the three grid cells {gc2 , gc3 , gc4
}, and the baseline approach

Fig. 4 Grid Indexing

Geoinformatica

repeatedly retrieves the trajectory IDs indexed by the grid cells. It means that the four tra-
jectory IDs are redundantly retrieved by three times, leading to higher query processing
overhead.

To overcome the issue above, we propose to merge the common items within inverted
lists and then extend the associated grid cells. We first denote the grid cell set as G and
the inverted list of grid cell g as L(g) (g ∈ G). As shown in Fig. 4c, the inverted lists of
three cells L(gc2 ), L(gc3 ), L(gc4 ) share the four items {T1, T2, T3, T4}. We then merge these
cells into a greater cell and assign a new merged grid cell ID mg1 for the four trajectories
{T1, T2, T3, T4}. In this way, the three cells now all refer to the merged grid cell ID mg1,
instead of three trajectory IDs. Intuitively, the merged grid cell mg1 can be treated as the
skeletons of the four referred trajectories {T1, T2, T3, T4}. We then denote the merged grids
set as M and merged grid cell ID list as ML. The result of merging process is shown
in Fig. 4d, we find that M = {mg1, mg2, mg3
} and L(mg1) = {T1, T2, T3, T4}. And the
inverted list of grid gc2 becomes ML(gc2 ) = {mg1

}.

Problem 2 Given grid set G and inverted list L, our goal is to find a set M of merged grids
that minimize the space cost of L(G), computed by the sum of the space cost of the merged
inverted list L(M) and merged grids cell ID list ML(G), i.e., L(M) + ML(G).

5.2 Heuristic merging approach

We formulate the inverted list merging problem in Problem 2. We then show that it is
NP-hard and give a heuristic approach to reduce the redundant trajectory IDs in inverted
list.

Theorem 1 Problem 2 is NP-hard.

Proof We follow the previous work [26] to give the proof that Problem 2 is NP-hard. We
show that Problem 2 is reducible from the well-known problem minimum set cover problem.
The set that is to be covered corresponds to the original inverted list L(G) and the sets that
can be used in the cover are the merged grids set M.

It is easy to see that the minimal space cost of inverted lists with merged grids corre-
sponds to the minimum set cover. It is well-known that the set cover problem is NP-hard.
This completes the proof.

Since Problem 2 is NP-hard, we propose a heuristic approach to greedily merge the
inverted lists of trajectory IDs over the grid cells. Specifically, for a grid cell g, we denote
L(g) to be the inverted list of g, and |L(g)| to be the size of L(g), i.e., the number of
trajectory IDs in L(g). We define that the most popular grid pg is the one with the largest
size |L(pg)| among all grid cells. Among all neighbor grid cells of pg, we choose some
of them, say ng, to ensure that the merge between pg and ng leads to the greatest positive
benefit. Consequently, we create a new merged grid cell, namely mg, and an associated
inverted list L(mg) = L(pg) (cid:12) L(ng). Meanwhile we update L(pg) ← L(pg) \ L(mg) (cid:11)
{mg} and L(ng) ← L(ng)\L(mg)(cid:11){mg}. We repeat the step of merging the currently most
popular grid cell pg with its neighbor grid cells ng if the merge leads to the greatest positive
benefit. To combine merged grids with original index structure, we maintain a merged girds
ID list (ML) for each grid, i.e., we add mg’s ID into ML(g ∈ mg).

In the approach above, we need to define the merge benefit. Specifically, consider a set
mg of to-be-merged grid cells with |mg| ≥ 2, and the common items in the inverted lists

Geoinformatica

of grid cells in mg can be denoted by L(mg) = (cid:12)g∈mgL(g). Then we define the merging
benefit as follows.

MB(mg) = |mg| · |L(mg)| − (|L(mg)| + |mg| + 1)

(6)

In the equation above, |mg| · |L(mg)| and (|L(mg)| + |mg| + 1) indicate the space cost of
L(mg) before and after the merging operation is adopted on the common items in the lists.
} is 3 × 4 − (4 + 3 + 1) = 4.
For example in Fig. 4c, the merge benefit of mg = {gc2 , gc3 , gc4
}, the merge benefit mg
If we continue to merge the inverted lists of mg = {gc2 , gc3 , gc4 , gc5
now becomes 4 × 2 − (2 + 4 + 1) = 1, smaller than the mg = {gc2 , gc3 , gc4

}.

The details of grid merging are shown in Algorithm 2. We maintain a heap of all grids
with their size (i.e., the number of trajectory IDs in each inverted list). At each stage,
we select the most popular grid pg with most trajectory IDs. For the inverted list L(pg)
referred by grid cell pg, we expect to merge with the inverted list of one of the pg’s
neighbor grids which leads to the maximum positive benefit. The neighbor grids can be
easily found by the grid ID of pg. For example, the grid gc4 in Fig. 4a, its neighbor grids
are {gc3 , gd4 , gc5

The time complexity of this algorithm is O(|T | · |G| · log(|G|)), where O(|T | · |G|) is
the number of all to-be-merged trajectory IDs and O(log(|G|)) is the cost of heap operation
over all grids G.

}.

Running example To illustrate how Algorithm 2 works, we give the following running
example. As shown in Fig. 4, the three grid cells gc2 , gc3 , gc4 refer to the inverted lists
with the same size. We thus break the tie to randomly select one of the three grids, e.g,

Geoinformatica

gc2 , as pg and retrieve its inverted list L(pg) (line 4). Meanwhile, we have the neighbor
} (line 5). We initialize the merged grid set Gsofar, merg-
grids Nbr = {gc1 , gb2 , gc3
ing benefit benefitSofar and trajectory set Lsofar (lines 6-7). Inside the while loop, we
select gNbr = gc3 and compute benefitNew = 2 × 4 − (4 + 2 + 1) = 1 (lines 9-10).
Thus, the condition in line 11 holds, we have benefitSofar = 1, Gsof ar = {gc2 , gc3
},
Nbr = {gc1 , gb2 , gc4
} and Lsofar = {T1, T2, T3, T4} (lines 12-14). Next, we continue the
inner while loop, and reselect gNbr = gc4 and re-compute benefitNew = 3 × 4 − (4 +
}. Again the if condition in line 11 holds,
3 + 1) = 4 due to Gsof ar ∪ gNbr = {gc2 , gc3 , gc4
and we have benefitSofar = 4, Gsofar = {gc2 , gc3 , gc4
} and
}, Nbr = {gc1 , gb2 , gc5 , gd4
Lsof ar = {T1, T2, T3, T4}. After that, inside the while loop, we re-select gNbr = gc5 . Due to
Gsof ar ∪ gNbr = {gc2 , gc3 , gc4 , gc5
}, we re-compute benefitNew = 4 × 2 − (4 + 2 + 1) = 1,
smaller than benefitSofar (=4). Now the if condition in line 11 does not hold due to
benefitSofar = 4 > benefitNew = 1 and the inner while loop then breaks. We then create
the merged grids mg1 referring to the trajectory ID list L(mg1) = {T1, T2, T3, T4}, and mg1
is added into M (lines 16-17). The inverted lists L(g ∈ Gsofar) are updated and the mg1 is
added into the merged grids ID lists ML (line 19). With those merged grids g ∈ Gsofar, we
update their positions in the heap H (line 20). Then we go back to line 3 and process the
remaining inverted lists as before. Finally, as shown in Fig. 4d, we return the merged grids
set M with the merged grids ID lists ML referred by grids and new trajectory ID lists L
referred by mg ∈ M.

6 Query processing

Given the query Q = (cid:4)(cid:2)1, ..., (cid:2)n(cid:5), we consider two neighbor query segments (cid:2)i and (cid:2)i+1
(with 1 ≤ i ≤ n − 1) and associated trajectory candidate sets Ci and Ci+1 (see the baseline
approach in Section 4). When the sets Ci and Ci+1 contain substantial overlap, the overlap
could incur redundant search overhead. To this end, our general idea is to divide the query
Q into several partitions of query segments and query segments in one partition share the
same search process.

Formally, let R = {r0, r1, ..., rρ} be a set of integers such that 0 = r0 < r1 <
},
... < rρ−1 < rρ = n. Then R divides Q into ρ partitions:{(cid:2)r0+1, ..., (cid:2)r1
..., {(cid:2)rρ−1+1, ..., (cid:2)rρ
}), we replace all segments
with a representative segment from the start point (cid:2)rj +1.s to end point (cid:2)rj +1 .e and the
corresponding search process starts from this representative segment.

}. In each partition (e.g., {(cid:2)rj +1, ..., (cid:2)rj +1

}, {(cid:2)r1+1, ..., (cid:2)r2

Extremely, when R = {0, n}, we divide all query segments into one partition and thus
the overlapping search space is eliminated completely due to that we only have one search
process. However, in this case, the representative segment greatly deviates from the orig-
inal query segments and its search process may retrieve unnecessary candidates for the
partition. Thus, such extreme partition leads to the largest candidate maintenance cost.
There is a trade-off between the candidate maintenance cost and search cost in query
partitioning.

To partition query segments which balances these two costs, we design a cost model
to estimate the two costs for each partition. Based on the cost model, we find that
the optimal partitioning is NP-hard. Therefore, we design a greedy algorithm to merge
neighbor query segments which aims to minimize the total cost of query partition. Fur-
thermore, we take the connectivity of partitions into account to improve the partitioning
results.

Geoinformatica

6.1 Query partitioning

To fill the function QueryPartition(Q), we design a cost model to evaluate the search
cost and the candidate maintenance cost. Then we design a partitioning method to minimize
the overall cost of partitions.

In order to take into account the real distribution of trajectory database into the cost
estimation, we search c grid cells for each query segments (cid:2)i ∈ Q, here c is a constant (say
c = 5). We denote the grid set of each query segment (cid:2)i as Gi. We define the total cost of
merging continuous query segments (cid:2)[i:j ] where 1 ≤ i ≤ j ≤ |Q|.

Cost[i,j ] = Cs(∪x∈[i,j ]Gx) + |

ML(g)|

(7)

(cid:4)

g∈∪x∈[i,j ]Gx
ML(g)| is the maintenance cost of all merged grids IDs in these grids

where |
and Cs(∪x∈[i,j ]Gx) is the search cost of grids retrieved from the R-Tree.

g∈∪x∈[i,j ]Gx

Based on the cost model above, our goal is to divide query segments into several par-
titions which achieves the minimum total cost. The optimal solution to this problem is
NP-hard because it can be reduced from the job-shop scheduling problem.

We thus propose a greedy merging algorithm to merge neighbor query segments until

there is no cost saving by merging operation.

(cid:3)

The greedy merging is shown in Algorithm 3. First, we search c grid cells for each
query segments (cid:2)i ∈ Q. We carefully maintain a heap of candidate partition pairs (line 1).
Initially, each original query segment forms a partition and we construct merge pairs of each
partition with it’s next neighbor partition (except the last one). In each pair of two groups,
denoted as (cid:2)[x:y] and (cid:2)[y+1:z], we define the cost saving of merging these two partitions
as Saving[x:z] =
i∈[x:z] Costi − Cost[x:z] (line 4). We add all these pairs into the heap
prioritized by cost saving (line 5). We use a doubly linked list (DLL) to maintain the groups.
At each stage, we get the merge pair from the heap with maximum cost saving (line 7). If

(cid:2)

Geoinformatica

the merge pair still exists in DLL, we merge a pair of partitions in DLL and add two new
pairs, (cid:4)previous partition, merged partition(cid:5) and (cid:4)merged partition, next partition(cid:5), into the
heap (line 9-17). The process will stop when the maximum cost saving is less than 0 or the
heap is empty (line 6 and 8). And its time complexity is (cid:7)(n · log(n) · c), where n is the
number of query segments of Q.

Connectivity optimization Algorithm 3 only takes into account the cost saving to partition
the query segments. However, from our observation, the more similar trajectories near the
partition of query segments, the more possible that the final top-k results exist in those tra-
jectories. We define the number of similar trajectories near the partition of query segments
as the connectivity.

Given a pair of two partitions, (cid:2)[x:y] and (cid:2)[y+1:z], we formally define the connectivity as
(cid:2)

(cid:2)

below.

Con[x:z] =

g∈Gy ∩Gy+1

mg∈ML(g)
GridsNum((cid:2)[x:z])

|mg| · sup(mg)

(8)

where Gy ∩ Gy+1 is the connective grids between two partitions, mg is the merged grids
in connective grid, |mg| is the number of grids in the merged grid mg and sup(mg) is the
number of trajectories in the mg. The GridsNum((cid:2)[x:z]) is the number of grids when we
apply gridding on query segments from (cid:2)x to (cid:2)z. This is because the similar trajectories near
to the partition (cid:2)[x:z] should have the approximate number of grids as our query segments. To
implement this connectivity optimization, for each to-be-merged partition pair, we compute
their connectivity at line 4, 12, 16 in Algorithm 3 and the pairs in the heap are prioritized
by Saving[x:z] · Con[x:z].

6.2 Top-k query

We adapt the top-k search (Algorithm 1) to cooperate with our grid indexing structure and
query partitions. First, to implement BuildIndex(T ) , we follow the method in Section 5
to build grid indexing structures over trajectory database. In online phase, we partition the
original query Q into partitions with method in Section 6.1 (QueryPartition(Q)). To
retrieve candidates from indexing structure RetrieveCands(), we incrementally search
grids from 3D R-tree for each query partition. We then retrieve trajectory candidates from
the inverted lists of those grids. The similarity upper/lower bounds between query Q and
trajectory candidates can be computed by the bounds estimation in [9]. Here, we use those
searched grids and query segments to estimate the upper/lower bounds for each trajectory
candidate. Noted that grid based similarity bounds avoid the non-trivial bounds estimation
between database segments and query segments in baseline solution. Benefiting from this,
the computation of search process is greatly reduced in top-k query and this will be verified
in our experiments. Finally, we refine all candidates by computing exact similarities of
candidates in descending order of their upper bounds until we get the top-k results.

Complexity: The top-k query processing above contains three parts, gird indexing con-
struction, query partitioning and top-k search. Thus, the overall time complexity of our
proposed approach is O(|T | · |G| · log(|G|) + n · log(n) · c + |P| · |Cmax| · log(|G|)). The
time complexities of gird indexing construction and query partitioning have been analyzed
in Sections 5 and 6, respectively. And |P| · |Cmax| · log(|G|) is the time complexity of top-k
search over grid indexing and query partitions, where |P| is the number of query partitions,
|Cmax| is the maximum candidate size and log(|G|) is the cost of grid-based search with
R-tree.

Geoinformatica

7 Experiments

7.1 Setup

In this section, we conduct intensive experiments to validate the effectiveness of our sim-
ilarity measurement and the efficiency of the top-k search framework respectively. We
implement the algorithms with the C/C++ language and evaluate its performance on a
computer with Intel(R) Xeon(R) CPU E5-2620 v3 @2.40GHz and 64 GB memory.

Data sets We evaluate the performance of all methods on two real trajectory data sets col-
lected by two taxi companies, one in Shanghai, China and the other in New York, USA.
Table 2 lists the statistics of the two data sets.

We found that the sampling rate of trajectories in Shanghai is more frequent than that of

trajectories in New York.

The original trajectories in both data sets are very long, often lasting days. In order to
create trips with a realistic length and duration, we divide these trajectories into hour-long
sub-trajectories, give them an average length (number of segments) of ∼ 300 in Shanghai
and ∼ 30 in New York.

The details of all tested methods are listed in Table 3. Note that we only compare our sim-
ilarity measurement MPS with the state-of-the-art SimST [8, 9] in effectiveness evaluation.
The trajectory indexing and search algorithms in SimST [8, 9] are based on road networks.
Instead, our approach does note require this constraint. Thus we do not compare our work
against [8, 9] in efficiency evaluation.

In all query-processing experiments, we randomly select 20 trajectories from trajectory
database as query tests. The CPU time cost of each algorithm is averaged by these queries.
We give the default parameters of our top-k search framework in Table 4.

7.2 Effectiveness evaluation

First, we study the effectiveness of our new similarity measurement. Intuitively, we assume
that a trajectory T is most similar to its subsampled variant T (cid:3) which is generated by
reducing sampling points in T , vice versa. This is because that T and T (cid:3) can be regarded
as the different representations of the same real travel path. Thus, given a trajectory set
TS, a trajectory T ∈ TS, the subsampled variant T (cid:3) /∈ TS, and a similarity measurement
Msim(), we define T (cid:3) successfully discriminate T from a trajectory set TS as a hit of T (cid:3), i.e.,
Msim(T (cid:3), T ) ≥ ∀T x ∈TSMsim(T (cid:3), T x).

To avoid computing similarity of T (cid:3) with all trajectories in the database, we extract tra-
jectories in traffic centers which are likely to contain many similar trajectories. Given a
subsampling rate, we compute the subsampled variants of those trajectories. Specifically,
we use a uniform subsampling method to compute the subsampled variant of each trajec-
tory. Using different similarity measurement, we compute the similarity of each subsampled
variant with all trajectories in the traffic center and count the number of hits. We define the

Table 2 Trajectory information

Shanghai

New York

#trajs

1M

1M

#taxis

17110

11430

Avg.sampling

Avg.L

11s

109s

12501m

20440m

Avg.T

∼ 3300s
∼ 3270s

Geoinformatica

Similarities

MPS

SimST, Simo
ST

BDS

EDwP

DTW

BF

BF+GI

BF+GPI

Table 3 Tested similarities and top-k methods

Description

We refer to our similarity measurement as the MPS (Matching Point-point

based Similarity)
A separated spatial-temporal trajectory similarity (SimST) [8, 9], and Simo
ST
is an extension of SimST.
A spatial projection based Bi-Directional trajectory Similarity (BDS) [5].

Edit distance with projections (EDwP) [4] orderly aligns points in one

trajectory to the segments in another trajectory.

Dynamic Time Warping (DTW) [6] is a well-known trajectory similarity.

Top-k methods

Description

The Baseline Framework (BF) of top-k search defined in Section 4.

BF with Grid Indexing (GI) structure in Section 5.

BF with both Grid indexing and query Partition based Indexing (GPI)

in Section 6.1.

BF+GPI-O

The connectivity based optimization of BF+GPI in Section 6.1.

hit ratio as the number of hits divided by the size of the selected trajectories. The higher hit
ratio of a similarity measurement is, the more discriminative the measurement is.

We compare MPS with SimST, Simo

ST, EDwP, BDS and DTW. As shown in Fig. 5, MPS
has the highest hit ratio under all subsampling rate in both Shanghai and New York data
sets. SimST is the latest work that also combines the spatial and temporal similarity. Simo
ST
outperforms SimST due to that it takes order of trajectory sample points into account. How-
ever, both SimST, Simo
ST measure spatial and temporal similarity in a separated manner. This
causes the mismatching between spatial similarity and temporal similarity in both SimST
and Simo

ST.

MPS combines spatial similarity and temporal similarity of each matched point pair, thus

any difference between trajectories can be captured by MPS.

We can see that, when the subsampling rate goes extremely lower, MPS still have the
highest hit ratio. BDS and EDwP both are spatial projection based similarities. They outper-
forms classic DTW similarity which is point matching based. We found EDwP outperforms
BDS due to that EDwP takes account of the order of trajectory sample points.

Table 4 Default parameter settings

Parameter

α = 0.5
β = 0.5
k = 10
wS =600m wT =600s
c = 5

Datasize = 100000
|Q| = 100

Description

Relative importance of Q-to-T and T-to-Q similarity

Relative importance of spatial and temporal similarity

Top-k similar trajectories of query Q
Spatial-temporal gird width wS × wS × wT
Number of searched grids for each query segment

Number of trajectories in database

Number of line segments in query Q

Geoinformatica

Fig. 5 Subsampling

7.3 Efﬁciency evaluation

7.3.1 Eﬀect of the number of query segments |Q|

First of all, we investigate the effect of the number of query segments on the performance
of the algorithms with the default settings. We implement four algorithms, BF, BF+GI and
BF+GPI and BF+GPI-O.

Intuitively, the longer the query is, the larger the required search space is, and thus,
the queries can be slower. In Fig. 6a and b, the CPU time cost of BF solution increase
rapidly with the increasing number of query segments. When |Q| = 200, we see the best
approach BF+GPI-O is 8.3× and 3.1× faster than baseline approach BF on Shanghai and
New York data set respectively. Due to the sampling rate difference(∼11s/point in Shanghai,
∼109s/point in New York), high sampling rate trajectory database needs more computations
in top-k search. We see that our indexing structures and optimizations are more effective on
high sampling rate trajectory database. In terms of the time cost of refinement, BF has the
least time cost of refinement. BF+GI, BF+GPI and BF+GPI-O have higher time costs of the
refinement due to the grid based estimation of similarity lower/upper bounds. Obviously,
this sacrifice is worth it because the time cost of the top-k search process is 38× and 8.9×
faster than BF over Shanghai and New York data sets, respectively.

7.3.2 Eﬀect of data size

Figure 6c and d presents the performance of the four algorithms with varying data size. Since
more trajectories in database cause more candidates need to be processed. Thus the time cost

Fig. 6 Number of query segments and Data size

Geoinformatica

is expected to be higher for all these algorithms. With 1M trajectories, we find that the best
approach BF+GPI-O is 27× and 7.2× faster than BF on Shanghai and New York data sets,
respectively. Comparing to the effect of |Q|, BF+GPI-O achieves larger improvement on
huge trajectory database. With 1M trajectories, we see that BF+GPI-O is 2.61× and 1.95×
faster than BF+GI on the two data sets, respectively. The query partitioning optimization is
more effective on huge trajectory data set.

7.3.3 Eﬀect of spatial-temporal grid width wS, wT

Next, we study the effect of the spatial-temporal grid width on the performance of our
best algorithm BF+GPI-O. With our spatial-temporal (3D) grid indexing in Section 5, we
define the spatial width of the grid as wS (meters) and the temporal width of the grid as wT
(seconds). Thus, the width of a 3D grid is represented as wS ×wS ×wT . Basically, the larger
wS and wT are, the larger the number of trajectories in a 3D grid is, the larger the number
of candidates is, and thus the larger the refinement cost is. On the other hand, the smaller
wS and wT are, the tighter lower and upper bound is, the larger the number of grids is, and
thus the larger search cost is. The appropriate gird width significantly affects the efficiency
of our top-k framework.

The grid width parameter is usually determined by experiments in different databases
[5]. As shown in Fig. 7a, with increasing both wS and wT , the time cost of different query
length first decrease, then increase. For |Q| = 200, the minimal time cost is located between

Fig. 7 Grid width wS and wT

Geoinformatica

600 and 800, while for |Q| = 25, it locates between 500 and 700. The larger grid width is
relatively more appropriate for long queries. This is because the small grid widths cause too
many grids near the long query to be processed. In Fig. 7b and c, we set the wS = 600m
and wT = 600s respectively to evaluate the effect of wT and wS on top-k search. We find
that the efficiency variation of wS is more effective than wT due to the higher selectivity
of the spatial domain. In Fig. 7d, we see that the best efficiency locates between 500 and
700 of both wS and wT in Shanghai and New York data set. Thus, we set wS = 600m and
wT = 600s by default.

7.3.4 Eﬀect of partitioning

To study the effect of our partition strategy, we compare it with uniform subsampling
and Dauglas Puecker(DP) simplification [27]. Trajectory simplification algorithms select
a subset of points in original trajectories constrained by a maximal deviation or a max-
imal number of selected points. These points can be regarded as a partition for original
trajectory in our framework. Given a subsampling rate sr and a trajectory T , we pick
(cid:18)sr × (|T |)(cid:19) points from T by uniform subsampling and DP algorithm respectively. In
this experiment, the number of sampling points in each tested query trajectory is 100.
sr = 0.02 means we only select the first and last point in a query trajectory as partition
R defined in Section 6. And sr = 1 means the partition R has all original query points
inside.

As shown in Fig. 8a, with increasing subsampling rates from 0.02 to 1, the time cost
of uniform subsampling and DP based partitioning first decrease, then increase. BF+GPI-
O does not require a subsampling rate parameter for partitioning. We see that BF+GPI-O
achieves the lower time cost than the minimum time cost of both uniform subsampling and
DP algorithm based partitioning.

While in the cost model for query partitioning (in Section 6.1), we have a parameter c to
search c grid cells for each original query segment. Figure 8b shows that the performance
becomes stable when c ≥ 5. This is because the trajectory segments in Shanghai (∼ 11s)
and New York(∼ 109s) data sets are usually smaller than the grid cell width (wS = 600m,
wT = 600s). Thus, in the cost model, we only need to search a few grid cells for each
query segment to estimate the search cost and candidate maintenance cost. We set c = 5 by
default in our framework.

Fig. 8 Partition

Geoinformatica

Fig. 9 Connectivity optimization

7.3.5 Eﬀect of connectivity-based optimization

Then we study the effect of the connectivity-based optimization in different areas. Intu-
itively, the denser the trajectories near the query, the more possible top-k results exist in
those trajectories. We randomly select 20 trajectories in the center area, middle area and
suburb of Shanghai respectively. Figure 9a shows that BF+GPI-O has higher improvement
for the queries in the center of the city.

Moreover, for the queries in the center area, we gradually move these queries out of the
center. Figure 9b shows that we obtain less improvement with the increasing distance from
the queries to the center of Shanghai.

8 Conclusion

In this paper, we have studied the trajectory similarity search problem. We proposed a new
trajectory similarity measurement MPS that synchronously combines spatial similarity and
temporal similarity at each matched point pair across two trajectories. We present an off-
line and online framework to address the top-k search problem efficiently. We first use
grid indexing and merging over trajectory database. Then for each query trajectory, we use
cost-based query partitioning algorithm to divide query trajectory into several partitions.
Experimental studies on two real data sets verified the effectiveness and efficiency of our
algorithms.

Acknowledgements This work is partially supported by National Natural Science Foundation of China
(Grant No. 61772371, No. 61972286).

References

1. Zhao K, Musolesi M, Hui P, Rao W, Tarkoma S (2015) Explaining the power-law distribution of human

mobility through transportationmodality decomposition. Sci Pep 5(1):1–7

2. de Berg M, Cheong O, van Kreveld MJ, Overmars MH (2008) Computational geometry: algorithms and

applications, 3rd edn. Springer

3. Das G, Gunopulos D, Mannila H (1997) Finding similar time series. In: PKDD 97, pp 88–100

Geoinformatica

4. Ranu S, Deepak P, Telang AD, Deshpande P, Raghavan S (2015) Indexing and matching trajectories

under inconsistent sampling rates. In: ICDE 2015, pp 999–1010

5. Ta N, Li G, Xie Y, Li C, Hao S, Feng J (2017) Signature-based similarity trajectory join. IEEE Trans

6. Yi B-K, Jagadish HV, Faloutsos C (1998) Efficient retrieval of similar time sequences under time

Knowl Data Eng 29(4):870–883

warping. In: ICDE 1998, pp 201–208

7. Chang J-W, Bista R, Kim Y-C, Kim Y-K (2007) Spatio-temporal similarity measure algorithm for

moving objects on spatial networks. In: ICCSA 2007, pp 1165–1178

8. Shang S, Chen L, Wei Z, Jensen CS, Zheng K, Kalnis P (2017) Trajectory similarity join in spatial

9. Shang S, Chen L, Wei Z, Jensen CS, Zheng K, Kalnis P (2018) Parallel trajectory similarity joins in

networks. PVLDB 10(11):1178–1189

spatial networks. VLDB J, 27(3):395–420

spatial networks. VLDB J 23(3):449–468

trajectories. In: TIME 2008, pp 79–87

2002, pp 673–684

In: SIGMOD 2010, pp 255–266

10. Shang S, Ding R, Zheng K, Jensen CS, Kalnis P, Zhou X (2014) Personalized trajectory matching in

11. Ding H, Trajcevski G, Scheuermann P (2008) Efficient similarity join of large sets of moving object

12. Vlachos M, Gunopulos D, Kollios G (2002) Discovering similar multidimensional trajectories. In: ICDE

13. Chen Z, Shen HT, Zhou X, Yu Z, Xie X (2010) Searching trajectories by locations: an efficiency study.

14. Ding X, Yuan Y, Su L, Wang W, Ai Z, Liu A (2018) Modeling and optimization of image mapper for

snapshot image mapping spectrometer. IEEE Access 6:29344–29352

15. Qi S, Bouros P, Sacharidis D, Mamoulis N (2015) Efficient point-based trajectory search. In: ISSTD,

16. Shang S, Ding R, Bo Y, Xie K, Zheng K, Kalnis P (2012) User oriented trajectory search for trip

2015. Springer, pp 179–196

recommendation. In: EDBT 12, pp 156–167

17. Xie D, Li F, Phillips JM (2017) Distributed trajectory similarity search. PVLDB 10(11):1478–1489
18. Zhao P, Zhao Q, Zhang C, Su G, Qi Z, Rao W (2019) CLEAN: frequent pattern-based trajectory
spatial-temporal compression on road networks. In: 20th IEEE international conference on mobile data
management, MDM 2019, Hong Kong, SAR, China, June 10-13, 2019, pp 605–610

19. Zhao P, Zhao Q, Zhang C, Su G, Qi Z, Rao Wg (2020) CLEAN: frequent pattern-based trajectory

compression and computation on road networks. China Communications

20. Yuan P, Zhao Q, Rao W, Yuan M, Zeng J (2017) Searching k-nearest neighbor trajectories on road

networks. In: ADC 2017, pp 85–97

21. Newson P, Krumm J (2009) Hidden Markov map matching through noise and sparseness. In: ACM-GIS

2009, pp 336–343

2013, pp 230–241

22. Zheng K, Shang S, Yuan NJ, Yi Y (2013) Towards efficient search for activity trajectories. In: ICDE

23. Isaacson E (1988) Numerical recipes: the art of scientific computing (william h. press, brian p. flannery,

saul a. teukolsky, and william t. vetterling). SIAM Rev 30(2):331–332

24. Hjaltason GR, Samet H (1999) Distance browsing in spatial databases. ACM Transon Datab Syst

25. Sadri A, Salim FD, Ren Y (2017) Full trajectory prediction: what will you do the rest of the day? In:

26. Vreeken J, van Leeuwen M, Siebes A (2011) Krimp: mining itemsets that compress. Data Min Knowl

27. Visvalingam M, Whyatt JD (1990) The douglas-peucker algorithm for line simplification: re-evaluation

through visualization. Comput Graph Forum 9(3):213–225

(TODS) 24(2):265–318

UbiComp 17. ACM, pp 189–192

Discov 23(1):169–214

Publisher’s note
and institutional affiliations.

Springer Nature remains neutral with regard to jurisdictional claims in published maps

Geoinformatica

Peng Zhao is now a Ph.D. student at the School of Software
Engineering, Tongji University. He received the B.E. degree from
Tongji University, Shanghai, China, in 2016. His research interests
include the data mining, spatial-temporal data management, mobile
computing.

Weixiong Rao received the BSc and MSc degrees from North (Bei-
jing) Jiaotong University and Shanghai Jiaotong University respec-
tively, and the PhD degree from the Chinese University of Hong Kong
in 2009. After that, he was with the Hong Kong University of Sci-
ence and Technology (2010), University of Helsinki (2011-2012),
and the University of Cambridge Computer Laboratory Systems
Research Group (2013). He is currently with the School of Software
Engineering, Tongji University, China. His research interests include
networked data system and energy-aware mobile computing.

Chengxi Zhang is Professor of Computer Science in School of Soft-
ware Engineering in Tongji University. He graduated from National
University of Defense Technology in 1988. His research interests
include methods and theory in distributed systems, peer-to-peer
network and next generation network. He has written or edited
2 books, including New Generation Computing: Recent Research
(North-Holland Press, 1990) and Research on Frontiers in Computing
(Tsinghua University Press, 1989). He obtained The National Science
Fund for Distinguished Young Scholars in 1996.

Geoinformatica

Gong Su is a Research Staff Member at the IBM T.J. Watson
Research Center in Yorktown, New York. He conducts system related
research on IBM’s zSeries mainframe platform. He received BS
degree in Physics from the University of Science and Technology of
China in 1988, and MS and PhD degrees in Computer Science, both
from Columbia University, in 1997 and 2004, respectively. Dr. Su
is interested in various aspects of systems research with a particular
focus on operating system and networking.

Qi Zhang received Ph.D. from School of Computer Science at Geor-
gia Institute of Technology in 2017, where he worked with Prof. Ling
Liu. Dr. Qi Zhang received his Bachelor of Science and Master of
Science degrees from Department of Computer Science & Technol-
ogy at Huazhong University of Science and Technology in 2009 and
2012, respectively. Dr. Zhang’s research is focused on virtualization
and big data systems.

